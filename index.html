<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=Lx1xfUTR4qFjwg0Z_pb902yWOW57Glq29V3__n4AGA4U98cTH0AXYqBJCjdiQdfw0c_NB-THYsQheuqnlp0ypA);ul.lst-kix_e97rs1rrkyjo-5{list-style-type:none}ul.lst-kix_e97rs1rrkyjo-6{list-style-type:none}ul.lst-kix_e97rs1rrkyjo-7{list-style-type:none}ul.lst-kix_xczac0sw8y6a-1{list-style-type:none}ul.lst-kix_e97rs1rrkyjo-8{list-style-type:none}ul.lst-kix_xczac0sw8y6a-0{list-style-type:none}ul.lst-kix_e97rs1rrkyjo-1{list-style-type:none}ul.lst-kix_e97rs1rrkyjo-2{list-style-type:none}ul.lst-kix_e97rs1rrkyjo-3{list-style-type:none}ul.lst-kix_e97rs1rrkyjo-4{list-style-type:none}.lst-kix_8ylfq8z9iqph-8>li:before{content:"\0025a0   "}.lst-kix_ge70ia1l9j2p-4>li:before{content:"\0025cb   "}.lst-kix_k4lchlqktts-0>li:before{content:"\0025cf   "}.lst-kix_k4lchlqktts-8>li:before{content:"\0025a0   "}.lst-kix_fo3xfsyzwa37-4>li:before{content:"\0025cb   "}.lst-kix_3ppobcpt0okh-6>li:before{content:"\0025cf   "}.lst-kix_jts281wjqw39-7>li:before{content:"\0025cb   "}.lst-kix_8ylfq8z9iqph-4>li:before{content:"\0025cb   "}ol.lst-kix_srupee17v0mb-5.start{counter-reset:lst-ctn-kix_srupee17v0mb-5 0}.lst-kix_thg0lt5umapc-5>li:before{content:"\0025a0   "}.lst-kix_hdamu5z1kajk-0>li:before{content:"-  "}.lst-kix_hdamu5z1kajk-4>li:before{content:"-  "}.lst-kix_vcrwp2bwzubh-6>li:before{content:"\0025cf   "}ul.lst-kix_xczac0sw8y6a-7{list-style-type:none}ul.lst-kix_xczac0sw8y6a-6{list-style-type:none}ul.lst-kix_xczac0sw8y6a-8{list-style-type:none}ul.lst-kix_xczac0sw8y6a-3{list-style-type:none}.lst-kix_ge70ia1l9j2p-8>li:before{content:"\0025a0   "}ul.lst-kix_xczac0sw8y6a-2{list-style-type:none}.lst-kix_x803kyc5p3g4-2>li:before{content:"\0025a0   "}ul.lst-kix_xczac0sw8y6a-5{list-style-type:none}ul.lst-kix_xczac0sw8y6a-4{list-style-type:none}.lst-kix_fo3xfsyzwa37-0>li:before{content:"\0025cf   "}.lst-kix_hdamu5z1kajk-8>li:before{content:"-  "}.lst-kix_vbr74uzbiasm-6>li:before{content:"\0025cf   "}.lst-kix_jts281wjqw39-3>li:before{content:"\0025cf   "}.lst-kix_8ylfq8z9iqph-0>li:before{content:"\0025cf   "}.lst-kix_x803kyc5p3g4-6>li:before{content:"\0025cf   "}.lst-kix_2mr9vgw3av16-5>li:before{content:"\0025a0   "}.lst-kix_d2maxule6lxs-6>li:before{content:"\0025cf   "}.lst-kix_m4siyyggc8wg-7>li:before{content:"\0025cb   "}.lst-kix_3ppobcpt0okh-2>li:before{content:"\0025a0   "}.lst-kix_2mr9vgw3av16-1>li:before{content:"\0025cb   "}.lst-kix_d2maxule6lxs-2>li:before{content:"\0025a0   "}.lst-kix_ge70ia1l9j2p-0>li:before{content:"\0025cf   "}.lst-kix_k4lchlqktts-4>li:before{content:"\0025cb   "}.lst-kix_xgrv9tn3a2rg-6>li:before{content:"\0025cf   "}.lst-kix_xgrv9tn3a2rg-2>li:before{content:"\0025a0   "}.lst-kix_tgfvho118md4-1>li:before{content:"\0025cb   "}.lst-kix_y4vuy41h8k5q-2>li:before{content:"\0025a0   "}.lst-kix_tgfvho118md4-5>li:before{content:"\0025a0   "}ul.lst-kix_53eqpuuodt5v-8{list-style-type:none}ul.lst-kix_53eqpuuodt5v-7{list-style-type:none}.lst-kix_gtofryf4bnby-7>li:before{content:"\0025cb   "}ul.lst-kix_i0yf1mju0g1s-0{list-style-type:none}ul.lst-kix_i0yf1mju0g1s-4{list-style-type:none}ul.lst-kix_i0yf1mju0g1s-3{list-style-type:none}ul.lst-kix_i0yf1mju0g1s-2{list-style-type:none}.lst-kix_vbr74uzbiasm-2>li:before{content:"\0025a0   "}ul.lst-kix_i0yf1mju0g1s-1{list-style-type:none}ul.lst-kix_cfsaqxe055dn-6{list-style-type:none}ul.lst-kix_i0yf1mju0g1s-8{list-style-type:none}ul.lst-kix_cfsaqxe055dn-7{list-style-type:none}ul.lst-kix_i0yf1mju0g1s-7{list-style-type:none}ul.lst-kix_cfsaqxe055dn-4{list-style-type:none}ul.lst-kix_i0yf1mju0g1s-6{list-style-type:none}ul.lst-kix_cfsaqxe055dn-5{list-style-type:none}ul.lst-kix_i0yf1mju0g1s-5{list-style-type:none}ul.lst-kix_cfsaqxe055dn-8{list-style-type:none}.lst-kix_snh8lpyqaleg-1>li:before{content:"\0025cb   "}.lst-kix_gtofryf4bnby-3>li:before{content:"\0025cf   "}ul.lst-kix_cfsaqxe055dn-2{list-style-type:none}ul.lst-kix_rdl0mbsx7m1b-0{list-style-type:none}ul.lst-kix_cfsaqxe055dn-3{list-style-type:none}ul.lst-kix_rdl0mbsx7m1b-1{list-style-type:none}ul.lst-kix_cfsaqxe055dn-0{list-style-type:none}ul.lst-kix_cfsaqxe055dn-1{list-style-type:none}.lst-kix_y4vuy41h8k5q-6>li:before{content:"\0025cf   "}ul.lst-kix_rdl0mbsx7m1b-4{list-style-type:none}ul.lst-kix_rdl0mbsx7m1b-5{list-style-type:none}ul.lst-kix_rdl0mbsx7m1b-2{list-style-type:none}ul.lst-kix_rdl0mbsx7m1b-3{list-style-type:none}ul.lst-kix_rdl0mbsx7m1b-8{list-style-type:none}ul.lst-kix_rdl0mbsx7m1b-6{list-style-type:none}.lst-kix_snh8lpyqaleg-5>li:before{content:"\0025a0   "}ul.lst-kix_rdl0mbsx7m1b-7{list-style-type:none}ul.lst-kix_r20deuqh30jy-5{list-style-type:none}ul.lst-kix_r20deuqh30jy-4{list-style-type:none}ul.lst-kix_r20deuqh30jy-3{list-style-type:none}.lst-kix_b966qb5z56w2-1>li:before{content:"\0025cb   "}ul.lst-kix_r20deuqh30jy-2{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-7{list-style-type:none}ul.lst-kix_yoaj41w0jig0-2{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-6{list-style-type:none}ul.lst-kix_r20deuqh30jy-8{list-style-type:none}ul.lst-kix_yoaj41w0jig0-3{list-style-type:none}ol.lst-kix_tsc2yqmm539t-4.start{counter-reset:lst-ctn-kix_tsc2yqmm539t-4 0}ul.lst-kix_r20deuqh30jy-7{list-style-type:none}ul.lst-kix_yoaj41w0jig0-0{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-8{list-style-type:none}ul.lst-kix_r20deuqh30jy-6{list-style-type:none}ul.lst-kix_yoaj41w0jig0-1{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-3{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-2{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-5{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-4{list-style-type:none}ul.lst-kix_r20deuqh30jy-1{list-style-type:none}ul.lst-kix_r20deuqh30jy-0{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-1{list-style-type:none}ul.lst-kix_ifg2eqszm6qp-0{list-style-type:none}.lst-kix_1oywm8db5jne-0>li:before{content:"\0025cf   "}.lst-kix_1oywm8db5jne-4>li:before{content:"\0025cb   "}.lst-kix_4qgjp0e8yt8m-2>li:before{content:"\0025a0   "}.lst-kix_gxvla3x57ko6-3>li:before{content:"\0025cf   "}.lst-kix_45zyqca0dor3-1>li:before{content:"\0025cb   "}ul.lst-kix_53eqpuuodt5v-4{list-style-type:none}ul.lst-kix_53eqpuuodt5v-3{list-style-type:none}ul.lst-kix_53eqpuuodt5v-6{list-style-type:none}.lst-kix_qkmj4hklqu51-5>li:before{content:"\0025a0   "}ul.lst-kix_53eqpuuodt5v-5{list-style-type:none}ul.lst-kix_53eqpuuodt5v-0{list-style-type:none}ul.lst-kix_7fftgdac6j6-1{list-style-type:none}ul.lst-kix_7fftgdac6j6-2{list-style-type:none}ul.lst-kix_53eqpuuodt5v-2{list-style-type:none}ul.lst-kix_53eqpuuodt5v-1{list-style-type:none}.lst-kix_a130djrb9y6e-1>li:before{content:"\0025cb   "}ul.lst-kix_7fftgdac6j6-0{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-1{list-style-type:none}ul.lst-kix_7fftgdac6j6-5{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-0{list-style-type:none}ul.lst-kix_7fftgdac6j6-6{list-style-type:none}ul.lst-kix_7fftgdac6j6-3{list-style-type:none}ul.lst-kix_7fftgdac6j6-4{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-5{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-4{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-3{list-style-type:none}ul.lst-kix_7fftgdac6j6-7{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-2{list-style-type:none}ul.lst-kix_7fftgdac6j6-8{list-style-type:none}ul.lst-kix_yoaj41w0jig0-6{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-8{list-style-type:none}ul.lst-kix_yoaj41w0jig0-7{list-style-type:none}ul.lst-kix_p6zn1qdl1q6g-7{list-style-type:none}ul.lst-kix_yoaj41w0jig0-4{list-style-type:none}.lst-kix_gxvla3x57ko6-7>li:before{content:"\0025cb   "}.lst-kix_rdl0mbsx7m1b-0>li:before{content:"\0025cf   "}ul.lst-kix_p6zn1qdl1q6g-6{list-style-type:none}ul.lst-kix_yoaj41w0jig0-5{list-style-type:none}ul.lst-kix_yoaj41w0jig0-8{list-style-type:none}.lst-kix_a130djrb9y6e-5>li:before{content:"\0025a0   "}.lst-kix_68nz8s40mnx9-3>li:before{content:"\0025cf   "}.lst-kix_mglb6ei1fc9r-1>li:before{content:"\0025cb   "}.lst-kix_mglb6ei1fc9r-5>li:before{content:"\0025a0   "}.lst-kix_m4siyyggc8wg-3>li:before{content:"\0025cf   "}.lst-kix_8pxi403yy138-6>li:before{content:"\0025cf   "}.lst-kix_lojbu18a3l9-0>li:before{content:"\0025cf   "}.lst-kix_lojbu18a3l9-8>li:before{content:"\0025a0   "}ul.lst-kix_qvmzdr2urb9j-0{list-style-type:none}ul.lst-kix_qyngqrxks4hj-0{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-3{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-4{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-1{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-2{list-style-type:none}.lst-kix_mtdb7jqchtcn-5>li:before{content:"\0025a0   "}ul.lst-kix_qyngqrxks4hj-5{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-7{list-style-type:none}ul.lst-kix_qyngqrxks4hj-6{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-8{list-style-type:none}.lst-kix_bm3nprf82w8o-0>li:before{content:"\0025cf   "}ul.lst-kix_qyngqrxks4hj-7{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-5{list-style-type:none}ul.lst-kix_qyngqrxks4hj-8{list-style-type:none}ul.lst-kix_qvmzdr2urb9j-6{list-style-type:none}ul.lst-kix_qyngqrxks4hj-1{list-style-type:none}.lst-kix_8pxi403yy138-2>li:before{content:"\0025a0   "}.lst-kix_mniaj44rhjrq-8>li:before{content:"\0025a0   "}ul.lst-kix_qyngqrxks4hj-2{list-style-type:none}ul.lst-kix_qyngqrxks4hj-3{list-style-type:none}.lst-kix_lojbu18a3l9-4>li:before{content:"\0025cb   "}ul.lst-kix_qyngqrxks4hj-4{list-style-type:none}.lst-kix_5uwviijqeog0-6>li:before{content:"\0025cf   "}.lst-kix_9io9le2bbu11-0>li:before{content:"\0025cf   "}.lst-kix_1oywm8db5jne-8>li:before{content:"\0025a0   "}.lst-kix_4683th2gmjda-5>li:before{content:"\0025a0   "}.lst-kix_gqz270r7o0q1-6>li:before{content:"\0025cf   "}.lst-kix_mtdb7jqchtcn-1>li:before{content:"\0025cb   "}.lst-kix_5uwviijqeog0-2>li:before{content:"\0025a0   "}ul.lst-kix_2grrmxr8q0i0-0{list-style-type:none}ul.lst-kix_2grrmxr8q0i0-2{list-style-type:none}.lst-kix_mniaj44rhjrq-4>li:before{content:"\0025cb   "}ul.lst-kix_2grrmxr8q0i0-1{list-style-type:none}ol.lst-kix_srupee17v0mb-0.start{counter-reset:lst-ctn-kix_srupee17v0mb-0 0}ul.lst-kix_2grrmxr8q0i0-4{list-style-type:none}ul.lst-kix_2grrmxr8q0i0-3{list-style-type:none}.lst-kix_53eqpuuodt5v-7>li:before{content:"\0025cb   "}ul.lst-kix_2grrmxr8q0i0-6{list-style-type:none}ul.lst-kix_c2b60wgdja8r-5{list-style-type:none}.lst-kix_nd4cj51qmb1k-2>li:before{content:"\0025a0   "}ul.lst-kix_2grrmxr8q0i0-5{list-style-type:none}ul.lst-kix_c2b60wgdja8r-6{list-style-type:none}.lst-kix_9io9le2bbu11-8>li:before{content:"\0025a0   "}ul.lst-kix_2grrmxr8q0i0-8{list-style-type:none}ul.lst-kix_c2b60wgdja8r-7{list-style-type:none}ul.lst-kix_2grrmxr8q0i0-7{list-style-type:none}ul.lst-kix_c2b60wgdja8r-8{list-style-type:none}.lst-kix_4683th2gmjda-1>li:before{content:"\0025cb   "}ul.lst-kix_c2b60wgdja8r-1{list-style-type:none}.lst-kix_gqz270r7o0q1-2>li:before{content:"\0025a0   "}ul.lst-kix_c2b60wgdja8r-2{list-style-type:none}ul.lst-kix_c2b60wgdja8r-3{list-style-type:none}ul.lst-kix_c2b60wgdja8r-4{list-style-type:none}.lst-kix_nd4cj51qmb1k-6>li:before{content:"\0025cf   "}.lst-kix_68nz8s40mnx9-7>li:before{content:"\0025cb   "}.lst-kix_9io9le2bbu11-4>li:before{content:"\0025cb   "}ul.lst-kix_e97rs1rrkyjo-0{list-style-type:none}ul.lst-kix_c2b60wgdja8r-0{list-style-type:none}.lst-kix_thg0lt5umapc-1>li:before{content:"\0025cb   "}.lst-kix_mniaj44rhjrq-0>li:before{content:"\0025cf   "}.lst-kix_53eqpuuodt5v-3>li:before{content:"\0025cf   "}.lst-kix_87g5rwruaqks-7>li:before{content:"\0025cb   "}.lst-kix_c2b60wgdja8r-4>li:before{content:"\0025cb   "}.lst-kix_g4octshi0erf-8>li:before{content:"\0025a0   "}.lst-kix_p0wl0w4s0sa-0>li:before{content:"\0025cf   "}.lst-kix_p0wl0w4s0sa-4>li:before{content:"\0025cb   "}.lst-kix_hvoiym2mrtz4-5>li:before{content:"\0025a0   "}.lst-kix_c2b60wgdja8r-0>li:before{content:"\0025cf   "}.lst-kix_c2b60wgdja8r-8>li:before{content:"\0025a0   "}.lst-kix_g4octshi0erf-4>li:before{content:"\0025cb   "}.lst-kix_az8p3db80uc9-2>li:before{content:"\0025a0   "}.lst-kix_qyngqrxks4hj-3>li:before{content:"\0025cf   "}.lst-kix_rj0mmf4fl3tb-7>li:before{content:"\0025cb   "}.lst-kix_cqp59gjcdgvg-5>li:before{content:"\0025a0   "}ul.lst-kix_srn1fozfk9nn-8{list-style-type:none}.lst-kix_g4octshi0erf-0>li:before{content:"\0025cf   "}ul.lst-kix_srn1fozfk9nn-5{list-style-type:none}ul.lst-kix_srn1fozfk9nn-4{list-style-type:none}ul.lst-kix_srn1fozfk9nn-7{list-style-type:none}ul.lst-kix_srn1fozfk9nn-6{list-style-type:none}ul.lst-kix_srn1fozfk9nn-1{list-style-type:none}ul.lst-kix_srn1fozfk9nn-0{list-style-type:none}ul.lst-kix_srn1fozfk9nn-3{list-style-type:none}ul.lst-kix_srn1fozfk9nn-2{list-style-type:none}.lst-kix_i0yf1mju0g1s-0>li:before{content:"\0025cf   "}.lst-kix_az8p3db80uc9-6>li:before{content:"\0025cf   "}.lst-kix_qyngqrxks4hj-7>li:before{content:"\0025cb   "}.lst-kix_c6t6pz4sgcyt-1>li:before{content:"\0025cb   "}.lst-kix_ifg2eqszm6qp-7>li:before{content:"\0025cb   "}.lst-kix_7noh502jhq1p-5>li:before{content:"\0025a0   "}.lst-kix_bpsai7a4nzlw-2>li:before{content:"\0025a0   "}.lst-kix_h55j0o7g1asr-6>li:before{content:"\0025cf   "}ul.lst-kix_f539m7fvzj9k-8{list-style-type:none}ul.lst-kix_f539m7fvzj9k-7{list-style-type:none}ul.lst-kix_f539m7fvzj9k-6{list-style-type:none}ul.lst-kix_f539m7fvzj9k-5{list-style-type:none}ul.lst-kix_f539m7fvzj9k-4{list-style-type:none}.lst-kix_4j92pbqgy1h-0>li:before{content:"\0025cf   "}ul.lst-kix_f539m7fvzj9k-3{list-style-type:none}.lst-kix_f539m7fvzj9k-1>li:before{content:"\0025cb   "}ul.lst-kix_f539m7fvzj9k-2{list-style-type:none}ul.lst-kix_f539m7fvzj9k-1{list-style-type:none}.lst-kix_dii13kfyl9ma-0>li:before{content:"\0025cf   "}.lst-kix_dii13kfyl9ma-8>li:before{content:"\0025a0   "}.lst-kix_mn5hganrvuk0-8>li:before{content:"\0025a0   "}ul.lst-kix_f539m7fvzj9k-0{list-style-type:none}ul.lst-kix_codfi3rttsmj-8{list-style-type:none}.lst-kix_hvoiym2mrtz4-1>li:before{content:"\0025cf   "}ul.lst-kix_codfi3rttsmj-7{list-style-type:none}.lst-kix_bo1j5nej66rh-2>li:before{content:"-  "}ul.lst-kix_codfi3rttsmj-4{list-style-type:none}.lst-kix_h55j0o7g1asr-2>li:before{content:"\0025a0   "}ul.lst-kix_codfi3rttsmj-3{list-style-type:none}ul.lst-kix_codfi3rttsmj-6{list-style-type:none}ul.lst-kix_codfi3rttsmj-5{list-style-type:none}ul.lst-kix_codfi3rttsmj-0{list-style-type:none}ul.lst-kix_codfi3rttsmj-2{list-style-type:none}.lst-kix_bpsai7a4nzlw-6>li:before{content:"\0025cf   "}ul.lst-kix_codfi3rttsmj-1{list-style-type:none}.lst-kix_4j92pbqgy1h-4>li:before{content:"\0025cb   "}.lst-kix_rj0mmf4fl3tb-3>li:before{content:"\0025cf   "}.lst-kix_f539m7fvzj9k-5>li:before{content:"\0025a0   "}.lst-kix_cqp59gjcdgvg-1>li:before{content:"\0025cb   "}.lst-kix_dii13kfyl9ma-4>li:before{content:"\0025cb   "}.lst-kix_qx6x5q8dhn22-1>li:before{content:"\0025cb   "}.lst-kix_gc3eht6946jv-5>li:before{content:"\0025a0   "}.lst-kix_podkn7p9liyz-0>li:before{content:"\0025cf   "}.lst-kix_codfi3rttsmj-8>li:before{content:"\0025a0   "}.lst-kix_45gqldd6ykix-3>li:before{content:"\0025cf   "}.lst-kix_j9krs4wwadz8-6>li:before{content:"\0025cf   "}.lst-kix_mn5hganrvuk0-0>li:before{content:"\0025cf   "}.lst-kix_podkn7p9liyz-8>li:before{content:"\0025a0   "}.lst-kix_qx6x5q8dhn22-5>li:before{content:"\0025a0   "}.lst-kix_podkn7p9liyz-4>li:before{content:"\0025cb   "}.lst-kix_bo1j5nej66rh-6>li:before{content:"-  "}.lst-kix_45gqldd6ykix-7>li:before{content:"\0025cb   "}.lst-kix_4wi60e30t59b-7>li:before{content:"\0025cb   "}.lst-kix_mn5hganrvuk0-4>li:before{content:"\0025cb   "}.lst-kix_45zyqca0dor3-5>li:before{content:"\0025a0   "}ul.lst-kix_9x4yq5ss9tc1-8{list-style-type:none}.lst-kix_qkmj4hklqu51-1>li:before{content:"\0025cb   "}.lst-kix_vexpnyyatkbq-6>li:before{content:"\0025cf   "}.lst-kix_7noh502jhq1p-1>li:before{content:"\0025cb   "}ul.lst-kix_9x4yq5ss9tc1-1{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-8{list-style-type:none}ul.lst-kix_9x4yq5ss9tc1-0{list-style-type:none}.lst-kix_codfi3rttsmj-0>li:before{content:"\0025cf   "}ul.lst-kix_9x4yq5ss9tc1-3{list-style-type:none}ul.lst-kix_9x4yq5ss9tc1-2{list-style-type:none}.lst-kix_i0yf1mju0g1s-4>li:before{content:"\0025cb   "}ul.lst-kix_9x4yq5ss9tc1-5{list-style-type:none}ul.lst-kix_9x4yq5ss9tc1-4{list-style-type:none}.lst-kix_c6t6pz4sgcyt-5>li:before{content:"\0025a0   "}ul.lst-kix_9x4yq5ss9tc1-7{list-style-type:none}.lst-kix_ey106e39uxys-2>li:before{content:"\0025a0   "}ul.lst-kix_9x4yq5ss9tc1-6{list-style-type:none}.lst-kix_dg9rb9temrvk-0>li:before{content:"\0025cf   "}.lst-kix_dg9rb9temrvk-8>li:before{content:"\0025a0   "}ul.lst-kix_c4mjpxs5t8z-7{list-style-type:none}ul.lst-kix_8pxi403yy138-5{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-0{list-style-type:none}ul.lst-kix_c4mjpxs5t8z-8{list-style-type:none}.lst-kix_codfi3rttsmj-4>li:before{content:"\0025cb   "}ul.lst-kix_8pxi403yy138-6{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-1{list-style-type:none}ul.lst-kix_8pxi403yy138-7{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-2{list-style-type:none}.lst-kix_dav1jecmp52o-2>li:before{content:"\0025a0   "}ul.lst-kix_8pxi403yy138-8{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-3{list-style-type:none}ul.lst-kix_c4mjpxs5t8z-3{list-style-type:none}ul.lst-kix_8pxi403yy138-1{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-4{list-style-type:none}ul.lst-kix_c4mjpxs5t8z-4{list-style-type:none}.lst-kix_vexpnyyatkbq-2>li:before{content:"\0025a0   "}ul.lst-kix_8pxi403yy138-2{list-style-type:none}.lst-kix_p0wl0w4s0sa-8>li:before{content:"\0025a0   "}ul.lst-kix_9l9kjglfjgjz-5{list-style-type:none}ul.lst-kix_c4mjpxs5t8z-5{list-style-type:none}ul.lst-kix_8pxi403yy138-3{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-6{list-style-type:none}ul.lst-kix_c4mjpxs5t8z-6{list-style-type:none}ul.lst-kix_8pxi403yy138-4{list-style-type:none}ul.lst-kix_9l9kjglfjgjz-7{list-style-type:none}ul.lst-kix_c4mjpxs5t8z-0{list-style-type:none}ul.lst-kix_c4mjpxs5t8z-1{list-style-type:none}.lst-kix_dav1jecmp52o-6>li:before{content:"\0025cf   "}ul.lst-kix_c4mjpxs5t8z-2{list-style-type:none}.lst-kix_b966qb5z56w2-5>li:before{content:"\0025a0   "}ul.lst-kix_8pxi403yy138-0{list-style-type:none}.lst-kix_i0yf1mju0g1s-8>li:before{content:"\0025a0   "}.lst-kix_dg9rb9temrvk-4>li:before{content:"\0025cb   "}.lst-kix_6jxu4l7p3d4o-8>li:before{content:"\0025a0   "}.lst-kix_qymwuf8ggtk1-0>li:before{content:"\0025cf   "}.lst-kix_xczac0sw8y6a-5>li:before{content:"\0025a0   "}.lst-kix_h00g16e7ufft-8>li:before{content:"\0025a0   "}.lst-kix_6omq6vtmahws-3>li:before{content:"\0025cf   "}.lst-kix_xclf8ew5xwnq-2>li:before{content:"\0025a0   "}ul.lst-kix_fvsyn7dqkka1-0{list-style-type:none}ul.lst-kix_fvsyn7dqkka1-1{list-style-type:none}ul.lst-kix_fvsyn7dqkka1-2{list-style-type:none}.lst-kix_6jxu4l7p3d4o-0>li:before{content:"  "}ul.lst-kix_fvsyn7dqkka1-3{list-style-type:none}ul.lst-kix_fvsyn7dqkka1-4{list-style-type:none}.lst-kix_8qeqm584pmza-0>li:before{content:"\0025cf   "}.lst-kix_7mi52l6y9ptp-0>li:before{content:"\0025cf   "}.lst-kix_ey106e39uxys-6>li:before{content:"\0025cf   "}.lst-kix_v38knoi1xqwy-1>li:before{content:"-  "}.lst-kix_qor9p1a81vaf-7>li:before{content:"\0025cb   "}.lst-kix_qymwuf8ggtk1-8>li:before{content:"\0025a0   "}.lst-kix_5ov7bblzaw0u-5>li:before{content:"\0025a0   "}.lst-kix_7mi52l6y9ptp-4>li:before{content:"\0025cb   "}.lst-kix_h00g16e7ufft-0>li:before{content:"\0025cf   "}.lst-kix_yvj42sc4s1lo-5>li:before{content:"\0025a0   "}.lst-kix_qymwuf8ggtk1-4>li:before{content:"\0025cb   "}.lst-kix_8qeqm584pmza-4>li:before{content:"\0025cb   "}.lst-kix_5ov7bblzaw0u-1>li:before{content:"\0025cb   "}.lst-kix_qor9p1a81vaf-3>li:before{content:"\0025cf   "}.lst-kix_v38knoi1xqwy-5>li:before{content:"-  "}.lst-kix_6omq6vtmahws-7>li:before{content:"\0025cb   "}.lst-kix_tclc6bzuyhm-8>li:before{content:"\0025a0   "}.lst-kix_8qeqm584pmza-8>li:before{content:"\0025a0   "}.lst-kix_4cx6uiey4qy0-5>li:before{content:"\0025a0   "}.lst-kix_7mi52l6y9ptp-8>li:before{content:"\0025a0   "}.lst-kix_h00g16e7ufft-4>li:before{content:"\0025cb   "}.lst-kix_cpaf1rpc28c-2>li:before{content:"\0025a0   "}.lst-kix_sf1qf9bwyojp-8>li:before{content:"\0025a0   "}.lst-kix_4j92pbqgy1h-8>li:before{content:"\0025a0   "}.lst-kix_1l36jc1oov6-1>li:before{content:"\0025cb   "}.lst-kix_srupee17v0mb-7>li{counter-increment:lst-ctn-kix_srupee17v0mb-7}.lst-kix_4cx6uiey4qy0-1>li:before{content:"\0025cb   "}.lst-kix_tclc6bzuyhm-4>li:before{content:"\0025cb   "}.lst-kix_evcxr39uk36z-2>li:before{content:"\0025a0   "}ul.lst-kix_npq7lfz9ly6z-8{list-style-type:none}ul.lst-kix_npq7lfz9ly6z-7{list-style-type:none}.lst-kix_cpaf1rpc28c-6>li:before{content:"\0025cf   "}.lst-kix_yvj42sc4s1lo-1>li:before{content:"\0025cb   "}ul.lst-kix_npq7lfz9ly6z-4{list-style-type:none}ul.lst-kix_3ppobcpt0okh-1{list-style-type:none}ul.lst-kix_npq7lfz9ly6z-3{list-style-type:none}ul.lst-kix_3ppobcpt0okh-0{list-style-type:none}.lst-kix_tclc6bzuyhm-0>li:before{content:"\0025cf   "}ul.lst-kix_npq7lfz9ly6z-6{list-style-type:none}ul.lst-kix_3ppobcpt0okh-3{list-style-type:none}ul.lst-kix_npq7lfz9ly6z-5{list-style-type:none}.lst-kix_evcxr39uk36z-6>li:before{content:"\0025cf   "}ul.lst-kix_3ppobcpt0okh-2{list-style-type:none}ul.lst-kix_npq7lfz9ly6z-0{list-style-type:none}.lst-kix_1l36jc1oov6-5>li:before{content:"\0025a0   "}ul.lst-kix_npq7lfz9ly6z-2{list-style-type:none}.lst-kix_hc4vnvmn7si1-5>li:before{content:"\0025a0   "}ul.lst-kix_npq7lfz9ly6z-1{list-style-type:none}.lst-kix_efwsvsniz58g-6>li:before{content:"\0025cf   "}ul.lst-kix_3ppobcpt0okh-8{list-style-type:none}.lst-kix_3mbe6pf0vyok-1>li:before{content:"\0025cb   "}.lst-kix_eqjgku92ysne-2>li:before{content:"\0025a0   "}.lst-kix_eqjgku92ysne-6>li:before{content:"\0025cf   "}ul.lst-kix_3ppobcpt0okh-5{list-style-type:none}.lst-kix_yvkwax5bonzj-2>li:before{content:"\0025a0   "}.lst-kix_yvkwax5bonzj-6>li:before{content:"\0025cf   "}ul.lst-kix_3ppobcpt0okh-4{list-style-type:none}ul.lst-kix_3ppobcpt0okh-7{list-style-type:none}ul.lst-kix_3ppobcpt0okh-6{list-style-type:none}ul.lst-kix_fvsyn7dqkka1-5{list-style-type:none}ul.lst-kix_fvsyn7dqkka1-6{list-style-type:none}.lst-kix_xclf8ew5xwnq-6>li:before{content:"\0025cf   "}ul.lst-kix_fvsyn7dqkka1-7{list-style-type:none}ul.lst-kix_fvsyn7dqkka1-8{list-style-type:none}.lst-kix_3mbe6pf0vyok-5>li:before{content:"\0025a0   "}.lst-kix_sf1qf9bwyojp-0>li:before{content:"\0025cf   "}.lst-kix_ifg2eqszm6qp-3>li:before{content:"\0025cf   "}.lst-kix_vcrwp2bwzubh-2>li:before{content:"\0025a0   "}.lst-kix_6jxu4l7p3d4o-4>li:before{content:"\0025cb   "}.lst-kix_wdnsgpew1acl-1>li:before{content:"\0025cb   "}.lst-kix_wdnsgpew1acl-5>li:before{content:"\0025a0   "}.lst-kix_87g5rwruaqks-3>li:before{content:"\0025cf   "}.lst-kix_efwsvsniz58g-2>li:before{content:"\0025a0   "}.lst-kix_sf1qf9bwyojp-4>li:before{content:"\0025cb   "}.lst-kix_xczac0sw8y6a-1>li:before{content:"\0025cb   "}.lst-kix_fo3xfsyzwa37-8>li:before{content:"\0025a0   "}.lst-kix_2ze49x6dwuyc-3>li:before{content:"\0025cf   "}.lst-kix_r953kfpy79kt-4>li:before{content:"\0025cb   "}.lst-kix_mlex94wk5tq-4>li:before{content:"\0025cb   "}ul.lst-kix_tzrck1qfmyqd-7{list-style-type:none}ul.lst-kix_69pm6toa84wm-0{list-style-type:none}ul.lst-kix_tzrck1qfmyqd-6{list-style-type:none}ul.lst-kix_69pm6toa84wm-1{list-style-type:none}.lst-kix_gzy546en7hix-0>li:before{content:"\0025cf   "}ul.lst-kix_tzrck1qfmyqd-5{list-style-type:none}ul.lst-kix_69pm6toa84wm-2{list-style-type:none}ul.lst-kix_tzrck1qfmyqd-4{list-style-type:none}ul.lst-kix_69pm6toa84wm-3{list-style-type:none}.lst-kix_up6yrorns79d-6>li:before{content:"\0025cf   "}ul.lst-kix_tzrck1qfmyqd-3{list-style-type:none}ul.lst-kix_69pm6toa84wm-4{list-style-type:none}ul.lst-kix_tzrck1qfmyqd-2{list-style-type:none}ul.lst-kix_69pm6toa84wm-5{list-style-type:none}ul.lst-kix_tzrck1qfmyqd-1{list-style-type:none}ul.lst-kix_69pm6toa84wm-6{list-style-type:none}ul.lst-kix_tzrck1qfmyqd-0{list-style-type:none}ul.lst-kix_69pm6toa84wm-7{list-style-type:none}ul.lst-kix_69pm6toa84wm-8{list-style-type:none}.lst-kix_z0m8tzh04abu-6>li:before{content:"\0025cf   "}.lst-kix_thjul0jak92m-1>li:before{content:"\0025cb   "}.lst-kix_qy2pejxz7e1k-5>li:before{content:"\0025a0   "}ul.lst-kix_tzrck1qfmyqd-8{list-style-type:none}ul.lst-kix_pfk02alca94e-6{list-style-type:none}ul.lst-kix_pfk02alca94e-5{list-style-type:none}ul.lst-kix_pfk02alca94e-4{list-style-type:none}ul.lst-kix_pfk02alca94e-3{list-style-type:none}ul.lst-kix_pfk02alca94e-2{list-style-type:none}.lst-kix_bbzhpmijr633-5>li:before{content:"\0025a0   "}.lst-kix_p6zn1qdl1q6g-3>li:before{content:"\0025cf   "}ul.lst-kix_pfk02alca94e-1{list-style-type:none}ul.lst-kix_pfk02alca94e-0{list-style-type:none}.lst-kix_tx52nn14y93q-3>li:before{content:"\0025cf   "}.lst-kix_bhoq2060wyww-5>li:before{content:"\0025a0   "}.lst-kix_asvfnufot7md-6>li:before{content:"\0025cf   "}ul.lst-kix_pfk02alca94e-8{list-style-type:none}ul.lst-kix_pfk02alca94e-7{list-style-type:none}.lst-kix_men9lw1a0mnk-2>li:before{content:"\0025a0   "}.lst-kix_m5vzryjtrruz-4>li:before{content:"\0025cb   "}.lst-kix_scp6tbbd2fcq-3>li:before{content:"\0025cf   "}.lst-kix_a0n7j7tvxmqv-5>li:before{content:"\0025a0   "}ul.lst-kix_3jdd6arud0e0-2{list-style-type:none}ul.lst-kix_3jdd6arud0e0-1{list-style-type:none}ul.lst-kix_3jdd6arud0e0-4{list-style-type:none}.lst-kix_93x7l69l06zp-1>li:before{content:"\0025cb   "}ul.lst-kix_3jdd6arud0e0-3{list-style-type:none}.lst-kix_s0kih9e12ax-7>li:before{content:"\0025cb   "}.lst-kix_zhnrfbqi7c3p-3>li:before{content:"\0025cf   "}ul.lst-kix_3jdd6arud0e0-0{list-style-type:none}.lst-kix_srupee17v0mb-0>li{counter-increment:lst-ctn-kix_srupee17v0mb-0}.lst-kix_npq7lfz9ly6z-5>li:before{content:"\0025a0   "}.lst-kix_fum98hryzqm2-2>li:before{content:"\0025a0   "}.lst-kix_ktcl1r9scb7w-6>li:before{content:"\0025cf   "}.lst-kix_e97rs1rrkyjo-4>li:before{content:"\0025cb   "}.lst-kix_hugw2gsg69de-2>li:before{content:"\0025a0   "}.lst-kix_4gu29fysjsb-5>li:before{content:"\0025a0   "}.lst-kix_gzy546en7hix-8>li:before{content:"\0025a0   "}.lst-kix_by7qhqpvs1r5-7>li:before{content:"\0025cb   "}ul.lst-kix_fum98hryzqm2-8{list-style-type:none}.lst-kix_91x2wdjlgwp1-6>li:before{content:"\0025cf   "}ul.lst-kix_fum98hryzqm2-7{list-style-type:none}ul.lst-kix_fum98hryzqm2-6{list-style-type:none}ul.lst-kix_3jdd6arud0e0-6{list-style-type:none}ul.lst-kix_fum98hryzqm2-5{list-style-type:none}ul.lst-kix_3jdd6arud0e0-5{list-style-type:none}ul.lst-kix_fum98hryzqm2-4{list-style-type:none}ul.lst-kix_3jdd6arud0e0-8{list-style-type:none}ul.lst-kix_fum98hryzqm2-3{list-style-type:none}ul.lst-kix_3jdd6arud0e0-7{list-style-type:none}ul.lst-kix_ya0b59jf88o6-6{list-style-type:none}ul.lst-kix_fum98hryzqm2-2{list-style-type:none}ul.lst-kix_ya0b59jf88o6-7{list-style-type:none}ul.lst-kix_fum98hryzqm2-1{list-style-type:none}ul.lst-kix_ya0b59jf88o6-4{list-style-type:none}ul.lst-kix_fum98hryzqm2-0{list-style-type:none}ul.lst-kix_ya0b59jf88o6-5{list-style-type:none}.lst-kix_wwus9q4jjlww-3>li:before{content:"\0025cf   "}.lst-kix_tsc2yqmm539t-3>li{counter-increment:lst-ctn-kix_tsc2yqmm539t-3}ul.lst-kix_ya0b59jf88o6-2{list-style-type:none}ul.lst-kix_ya0b59jf88o6-3{list-style-type:none}.lst-kix_47wl9llpry5i-5>li:before{content:"\0025a0   "}ul.lst-kix_ya0b59jf88o6-0{list-style-type:none}ul.lst-kix_ya0b59jf88o6-1{list-style-type:none}.lst-kix_5l7scb4zq2ts-2>li:before{content:"\0025a0   "}.lst-kix_5chsivk2mkzi-6>li:before{content:"\0025cf   "}ul.lst-kix_ya0b59jf88o6-8{list-style-type:none}ul.lst-kix_9czq3plvi9ig-6{list-style-type:none}ul.lst-kix_9ynuh6dd4pus-4{list-style-type:none}ul.lst-kix_9czq3plvi9ig-5{list-style-type:none}ul.lst-kix_9ynuh6dd4pus-5{list-style-type:none}ul.lst-kix_9czq3plvi9ig-4{list-style-type:none}ul.lst-kix_9ynuh6dd4pus-2{list-style-type:none}ul.lst-kix_9czq3plvi9ig-3{list-style-type:none}ul.lst-kix_9ynuh6dd4pus-3{list-style-type:none}ul.lst-kix_9ynuh6dd4pus-8{list-style-type:none}ul.lst-kix_9czq3plvi9ig-8{list-style-type:none}ul.lst-kix_9ynuh6dd4pus-6{list-style-type:none}ul.lst-kix_9czq3plvi9ig-7{list-style-type:none}.lst-kix_kfuatcy312kx-3>li:before{content:"\0025cf   "}ul.lst-kix_9ynuh6dd4pus-7{list-style-type:none}ul.lst-kix_9czq3plvi9ig-2{list-style-type:none}ul.lst-kix_9czq3plvi9ig-1{list-style-type:none}ul.lst-kix_9czq3plvi9ig-0{list-style-type:none}.lst-kix_o4w8hr2p0ha-0>li:before{content:"\0025cf   "}.lst-kix_r20deuqh30jy-7>li:before{content:"\0025cb   "}.lst-kix_dk6ingbu8z4-4>li:before{content:"\0025cb   "}.lst-kix_lf7onj2nrr7v-6>li:before{content:"\0025cf   "}.lst-kix_xlixir5f8ikv-2>li:before{content:"\0025a0   "}.lst-kix_t7dbdae30u9t-4>li:before{content:"\0025cb   "}.lst-kix_fvsyn7dqkka1-7>li:before{content:"\0025cb   "}.lst-kix_srupee17v0mb-3>li{counter-increment:lst-ctn-kix_srupee17v0mb-3}ul.lst-kix_9ynuh6dd4pus-0{list-style-type:none}ul.lst-kix_9ynuh6dd4pus-1{list-style-type:none}.lst-kix_8qkhix9sdgh8-8>li:before{content:"\0025a0   "}.lst-kix_l2qc0wi8rc8e-7>li:before{content:"\0025cb   "}.lst-kix_o7qc3ia828r4-1>li:before{content:"\0025cb   "}.lst-kix_izsd5g4fgpc-8>li:before{content:"\0025a0   "}ul.lst-kix_vwxe3fdqgja8-0{list-style-type:none}.lst-kix_o4w8hr2p0ha-8>li:before{content:"\0025a0   "}ul.lst-kix_vwxe3fdqgja8-5{list-style-type:none}ul.lst-kix_vwxe3fdqgja8-6{list-style-type:none}ul.lst-kix_vwxe3fdqgja8-7{list-style-type:none}ul.lst-kix_vwxe3fdqgja8-8{list-style-type:none}.lst-kix_hcwipu97fgnf-5>li:before{content:"\0025a0   "}ul.lst-kix_vwxe3fdqgja8-1{list-style-type:none}ul.lst-kix_vwxe3fdqgja8-2{list-style-type:none}ul.lst-kix_vwxe3fdqgja8-3{list-style-type:none}ul.lst-kix_vwxe3fdqgja8-4{list-style-type:none}.lst-kix_l5sge8zce4vp-4>li:before{content:"\0025cb   "}.lst-kix_yk9rpx5uikpv-6>li:before{content:"\0025cf   "}.lst-kix_ya0b59jf88o6-1>li:before{content:"\0025cb   "}.lst-kix_yeuz6sv2qnho-4>li:before{content:"\0025cb   "}.lst-kix_8qkhix9sdgh8-0>li:before{content:"\0025cf   "}.lst-kix_9x4yq5ss9tc1-7>li:before{content:"\0025cb   "}ul.lst-kix_u6oawcl4nq58-7{list-style-type:none}.lst-kix_3uimjn60qjnx-5>li:before{content:"\0025a0   "}.lst-kix_3jdd6arud0e0-3>li:before{content:"\0025cf   "}ul.lst-kix_u6oawcl4nq58-6{list-style-type:none}.lst-kix_r2llq4i0x498-1>li:before{content:"\0025cb   "}ul.lst-kix_u6oawcl4nq58-5{list-style-type:none}.lst-kix_8979tijdi163-0>li:before{content:"\0025cf   "}ul.lst-kix_u6oawcl4nq58-4{list-style-type:none}.lst-kix_pwl0pufgh6dv-1>li:before{content:"\0025cb   "}.lst-kix_idsnzgd8q5di-3>li:before{content:"\0025cf   "}.lst-kix_fktfq9ltsq98-2>li:before{content:"-  "}ul.lst-kix_u6oawcl4nq58-8{list-style-type:none}.lst-kix_4u8tsqm7y9op-1>li:before{content:"\0025cb   "}ul.lst-kix_a0n7j7tvxmqv-1{list-style-type:none}ul.lst-kix_a0n7j7tvxmqv-0{list-style-type:none}ul.lst-kix_a0n7j7tvxmqv-3{list-style-type:none}.lst-kix_8979tijdi163-8>li:before{content:"\0025a0   "}ul.lst-kix_a0n7j7tvxmqv-2{list-style-type:none}.lst-kix_mo5grncnzemi-7>li:before{content:"\0025cb   "}ul.lst-kix_a0n7j7tvxmqv-5{list-style-type:none}ul.lst-kix_a0n7j7tvxmqv-4{list-style-type:none}ul.lst-kix_a0n7j7tvxmqv-7{list-style-type:none}ul.lst-kix_a0n7j7tvxmqv-6{list-style-type:none}.lst-kix_pfidrtjb5lqv-8>li:before{content:"\0025a0   "}.lst-kix_apk8f490x7qb-5>li:before{content:"\0025a0   "}ul.lst-kix_a0n7j7tvxmqv-8{list-style-type:none}.lst-kix_e3cxiuksdiku-0>li:before{content:"\0025cf   "}ul.lst-kix_u6oawcl4nq58-3{list-style-type:none}ul.lst-kix_u6oawcl4nq58-2{list-style-type:none}.lst-kix_eh7lncq6en9i-1>li:before{content:"\0025cb   "}ul.lst-kix_u6oawcl4nq58-1{list-style-type:none}ul.lst-kix_u6oawcl4nq58-0{list-style-type:none}.lst-kix_kw4p74ijjapz-6>li:before{content:"\0025cf   "}.lst-kix_8l5du8p17xdg-2>li:before{content:"\0025a0   "}.lst-kix_oofi1dgq0nej-3>li:before{content:"\0025cf   "}.lst-kix_pfidrtjb5lqv-0>li:before{content:"\0025cf   "}.lst-kix_nn0h438aq2o5-3>li:before{content:"\0025cf   "}.lst-kix_kizzdizga4v0-4>li:before{content:"\0025cb   "}.lst-kix_w1xl8yxhafp5-7>li:before{content:"\0025cb   "}.lst-kix_izsd5g4fgpc-0>li:before{content:"\0025cf   "}.lst-kix_7fftgdac6j6-7>li:before{content:"\0025cb   "}.lst-kix_zcy565gabcmu-5>li:before{content:"\0025a0   "}.lst-kix_e3cxiuksdiku-8>li:before{content:"\0025a0   "}.lst-kix_z4v6nrp70nz7-1>li:before{content:"\0025cb   "}.lst-kix_pvyv30yiwv0n-2>li:before{content:"\0025a0   "}.lst-kix_4o6376uieeve-5>li:before{content:"\0025a0   "}.lst-kix_ek5wwvmsnqx1-4>li:before{content:"\0025cb   "}.lst-kix_5fltblknzo3j-0>li:before{content:"  "}.lst-kix_6zz37ot1aoo-3>li:before{content:"\0025cf   "}ul.lst-kix_xsdedfcj27fz-0{list-style-type:none}ul.lst-kix_xsdedfcj27fz-1{list-style-type:none}ul.lst-kix_xsdedfcj27fz-2{list-style-type:none}ul.lst-kix_1bifduglsyp2-0{list-style-type:none}ul.lst-kix_1bifduglsyp2-4{list-style-type:none}ul.lst-kix_1bifduglsyp2-3{list-style-type:none}ul.lst-kix_j8606buix1qi-8{list-style-type:none}ul.lst-kix_1bifduglsyp2-2{list-style-type:none}ul.lst-kix_1bifduglsyp2-1{list-style-type:none}ul.lst-kix_1bifduglsyp2-8{list-style-type:none}.lst-kix_wsfytj8n987p-4>li:before{content:"\0025cb   "}ul.lst-kix_1bifduglsyp2-7{list-style-type:none}.lst-kix_w9krzpl9jsp-1>li:before{content:"\0025cb   "}ul.lst-kix_1bifduglsyp2-6{list-style-type:none}ul.lst-kix_1bifduglsyp2-5{list-style-type:none}.lst-kix_5fltblknzo3j-8>li:before{content:"\0025a0   "}.lst-kix_1m661ata3am9-3>li:before{content:"\0025cf   "}.lst-kix_gxbfiekgqjd6-0>li:before{content:"\0025cf   "}ul.lst-kix_eqjgku92ysne-8{list-style-type:none}ul.lst-kix_eqjgku92ysne-7{list-style-type:none}ul.lst-kix_eqjgku92ysne-6{list-style-type:none}ul.lst-kix_eqjgku92ysne-5{list-style-type:none}.lst-kix_3iyql9jafv7n-2>li:before{content:"\0025a0   "}ul.lst-kix_eqjgku92ysne-4{list-style-type:none}.lst-kix_zdgpaglha5wb-2>li:before{content:"\0025a0   "}ul.lst-kix_eqjgku92ysne-3{list-style-type:none}.lst-kix_1bifduglsyp2-0>li:before{content:"\0025cf   "}ul.lst-kix_eqjgku92ysne-2{list-style-type:none}.lst-kix_bm3nprf82w8o-4>li:before{content:"\0025cb   "}ul.lst-kix_eqjgku92ysne-1{list-style-type:none}ul.lst-kix_eqjgku92ysne-0{list-style-type:none}.lst-kix_1k1th764da5j-1>li:before{content:"\0025cb   "}ul.lst-kix_gl7fpz1y51y1-1{list-style-type:none}ul.lst-kix_gl7fpz1y51y1-2{list-style-type:none}.lst-kix_3cigoxtebeue-7>li:before{content:"\0025cb   "}ul.lst-kix_gl7fpz1y51y1-0{list-style-type:none}.lst-kix_9vnfdb4co7p6-5>li:before{content:"\0025a0   "}ul.lst-kix_gl7fpz1y51y1-5{list-style-type:none}ul.lst-kix_gl7fpz1y51y1-6{list-style-type:none}.lst-kix_d74axqjz5yj6-5>li:before{content:"\0025a0   "}ul.lst-kix_gl7fpz1y51y1-3{list-style-type:none}ul.lst-kix_gl7fpz1y51y1-4{list-style-type:none}ul.lst-kix_kfa6jji21f4h-8{list-style-type:none}ul.lst-kix_kfa6jji21f4h-7{list-style-type:none}ul.lst-kix_kfa6jji21f4h-2{list-style-type:none}.lst-kix_6m7znixdz235-4>li:before{content:"\0025cb   "}.lst-kix_gxbfiekgqjd6-8>li:before{content:"\0025a0   "}ul.lst-kix_9cjyjkedxdni-1{list-style-type:none}ul.lst-kix_xsdedfcj27fz-3{list-style-type:none}ul.lst-kix_kfa6jji21f4h-1{list-style-type:none}ul.lst-kix_9cjyjkedxdni-2{list-style-type:none}ul.lst-kix_xsdedfcj27fz-4{list-style-type:none}ul.lst-kix_kfa6jji21f4h-0{list-style-type:none}ul.lst-kix_9cjyjkedxdni-3{list-style-type:none}ul.lst-kix_xsdedfcj27fz-5{list-style-type:none}ul.lst-kix_9cjyjkedxdni-4{list-style-type:none}ul.lst-kix_xsdedfcj27fz-6{list-style-type:none}ul.lst-kix_kfa6jji21f4h-6{list-style-type:none}ul.lst-kix_9cjyjkedxdni-5{list-style-type:none}ul.lst-kix_xsdedfcj27fz-7{list-style-type:none}.lst-kix_dmlj8k237tx2-5>li:before{content:"\0025a0   "}ul.lst-kix_kfa6jji21f4h-5{list-style-type:none}ul.lst-kix_9cjyjkedxdni-6{list-style-type:none}ul.lst-kix_xsdedfcj27fz-8{list-style-type:none}ul.lst-kix_kfa6jji21f4h-4{list-style-type:none}.lst-kix_7kr9zis60z3j-5>li:before{content:"\0025a0   "}.lst-kix_ap8rxrqvqt32-5>li:before{content:"\0025a0   "}ul.lst-kix_9cjyjkedxdni-7{list-style-type:none}.lst-kix_9l9kjglfjgjz-2>li:before{content:"\0025a0   "}ul.lst-kix_kfa6jji21f4h-3{list-style-type:none}ul.lst-kix_9cjyjkedxdni-8{list-style-type:none}.lst-kix_ie13bttc6n1-0>li:before{content:"\0025cf   "}ul.lst-kix_yxl9yzqp3bqd-3{list-style-type:none}ul.lst-kix_yxl9yzqp3bqd-4{list-style-type:none}ul.lst-kix_yxl9yzqp3bqd-5{list-style-type:none}.lst-kix_hw08zzin6mm8-3>li:before{content:"\0025cf   "}.lst-kix_9cjyjkedxdni-6>li:before{content:"\0025cf   "}ul.lst-kix_yxl9yzqp3bqd-6{list-style-type:none}ul.lst-kix_yxl9yzqp3bqd-7{list-style-type:none}ul.lst-kix_yxl9yzqp3bqd-8{list-style-type:none}.lst-kix_ehfx5m3tdqyv-2>li:before{content:"\0025a0   "}ul.lst-kix_9cjyjkedxdni-0{list-style-type:none}.lst-kix_9czq3plvi9ig-5>li:before{content:"\0025a0   "}.lst-kix_izm55n8luwgn-4>li:before{content:"\0025cb   "}.lst-kix_l555prmkzand-4>li:before{content:"\0025cb   "}ul.lst-kix_s7yi1m4cq9qk-0{list-style-type:none}.lst-kix_ie13bttc6n1-8>li:before{content:"\0025a0   "}ul.lst-kix_s7yi1m4cq9qk-1{list-style-type:none}.lst-kix_crntwpm3ewxb-6>li:before{content:"\0025cf   "}ul.lst-kix_s7yi1m4cq9qk-2{list-style-type:none}.lst-kix_w3t6jbyimnfw-4>li:before{content:"\0025cb   "}ul.lst-kix_s7yi1m4cq9qk-3{list-style-type:none}ul.lst-kix_s7yi1m4cq9qk-4{list-style-type:none}ul.lst-kix_s7yi1m4cq9qk-5{list-style-type:none}ul.lst-kix_s7yi1m4cq9qk-6{list-style-type:none}ul.lst-kix_s7yi1m4cq9qk-7{list-style-type:none}ul.lst-kix_s7yi1m4cq9qk-8{list-style-type:none}.lst-kix_4qgjp0e8yt8m-6>li:before{content:"\0025cf   "}.lst-kix_rdl0mbsx7m1b-8>li:before{content:"\0025a0   "}.lst-kix_tzrck1qfmyqd-8>li:before{content:"\0025a0   "}.lst-kix_lhigxpi4bbt5-3>li:before{content:"\0025cf   "}ul.lst-kix_yxl9yzqp3bqd-0{list-style-type:none}.lst-kix_2tcxxdhwr5nc-3>li:before{content:"\0025cf   "}ul.lst-kix_yxl9yzqp3bqd-1{list-style-type:none}ul.lst-kix_yxl9yzqp3bqd-2{list-style-type:none}.lst-kix_i91p7evgzc6j-6>li:before{content:"\0025cf   "}.lst-kix_xsdedfcj27fz-8>li:before{content:"\0025a0   "}.lst-kix_o5dtwbk7bxd5-3>li:before{content:"\0025cf   "}.lst-kix_t1nnqma9pg08-7>li:before{content:"\0025cb   "}.lst-kix_tzrck1qfmyqd-0>li:before{content:"\0025cf   "}.lst-kix_prgyqriqvk4e-7>li:before{content:"\0025cb   "}.lst-kix_m1mzfy5afs2o-4>li:before{content:"\0025cb   "}.lst-kix_srupee17v0mb-5>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-5,lower-roman) ". "}.lst-kix_pfk02alca94e-6>li:before{content:"\0025cf   "}.lst-kix_c4mjpxs5t8z-1>li:before{content:"\0025cb   "}ul.lst-kix_m4siyyggc8wg-8{list-style-type:none}.lst-kix_69pm6toa84wm-7>li:before{content:"\0025cb   "}ul.lst-kix_m4siyyggc8wg-7{list-style-type:none}.lst-kix_hefc4tmerznh-3>li:before{content:"\0025cf   "}ul.lst-kix_m4siyyggc8wg-4{list-style-type:none}ul.lst-kix_m4siyyggc8wg-3{list-style-type:none}ul.lst-kix_m4siyyggc8wg-6{list-style-type:none}.lst-kix_3vhpfjuy7tvg-2>li:before{content:"\0025a0   "}ul.lst-kix_m4siyyggc8wg-5{list-style-type:none}ul.lst-kix_m4siyyggc8wg-0{list-style-type:none}.lst-kix_1grzdb2vlz2q-5>li:before{content:"\0025a0   "}.lst-kix_3sqsdlm3qg3k-4>li:before{content:"\0025cb   "}ul.lst-kix_m4siyyggc8wg-2{list-style-type:none}ul.lst-kix_m4siyyggc8wg-1{list-style-type:none}.lst-kix_3b0ouvydct1b-8>li:before{content:"\0025a0   "}.lst-kix_d62vaysn6wq1-7>li:before{content:"\0025cb   "}ul.lst-kix_g5ocf0ak9bci-1{list-style-type:none}.lst-kix_zep9qz8je63n-7>li:before{content:"\0025cb   "}ul.lst-kix_g5ocf0ak9bci-0{list-style-type:none}ul.lst-kix_g5ocf0ak9bci-3{list-style-type:none}.lst-kix_jjh106bq03g-4>li:before{content:"\0025cb   "}ul.lst-kix_g5ocf0ak9bci-2{list-style-type:none}.lst-kix_xsdedfcj27fz-0>li:before{content:"\0025cb   "}ul.lst-kix_g5ocf0ak9bci-5{list-style-type:none}ul.lst-kix_g5ocf0ak9bci-4{list-style-type:none}.lst-kix_srn1fozfk9nn-2>li:before{content:"\0025a0   "}ul.lst-kix_g5ocf0ak9bci-7{list-style-type:none}ul.lst-kix_g5ocf0ak9bci-6{list-style-type:none}ul.lst-kix_g5ocf0ak9bci-8{list-style-type:none}.lst-kix_8ljhu9hqkk7j-7>li:before{content:"\0025cb   "}.lst-kix_12ba2se2e37v-6>li:before{content:"\0025cf   "}ul.lst-kix_ap8rxrqvqt32-0{list-style-type:none}.lst-kix_3b0ouvydct1b-0>li:before{content:"\0025cf   "}ul.lst-kix_ap8rxrqvqt32-2{list-style-type:none}ul.lst-kix_afne6v2lp0be-8{list-style-type:none}ul.lst-kix_ap8rxrqvqt32-1{list-style-type:none}ul.lst-kix_ap8rxrqvqt32-4{list-style-type:none}.lst-kix_ixqfp12krdrg-8>li:before{content:"\0025a0   "}.lst-kix_p66sfkc4ny5f-1>li:before{content:"\0025cb   "}ul.lst-kix_ap8rxrqvqt32-3{list-style-type:none}ul.lst-kix_ap8rxrqvqt32-6{list-style-type:none}ul.lst-kix_ap8rxrqvqt32-5{list-style-type:none}.lst-kix_n0ff4gjm91tm-7>li:before{content:"\0025cb   "}.lst-kix_jk6itlvdyknk-1>li:before{content:"\0025cb   "}.lst-kix_q0wctjb2y8b-1>li:before{content:"\0025cb   "}ul.lst-kix_1m661ata3am9-4{list-style-type:none}ul.lst-kix_1m661ata3am9-5{list-style-type:none}.lst-kix_x87etp2vfva3-6>li:before{content:"-  "}ul.lst-kix_1m661ata3am9-2{list-style-type:none}.lst-kix_w9ot5xs5iuad-2>li:before{content:"\0025a0   "}ul.lst-kix_1m661ata3am9-3{list-style-type:none}ul.lst-kix_1m661ata3am9-0{list-style-type:none}.lst-kix_ixqfp12krdrg-0>li:before{content:"\0025cf   "}ul.lst-kix_1m661ata3am9-1{list-style-type:none}.lst-kix_isl8ltogczje-8>li:before{content:"\0025a0   "}ul.lst-kix_ap8rxrqvqt32-8{list-style-type:none}ul.lst-kix_ap8rxrqvqt32-7{list-style-type:none}ul.lst-kix_1m661ata3am9-8{list-style-type:none}.lst-kix_4lz6xppq9i7h-2>li:before{content:"\0025a0   "}.lst-kix_uekzkb8qvgdk-3>li:before{content:"\0025cf   "}ul.lst-kix_1m661ata3am9-6{list-style-type:none}ul.lst-kix_1m661ata3am9-7{list-style-type:none}.lst-kix_j0o0ck7ntjzh-1>li:before{content:"\0025cb   "}.lst-kix_mecbkjiqxfnl-4>li:before{content:"\0025cb   "}.lst-kix_5t41ldrjeoj7-1>li:before{content:"\0025cb   "}.lst-kix_dbltq7i3dnfs-4>li:before{content:"\0025cb   "}.lst-kix_brn07ewm5d7x-1>li:before{content:"\0025cb   "}ul.lst-kix_gl7fpz1y51y1-7{list-style-type:none}.lst-kix_3hrtg26wb9bu-7>li:before{content:"\0025cb   "}ul.lst-kix_gl7fpz1y51y1-8{list-style-type:none}ul.lst-kix_afne6v2lp0be-3{list-style-type:none}ul.lst-kix_afne6v2lp0be-2{list-style-type:none}.lst-kix_vwxe3fdqgja8-3>li:before{content:"\0025cf   "}ul.lst-kix_afne6v2lp0be-1{list-style-type:none}ul.lst-kix_afne6v2lp0be-0{list-style-type:none}.lst-kix_l25ba28sjj7-3>li:before{content:"\0025cf   "}.lst-kix_hdkieo28r82q-5>li:before{content:"\0025a0   "}ul.lst-kix_afne6v2lp0be-7{list-style-type:none}ul.lst-kix_afne6v2lp0be-6{list-style-type:none}ul.lst-kix_afne6v2lp0be-5{list-style-type:none}ul.lst-kix_afne6v2lp0be-4{list-style-type:none}.lst-kix_4vyaz9wpvlga-3>li:before{content:"\0025cf   "}.lst-kix_bzxxtmx6vbow-0>li:before{content:"\0025cf   "}.lst-kix_isl8ltogczje-0>li:before{content:"\0025cf   "}.lst-kix_afhhqgs3rfh2-6>li:before{content:"\0025cf   "}.lst-kix_89fkn9gnr9w9-5>li:before{content:"\0025a0   "}.lst-kix_txo0zcn8hx7-2>li:before{content:"\0025a0   "}.lst-kix_w9nfenze7id7-6>li:before{content:"\0025cf   "}.lst-kix_cszf4nosnav1-4>li:before{content:"\0025cb   "}.lst-kix_pvxrwallhhlw-1>li:before{content:"\0025cb   "}.lst-kix_8ph4j5309jg1-3>li:before{content:"\0025cf   "}.lst-kix_t75jqyambp7u-1>li:before{content:"\0025cb   "}.lst-kix_l5j0c6x8jedh-1>li:before{content:"-  "}.lst-kix_qsmqo56xypa0-6>li:before{content:"\0025cf   "}ul.lst-kix_89fkn9gnr9w9-3{list-style-type:none}.lst-kix_4knzszhhdok2-3>li:before{content:"\0025cf   "}ul.lst-kix_89fkn9gnr9w9-2{list-style-type:none}ul.lst-kix_89fkn9gnr9w9-1{list-style-type:none}ul.lst-kix_89fkn9gnr9w9-0{list-style-type:none}ul.lst-kix_89fkn9gnr9w9-7{list-style-type:none}ul.lst-kix_89fkn9gnr9w9-6{list-style-type:none}.lst-kix_u6oawcl4nq58-8>li:before{content:"\0025a0   "}ul.lst-kix_89fkn9gnr9w9-5{list-style-type:none}ul.lst-kix_89fkn9gnr9w9-4{list-style-type:none}.lst-kix_4knzszhhdok2-0>li:before{content:"\0025cf   "}.lst-kix_bzxxtmx6vbow-8>li:before{content:"\0025a0   "}ul.lst-kix_89fkn9gnr9w9-8{list-style-type:none}.lst-kix_64o9mnu4lnxd-5>li:before{content:"\0025a0   "}.lst-kix_g2wmx2i89hb-3>li:before{content:"\0025cf   "}.lst-kix_u7by882ixwqv-1>li:before{content:"\0025cb   "}.lst-kix_bzxxtmx6vbow-3>li:before{content:"\0025cf   "}.lst-kix_du8w67pu7mte-7>li:before{content:"-  "}.lst-kix_64o9mnu4lnxd-8>li:before{content:"\0025a0   "}ul.lst-kix_3uimjn60qjnx-0{list-style-type:none}ul.lst-kix_3uimjn60qjnx-1{list-style-type:none}.lst-kix_yxl9yzqp3bqd-5>li:before{content:"\0025a0   "}ul.lst-kix_3uimjn60qjnx-8{list-style-type:none}.lst-kix_g2wmx2i89hb-0>li:before{content:"\0025cf   "}ul.lst-kix_3uimjn60qjnx-6{list-style-type:none}ul.lst-kix_3uimjn60qjnx-7{list-style-type:none}ul.lst-kix_3uimjn60qjnx-4{list-style-type:none}ul.lst-kix_3uimjn60qjnx-5{list-style-type:none}ul.lst-kix_3uimjn60qjnx-2{list-style-type:none}ul.lst-kix_3uimjn60qjnx-3{list-style-type:none}.lst-kix_yxl9yzqp3bqd-8>li:before{content:"\0025a0   "}.lst-kix_pfbe3x4ba630-2>li:before{content:"\0025a0   "}.lst-kix_3g1k0ldodoso-0>li:before{content:"\0025cf   "}.lst-kix_pfbe3x4ba630-1>li:before{content:"\0025cb   "}.lst-kix_u6oawcl4nq58-4>li:before{content:"\0025cb   "}.lst-kix_j0o0ck7ntjzh-5>li:before{content:"\0025a0   "}.lst-kix_u6oawcl4nq58-7>li:before{content:"\0025cb   "}.lst-kix_gjh3cugwmzpc-1>li:before{content:"\0025cb   "}.lst-kix_2grrmxr8q0i0-2>li:before{content:"\0025a0   "}.lst-kix_4lz6xppq9i7h-1>li:before{content:"\0025cb   "}.lst-kix_2grrmxr8q0i0-5>li:before{content:"\0025a0   "}.lst-kix_gjh3cugwmzpc-5>li:before{content:"\0025a0   "}.lst-kix_2grrmxr8q0i0-6>li:before{content:"\0025cf   "}.lst-kix_4v5uuo4j022q-4>li:before{content:"\0025cb   "}ul.lst-kix_vbr74uzbiasm-8{list-style-type:none}.lst-kix_wt4lxomyh94s-7>li:before{content:"-  "}.lst-kix_gjh3cugwmzpc-4>li:before{content:"\0025cb   "}ul.lst-kix_vbr74uzbiasm-7{list-style-type:none}ul.lst-kix_vbr74uzbiasm-6{list-style-type:none}ul.lst-kix_vbr74uzbiasm-5{list-style-type:none}ul.lst-kix_vbr74uzbiasm-4{list-style-type:none}.lst-kix_j0o0ck7ntjzh-8>li:before{content:"\0025a0   "}ul.lst-kix_vbr74uzbiasm-3{list-style-type:none}ul.lst-kix_vbr74uzbiasm-2{list-style-type:none}ul.lst-kix_9io9le2bbu11-7{list-style-type:none}ul.lst-kix_vbr74uzbiasm-1{list-style-type:none}ul.lst-kix_9io9le2bbu11-8{list-style-type:none}.lst-kix_24obzjkgjhqt-1>li:before{content:"\0025cb   "}ul.lst-kix_vbr74uzbiasm-0{list-style-type:none}ul.lst-kix_9io9le2bbu11-5{list-style-type:none}.lst-kix_5mcoll6nkdaa-4>li:before{content:"\0025cb   "}ul.lst-kix_9io9le2bbu11-6{list-style-type:none}ul.lst-kix_9io9le2bbu11-3{list-style-type:none}ul.lst-kix_9io9le2bbu11-4{list-style-type:none}ul.lst-kix_9io9le2bbu11-1{list-style-type:none}ul.lst-kix_9io9le2bbu11-2{list-style-type:none}ul.lst-kix_9io9le2bbu11-0{list-style-type:none}.lst-kix_4v5uuo4j022q-8>li:before{content:"\0025a0   "}.lst-kix_s7yi1m4cq9qk-3>li:before{content:"\0025cf   "}.lst-kix_gjh3cugwmzpc-8>li:before{content:"\0025a0   "}.lst-kix_4v5uuo4j022q-7>li:before{content:"\0025cb   "}.lst-kix_wt4lxomyh94s-2>li:before{content:"-  "}.lst-kix_du8w67pu7mte-0>li:before{content:"-  "}.lst-kix_ujecnpd9ox2a-4>li:before{content:"\0025cb   "}.lst-kix_ujecnpd9ox2a-7>li:before{content:"\0025cb   "}.lst-kix_ujecnpd9ox2a-8>li:before{content:"\0025a0   "}.lst-kix_du8w67pu7mte-3>li:before{content:"-  "}.lst-kix_qvmzdr2urb9j-8>li:before{content:"\0025a0   "}.lst-kix_du8w67pu7mte-4>li:before{content:"-  "}.lst-kix_s7yi1m4cq9qk-0>li:before{content:"\0025cf   "}.lst-kix_j8606buix1qi-8>li:before{content:"\0025a0   "}.lst-kix_trx91tt3i1ee-1>li:before{content:"\0025cb   "}.lst-kix_n64wxslery5z-2>li:before{content:"\0025a0   "}.lst-kix_srn1fozfk9nn-7>li:before{content:"\0025cb   "}.lst-kix_ef6tx1pahaqo-6>li:before{content:"\0025cf   "}.lst-kix_vnj3yd9aagbp-3>li:before{content:"\0025cf   "}.lst-kix_saj7a8hkorgr-1>li:before{content:"\0025cb   "}.lst-kix_2yb6ynjarz9t-2>li:before{content:"\0025a0   "}.lst-kix_mrqrqp74n3id-6>li:before{content:"\0025cf   "}.lst-kix_tsc2yqmm539t-0>li:before{content:"" counter(lst-ctn-kix_tsc2yqmm539t-0,decimal) ". "}.lst-kix_whyql51jliaq-0>li:before{content:"\0025cf   "}.lst-kix_afne6v2lp0be-8>li:before{content:"\0025a0   "}ul.lst-kix_gc3eht6946jv-0{list-style-type:none}.lst-kix_ag80f2hqwfhx-0>li:before{content:"\0025cf   "}.lst-kix_p66sfkc4ny5f-2>li:before{content:"\0025a0   "}ul.lst-kix_gc3eht6946jv-1{list-style-type:none}ul.lst-kix_gc3eht6946jv-2{list-style-type:none}ul.lst-kix_gc3eht6946jv-3{list-style-type:none}.lst-kix_5mcoll6nkdaa-8>li:before{content:"\0025a0   "}ul.lst-kix_gc3eht6946jv-4{list-style-type:none}.lst-kix_i2eyp2pt4qrz-7>li:before{content:"\0025cb   "}ul.lst-kix_gc3eht6946jv-5{list-style-type:none}.lst-kix_afne6v2lp0be-4>li:before{content:"\0025cb   "}.lst-kix_v4vy1dgu53ia-3>li:before{content:"\0025cf   "}.lst-kix_dacire7nzy6o-0>li:before{content:"\0025cf   "}ul.lst-kix_brn07ewm5d7x-8{list-style-type:none}ul.lst-kix_brn07ewm5d7x-7{list-style-type:none}.lst-kix_saj7a8hkorgr-5>li:before{content:"\0025a0   "}.lst-kix_j6b3cjdkd1ra-7>li:before{content:"\0025cb   "}ul.lst-kix_brn07ewm5d7x-4{list-style-type:none}ul.lst-kix_brn07ewm5d7x-3{list-style-type:none}.lst-kix_kihk58z8dl9b-2>li:before{content:"\0025a0   "}.lst-kix_i2eyp2pt4qrz-3>li:before{content:"\0025cf   "}ul.lst-kix_brn07ewm5d7x-6{list-style-type:none}.lst-kix_2cqjr2ei92jl-8>li:before{content:"\0025a0   "}ul.lst-kix_brn07ewm5d7x-5{list-style-type:none}ul.lst-kix_gc3eht6946jv-6{list-style-type:none}ul.lst-kix_brn07ewm5d7x-0{list-style-type:none}ul.lst-kix_gc3eht6946jv-7{list-style-type:none}ul.lst-kix_gc3eht6946jv-8{list-style-type:none}ul.lst-kix_brn07ewm5d7x-2{list-style-type:none}.lst-kix_i94q0a22exrp-8>li:before{content:"\0025a0   "}ul.lst-kix_brn07ewm5d7x-1{list-style-type:none}.lst-kix_cruajxrmao23-5>li:before{content:"\0025a0   "}.lst-kix_kviltkqr3kxc-6>li:before{content:"\0025cf   "}.lst-kix_4lz6xppq9i7h-5>li:before{content:"\0025a0   "}.lst-kix_epmllfkx8tp-3>li:before{content:"\0025cf   "}.lst-kix_3hrtg26wb9bu-4>li:before{content:"\0025cb   "}ul.lst-kix_3b0ouvydct1b-8{list-style-type:none}ul.lst-kix_3b0ouvydct1b-7{list-style-type:none}ul.lst-kix_3b0ouvydct1b-6{list-style-type:none}ul.lst-kix_3b0ouvydct1b-5{list-style-type:none}.lst-kix_kviltkqr3kxc-2>li:before{content:"\0025a0   "}.lst-kix_9ynuh6dd4pus-1>li:before{content:"\0025cb   "}.lst-kix_3g1k0ldodoso-4>li:before{content:"\0025cb   "}.lst-kix_pfbe3x4ba630-5>li:before{content:"\0025a0   "}.lst-kix_3hrtg26wb9bu-8>li:before{content:"\0025a0   "}.lst-kix_kfa6jji21f4h-5>li:before{content:"\0025a0   "}.lst-kix_isl8ltogczje-3>li:before{content:"\0025cf   "}.lst-kix_kymf5on3p83t-6>li:before{content:"\0025cf   "}.lst-kix_rtxzgybdcpml-6>li:before{content:"\0025cf   "}.lst-kix_l5j0c6x8jedh-4>li:before{content:"-  "}.lst-kix_n0ff4gjm91tm-2>li:before{content:"\0025a0   "}ul.lst-kix_3b0ouvydct1b-0{list-style-type:none}.lst-kix_zdgpaglha5wb-5>li:before{content:"\0025a0   "}.lst-kix_4nm4szcl7et4-3>li:before{content:"\0025cf   "}ul.lst-kix_3b0ouvydct1b-4{list-style-type:none}.lst-kix_kfa6jji21f4h-1>li:before{content:"\0025cb   "}ul.lst-kix_3b0ouvydct1b-3{list-style-type:none}ul.lst-kix_3b0ouvydct1b-2{list-style-type:none}.lst-kix_yoaj41w0jig0-5>li:before{content:"\0025a0   "}ul.lst-kix_3b0ouvydct1b-1{list-style-type:none}.lst-kix_1bifduglsyp2-8>li:before{content:"\0025a0   "}.lst-kix_txo0zcn8hx7-3>li:before{content:"\0025cf   "}ul.lst-kix_p66sfkc4ny5f-8{list-style-type:none}.lst-kix_l5j0c6x8jedh-0>li:before{content:"-  "}ul.lst-kix_p66sfkc4ny5f-6{list-style-type:none}ul.lst-kix_p66sfkc4ny5f-7{list-style-type:none}ul.lst-kix_p66sfkc4ny5f-4{list-style-type:none}ul.lst-kix_p66sfkc4ny5f-5{list-style-type:none}ul.lst-kix_p66sfkc4ny5f-2{list-style-type:none}ul.lst-kix_p66sfkc4ny5f-3{list-style-type:none}ul.lst-kix_p66sfkc4ny5f-0{list-style-type:none}.lst-kix_zep9qz8je63n-0>li:before{content:"\0025cf   "}ul.lst-kix_p66sfkc4ny5f-1{list-style-type:none}.lst-kix_epmllfkx8tp-7>li:before{content:"\0025cb   "}.lst-kix_tgtuyk7iugqt-7>li:before{content:"\0025cb   "}ul.lst-kix_qzdp8v5qa4kd-1{list-style-type:none}ul.lst-kix_qzdp8v5qa4kd-0{list-style-type:none}.lst-kix_a6lqukhx5fat-0>li:before{content:"\0025cf   "}.lst-kix_a6lqukhx5fat-4>li:before{content:"\0025cb   "}.lst-kix_j3ti34irq4rs-8>li:before{content:"\0025a0   "}ul.lst-kix_qzdp8v5qa4kd-3{list-style-type:none}ul.lst-kix_qzdp8v5qa4kd-2{list-style-type:none}.lst-kix_pvxrwallhhlw-6>li:before{content:"\0025cf   "}.lst-kix_a6lqukhx5fat-1>li:before{content:"\0025cb   "}ul.lst-kix_qzdp8v5qa4kd-5{list-style-type:none}ul.lst-kix_qzdp8v5qa4kd-4{list-style-type:none}ul.lst-kix_tclc6bzuyhm-8{list-style-type:none}.lst-kix_yn02lgpxo9se-2>li:before{content:"\0025a0   "}.lst-kix_54yn6dknd642-6>li:before{content:"\0025cf   "}.lst-kix_xsot34m5j4b-2>li:before{content:"\0025a0   "}.lst-kix_abg8yi9rye91-2>li:before{content:"\0025a0   "}.lst-kix_h8mmrek0o9p9-2>li:before{content:"\0025a0   "}.lst-kix_5fltblknzo3j-5>li:before{content:"\0025a0   "}.lst-kix_zdgpaglha5wb-1>li:before{content:"\0025cb   "}.lst-kix_w9krzpl9jsp-0>li:before{content:"\0025cf   "}.lst-kix_w9krzpl9jsp-4>li:before{content:"\0025cb   "}.lst-kix_fd670jgoibjs-2>li:before{content:"\0025a0   "}.lst-kix_vs58j7xf1fh7-4>li:before{content:"\0025cb   "}.lst-kix_w1xl8yxhafp5-0>li:before{content:"\0025cf   "}.lst-kix_p75x57uzf1s1-7>li:before{content:"\0025cb   "}.lst-kix_vs58j7xf1fh7-8>li:before{content:"\0025a0   "}.lst-kix_mx9uog95vz5r-1>li:before{content:"\0025cb   "}.lst-kix_mx9uog95vz5r-2>li:before{content:"\0025a0   "}.lst-kix_vs58j7xf1fh7-7>li:before{content:"\0025cb   "}ul.lst-kix_9bz6byc4bv0o-0{list-style-type:none}.lst-kix_9l9kjglfjgjz-5>li:before{content:"\0025a0   "}.lst-kix_abg8yi9rye91-3>li:before{content:"\0025cf   "}.lst-kix_j3ti34irq4rs-4>li:before{content:"\0025cb   "}.lst-kix_3iyql9jafv7n-7>li:before{content:"\0025cb   "}.lst-kix_9l9kjglfjgjz-1>li:before{content:"\0025cb   "}.lst-kix_abg8yi9rye91-6>li:before{content:"\0025cf   "}.lst-kix_7v1cxulxokc7-5>li:before{content:"\0025a0   "}.lst-kix_mx9uog95vz5r-5>li:before{content:"\0025a0   "}.lst-kix_7v1cxulxokc7-2>li:before{content:"\0025a0   "}.lst-kix_prgyqriqvk4e-2>li:before{content:"\0025a0   "}.lst-kix_7v1cxulxokc7-1>li:before{content:"\0025cb   "}ul.lst-kix_bzxxtmx6vbow-8{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-7{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-6{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-5{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-4{list-style-type:none}ul.lst-kix_yk9rpx5uikpv-0{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-3{list-style-type:none}.lst-kix_izm55n8luwgn-3>li:before{content:"\0025cf   "}ul.lst-kix_yk9rpx5uikpv-1{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-2{list-style-type:none}ul.lst-kix_yk9rpx5uikpv-2{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-1{list-style-type:none}ul.lst-kix_yk9rpx5uikpv-3{list-style-type:none}ul.lst-kix_bzxxtmx6vbow-0{list-style-type:none}ul.lst-kix_yk9rpx5uikpv-4{list-style-type:none}ul.lst-kix_yk9rpx5uikpv-5{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-0{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-1{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-1{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-2{list-style-type:none}.lst-kix_izm55n8luwgn-7>li:before{content:"\0025cb   "}ul.lst-kix_ssouwh4l2bgy-2{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-3{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-3{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-4{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-4{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-5{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-5{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-6{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-6{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-7{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-7{list-style-type:none}ul.lst-kix_9bz6byc4bv0o-8{list-style-type:none}ul.lst-kix_ssouwh4l2bgy-8{list-style-type:none}.lst-kix_g5ocf0ak9bci-5>li:before{content:"\0025a0   "}.lst-kix_gu62etns0rjq-8>li:before{content:"\0025a0   "}.lst-kix_t1nnqma9pg08-0>li:before{content:"\0025cf   "}ul.lst-kix_6zz37ot1aoo-0{list-style-type:none}.lst-kix_trs82cplclba-0>li:before{content:"\0025cf   "}ul.lst-kix_6zz37ot1aoo-1{list-style-type:none}.lst-kix_o9zj68me8yj0-0>li:before{content:"-  "}.lst-kix_m1mzfy5afs2o-1>li:before{content:"\0025cb   "}.lst-kix_9bz6byc4bv0o-6>li:before{content:"\0025cf   "}.lst-kix_gmr2bu8eavte-2>li:before{content:"\0025a0   "}ul.lst-kix_6zz37ot1aoo-8{list-style-type:none}ul.lst-kix_6zz37ot1aoo-6{list-style-type:none}ul.lst-kix_6zz37ot1aoo-7{list-style-type:none}ul.lst-kix_6zz37ot1aoo-4{list-style-type:none}.lst-kix_mrqrqp74n3id-2>li:before{content:"\0025a0   "}.lst-kix_hrnpa7no5eg-3>li:before{content:"\0025cf   "}ul.lst-kix_6zz37ot1aoo-5{list-style-type:none}ul.lst-kix_6zz37ot1aoo-2{list-style-type:none}.lst-kix_whyql51jliaq-4>li:before{content:"\0025cb   "}.lst-kix_wv60nibffqic-2>li:before{content:"\0025a0   "}ul.lst-kix_6zz37ot1aoo-3{list-style-type:none}.lst-kix_6jta2mj2opdj-4>li:before{content:"\0025cb   "}ul.lst-kix_yk9rpx5uikpv-6{list-style-type:none}ul.lst-kix_yk9rpx5uikpv-7{list-style-type:none}ul.lst-kix_yk9rpx5uikpv-8{list-style-type:none}.lst-kix_hrnpa7no5eg-6>li:before{content:"\0025cf   "}.lst-kix_2yb6ynjarz9t-6>li:before{content:"\0025cf   "}ul.lst-kix_qzdp8v5qa4kd-7{list-style-type:none}ul.lst-kix_qzdp8v5qa4kd-6{list-style-type:none}.lst-kix_uu0tjb1960c1-8>li:before{content:"\0025a0   "}.lst-kix_wv60nibffqic-5>li:before{content:"\0025a0   "}.lst-kix_6jta2mj2opdj-1>li:before{content:"\0025cb   "}.lst-kix_m1mzfy5afs2o-5>li:before{content:"\0025a0   "}ul.lst-kix_qzdp8v5qa4kd-8{list-style-type:none}.lst-kix_o9zj68me8yj0-3>li:before{content:"-  "}.lst-kix_wv60nibffqic-6>li:before{content:"\0025cf   "}.lst-kix_6jta2mj2opdj-0>li:before{content:"\0025cf   "}.lst-kix_hrnpa7no5eg-7>li:before{content:"\0025cb   "}.lst-kix_ef6tx1pahaqo-7>li:before{content:"\0025cb   "}.lst-kix_47wl9llpry5i-1>li:before{content:"\0025cb   "}.lst-kix_n64wxslery5z-1>li:before{content:"\0025cb   "}.lst-kix_n64wxslery5z-5>li:before{content:"\0025a0   "}.lst-kix_vnj3yd9aagbp-0>li:before{content:"\0025cf   "}.lst-kix_2yb6ynjarz9t-3>li:before{content:"\0025cf   "}.lst-kix_whyql51jliaq-1>li:before{content:"\0025cb   "}.lst-kix_o4w8hr2p0ha-3>li:before{content:"\0025cf   "}.lst-kix_afne6v2lp0be-1>li:before{content:"\0025cb   "}.lst-kix_cfsaqxe055dn-3>li:before{content:"\0025cf   "}.lst-kix_mrqrqp74n3id-5>li:before{content:"\0025a0   "}.lst-kix_ef6tx1pahaqo-3>li:before{content:"\0025cf   "}.lst-kix_gxvgspx76nqx-8>li:before{content:"-  "}.lst-kix_ya0b59jf88o6-8>li:before{content:"\0025a0   "}.lst-kix_o1ljou14zs74-5>li:before{content:"\0025a0   "}.lst-kix_hcwipu97fgnf-8>li:before{content:"\0025a0   "}.lst-kix_v4vy1dgu53ia-6>li:before{content:"\0025cf   "}.lst-kix_afne6v2lp0be-5>li:before{content:"\0025a0   "}.lst-kix_saj7a8hkorgr-8>li:before{content:"\0025a0   "}.lst-kix_1jsoq3g3afbv-6>li:before{content:"\0025cf   "}.lst-kix_5mcoll6nkdaa-7>li:before{content:"\0025cb   "}.lst-kix_rjpi34omqxus-3>li:before{content:"\0025cf   "}.lst-kix_i2eyp2pt4qrz-4>li:before{content:"\0025cb   "}.lst-kix_ag80f2hqwfhx-3>li:before{content:"\0025cf   "}.lst-kix_hcwipu97fgnf-4>li:before{content:"\0025cb   "}.lst-kix_qzdp8v5qa4kd-6>li:before{content:"\0025cf   "}.lst-kix_sp06awf5qvvx-0>li:before{content:"\0025cf   "}.lst-kix_saj7a8hkorgr-4>li:before{content:"\0025cb   "}.lst-kix_j6b3cjdkd1ra-8>li:before{content:"\0025a0   "}.lst-kix_gl7fpz1y51y1-0>li:before{content:"\0025cf   "}.lst-kix_o7qc3ia828r4-8>li:before{content:"\0025a0   "}.lst-kix_eh7lncq6en9i-8>li:before{content:"\0025a0   "}.lst-kix_j6b3cjdkd1ra-4>li:before{content:"\0025cb   "}.lst-kix_i2eyp2pt4qrz-0>li:before{content:"\0025cf   "}.lst-kix_9sxg1s3wlz7-7>li:before{content:"\0025cb   "}ul.lst-kix_4nm4szcl7et4-3{list-style-type:none}.lst-kix_7fftgdac6j6-2>li:before{content:"\0025a0   "}ul.lst-kix_4nm4szcl7et4-2{list-style-type:none}ul.lst-kix_4nm4szcl7et4-5{list-style-type:none}.lst-kix_lp80c754wvim-0>li:before{content:"\0025cf   "}ul.lst-kix_4nm4szcl7et4-4{list-style-type:none}.lst-kix_r2llq4i0x498-0>li:before{content:"\0025cf   "}.lst-kix_r2llq4i0x498-4>li:before{content:"\0025cb   "}ul.lst-kix_4nm4szcl7et4-7{list-style-type:none}ul.lst-kix_4nm4szcl7et4-6{list-style-type:none}.lst-kix_cruajxrmao23-2>li:before{content:"\0025a0   "}.lst-kix_cruajxrmao23-6>li:before{content:"\0025cf   "}ul.lst-kix_4nm4szcl7et4-8{list-style-type:none}.lst-kix_4xd0kx9tx9nh-1>li:before{content:"\0025cb   "}.lst-kix_kfa6jji21f4h-8>li:before{content:"\0025a0   "}.lst-kix_kviltkqr3kxc-3>li:before{content:"\0025cf   "}.lst-kix_epmllfkx8tp-4>li:before{content:"\0025cb   "}.lst-kix_3g1k0ldodoso-1>li:before{content:"\0025cb   "}.lst-kix_4xd0kx9tx9nh-5>li:before{content:"\0025a0   "}.lst-kix_2cqjr2ei92jl-5>li:before{content:"\0025a0   "}.lst-kix_kfa6jji21f4h-4>li:before{content:"\0025cb   "}.lst-kix_4nm4szcl7et4-6>li:before{content:"\0025cf   "}.lst-kix_v4vy1dgu53ia-2>li:before{content:"\0025a0   "}.lst-kix_epmllfkx8tp-0>li:before{content:"\0025cf   "}.lst-kix_ssouwh4l2bgy-7>li:before{content:"\0025cb   "}ul.lst-kix_w9nfenze7id7-0{list-style-type:none}ul.lst-kix_w9nfenze7id7-1{list-style-type:none}.lst-kix_pfidrtjb5lqv-3>li:before{content:"\0025cf   "}ul.lst-kix_w9nfenze7id7-2{list-style-type:none}ul.lst-kix_w9nfenze7id7-3{list-style-type:none}ul.lst-kix_w9nfenze7id7-4{list-style-type:none}ul.lst-kix_w9nfenze7id7-5{list-style-type:none}ul.lst-kix_jts281wjqw39-8{list-style-type:none}ul.lst-kix_w9nfenze7id7-6{list-style-type:none}ul.lst-kix_jts281wjqw39-7{list-style-type:none}ul.lst-kix_w9nfenze7id7-7{list-style-type:none}ul.lst-kix_yeuz6sv2qnho-0{list-style-type:none}ul.lst-kix_jts281wjqw39-6{list-style-type:none}ul.lst-kix_w9nfenze7id7-8{list-style-type:none}.lst-kix_4nm4szcl7et4-2>li:before{content:"\0025a0   "}ul.lst-kix_yeuz6sv2qnho-1{list-style-type:none}ul.lst-kix_jts281wjqw39-5{list-style-type:none}.lst-kix_1bifduglsyp2-5>li:before{content:"\0025a0   "}.lst-kix_4o6376uieeve-0>li:before{content:"\0025cf   "}ul.lst-kix_yeuz6sv2qnho-2{list-style-type:none}ul.lst-kix_jts281wjqw39-4{list-style-type:none}ul.lst-kix_jts281wjqw39-3{list-style-type:none}.lst-kix_yoaj41w0jig0-6>li:before{content:"\0025cf   "}ul.lst-kix_jts281wjqw39-2{list-style-type:none}ul.lst-kix_jts281wjqw39-1{list-style-type:none}ul.lst-kix_jts281wjqw39-0{list-style-type:none}ul.lst-kix_yeuz6sv2qnho-7{list-style-type:none}ul.lst-kix_tclc6bzuyhm-1{list-style-type:none}ul.lst-kix_yeuz6sv2qnho-8{list-style-type:none}ul.lst-kix_tclc6bzuyhm-0{list-style-type:none}ul.lst-kix_tclc6bzuyhm-3{list-style-type:none}ul.lst-kix_tclc6bzuyhm-2{list-style-type:none}ul.lst-kix_yeuz6sv2qnho-3{list-style-type:none}ul.lst-kix_tclc6bzuyhm-5{list-style-type:none}ul.lst-kix_yeuz6sv2qnho-4{list-style-type:none}ul.lst-kix_tclc6bzuyhm-4{list-style-type:none}ul.lst-kix_yeuz6sv2qnho-5{list-style-type:none}ul.lst-kix_tclc6bzuyhm-7{list-style-type:none}ul.lst-kix_yeuz6sv2qnho-6{list-style-type:none}ul.lst-kix_tclc6bzuyhm-6{list-style-type:none}.lst-kix_yoaj41w0jig0-2>li:before{content:"\0025a0   "}ul.lst-kix_4nm4szcl7et4-1{list-style-type:none}ul.lst-kix_4nm4szcl7et4-0{list-style-type:none}.lst-kix_2ze49x6dwuyc-7>li:before{content:"\0025cb   "}.lst-kix_r953kfpy79kt-8>li:before{content:"\0025a0   "}.lst-kix_qy2pejxz7e1k-0>li:before{content:"\0025cf   "}ul.lst-kix_kihk58z8dl9b-8{list-style-type:none}ul.lst-kix_kihk58z8dl9b-6{list-style-type:none}ul.lst-kix_kihk58z8dl9b-7{list-style-type:none}ul.lst-kix_kihk58z8dl9b-4{list-style-type:none}ul.lst-kix_kihk58z8dl9b-5{list-style-type:none}.lst-kix_r953kfpy79kt-5>li:before{content:"\0025a0   "}ul.lst-kix_kihk58z8dl9b-2{list-style-type:none}ul.lst-kix_kihk58z8dl9b-3{list-style-type:none}ul.lst-kix_kihk58z8dl9b-0{list-style-type:none}.lst-kix_thjul0jak92m-5>li:before{content:"\0025a0   "}ul.lst-kix_kihk58z8dl9b-1{list-style-type:none}.lst-kix_g3e6y0f95n7u-0>li:before{content:"\0025cf   "}.lst-kix_tx52nn14y93q-7>li:before{content:"\0025cb   "}.lst-kix_z0m8tzh04abu-2>li:before{content:"\0025a0   "}.lst-kix_5chsivk2mkzi-2>li:before{content:"\0025a0   "}.lst-kix_mlex94wk5tq-0>li:before{content:"\0025cf   "}.lst-kix_p6zn1qdl1q6g-4>li:before{content:"\0025cb   "}.lst-kix_bhoq2060wyww-6>li:before{content:"\0025cf   "}.lst-kix_hc4vnvmn7si1-2>li:before{content:"\0025a0   "}.lst-kix_p6zn1qdl1q6g-7>li:before{content:"\0025cb   "}.lst-kix_8l5du8p17xdg-7>li:before{content:"\0025cb   "}.lst-kix_ktcl1r9scb7w-2>li:before{content:"\0025a0   "}.lst-kix_e97rs1rrkyjo-0>li:before{content:"\0025cf   "}ul.lst-kix_podkn7p9liyz-3{list-style-type:none}ul.lst-kix_podkn7p9liyz-4{list-style-type:none}ul.lst-kix_podkn7p9liyz-5{list-style-type:none}ul.lst-kix_podkn7p9liyz-6{list-style-type:none}ul.lst-kix_podkn7p9liyz-7{list-style-type:none}ul.lst-kix_podkn7p9liyz-8{list-style-type:none}ul.lst-kix_podkn7p9liyz-0{list-style-type:none}ul.lst-kix_podkn7p9liyz-1{list-style-type:none}ul.lst-kix_podkn7p9liyz-2{list-style-type:none}.lst-kix_scp6tbbd2fcq-7>li:before{content:"\0025cb   "}.lst-kix_a0n7j7tvxmqv-1>li:before{content:"\0025cb   "}.lst-kix_m5vzryjtrruz-3>li:before{content:"\0025cf   "}ul.lst-kix_k4lchlqktts-1{list-style-type:none}ul.lst-kix_k4lchlqktts-0{list-style-type:none}ul.lst-kix_k4lchlqktts-3{list-style-type:none}ul.lst-kix_k4lchlqktts-2{list-style-type:none}.lst-kix_scp6tbbd2fcq-0>li:before{content:"\0025cf   "}.lst-kix_91x2wdjlgwp1-1>li:before{content:"\0025cb   "}.lst-kix_men9lw1a0mnk-5>li:before{content:"\0025a0   "}.lst-kix_m5vzryjtrruz-0>li:before{content:"\0025cf   "}.lst-kix_s0kih9e12ax-8>li:before{content:"\0025a0   "}.lst-kix_e97rs1rrkyjo-3>li:before{content:"\0025cf   "}.lst-kix_93x7l69l06zp-5>li:before{content:"\0025a0   "}.lst-kix_fum98hryzqm2-6>li:before{content:"\0025cf   "}.lst-kix_r20deuqh30jy-2>li:before{content:"\0025a0   "}.lst-kix_hugw2gsg69de-1>li:before{content:"\0025cb   "}.lst-kix_4gu29fysjsb-1>li:before{content:"\0025cb   "}ul.lst-kix_k4lchlqktts-5{list-style-type:none}.lst-kix_5l7scb4zq2ts-6>li:before{content:"\0025cf   "}ul.lst-kix_k4lchlqktts-4{list-style-type:none}ul.lst-kix_k4lchlqktts-7{list-style-type:none}ul.lst-kix_k4lchlqktts-6{list-style-type:none}ul.lst-kix_k4lchlqktts-8{list-style-type:none}.lst-kix_tsc2yqmm539t-6>li{counter-increment:lst-ctn-kix_tsc2yqmm539t-6}.lst-kix_d62vaysn6wq1-3>li:before{content:"\0025cf   "}.lst-kix_a0n7j7tvxmqv-8>li:before{content:"\0025a0   "}.lst-kix_4gu29fysjsb-4>li:before{content:"\0025cb   "}ul.lst-kix_cszf4nosnav1-6{list-style-type:none}.lst-kix_c4mjpxs5t8z-2>li:before{content:"\0025a0   "}.lst-kix_69pm6toa84wm-6>li:before{content:"\0025cf   "}ul.lst-kix_cszf4nosnav1-5{list-style-type:none}ul.lst-kix_cszf4nosnav1-8{list-style-type:none}ul.lst-kix_cszf4nosnav1-7{list-style-type:none}ul.lst-kix_cszf4nosnav1-2{list-style-type:none}ul.lst-kix_cszf4nosnav1-1{list-style-type:none}ul.lst-kix_cszf4nosnav1-4{list-style-type:none}ul.lst-kix_cszf4nosnav1-3{list-style-type:none}.lst-kix_l5sge8zce4vp-0>li:before{content:"\0025cf   "}.lst-kix_3vhpfjuy7tvg-3>li:before{content:"\0025cf   "}ul.lst-kix_cszf4nosnav1-0{list-style-type:none}.lst-kix_9orpva36zqgw-1>li:before{content:"\0025cb   "}.lst-kix_fvsyn7dqkka1-3>li:before{content:"\0025cf   "}.lst-kix_8qkhix9sdgh8-4>li:before{content:"\0025cb   "}.lst-kix_6omq6vtmahws-2>li:before{content:"\0025a0   "}.lst-kix_dk6ingbu8z4-0>li:before{content:"\0025cf   "}ul.lst-kix_y4vuy41h8k5q-3{list-style-type:none}ul.lst-kix_y4vuy41h8k5q-2{list-style-type:none}ul.lst-kix_y4vuy41h8k5q-5{list-style-type:none}.lst-kix_izsd5g4fgpc-4>li:before{content:"\0025cb   "}ul.lst-kix_y4vuy41h8k5q-4{list-style-type:none}.lst-kix_cfsaqxe055dn-6>li:before{content:"\0025cf   "}.lst-kix_8ljhu9hqkk7j-8>li:before{content:"\0025a0   "}ul.lst-kix_y4vuy41h8k5q-1{list-style-type:none}ul.lst-kix_y4vuy41h8k5q-0{list-style-type:none}.lst-kix_ya0b59jf88o6-5>li:before{content:"\0025a0   "}.lst-kix_3b0ouvydct1b-1>li:before{content:"\0025cb   "}.lst-kix_zhnrfbqi7c3p-7>li:before{content:"\0025cb   "}.lst-kix_9sxg1s3wlz7-4>li:before{content:"\0025cb   "}.lst-kix_5ov7bblzaw0u-8>li:before{content:"\0025a0   "}.lst-kix_o7qc3ia828r4-5>li:before{content:"\0025a0   "}.lst-kix_mo5grncnzemi-3>li:before{content:"\0025cf   "}.lst-kix_t7dbdae30u9t-8>li:before{content:"\0025a0   "}.lst-kix_eh7lncq6en9i-5>li:before{content:"\0025a0   "}.lst-kix_qymwuf8ggtk1-7>li:before{content:"\0025cb   "}ul.lst-kix_b966qb5z56w2-8{list-style-type:none}ul.lst-kix_b966qb5z56w2-7{list-style-type:none}.lst-kix_x87etp2vfva3-5>li:before{content:"-  "}ul.lst-kix_b966qb5z56w2-6{list-style-type:none}ul.lst-kix_b966qb5z56w2-5{list-style-type:none}ul.lst-kix_b966qb5z56w2-4{list-style-type:none}.lst-kix_hcwipu97fgnf-1>li:before{content:"\0025cb   "}ul.lst-kix_b966qb5z56w2-3{list-style-type:none}ul.lst-kix_b966qb5z56w2-2{list-style-type:none}ul.lst-kix_b966qb5z56w2-1{list-style-type:none}.lst-kix_v38knoi1xqwy-8>li:before{content:"-  "}ul.lst-kix_b966qb5z56w2-0{list-style-type:none}.lst-kix_qzdp8v5qa4kd-3>li:before{content:"\0025cf   "}.lst-kix_j9krs4wwadz8-2>li:before{content:"\0025a0   "}.lst-kix_e3cxiuksdiku-4>li:before{content:"\0025cb   "}.lst-kix_fktfq9ltsq98-6>li:before{content:"-  "}.lst-kix_3jdd6arud0e0-7>li:before{content:"\0025cb   "}.lst-kix_gl7fpz1y51y1-3>li:before{content:"\0025cf   "}.lst-kix_lp80c754wvim-3>li:before{content:"\0025cf   "}.lst-kix_dbltq7i3dnfs-5>li:before{content:"\0025a0   "}.lst-kix_yeuz6sv2qnho-0>li:before{content:"\0025cf   "}.lst-kix_pp0573v7gp5z-0>li:before{content:"\0025cf   "}.lst-kix_brn07ewm5d7x-0>li:before{content:"\0025cf   "}.lst-kix_tclc6bzuyhm-3>li:before{content:"\0025cf   "}.lst-kix_3mbe6pf0vyok-6>li:before{content:"\0025cf   "}.lst-kix_bbzhpmijr633-4>li:before{content:"\0025cb   "}.lst-kix_w1xl8yxhafp5-3>li:before{content:"\0025cf   "}.lst-kix_cpaf1rpc28c-7>li:before{content:"\0025cb   "}.lst-kix_kizzdizga4v0-8>li:before{content:"\0025a0   "}.lst-kix_lf7onj2nrr7v-2>li:before{content:"\0025a0   "}.lst-kix_ifg2eqszm6qp-0>li:before{content:"\0025cf   "}.lst-kix_nn0h438aq2o5-7>li:before{content:"\0025cb   "}ul.lst-kix_y4vuy41h8k5q-7{list-style-type:none}ul.lst-kix_y4vuy41h8k5q-6{list-style-type:none}.lst-kix_oofi1dgq0nej-7>li:before{content:"\0025cb   "}ul.lst-kix_y4vuy41h8k5q-8{list-style-type:none}.lst-kix_89fkn9gnr9w9-4>li:before{content:"\0025cb   "}.lst-kix_jjh106bq03g-3>li:before{content:"\0025cf   "}.lst-kix_w9nfenze7id7-5>li:before{content:"\0025a0   "}.lst-kix_idsnzgd8q5di-7>li:before{content:"\0025cb   "}.lst-kix_g3e6y0f95n7u-3>li:before{content:"\0025cf   "}.lst-kix_eqjgku92ysne-3>li:before{content:"\0025cf   "}ul.lst-kix_7kr9zis60z3j-6{list-style-type:none}ul.lst-kix_7kr9zis60z3j-5{list-style-type:none}.lst-kix_p0wl0w4s0sa-3>li:before{content:"\0025cf   "}ul.lst-kix_7kr9zis60z3j-4{list-style-type:none}ul.lst-kix_7kr9zis60z3j-3{list-style-type:none}ul.lst-kix_kfuatcy312kx-2{list-style-type:none}ul.lst-kix_kfuatcy312kx-1{list-style-type:none}ol.lst-kix_tsc2yqmm539t-8{list-style-type:none}ul.lst-kix_7kr9zis60z3j-8{list-style-type:none}ul.lst-kix_kfuatcy312kx-0{list-style-type:none}ul.lst-kix_7kr9zis60z3j-7{list-style-type:none}.lst-kix_yn02lgpxo9se-5>li:before{content:"\0025a0   "}.lst-kix_wsfytj8n987p-0>li:before{content:"\0025cf   "}.lst-kix_ek5wwvmsnqx1-0>li:before{content:"\0025cf   "}.lst-kix_fd670jgoibjs-5>li:before{content:"\0025a0   "}.lst-kix_gxbfiekgqjd6-4>li:before{content:"\0025cb   "}.lst-kix_1m661ata3am9-4>li:before{content:"\0025cb   "}.lst-kix_1m661ata3am9-7>li:before{content:"\0025cb   "}.lst-kix_j3ti34irq4rs-1>li:before{content:"\0025cb   "}ul.lst-kix_7kr9zis60z3j-2{list-style-type:none}ul.lst-kix_7kr9zis60z3j-1{list-style-type:none}ul.lst-kix_7kr9zis60z3j-0{list-style-type:none}.lst-kix_kw4p74ijjapz-7>li:before{content:"\0025cb   "}.lst-kix_1k1th764da5j-5>li:before{content:"\0025a0   "}.lst-kix_6m7znixdz235-0>li:before{content:"\0025cf   "}ul.lst-kix_az8p3db80uc9-7{list-style-type:none}ul.lst-kix_az8p3db80uc9-6{list-style-type:none}ul.lst-kix_az8p3db80uc9-8{list-style-type:none}.lst-kix_dii13kfyl9ma-1>li:before{content:"\0025cb   "}ul.lst-kix_4wi60e30t59b-5{list-style-type:none}ul.lst-kix_4wi60e30t59b-6{list-style-type:none}.lst-kix_gu62etns0rjq-5>li:before{content:"\0025a0   "}.lst-kix_1k1th764da5j-2>li:before{content:"\0025a0   "}ul.lst-kix_4wi60e30t59b-7{list-style-type:none}ul.lst-kix_4wi60e30t59b-8{list-style-type:none}.lst-kix_d74axqjz5yj6-6>li:before{content:"\0025cf   "}.lst-kix_gxbfiekgqjd6-7>li:before{content:"\0025cb   "}ul.lst-kix_az8p3db80uc9-1{list-style-type:none}ul.lst-kix_zep9qz8je63n-1{list-style-type:none}ul.lst-kix_az8p3db80uc9-0{list-style-type:none}ul.lst-kix_zep9qz8je63n-0{list-style-type:none}ul.lst-kix_az8p3db80uc9-3{list-style-type:none}ul.lst-kix_zep9qz8je63n-3{list-style-type:none}ul.lst-kix_az8p3db80uc9-2{list-style-type:none}ul.lst-kix_zep9qz8je63n-2{list-style-type:none}ul.lst-kix_az8p3db80uc9-5{list-style-type:none}ul.lst-kix_zep9qz8je63n-5{list-style-type:none}.lst-kix_3cigoxtebeue-8>li:before{content:"\0025a0   "}ul.lst-kix_az8p3db80uc9-4{list-style-type:none}ul.lst-kix_zep9qz8je63n-4{list-style-type:none}.lst-kix_8pk9oqxklycz-2>li:before{content:"\0025a0   "}.lst-kix_dmlj8k237tx2-6>li:before{content:"\0025cf   "}ul.lst-kix_4wi60e30t59b-1{list-style-type:none}ul.lst-kix_kfuatcy312kx-6{list-style-type:none}ul.lst-kix_4wi60e30t59b-2{list-style-type:none}.lst-kix_bm3nprf82w8o-8>li:before{content:"\0025a0   "}ul.lst-kix_kfuatcy312kx-5{list-style-type:none}ul.lst-kix_4wi60e30t59b-3{list-style-type:none}.lst-kix_6m7znixdz235-3>li:before{content:"\0025cf   "}ul.lst-kix_kfuatcy312kx-4{list-style-type:none}ul.lst-kix_4wi60e30t59b-4{list-style-type:none}ul.lst-kix_kfuatcy312kx-3{list-style-type:none}ul.lst-kix_kfuatcy312kx-8{list-style-type:none}ul.lst-kix_4wi60e30t59b-0{list-style-type:none}ul.lst-kix_kfuatcy312kx-7{list-style-type:none}.lst-kix_izm55n8luwgn-0>li:before{content:"\0025cf   "}.lst-kix_rdl0mbsx7m1b-4>li:before{content:"\0025cb   "}.lst-kix_pfk02alca94e-5>li:before{content:"\0025a0   "}.lst-kix_7kr9zis60z3j-6>li:before{content:"\0025cf   "}.lst-kix_mn5hganrvuk0-1>li:before{content:"\0025cb   "}.lst-kix_ap8rxrqvqt32-1>li:before{content:"\0025cb   "}.lst-kix_pfk02alca94e-2>li:before{content:"\0025a0   "}ul.lst-kix_j9krs4wwadz8-8{list-style-type:none}ul.lst-kix_zep9qz8je63n-7{list-style-type:none}ul.lst-kix_j9krs4wwadz8-7{list-style-type:none}.lst-kix_l555prmkzand-0>li:before{content:"\0025cf   "}ul.lst-kix_zep9qz8je63n-6{list-style-type:none}ul.lst-kix_j9krs4wwadz8-6{list-style-type:none}ul.lst-kix_j9krs4wwadz8-5{list-style-type:none}ul.lst-kix_zep9qz8je63n-8{list-style-type:none}ul.lst-kix_j9krs4wwadz8-4{list-style-type:none}ul.lst-kix_j9krs4wwadz8-3{list-style-type:none}ul.lst-kix_j9krs4wwadz8-2{list-style-type:none}ul.lst-kix_j9krs4wwadz8-1{list-style-type:none}.lst-kix_ehfx5m3tdqyv-6>li:before{content:"\0025cf   "}ul.lst-kix_j9krs4wwadz8-0{list-style-type:none}.lst-kix_ie13bttc6n1-4>li:before{content:"\0025cb   "}ul.lst-kix_12ba2se2e37v-8{list-style-type:none}.lst-kix_w3t6jbyimnfw-0>li:before{content:"\0025cf   "}ul.lst-kix_12ba2se2e37v-7{list-style-type:none}.lst-kix_qx6x5q8dhn22-4>li:before{content:"\0025cb   "}.lst-kix_w9ot5xs5iuad-6>li:before{content:"\0025cf   "}.lst-kix_9cjyjkedxdni-2>li:before{content:"\0025a0   "}ul.lst-kix_12ba2se2e37v-6{list-style-type:none}.lst-kix_9vnfdb4co7p6-1>li:before{content:"\0025cb   "}.lst-kix_q0wctjb2y8b-5>li:before{content:"\0025a0   "}ul.lst-kix_pp0573v7gp5z-6{list-style-type:none}.lst-kix_ey106e39uxys-1>li:before{content:"\0025cb   "}ul.lst-kix_pp0573v7gp5z-5{list-style-type:none}ul.lst-kix_pp0573v7gp5z-8{list-style-type:none}.lst-kix_q0wctjb2y8b-8>li:before{content:"\0025a0   "}ul.lst-kix_pp0573v7gp5z-7{list-style-type:none}ul.lst-kix_pp0573v7gp5z-2{list-style-type:none}ul.lst-kix_pp0573v7gp5z-1{list-style-type:none}.lst-kix_i0yf1mju0g1s-7>li:before{content:"\0025cb   "}ul.lst-kix_pp0573v7gp5z-4{list-style-type:none}ul.lst-kix_5l7scb4zq2ts-0{list-style-type:none}ul.lst-kix_pp0573v7gp5z-3{list-style-type:none}.lst-kix_c6t6pz4sgcyt-4>li:before{content:"\0025cb   "}ul.lst-kix_5l7scb4zq2ts-2{list-style-type:none}ul.lst-kix_5l7scb4zq2ts-1{list-style-type:none}ul.lst-kix_5l7scb4zq2ts-4{list-style-type:none}.lst-kix_t1nnqma9pg08-3>li:before{content:"\0025cf   "}ul.lst-kix_5l7scb4zq2ts-3{list-style-type:none}ul.lst-kix_5l7scb4zq2ts-6{list-style-type:none}ul.lst-kix_5l7scb4zq2ts-5{list-style-type:none}ul.lst-kix_5l7scb4zq2ts-8{list-style-type:none}.lst-kix_m1mzfy5afs2o-8>li:before{content:"\0025a0   "}.lst-kix_srupee17v0mb-1>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-1,lower-latin) ". "}ul.lst-kix_5l7scb4zq2ts-7{list-style-type:none}.lst-kix_9czq3plvi9ig-1>li:before{content:"\0025cb   "}.lst-kix_kfuatcy312kx-7>li:before{content:"\0025cb   "}.lst-kix_xsdedfcj27fz-4>li:before{content:"\0025cb   "}ol.lst-kix_tsc2yqmm539t-5{list-style-type:none}ol.lst-kix_tsc2yqmm539t-4{list-style-type:none}ul.lst-kix_pp0573v7gp5z-0{list-style-type:none}ol.lst-kix_tsc2yqmm539t-7{list-style-type:none}.lst-kix_xsdedfcj27fz-7>li:before{content:"\0025cb   "}.lst-kix_srupee17v0mb-4>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-4,lower-latin) ". "}ol.lst-kix_tsc2yqmm539t-6{list-style-type:none}ol.lst-kix_tsc2yqmm539t-0{list-style-type:none}.lst-kix_xsot34m5j4b-5>li:before{content:"\0025a0   "}ol.lst-kix_tsc2yqmm539t-3{list-style-type:none}.lst-kix_xlixir5f8ikv-1>li:before{content:"\0025cb   "}.lst-kix_69pm6toa84wm-3>li:before{content:"\0025cf   "}.lst-kix_d62vaysn6wq1-0>li:before{content:"\0025cf   "}.lst-kix_b966qb5z56w2-0>li:before{content:"\0025cf   "}ul.lst-kix_91x2wdjlgwp1-6{list-style-type:none}ul.lst-kix_91x2wdjlgwp1-5{list-style-type:none}ul.lst-kix_91x2wdjlgwp1-4{list-style-type:none}ul.lst-kix_91x2wdjlgwp1-3{list-style-type:none}ul.lst-kix_91x2wdjlgwp1-2{list-style-type:none}ul.lst-kix_91x2wdjlgwp1-1{list-style-type:none}ul.lst-kix_91x2wdjlgwp1-0{list-style-type:none}.lst-kix_c4mjpxs5t8z-5>li:before{content:"\0025a0   "}.lst-kix_3sqsdlm3qg3k-0>li:before{content:"\0025cf   "}.lst-kix_gxvla3x57ko6-0>li:before{content:"\0025cf   "}ul.lst-kix_91x2wdjlgwp1-8{list-style-type:none}ul.lst-kix_91x2wdjlgwp1-7{list-style-type:none}.lst-kix_p66sfkc4ny5f-5>li:before{content:"\0025a0   "}.lst-kix_3b0ouvydct1b-4>li:before{content:"\0025cb   "}.lst-kix_x87etp2vfva3-2>li:before{content:"-  "}ul.lst-kix_t7dbdae30u9t-7{list-style-type:none}.lst-kix_uekzkb8qvgdk-7>li:before{content:"\0025cb   "}ul.lst-kix_t7dbdae30u9t-8{list-style-type:none}.lst-kix_fnntpv12ge7c-6>li:before{content:"\0025cf   "}ul.lst-kix_t7dbdae30u9t-5{list-style-type:none}ul.lst-kix_t7dbdae30u9t-6{list-style-type:none}ul.lst-kix_t7dbdae30u9t-3{list-style-type:none}ul.lst-kix_t7dbdae30u9t-4{list-style-type:none}.lst-kix_kihk58z8dl9b-5>li:before{content:"\0025a0   "}ul.lst-kix_t7dbdae30u9t-1{list-style-type:none}.lst-kix_3vhpfjuy7tvg-6>li:before{content:"\0025cf   "}ul.lst-kix_t7dbdae30u9t-2{list-style-type:none}ul.lst-kix_rjpi34omqxus-1{list-style-type:none}ul.lst-kix_t7dbdae30u9t-0{list-style-type:none}ul.lst-kix_rjpi34omqxus-0{list-style-type:none}ul.lst-kix_rjpi34omqxus-3{list-style-type:none}.lst-kix_i94q0a22exrp-5>li:before{content:"\0025a0   "}ul.lst-kix_rjpi34omqxus-2{list-style-type:none}ul.lst-kix_rjpi34omqxus-5{list-style-type:none}ul.lst-kix_rjpi34omqxus-4{list-style-type:none}ul.lst-kix_rjpi34omqxus-7{list-style-type:none}ul.lst-kix_rjpi34omqxus-6{list-style-type:none}ul.lst-kix_rjpi34omqxus-8{list-style-type:none}.lst-kix_mecbkjiqxfnl-8>li:before{content:"\0025a0   "}.lst-kix_idsnzgd8q5di-4>li:before{content:"\0025cb   "}.lst-kix_hdkieo28r82q-1>li:before{content:"\0025cb   "}.lst-kix_bbzhpmijr633-1>li:before{content:"\0025cb   "}.lst-kix_cszf4nosnav1-8>li:before{content:"\0025a0   "}.lst-kix_afhhqgs3rfh2-2>li:before{content:"\0025a0   "}ul.lst-kix_gtofryf4bnby-0{list-style-type:none}.lst-kix_jk6itlvdyknk-5>li:before{content:"\0025a0   "}ul.lst-kix_gtofryf4bnby-2{list-style-type:none}.lst-kix_dbltq7i3dnfs-8>li:before{content:"\0025a0   "}ul.lst-kix_gtofryf4bnby-1{list-style-type:none}ul.lst-kix_gtofryf4bnby-4{list-style-type:none}ul.lst-kix_gtofryf4bnby-3{list-style-type:none}.lst-kix_9ynuh6dd4pus-4>li:before{content:"\0025cb   "}ul.lst-kix_gtofryf4bnby-6{list-style-type:none}ul.lst-kix_gtofryf4bnby-5{list-style-type:none}.lst-kix_4683th2gmjda-6>li:before{content:"\0025cf   "}ul.lst-kix_gtofryf4bnby-8{list-style-type:none}.lst-kix_l25ba28sjj7-7>li:before{content:"\0025cb   "}.lst-kix_53eqpuuodt5v-2>li:before{content:"\0025a0   "}ul.lst-kix_gtofryf4bnby-7{list-style-type:none}.lst-kix_4vyaz9wpvlga-7>li:before{content:"\0025cb   "}.lst-kix_rtxzgybdcpml-3>li:before{content:"\0025cf   "}.lst-kix_jjh106bq03g-0>li:before{content:"  "}.lst-kix_apk8f490x7qb-6>li:before{content:"\0025cf   "}.lst-kix_txo0zcn8hx7-6>li:before{content:"\0025cf   "}.lst-kix_w9nfenze7id7-2>li:before{content:"\0025a0   "}.lst-kix_8ph4j5309jg1-7>li:before{content:"\0025cb   "}.lst-kix_izsd5g4fgpc-1>li:before{content:"\0025cb   "}.lst-kix_t75jqyambp7u-5>li:before{content:"\0025a0   "}.lst-kix_zcy565gabcmu-6>li:before{content:"\0025cf   "}.lst-kix_68nz8s40mnx9-8>li:before{content:"\0025a0   "}.lst-kix_fvsyn7dqkka1-0>li:before{content:"\0025cf   "}.lst-kix_zep9qz8je63n-3>li:before{content:"\0025cf   "}.lst-kix_z4v6nrp70nz7-0>li:before{content:"\0025cf   "}.lst-kix_e3cxiuksdiku-7>li:before{content:"\0025cb   "}.lst-kix_3uimjn60qjnx-6>li:before{content:"\0025cf   "}.lst-kix_89fkn9gnr9w9-1>li:before{content:"\0025cb   "}.lst-kix_thg0lt5umapc-0>li:before{content:"\0025cf   "}.lst-kix_2mr9vgw3av16-0>li:before{content:"\0025cf   "}.lst-kix_ge70ia1l9j2p-5>li:before{content:"\0025a0   "}.lst-kix_fo3xfsyzwa37-5>li:before{content:"\0025a0   "}.lst-kix_nd4cj51qmb1k-1>li:before{content:"\0025cb   "}.lst-kix_x803kyc5p3g4-1>li:before{content:"\0025cb   "}.lst-kix_jts281wjqw39-6>li:before{content:"\0025cf   "}.lst-kix_hdamu5z1kajk-1>li:before{content:"-  "}.lst-kix_hdamu5z1kajk-3>li:before{content:"-  "}.lst-kix_fo3xfsyzwa37-3>li:before{content:"\0025cf   "}.lst-kix_jts281wjqw39-8>li:before{content:"\0025a0   "}.lst-kix_2mr9vgw3av16-8>li:before{content:"\0025a0   "}.lst-kix_8ylfq8z9iqph-3>li:before{content:"\0025cf   "}.lst-kix_8ylfq8z9iqph-7>li:before{content:"\0025cb   "}.lst-kix_vcrwp2bwzubh-7>li:before{content:"\0025cb   "}.lst-kix_thg0lt5umapc-8>li:before{content:"\0025a0   "}.lst-kix_jts281wjqw39-0>li:before{content:"\0025cf   "}.lst-kix_x803kyc5p3g4-7>li:before{content:"\0025cb   "}.lst-kix_vbr74uzbiasm-7>li:before{content:"\0025cb   "}ul.lst-kix_tsc2yqmm539t-2{list-style-type:none}.lst-kix_3ppobcpt0okh-3>li:before{content:"\0025cf   "}.lst-kix_jts281wjqw39-2>li:before{content:"\0025a0   "}.lst-kix_2mr9vgw3av16-6>li:before{content:"\0025cf   "}.lst-kix_8ylfq8z9iqph-1>li:before{content:"\0025cb   "}.lst-kix_ge70ia1l9j2p-3>li:before{content:"\0025cf   "}.lst-kix_m4siyyggc8wg-8>li:before{content:"\0025a0   "}.lst-kix_k4lchlqktts-3>li:before{content:"\0025cf   "}.lst-kix_2mr9vgw3av16-2>li:before{content:"\0025a0   "}.lst-kix_m4siyyggc8wg-6>li:before{content:"\0025cf   "}.lst-kix_xgrv9tn3a2rg-7>li:before{content:"\0025cb   "}.lst-kix_4cx6uiey4qy0-8>li:before{content:"\0025a0   "}.lst-kix_a130djrb9y6e-8>li:before{content:"\0025a0   "}ul.lst-kix_8ph4j5309jg1-5{list-style-type:none}ul.lst-kix_8ph4j5309jg1-4{list-style-type:none}.lst-kix_d2maxule6lxs-7>li:before{content:"\0025cb   "}ul.lst-kix_8ph4j5309jg1-3{list-style-type:none}ul.lst-kix_8ph4j5309jg1-2{list-style-type:none}ul.lst-kix_8ph4j5309jg1-8{list-style-type:none}.lst-kix_y4vuy41h8k5q-1>li:before{content:"\0025cb   "}ul.lst-kix_8ph4j5309jg1-7{list-style-type:none}ul.lst-kix_8ph4j5309jg1-6{list-style-type:none}.lst-kix_gtofryf4bnby-6>li:before{content:"\0025cf   "}ul.lst-kix_tsc2yqmm539t-1{list-style-type:none}ul.lst-kix_8ph4j5309jg1-1{list-style-type:none}ul.lst-kix_8ph4j5309jg1-0{list-style-type:none}.lst-kix_tgfvho118md4-6>li:before{content:"\0025cf   "}ul.lst-kix_4xd0kx9tx9nh-4{list-style-type:none}ul.lst-kix_4xd0kx9tx9nh-5{list-style-type:none}ul.lst-kix_4xd0kx9tx9nh-2{list-style-type:none}ul.lst-kix_4xd0kx9tx9nh-3{list-style-type:none}ul.lst-kix_4xd0kx9tx9nh-0{list-style-type:none}ul.lst-kix_4xd0kx9tx9nh-1{list-style-type:none}ul.lst-kix_gxvgspx76nqx-4{list-style-type:none}.lst-kix_vbr74uzbiasm-1>li:before{content:"\0025cb   "}ul.lst-kix_gxvgspx76nqx-5{list-style-type:none}ul.lst-kix_gxvgspx76nqx-6{list-style-type:none}ul.lst-kix_gxvgspx76nqx-7{list-style-type:none}ul.lst-kix_4xd0kx9tx9nh-8{list-style-type:none}ul.lst-kix_gxvgspx76nqx-8{list-style-type:none}ul.lst-kix_4xd0kx9tx9nh-6{list-style-type:none}.lst-kix_y4vuy41h8k5q-3>li:before{content:"\0025cf   "}ul.lst-kix_4xd0kx9tx9nh-7{list-style-type:none}ul.lst-kix_r953kfpy79kt-0{list-style-type:none}ul.lst-kix_r953kfpy79kt-4{list-style-type:none}.lst-kix_xgrv9tn3a2rg-1>li:before{content:"\0025cb   "}ul.lst-kix_r953kfpy79kt-3{list-style-type:none}ul.lst-kix_r953kfpy79kt-2{list-style-type:none}.lst-kix_tgfvho118md4-0>li:before{content:"\0025cb   "}ul.lst-kix_r953kfpy79kt-1{list-style-type:none}ul.lst-kix_r953kfpy79kt-8{list-style-type:none}ul.lst-kix_r953kfpy79kt-7{list-style-type:none}ul.lst-kix_r953kfpy79kt-6{list-style-type:none}ul.lst-kix_r953kfpy79kt-5{list-style-type:none}.lst-kix_snh8lpyqaleg-4>li:before{content:"\0025cb   "}.lst-kix_y4vuy41h8k5q-7>li:before{content:"\0025cb   "}.lst-kix_gtofryf4bnby-0>li:before{content:"\0025cf   "}.lst-kix_xczac0sw8y6a-4>li:before{content:"\0025cb   "}.lst-kix_6jxu4l7p3d4o-7>li:before{content:"\0025cb   "}.lst-kix_h00g16e7ufft-7>li:before{content:"\0025cb   "}.lst-kix_hefc4tmerznh-4>li:before{content:"\0025cb   "}.lst-kix_6jxu4l7p3d4o-1>li:before{content:"\0025cb   "}.lst-kix_xclf8ew5xwnq-5>li:before{content:"\0025a0   "}.lst-kix_7mi52l6y9ptp-1>li:before{content:"\0025cb   "}.lst-kix_qor9p1a81vaf-8>li:before{content:"\0025a0   "}.lst-kix_h00g16e7ufft-1>li:before{content:"\0025cb   "}.lst-kix_jk6itlvdyknk-0>li:before{content:"\0025cf   "}.lst-kix_7mi52l6y9ptp-5>li:before{content:"\0025a0   "}ul.lst-kix_q0wctjb2y8b-3{list-style-type:none}.lst-kix_qor9p1a81vaf-2>li:before{content:"\0025a0   "}ul.lst-kix_q0wctjb2y8b-4{list-style-type:none}ul.lst-kix_q0wctjb2y8b-5{list-style-type:none}ul.lst-kix_q0wctjb2y8b-6{list-style-type:none}.lst-kix_qor9p1a81vaf-4>li:before{content:"\0025cb   "}.lst-kix_8qeqm584pmza-5>li:before{content:"\0025a0   "}ul.lst-kix_q0wctjb2y8b-0{list-style-type:none}ul.lst-kix_q0wctjb2y8b-1{list-style-type:none}ul.lst-kix_q0wctjb2y8b-2{list-style-type:none}.lst-kix_7mi52l6y9ptp-7>li:before{content:"\0025cb   "}.lst-kix_yvj42sc4s1lo-8>li:before{content:"\0025a0   "}ul.lst-kix_4cx6uiey4qy0-8{list-style-type:none}.lst-kix_d2maxule6lxs-1>li:before{content:"\0025cb   "}.lst-kix_4cx6uiey4qy0-0>li:before{content:"\0025cf   "}.lst-kix_4cx6uiey4qy0-2>li:before{content:"\0025a0   "}ul.lst-kix_q0wctjb2y8b-7{list-style-type:none}ul.lst-kix_q0wctjb2y8b-8{list-style-type:none}.lst-kix_sf1qf9bwyojp-7>li:before{content:"\0025cb   "}.lst-kix_yvj42sc4s1lo-4>li:before{content:"\0025cb   "}.lst-kix_l25ba28sjj7-0>li:before{content:"\0025cf   "}.lst-kix_evcxr39uk36z-3>li:before{content:"\0025cf   "}.lst-kix_hdkieo28r82q-2>li:before{content:"\0025a0   "}ul.lst-kix_4cx6uiey4qy0-3{list-style-type:none}ul.lst-kix_4cx6uiey4qy0-2{list-style-type:none}.lst-kix_vwxe3fdqgja8-4>li:before{content:"\0025cb   "}ul.lst-kix_4cx6uiey4qy0-1{list-style-type:none}.lst-kix_yvj42sc4s1lo-2>li:before{content:"\0025a0   "}.lst-kix_jk6itlvdyknk-6>li:before{content:"\0025cf   "}ul.lst-kix_4cx6uiey4qy0-0{list-style-type:none}ul.lst-kix_4cx6uiey4qy0-7{list-style-type:none}ul.lst-kix_4cx6uiey4qy0-6{list-style-type:none}ul.lst-kix_4cx6uiey4qy0-5{list-style-type:none}ul.lst-kix_4cx6uiey4qy0-4{list-style-type:none}.lst-kix_hdkieo28r82q-4>li:before{content:"\0025cb   "}.lst-kix_efwsvsniz58g-5>li:before{content:"\0025a0   "}.lst-kix_sf1qf9bwyojp-1>li:before{content:"\0025cb   "}.lst-kix_l25ba28sjj7-4>li:before{content:"\0025cb   "}.lst-kix_wdnsgpew1acl-8>li:before{content:"\0025a0   "}.lst-kix_jk6itlvdyknk-8>li:before{content:"\0025a0   "}.lst-kix_vcrwp2bwzubh-5>li:before{content:"\0025a0   "}.lst-kix_xclf8ew5xwnq-7>li:before{content:"\0025cb   "}.lst-kix_efwsvsniz58g-7>li:before{content:"\0025cb   "}.lst-kix_hdkieo28r82q-8>li:before{content:"\0025a0   "}.lst-kix_l25ba28sjj7-6>li:before{content:"\0025cf   "}.lst-kix_wdnsgpew1acl-4>li:before{content:"\0025cb   "}.lst-kix_efwsvsniz58g-1>li:before{content:"\0025cb   "}.lst-kix_t75jqyambp7u-4>li:before{content:"\0025cb   "}.lst-kix_6jxu4l7p3d4o-3>li:before{content:"\0025cf   "}.lst-kix_t75jqyambp7u-2>li:before{content:"\0025a0   "}.lst-kix_4vyaz9wpvlga-8>li:before{content:"\0025a0   "}.lst-kix_wdnsgpew1acl-2>li:before{content:"\0025a0   "}.lst-kix_vcrwp2bwzubh-1>li:before{content:"\0025cb   "}.lst-kix_ek5wwvmsnqx1-3>li:before{content:"\0025cf   "}ul.lst-kix_54yn6dknd642-8{list-style-type:none}.lst-kix_87g5rwruaqks-6>li:before{content:"\0025cf   "}ul.lst-kix_54yn6dknd642-6{list-style-type:none}ul.lst-kix_54yn6dknd642-7{list-style-type:none}.lst-kix_qyngqrxks4hj-8>li:before{content:"\0025a0   "}.lst-kix_p0wl0w4s0sa-1>li:before{content:"\0025cb   "}ul.lst-kix_54yn6dknd642-4{list-style-type:none}ul.lst-kix_8ljhu9hqkk7j-8{list-style-type:none}ul.lst-kix_54yn6dknd642-5{list-style-type:none}ul.lst-kix_8ljhu9hqkk7j-7{list-style-type:none}.lst-kix_ek5wwvmsnqx1-7>li:before{content:"\0025cb   "}ul.lst-kix_54yn6dknd642-2{list-style-type:none}ul.lst-kix_8ljhu9hqkk7j-6{list-style-type:none}ul.lst-kix_54yn6dknd642-3{list-style-type:none}ul.lst-kix_8ljhu9hqkk7j-5{list-style-type:none}ul.lst-kix_54yn6dknd642-0{list-style-type:none}.lst-kix_az8p3db80uc9-3>li:before{content:"\0025cf   "}.lst-kix_hvoiym2mrtz4-6>li:before{content:"\0025cf   "}ul.lst-kix_8ljhu9hqkk7j-4{list-style-type:none}ul.lst-kix_54yn6dknd642-1{list-style-type:none}ul.lst-kix_8ljhu9hqkk7j-3{list-style-type:none}ul.lst-kix_8ljhu9hqkk7j-2{list-style-type:none}.lst-kix_6zz37ot1aoo-2>li:before{content:"\0025a0   "}ul.lst-kix_8ljhu9hqkk7j-1{list-style-type:none}ul.lst-kix_8ljhu9hqkk7j-0{list-style-type:none}.lst-kix_g4octshi0erf-3>li:before{content:"\0025cf   "}.lst-kix_1m661ata3am9-6>li:before{content:"\0025cf   "}.lst-kix_cqp59gjcdgvg-8>li:before{content:"\0025a0   "}.lst-kix_87g5rwruaqks-0>li:before{content:"\0025cf   "}.lst-kix_53eqpuuodt5v-8>li:before{content:"\0025a0   "}.lst-kix_wsfytj8n987p-3>li:before{content:"\0025cf   "}.lst-kix_wsfytj8n987p-7>li:before{content:"\0025cb   "}.lst-kix_c2b60wgdja8r-7>li:before{content:"\0025cb   "}.lst-kix_4vyaz9wpvlga-2>li:before{content:"\0025a0   "}ul.lst-kix_8qeqm584pmza-5{list-style-type:none}ul.lst-kix_8qeqm584pmza-4{list-style-type:none}.lst-kix_7noh502jhq1p-6>li:before{content:"\0025cf   "}ul.lst-kix_8qeqm584pmza-7{list-style-type:none}.lst-kix_dii13kfyl9ma-3>li:before{content:"\0025cf   "}ul.lst-kix_8qeqm584pmza-6{list-style-type:none}ul.lst-kix_8qeqm584pmza-8{list-style-type:none}.lst-kix_3cigoxtebeue-2>li:before{content:"\0025a0   "}ul.lst-kix_epmllfkx8tp-0{list-style-type:none}ul.lst-kix_epmllfkx8tp-1{list-style-type:none}.lst-kix_9vnfdb4co7p6-6>li:before{content:"\0025cf   "}.lst-kix_6m7znixdz235-5>li:before{content:"\0025a0   "}ul.lst-kix_epmllfkx8tp-4{list-style-type:none}ul.lst-kix_epmllfkx8tp-5{list-style-type:none}ul.lst-kix_epmllfkx8tp-2{list-style-type:none}.lst-kix_dmlj8k237tx2-0>li:before{content:"\0025a0   "}ul.lst-kix_epmllfkx8tp-3{list-style-type:none}ul.lst-kix_epmllfkx8tp-8{list-style-type:none}.lst-kix_f539m7fvzj9k-2>li:before{content:"\0025a0   "}ul.lst-kix_epmllfkx8tp-6{list-style-type:none}ul.lst-kix_epmllfkx8tp-7{list-style-type:none}.lst-kix_rj0mmf4fl3tb-2>li:before{content:"\0025a0   "}.lst-kix_rj0mmf4fl3tb-6>li:before{content:"\0025cf   "}.lst-kix_4j92pbqgy1h-5>li:before{content:"\0025a0   "}.lst-kix_bm3nprf82w8o-7>li:before{content:"\0025cb   "}ul.lst-kix_8qeqm584pmza-1{list-style-type:none}.lst-kix_6zz37ot1aoo-6>li:before{content:"\0025cf   "}.lst-kix_d74axqjz5yj6-8>li:before{content:"\0025a0   "}ul.lst-kix_8qeqm584pmza-0{list-style-type:none}ul.lst-kix_8qeqm584pmza-3{list-style-type:none}ul.lst-kix_8qeqm584pmza-2{list-style-type:none}.lst-kix_g4octshi0erf-7>li:before{content:"\0025cb   "}.lst-kix_l555prmkzand-7>li:before{content:"\0025cb   "}.lst-kix_45gqldd6ykix-6>li:before{content:"\0025cf   "}.lst-kix_qx6x5q8dhn22-2>li:before{content:"\0025a0   "}.lst-kix_ehfx5m3tdqyv-1>li:before{content:"\0025cb   "}.lst-kix_hw08zzin6mm8-0>li:before{content:"\0025cf   "}.lst-kix_podkn7p9liyz-3>li:before{content:"\0025cf   "}.lst-kix_9cjyjkedxdni-5>li:before{content:"\0025a0   "}.lst-kix_tzrck1qfmyqd-7>li:before{content:"\0025cb   "}.lst-kix_lhigxpi4bbt5-6>li:before{content:"\0025cf   "}.lst-kix_l555prmkzand-3>li:before{content:"\0025cf   "}.lst-kix_j9krs4wwadz8-7>li:before{content:"\0025cb   "}.lst-kix_w9ot5xs5iuad-3>li:before{content:"\0025cf   "}.lst-kix_dmlj8k237tx2-8>li:before{content:"\0025a0   "}ul.lst-kix_txo0zcn8hx7-6{list-style-type:none}ul.lst-kix_txo0zcn8hx7-7{list-style-type:none}.lst-kix_ie13bttc6n1-7>li:before{content:"\0025cb   "}ul.lst-kix_txo0zcn8hx7-8{list-style-type:none}.lst-kix_mn5hganrvuk0-7>li:before{content:"\0025cb   "}ul.lst-kix_txo0zcn8hx7-2{list-style-type:none}ul.lst-kix_txo0zcn8hx7-3{list-style-type:none}.lst-kix_crntwpm3ewxb-5>li:before{content:"\0025a0   "}ul.lst-kix_txo0zcn8hx7-4{list-style-type:none}.lst-kix_lhigxpi4bbt5-2>li:before{content:"\0025a0   "}ul.lst-kix_txo0zcn8hx7-5{list-style-type:none}ul.lst-kix_txo0zcn8hx7-0{list-style-type:none}.lst-kix_d74axqjz5yj6-0>li:before{content:"\0025cf   "}ul.lst-kix_txo0zcn8hx7-1{list-style-type:none}.lst-kix_bo1j5nej66rh-7>li:before{content:"-  "}.lst-kix_2tcxxdhwr5nc-4>li:before{content:"\0025cb   "}.lst-kix_rdl0mbsx7m1b-7>li:before{content:"\0025cb   "}ul.lst-kix_nn0h438aq2o5-0{list-style-type:none}ul.lst-kix_nn0h438aq2o5-1{list-style-type:none}.lst-kix_ey106e39uxys-3>li:before{content:"\0025cf   "}.lst-kix_45zyqca0dor3-6>li:before{content:"\0025cf   "}.lst-kix_qkmj4hklqu51-0>li:before{content:"\0025cf   "}ul.lst-kix_nn0h438aq2o5-6{list-style-type:none}ul.lst-kix_nn0h438aq2o5-7{list-style-type:none}ul.lst-kix_nn0h438aq2o5-8{list-style-type:none}.lst-kix_c6t6pz4sgcyt-6>li:before{content:"\0025cf   "}ul.lst-kix_nn0h438aq2o5-2{list-style-type:none}ul.lst-kix_nn0h438aq2o5-3{list-style-type:none}.lst-kix_i0yf1mju0g1s-5>li:before{content:"\0025a0   "}ul.lst-kix_nn0h438aq2o5-4{list-style-type:none}ul.lst-kix_nn0h438aq2o5-5{list-style-type:none}.lst-kix_srupee17v0mb-2>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-2,lower-roman) ". "}.lst-kix_hw08zzin6mm8-8>li:before{content:"\0025a0   "}.lst-kix_codfi3rttsmj-1>li:before{content:"\0025cb   "}.lst-kix_b966qb5z56w2-6>li:before{content:"\0025cf   "}.lst-kix_8qkhix9sdgh8-3>li:before{content:"\0025cf   "}.lst-kix_dk6ingbu8z4-7>li:before{content:"\0025cb   "}.lst-kix_dk6ingbu8z4-3>li:before{content:"\0025cf   "}.lst-kix_1oywm8db5jne-3>li:before{content:"\0025cf   "}.lst-kix_nn0h438aq2o5-8>li:before{content:"\0025a0   "}.lst-kix_l2qc0wi8rc8e-6>li:before{content:"\0025cf   "}.lst-kix_4qgjp0e8yt8m-5>li:before{content:"\0025a0   "}.lst-kix_mo5grncnzemi-0>li:before{content:"\0025cf   "}.lst-kix_gxvla3x57ko6-6>li:before{content:"\0025cf   "}.lst-kix_a130djrb9y6e-4>li:before{content:"\0025cb   "}.lst-kix_4wi60e30t59b-0>li:before{content:"\0025cf   "}.lst-kix_l5sge8zce4vp-3>li:before{content:"\0025cf   "}.lst-kix_l5sge8zce4vp-7>li:before{content:"\0025cb   "}.lst-kix_qkmj4hklqu51-8>li:before{content:"\0025a0   "}.lst-kix_lojbu18a3l9-3>li:before{content:"\0025cf   "}.lst-kix_3uimjn60qjnx-4>li:before{content:"\0025cb   "}.lst-kix_4u8tsqm7y9op-8>li:before{content:"\0025a0   "}.lst-kix_fktfq9ltsq98-3>li:before{content:"-  "}.lst-kix_3jdd6arud0e0-6>li:before{content:"\0025cf   "}.lst-kix_lojbu18a3l9-7>li:before{content:"\0025cb   "}.lst-kix_idsnzgd8q5di-6>li:before{content:"\0025cf   "}.lst-kix_mglb6ei1fc9r-6>li:before{content:"\0025cf   "}.lst-kix_apk8f490x7qb-0>li:before{content:"\0025cf   "}.lst-kix_m4siyyggc8wg-2>li:before{content:"\0025a0   "}ul.lst-kix_r2llq4i0x498-8{list-style-type:none}ul.lst-kix_r2llq4i0x498-5{list-style-type:none}ul.lst-kix_r2llq4i0x498-4{list-style-type:none}ul.lst-kix_r2llq4i0x498-7{list-style-type:none}ul.lst-kix_r2llq4i0x498-6{list-style-type:none}.lst-kix_mo5grncnzemi-8>li:before{content:"\0025a0   "}ul.lst-kix_r2llq4i0x498-1{list-style-type:none}ul.lst-kix_r2llq4i0x498-0{list-style-type:none}ul.lst-kix_r2llq4i0x498-3{list-style-type:none}ul.lst-kix_r2llq4i0x498-2{list-style-type:none}.lst-kix_8pxi403yy138-1>li:before{content:"\0025cb   "}.lst-kix_8979tijdi163-5>li:before{content:"\0025a0   "}.lst-kix_8l5du8p17xdg-3>li:before{content:"\0025cf   "}.lst-kix_lf7onj2nrr7v-1>li:before{content:"\0025cb   "}.lst-kix_mniaj44rhjrq-1>li:before{content:"\0025cb   "}.lst-kix_53eqpuuodt5v-0>li:before{content:"\0025cf   "}.lst-kix_mniaj44rhjrq-5>li:before{content:"\0025a0   "}.lst-kix_mtdb7jqchtcn-4>li:before{content:"\0025cb   "}.lst-kix_gqz270r7o0q1-7>li:before{content:"\0025cb   "}.lst-kix_apk8f490x7qb-8>li:before{content:"\0025a0   "}.lst-kix_9x4yq5ss9tc1-0>li:before{content:"  "}.lst-kix_qyngqrxks4hj-0>li:before{content:"\0025cf   "}.lst-kix_kw4p74ijjapz-1>li:before{content:"\0025cb   "}.lst-kix_thg0lt5umapc-2>li:before{content:"\0025a0   "}.lst-kix_68nz8s40mnx9-6>li:before{content:"\0025cf   "}.lst-kix_4683th2gmjda-4>li:before{content:"\0025cb   "}.lst-kix_gqz270r7o0q1-3>li:before{content:"\0025cf   "}.lst-kix_9io9le2bbu11-5>li:before{content:"\0025a0   "}.lst-kix_nd4cj51qmb1k-5>li:before{content:"\0025a0   "}.lst-kix_2ze49x6dwuyc-6>li:before{content:"\0025cf   "}.lst-kix_qy2pejxz7e1k-2>li:before{content:"\0025a0   "}ul.lst-kix_h8mmrek0o9p9-3{list-style-type:none}ul.lst-kix_h8mmrek0o9p9-2{list-style-type:none}ul.lst-kix_h8mmrek0o9p9-5{list-style-type:none}.lst-kix_mlex94wk5tq-1>li:before{content:"\0025cb   "}ul.lst-kix_h8mmrek0o9p9-4{list-style-type:none}.lst-kix_tx52nn14y93q-6>li:before{content:"\0025cf   "}ul.lst-kix_h8mmrek0o9p9-1{list-style-type:none}ul.lst-kix_h8mmrek0o9p9-0{list-style-type:none}.lst-kix_bbzhpmijr633-8>li:before{content:"\0025a0   "}.lst-kix_npq7lfz9ly6z-8>li:before{content:"\0025a0   "}ul.lst-kix_h8mmrek0o9p9-7{list-style-type:none}ul.lst-kix_h8mmrek0o9p9-6{list-style-type:none}.lst-kix_p6zn1qdl1q6g-6>li:before{content:"\0025cf   "}ul.lst-kix_h8mmrek0o9p9-8{list-style-type:none}.lst-kix_tx52nn14y93q-4>li:before{content:"\0025cb   "}.lst-kix_ktcl1r9scb7w-3>li:before{content:"\0025cf   "}.lst-kix_npq7lfz9ly6z-6>li:before{content:"\0025cf   "}ol.lst-kix_tsc2yqmm539t-0.start{counter-reset:lst-ctn-kix_tsc2yqmm539t-0 0}ul.lst-kix_93x7l69l06zp-7{list-style-type:none}ul.lst-kix_93x7l69l06zp-8{list-style-type:none}ul.lst-kix_93x7l69l06zp-5{list-style-type:none}ul.lst-kix_93x7l69l06zp-6{list-style-type:none}ul.lst-kix_93x7l69l06zp-3{list-style-type:none}.lst-kix_2ze49x6dwuyc-4>li:before{content:"\0025cb   "}ul.lst-kix_93x7l69l06zp-4{list-style-type:none}ul.lst-kix_93x7l69l06zp-1{list-style-type:none}ul.lst-kix_93x7l69l06zp-2{list-style-type:none}ul.lst-kix_93x7l69l06zp-0{list-style-type:none}ul.lst-kix_hc4vnvmn7si1-3{list-style-type:none}.lst-kix_yeuz6sv2qnho-7>li:before{content:"\0025cb   "}ul.lst-kix_hc4vnvmn7si1-4{list-style-type:none}ul.lst-kix_hc4vnvmn7si1-5{list-style-type:none}.lst-kix_e97rs1rrkyjo-7>li:before{content:"\0025cb   "}ul.lst-kix_hc4vnvmn7si1-6{list-style-type:none}.lst-kix_scp6tbbd2fcq-6>li:before{content:"\0025cf   "}.lst-kix_men9lw1a0mnk-1>li:before{content:"\0025cb   "}ul.lst-kix_hc4vnvmn7si1-0{list-style-type:none}.lst-kix_m5vzryjtrruz-7>li:before{content:"\0025cb   "}ul.lst-kix_hc4vnvmn7si1-1{list-style-type:none}ul.lst-kix_hc4vnvmn7si1-2{list-style-type:none}.lst-kix_scp6tbbd2fcq-4>li:before{content:"\0025cb   "}.lst-kix_men9lw1a0mnk-7>li:before{content:"\0025cb   "}.lst-kix_npq7lfz9ly6z-0>li:before{content:"\0025cb   "}.lst-kix_zhnrfbqi7c3p-2>li:before{content:"\0025a0   "}.lst-kix_93x7l69l06zp-2>li:before{content:"\0025a0   "}.lst-kix_p6zn1qdl1q6g-0>li:before{content:"\0025cf   "}.lst-kix_ktcl1r9scb7w-5>li:before{content:"\0025a0   "}.lst-kix_fum98hryzqm2-3>li:before{content:"\0025cf   "}.lst-kix_hugw2gsg69de-5>li:before{content:"\0025a0   "}ul.lst-kix_hc4vnvmn7si1-7{list-style-type:none}ul.lst-kix_hc4vnvmn7si1-8{list-style-type:none}.lst-kix_93x7l69l06zp-4>li:before{content:"\0025cb   "}ul.lst-kix_gqz270r7o0q1-1{list-style-type:none}ul.lst-kix_gqz270r7o0q1-0{list-style-type:none}ul.lst-kix_gqz270r7o0q1-3{list-style-type:none}.lst-kix_fum98hryzqm2-5>li:before{content:"\0025a0   "}ul.lst-kix_gqz270r7o0q1-2{list-style-type:none}ul.lst-kix_gqz270r7o0q1-5{list-style-type:none}ul.lst-kix_gqz270r7o0q1-4{list-style-type:none}ul.lst-kix_gqz270r7o0q1-7{list-style-type:none}ul.lst-kix_gqz270r7o0q1-6{list-style-type:none}.lst-kix_91x2wdjlgwp1-5>li:before{content:"\0025a0   "}.lst-kix_5chsivk2mkzi-5>li:before{content:"\0025a0   "}.lst-kix_gzy546en7hix-5>li:before{content:"\0025a0   "}ul.lst-kix_gqz270r7o0q1-8{list-style-type:none}.lst-kix_gzy546en7hix-3>li:before{content:"\0025cf   "}.lst-kix_4gu29fysjsb-0>li:before{content:"\0025cf   "}.lst-kix_5chsivk2mkzi-3>li:before{content:"\0025cf   "}.lst-kix_by7qhqpvs1r5-2>li:before{content:"\0025a0   "}.lst-kix_by7qhqpvs1r5-4>li:before{content:"\0025cb   "}.lst-kix_r953kfpy79kt-1>li:before{content:"\0025cb   "}.lst-kix_d62vaysn6wq1-2>li:before{content:"\0025a0   "}ul.lst-kix_hvoiym2mrtz4-0{list-style-type:none}ul.lst-kix_hvoiym2mrtz4-1{list-style-type:none}ul.lst-kix_hvoiym2mrtz4-4{list-style-type:none}ul.lst-kix_hvoiym2mrtz4-5{list-style-type:none}ul.lst-kix_hvoiym2mrtz4-2{list-style-type:none}ul.lst-kix_hvoiym2mrtz4-3{list-style-type:none}.lst-kix_o1ljou14zs74-6>li:before{content:"\0025cf   "}ul.lst-kix_hvoiym2mrtz4-8{list-style-type:none}ol.lst-kix_srupee17v0mb-1.start{counter-reset:lst-ctn-kix_srupee17v0mb-1 0}ul.lst-kix_hvoiym2mrtz4-6{list-style-type:none}ul.lst-kix_hvoiym2mrtz4-7{list-style-type:none}.lst-kix_9orpva36zqgw-3>li:before{content:"\0025cf   "}.lst-kix_o1ljou14zs74-8>li:before{content:"\0025a0   "}ul.lst-kix_qymwuf8ggtk1-2{list-style-type:none}ul.lst-kix_qymwuf8ggtk1-3{list-style-type:none}ul.lst-kix_qymwuf8ggtk1-0{list-style-type:none}ul.lst-kix_qymwuf8ggtk1-1{list-style-type:none}.lst-kix_69pm6toa84wm-2>li:before{content:"\0025a0   "}.lst-kix_3sqsdlm3qg3k-1>li:before{content:"\0025cb   "}ul.lst-kix_qymwuf8ggtk1-8{list-style-type:none}ul.lst-kix_qymwuf8ggtk1-6{list-style-type:none}.lst-kix_c4mjpxs5t8z-4>li:before{content:"\0025cb   "}ul.lst-kix_qymwuf8ggtk1-7{list-style-type:none}ul.lst-kix_qymwuf8ggtk1-4{list-style-type:none}ul.lst-kix_qymwuf8ggtk1-5{list-style-type:none}.lst-kix_9sxg1s3wlz7-0>li:before{content:"\0025cf   "}.lst-kix_uekzkb8qvgdk-8>li:before{content:"\0025a0   "}.lst-kix_6omq6vtmahws-6>li:before{content:"\0025cf   "}.lst-kix_3b0ouvydct1b-5>li:before{content:"\0025a0   "}.lst-kix_cfsaqxe055dn-2>li:before{content:"\0025a0   "}.lst-kix_x87etp2vfva3-3>li:before{content:"-  "}.lst-kix_cfsaqxe055dn-0>li:before{content:"\0025cf   "}.lst-kix_o1ljou14zs74-0>li:before{content:"\0025cf   "}.lst-kix_3vhpfjuy7tvg-5>li:before{content:"\0025a0   "}.lst-kix_tclc6bzuyhm-7>li:before{content:"\0025cb   "}.lst-kix_qymwuf8ggtk1-1>li:before{content:"\0025cb   "}.lst-kix_5ov7bblzaw0u-4>li:before{content:"\0025cb   "}.lst-kix_3sqsdlm3qg3k-7>li:before{content:"\0025cb   "}.lst-kix_qymwuf8ggtk1-3>li:before{content:"\0025cf   "}.lst-kix_5ov7bblzaw0u-2>li:before{content:"\0025a0   "}ul.lst-kix_gzy546en7hix-8{list-style-type:none}ul.lst-kix_gzy546en7hix-7{list-style-type:none}ul.lst-kix_hdamu5z1kajk-0{list-style-type:none}ul.lst-kix_hdamu5z1kajk-1{list-style-type:none}ul.lst-kix_hdamu5z1kajk-2{list-style-type:none}ul.lst-kix_hdamu5z1kajk-7{list-style-type:none}.lst-kix_cpaf1rpc28c-5>li:before{content:"\0025a0   "}.lst-kix_brn07ewm5d7x-6>li:before{content:"\0025cf   "}ul.lst-kix_hdamu5z1kajk-8{list-style-type:none}.lst-kix_4xd0kx9tx9nh-2>li:before{content:"\0025a0   "}ul.lst-kix_hdamu5z1kajk-3{list-style-type:none}ul.lst-kix_hdamu5z1kajk-4{list-style-type:none}.lst-kix_8ph4j5309jg1-0>li:before{content:"\0025cf   "}ul.lst-kix_hdamu5z1kajk-5{list-style-type:none}ul.lst-kix_hdamu5z1kajk-6{list-style-type:none}.lst-kix_dbltq7i3dnfs-7>li:before{content:"\0025cb   "}.lst-kix_1l36jc1oov6-8>li:before{content:"\0025a0   "}.lst-kix_4xd0kx9tx9nh-4>li:before{content:"\0025cb   "}.lst-kix_afhhqgs3rfh2-1>li:before{content:"\0025cb   "}ul.lst-kix_a6lqukhx5fat-7{list-style-type:none}.lst-kix_bbzhpmijr633-2>li:before{content:"\0025a0   "}ul.lst-kix_a6lqukhx5fat-8{list-style-type:none}.lst-kix_pp0573v7gp5z-2>li:before{content:"\0025a0   "}.lst-kix_brn07ewm5d7x-4>li:before{content:"\0025cb   "}ul.lst-kix_a6lqukhx5fat-5{list-style-type:none}.lst-kix_mecbkjiqxfnl-1>li:before{content:"\0025cb   "}ul.lst-kix_a6lqukhx5fat-6{list-style-type:none}ul.lst-kix_a6lqukhx5fat-3{list-style-type:none}ul.lst-kix_a6lqukhx5fat-4{list-style-type:none}ul.lst-kix_a6lqukhx5fat-1{list-style-type:none}ul.lst-kix_a6lqukhx5fat-2{list-style-type:none}.lst-kix_gl7fpz1y51y1-7>li:before{content:"\0025cb   "}.lst-kix_lp80c754wvim-7>li:before{content:"\0025cb   "}ul.lst-kix_a6lqukhx5fat-0{list-style-type:none}.lst-kix_qsmqo56xypa0-1>li:before{content:"\0025cb   "}.lst-kix_cfsaqxe055dn-8>li:before{content:"\0025a0   "}.lst-kix_g3e6y0f95n7u-7>li:before{content:"\0025cb   "}.lst-kix_eqjgku92ysne-1>li:before{content:"\0025cb   "}.lst-kix_qsmqo56xypa0-3>li:before{content:"\0025cf   "}.lst-kix_cszf4nosnav1-7>li:before{content:"\0025cb   "}.lst-kix_eqjgku92ysne-7>li:before{content:"\0025cb   "}.lst-kix_3mbe6pf0vyok-4>li:before{content:"\0025cb   "}.lst-kix_w9nfenze7id7-3>li:before{content:"\0025cf   "}.lst-kix_8ph4j5309jg1-6>li:before{content:"\0025cf   "}ul.lst-kix_gzy546en7hix-0{list-style-type:none}.lst-kix_cszf4nosnav1-1>li:before{content:"\0025cb   "}ul.lst-kix_gzy546en7hix-2{list-style-type:none}.lst-kix_87g5rwruaqks-4>li:before{content:"\0025cb   "}ul.lst-kix_gzy546en7hix-1{list-style-type:none}ul.lst-kix_gzy546en7hix-4{list-style-type:none}.lst-kix_dbltq7i3dnfs-1>li:before{content:"\0025cb   "}ul.lst-kix_gzy546en7hix-3{list-style-type:none}.lst-kix_89fkn9gnr9w9-0>li:before{content:"\0025cf   "}ul.lst-kix_gzy546en7hix-6{list-style-type:none}.lst-kix_mecbkjiqxfnl-7>li:before{content:"\0025cb   "}ul.lst-kix_gzy546en7hix-5{list-style-type:none}.lst-kix_qyngqrxks4hj-6>li:before{content:"\0025cf   "}.lst-kix_srupee17v0mb-8>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-8,lower-roman) ". "}.lst-kix_zcy565gabcmu-2>li:before{content:"\0025a0   "}.lst-kix_1m661ata3am9-0>li:before{content:"\0025cf   "}.lst-kix_6zz37ot1aoo-0>li:before{content:"\0025cf   "}.lst-kix_6zz37ot1aoo-8>li:before{content:"\0025a0   "}.lst-kix_xsot34m5j4b-1>li:before{content:"\0025cb   "}.lst-kix_rj0mmf4fl3tb-8>li:before{content:"\0025a0   "}.lst-kix_wsfytj8n987p-1>li:before{content:"\0025cb   "}.lst-kix_p0wl0w4s0sa-7>li:before{content:"\0025cb   "}.lst-kix_5fltblknzo3j-3>li:before{content:"\0025cf   "}.lst-kix_ek5wwvmsnqx1-1>li:before{content:"\0025cb   "}.lst-kix_a6lqukhx5fat-3>li:before{content:"\0025cf   "}.lst-kix_3iyql9jafv7n-5>li:before{content:"\0025a0   "}.lst-kix_c6t6pz4sgcyt-0>li:before{content:"\0025cf   "}ul.lst-kix_w3t6jbyimnfw-0{list-style-type:none}.lst-kix_gxbfiekgqjd6-3>li:before{content:"\0025cf   "}.lst-kix_9l9kjglfjgjz-7>li:before{content:"\0025cb   "}.lst-kix_abg8yi9rye91-0>li:before{content:"\0025cf   "}.lst-kix_g4octshi0erf-1>li:before{content:"\0025cb   "}ul.lst-kix_w3t6jbyimnfw-7{list-style-type:none}ul.lst-kix_w3t6jbyimnfw-8{list-style-type:none}.lst-kix_az8p3db80uc9-5>li:before{content:"\0025a0   "}ul.lst-kix_w3t6jbyimnfw-5{list-style-type:none}ul.lst-kix_w3t6jbyimnfw-6{list-style-type:none}.lst-kix_c2b60wgdja8r-5>li:before{content:"\0025a0   "}ul.lst-kix_w3t6jbyimnfw-3{list-style-type:none}ul.lst-kix_w3t6jbyimnfw-4{list-style-type:none}ul.lst-kix_w3t6jbyimnfw-1{list-style-type:none}.lst-kix_fd670jgoibjs-1>li:before{content:"\0025cb   "}ul.lst-kix_w3t6jbyimnfw-2{list-style-type:none}.lst-kix_bm3nprf82w8o-1>li:before{content:"\0025cb   "}.lst-kix_abg8yi9rye91-8>li:before{content:"\0025a0   "}.lst-kix_1k1th764da5j-6>li:before{content:"\0025cf   "}.lst-kix_vs58j7xf1fh7-5>li:before{content:"\0025a0   "}.lst-kix_rj0mmf4fl3tb-0>li:before{content:"\0025cf   "}.lst-kix_hvoiym2mrtz4-0>li:before{content:"\0025cf   "}ul.lst-kix_mrqrqp74n3id-7{list-style-type:none}.lst-kix_j3ti34irq4rs-5>li:before{content:"\0025a0   "}.lst-kix_dmlj8k237tx2-2>li:before{content:"\0025a0   "}ul.lst-kix_mrqrqp74n3id-8{list-style-type:none}ul.lst-kix_mrqrqp74n3id-5{list-style-type:none}ul.lst-kix_mrqrqp74n3id-6{list-style-type:none}ul.lst-kix_mrqrqp74n3id-3{list-style-type:none}.lst-kix_8pk9oqxklycz-6>li:before{content:"\0025cf   "}ul.lst-kix_mrqrqp74n3id-4{list-style-type:none}ul.lst-kix_mrqrqp74n3id-1{list-style-type:none}.lst-kix_7v1cxulxokc7-4>li:before{content:"\0025cb   "}ul.lst-kix_mrqrqp74n3id-2{list-style-type:none}.lst-kix_4j92pbqgy1h-3>li:before{content:"\0025cf   "}.lst-kix_3cigoxtebeue-4>li:before{content:"\0025cb   "}ul.lst-kix_mrqrqp74n3id-0{list-style-type:none}.lst-kix_izm55n8luwgn-1>li:before{content:"\0025cb   "}.lst-kix_rdl0mbsx7m1b-5>li:before{content:"\0025a0   "}.lst-kix_hw08zzin6mm8-6>li:before{content:"\0025cf   "}.lst-kix_lhigxpi4bbt5-0>li:before{content:"\0025cf   "}.lst-kix_lhigxpi4bbt5-8>li:before{content:"\0025a0   "}.lst-kix_d74axqjz5yj6-2>li:before{content:"\0025a0   "}.lst-kix_qx6x5q8dhn22-8>li:before{content:"\0025a0   "}.lst-kix_ehfx5m3tdqyv-7>li:before{content:"\0025cb   "}.lst-kix_mn5hganrvuk0-5>li:before{content:"\0025a0   "}.lst-kix_pfk02alca94e-1>li:before{content:"\0025cb   "}.lst-kix_w9ot5xs5iuad-5>li:before{content:"\0025a0   "}.lst-kix_hrnpa7no5eg-1>li:before{content:"\0025cb   "}.lst-kix_9vnfdb4co7p6-0>li:before{content:"\0025cf   "}.lst-kix_l555prmkzand-1>li:before{content:"\0025cb   "}.lst-kix_ie13bttc6n1-5>li:before{content:"\0025a0   "}.lst-kix_9cjyjkedxdni-3>li:before{content:"\0025cf   "}.lst-kix_qkmj4hklqu51-2>li:before{content:"\0025a0   "}.lst-kix_o5dtwbk7bxd5-0>li:before{content:"\0025cf   "}.lst-kix_7noh502jhq1p-4>li:before{content:"\0025cb   "}.lst-kix_trs82cplclba-2>li:before{content:"\0025a0   "}.lst-kix_wv60nibffqic-8>li:before{content:"\0025a0   "}.lst-kix_m1mzfy5afs2o-7>li:before{content:"\0025cb   "}.lst-kix_mrqrqp74n3id-3>li:before{content:"\0025cf   "}.lst-kix_kfuatcy312kx-8>li:before{content:"\0025a0   "}.lst-kix_o5dtwbk7bxd5-8>li:before{content:"\0025a0   "}.lst-kix_codfi3rttsmj-3>li:before{content:"\0025cf   "}.lst-kix_6jta2mj2opdj-3>li:before{content:"\0025cf   "}.lst-kix_xsdedfcj27fz-3>li:before{content:"\0025cf   "}ol.lst-kix_tsc2yqmm539t-8.start{counter-reset:lst-ctn-kix_tsc2yqmm539t-8 0}.lst-kix_uu0tjb1960c1-6>li:before{content:"\0025cf   "}.lst-kix_b966qb5z56w2-4>li:before{content:"\0025cb   "}.lst-kix_tsc2yqmm539t-0>li{counter-increment:lst-ctn-kix_tsc2yqmm539t-0}.lst-kix_l5sge8zce4vp-1>li:before{content:"\0025cb   "}.lst-kix_dk6ingbu8z4-1>li:before{content:"\0025cb   "}ul.lst-kix_gxvgspx76nqx-0{list-style-type:none}.lst-kix_whyql51jliaq-3>li:before{content:"\0025cf   "}ul.lst-kix_gxvgspx76nqx-1{list-style-type:none}.lst-kix_gxvgspx76nqx-6>li:before{content:"-  "}.lst-kix_xlixir5f8ikv-5>li:before{content:"\0025a0   "}ul.lst-kix_gxvgspx76nqx-2{list-style-type:none}.lst-kix_fvsyn7dqkka1-4>li:before{content:"\0025cb   "}.lst-kix_wv60nibffqic-0>li:before{content:"\0025cf   "}ul.lst-kix_gxvgspx76nqx-3{list-style-type:none}ul.lst-kix_o9zj68me8yj0-5{list-style-type:none}ul.lst-kix_o9zj68me8yj0-4{list-style-type:none}.lst-kix_r20deuqh30jy-4>li:before{content:"\0025cb   "}ul.lst-kix_o9zj68me8yj0-3{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-8{list-style-type:none}ul.lst-kix_o9zj68me8yj0-2{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-7{list-style-type:none}ul.lst-kix_o9zj68me8yj0-1{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-6{list-style-type:none}ul.lst-kix_o9zj68me8yj0-0{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-5{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-4{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-3{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-2{list-style-type:none}.lst-kix_zhnrfbqi7c3p-8>li:before{content:"\0025a0   "}ul.lst-kix_lhigxpi4bbt5-1{list-style-type:none}ul.lst-kix_lhigxpi4bbt5-0{list-style-type:none}ul.lst-kix_j6b3cjdkd1ra-1{list-style-type:none}.lst-kix_1jsoq3g3afbv-4>li:before{content:"\0025cb   "}ul.lst-kix_o9zj68me8yj0-8{list-style-type:none}ul.lst-kix_j6b3cjdkd1ra-0{list-style-type:none}ul.lst-kix_o9zj68me8yj0-7{list-style-type:none}ul.lst-kix_o9zj68me8yj0-6{list-style-type:none}ul.lst-kix_l2qc0wi8rc8e-4{list-style-type:none}ul.lst-kix_j6b3cjdkd1ra-5{list-style-type:none}.lst-kix_kihk58z8dl9b-1>li:before{content:"\0025cb   "}ul.lst-kix_l2qc0wi8rc8e-3{list-style-type:none}ul.lst-kix_j6b3cjdkd1ra-4{list-style-type:none}.lst-kix_o4w8hr2p0ha-5>li:before{content:"\0025a0   "}ul.lst-kix_l2qc0wi8rc8e-2{list-style-type:none}.lst-kix_o7qc3ia828r4-6>li:before{content:"\0025cf   "}ul.lst-kix_j6b3cjdkd1ra-3{list-style-type:none}ul.lst-kix_l2qc0wi8rc8e-1{list-style-type:none}.lst-kix_a130djrb9y6e-2>li:before{content:"\0025a0   "}ul.lst-kix_j6b3cjdkd1ra-2{list-style-type:none}ul.lst-kix_l2qc0wi8rc8e-0{list-style-type:none}.lst-kix_gxvla3x57ko6-4>li:before{content:"\0025cb   "}.lst-kix_ya0b59jf88o6-6>li:before{content:"\0025cf   "}ul.lst-kix_j6b3cjdkd1ra-8{list-style-type:none}.lst-kix_45zyqca0dor3-0>li:before{content:"\0025cf   "}ul.lst-kix_j6b3cjdkd1ra-7{list-style-type:none}ul.lst-kix_j6b3cjdkd1ra-6{list-style-type:none}.lst-kix_mo5grncnzemi-2>li:before{content:"\0025a0   "}.lst-kix_eh7lncq6en9i-6>li:before{content:"\0025cf   "}ul.lst-kix_l2qc0wi8rc8e-8{list-style-type:none}ul.lst-kix_l2qc0wi8rc8e-7{list-style-type:none}ul.lst-kix_l2qc0wi8rc8e-6{list-style-type:none}.lst-kix_hcwipu97fgnf-2>li:before{content:"\0025a0   "}ul.lst-kix_l2qc0wi8rc8e-5{list-style-type:none}.lst-kix_j9krs4wwadz8-1>li:before{content:"\0025cb   "}.lst-kix_fktfq9ltsq98-5>li:before{content:"-  "}.lst-kix_3g1k0ldodoso-3>li:before{content:"\0025cf   "}.lst-kix_8979tijdi163-3>li:before{content:"\0025cf   "}.lst-kix_m4siyyggc8wg-0>li:before{content:"\0025cf   "}.lst-kix_3jdd6arud0e0-0>li:before{content:"\0025cf   "}.lst-kix_8pxi403yy138-7>li:before{content:"\0025cb   "}.lst-kix_mglb6ei1fc9r-0>li:before{content:"\0025cf   "}.lst-kix_lojbu18a3l9-1>li:before{content:"\0025cb   "}.lst-kix_yoaj41w0jig0-8>li:before{content:"\0025a0   "}.lst-kix_pwl0pufgh6dv-6>li:before{content:"\0025cf   "}.lst-kix_kfa6jji21f4h-2>li:before{content:"\0025a0   "}.lst-kix_apk8f490x7qb-2>li:before{content:"\0025a0   "}.lst-kix_pfbe3x4ba630-4>li:before{content:"\0025cb   "}.lst-kix_mniaj44rhjrq-7>li:before{content:"\0025cb   "}.lst-kix_idsnzgd8q5di-0>li:before{content:"\0025cf   "}ul.lst-kix_gjh3cugwmzpc-0{list-style-type:none}.lst-kix_z4v6nrp70nz7-4>li:before{content:"\0025cb   "}.lst-kix_yoaj41w0jig0-0>li:before{content:"\0025cf   "}ul.lst-kix_wt4lxomyh94s-1{list-style-type:none}ul.lst-kix_wt4lxomyh94s-2{list-style-type:none}ul.lst-kix_wt4lxomyh94s-3{list-style-type:none}.lst-kix_pfidrtjb5lqv-5>li:before{content:"\0025a0   "}ul.lst-kix_wt4lxomyh94s-4{list-style-type:none}ul.lst-kix_wt4lxomyh94s-5{list-style-type:none}ul.lst-kix_wt4lxomyh94s-6{list-style-type:none}.lst-kix_nd4cj51qmb1k-7>li:before{content:"\0025cb   "}ul.lst-kix_wt4lxomyh94s-7{list-style-type:none}ul.lst-kix_wt4lxomyh94s-8{list-style-type:none}.lst-kix_9ynuh6dd4pus-8>li:before{content:"\0025a0   "}.lst-kix_4o6376uieeve-2>li:before{content:"\0025a0   "}.lst-kix_53eqpuuodt5v-6>li:before{content:"\0025cf   "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_kw4p74ijjapz-3>li:before{content:"\0025cf   "}ul.lst-kix_wt4lxomyh94s-0{list-style-type:none}.lst-kix_gqz270r7o0q1-1>li:before{content:"\0025cb   "}ul.lst-kix_gjh3cugwmzpc-8{list-style-type:none}.lst-kix_r2llq4i0x498-6>li:before{content:"\0025cf   "}ul.lst-kix_gjh3cugwmzpc-7{list-style-type:none}.lst-kix_oofi1dgq0nej-0>li:before{content:"\0025cf   "}.lst-kix_9io9le2bbu11-3>li:before{content:"\0025cf   "}.lst-kix_tgtuyk7iugqt-8>li:before{content:"\0025a0   "}ul.lst-kix_gjh3cugwmzpc-6{list-style-type:none}ul.lst-kix_gjh3cugwmzpc-5{list-style-type:none}.lst-kix_mlex94wk5tq-7>li:before{content:"\0025cb   "}ul.lst-kix_gjh3cugwmzpc-4{list-style-type:none}ul.lst-kix_gjh3cugwmzpc-3{list-style-type:none}ul.lst-kix_gjh3cugwmzpc-2{list-style-type:none}ul.lst-kix_gjh3cugwmzpc-1{list-style-type:none}.lst-kix_4knzszhhdok2-4>li:before{content:"\0025cb   "}.lst-kix_4knzszhhdok2-1>li:before{content:"\0025cb   "}.lst-kix_64o9mnu4lnxd-6>li:before{content:"\0025cf   "}.lst-kix_g2wmx2i89hb-8>li:before{content:"\0025a0   "}ul.lst-kix_abg8yi9rye91-2{list-style-type:none}.lst-kix_4knzszhhdok2-7>li:before{content:"\0025cb   "}.lst-kix_64o9mnu4lnxd-3>li:before{content:"\0025cf   "}ul.lst-kix_abg8yi9rye91-3{list-style-type:none}ul.lst-kix_abg8yi9rye91-4{list-style-type:none}ul.lst-kix_abg8yi9rye91-5{list-style-type:none}ul.lst-kix_abg8yi9rye91-6{list-style-type:none}ul.lst-kix_abg8yi9rye91-7{list-style-type:none}ul.lst-kix_abg8yi9rye91-8{list-style-type:none}.lst-kix_bzxxtmx6vbow-4>li:before{content:"\0025cb   "}.lst-kix_du8w67pu7mte-8>li:before{content:"-  "}.lst-kix_u7by882ixwqv-2>li:before{content:"\0025a0   "}.lst-kix_u7by882ixwqv-5>li:before{content:"\0025a0   "}.lst-kix_u6oawcl4nq58-0>li:before{content:"\0025cf   "}.lst-kix_bzxxtmx6vbow-7>li:before{content:"\0025cb   "}.lst-kix_txo0zcn8hx7-8>li:before{content:"\0025a0   "}.lst-kix_yxl9yzqp3bqd-4>li:before{content:"\0025cb   "}.lst-kix_yxl9yzqp3bqd-7>li:before{content:"\0025cb   "}.lst-kix_u7by882ixwqv-8>li:before{content:"\0025a0   "}.lst-kix_u6oawcl4nq58-3>li:before{content:"\0025cf   "}ol.lst-kix_tsc2yqmm539t-6.start{counter-reset:lst-ctn-kix_tsc2yqmm539t-6 0}.lst-kix_j0o0ck7ntjzh-4>li:before{content:"\0025cb   "}.lst-kix_u6oawcl4nq58-6>li:before{content:"\0025cf   "}ul.lst-kix_gu62etns0rjq-7{list-style-type:none}ul.lst-kix_gu62etns0rjq-6{list-style-type:none}ul.lst-kix_gu62etns0rjq-8{list-style-type:none}ul.lst-kix_gu62etns0rjq-3{list-style-type:none}.lst-kix_gjh3cugwmzpc-3>li:before{content:"\0025cf   "}ul.lst-kix_gu62etns0rjq-2{list-style-type:none}.lst-kix_j8606buix1qi-0>li:before{content:"\0025cf   "}ul.lst-kix_gu62etns0rjq-5{list-style-type:none}ul.lst-kix_gu62etns0rjq-4{list-style-type:none}.lst-kix_4lz6xppq9i7h-0>li:before{content:"\0025cf   "}.lst-kix_gjh3cugwmzpc-6>li:before{content:"\0025cf   "}ul.lst-kix_gu62etns0rjq-1{list-style-type:none}.lst-kix_2grrmxr8q0i0-8>li:before{content:"\0025a0   "}ul.lst-kix_gu62etns0rjq-0{list-style-type:none}.lst-kix_s7yi1m4cq9qk-7>li:before{content:"\0025cb   "}.lst-kix_4v5uuo4j022q-3>li:before{content:"\0025cf   "}.lst-kix_24obzjkgjhqt-6>li:before{content:"\0025cf   "}.lst-kix_j0o0ck7ntjzh-7>li:before{content:"\0025cb   "}.lst-kix_s7yi1m4cq9qk-1>li:before{content:"\0025cb   "}.lst-kix_5mcoll6nkdaa-2>li:before{content:"\0025a0   "}.lst-kix_dacire7nzy6o-7>li:before{content:"\0025cb   "}.lst-kix_j8606buix1qi-3>li:before{content:"\0025cf   "}.lst-kix_4v5uuo4j022q-6>li:before{content:"\0025cf   "}.lst-kix_24obzjkgjhqt-3>li:before{content:"\0025cf   "}.lst-kix_trx91tt3i1ee-8>li:before{content:"\0025a0   "}.lst-kix_s7yi1m4cq9qk-4>li:before{content:"\0025cb   "}.lst-kix_dacire7nzy6o-4>li:before{content:"\0025cb   "}ul.lst-kix_4vyaz9wpvlga-0{list-style-type:none}.lst-kix_ujecnpd9ox2a-6>li:before{content:"\0025cf   "}ul.lst-kix_4vyaz9wpvlga-2{list-style-type:none}ul.lst-kix_4vyaz9wpvlga-1{list-style-type:none}ul.lst-kix_4vyaz9wpvlga-4{list-style-type:none}ul.lst-kix_4vyaz9wpvlga-3{list-style-type:none}ul.lst-kix_4vyaz9wpvlga-6{list-style-type:none}ul.lst-kix_4vyaz9wpvlga-5{list-style-type:none}ul.lst-kix_4vyaz9wpvlga-8{list-style-type:none}ul.lst-kix_4vyaz9wpvlga-7{list-style-type:none}.lst-kix_trx91tt3i1ee-5>li:before{content:"\0025a0   "}.lst-kix_qvmzdr2urb9j-7>li:before{content:"\0025cb   "}.lst-kix_gxvgspx76nqx-3>li:before{content:"-  "}.lst-kix_du8w67pu7mte-5>li:before{content:"-  "}.lst-kix_qvmzdr2urb9j-1>li:before{content:"\0025cb   "}.lst-kix_trx91tt3i1ee-2>li:before{content:"\0025a0   "}ul.lst-kix_4qgjp0e8yt8m-0{list-style-type:none}ul.lst-kix_4qgjp0e8yt8m-1{list-style-type:none}ul.lst-kix_4qgjp0e8yt8m-2{list-style-type:none}.lst-kix_ujecnpd9ox2a-0>li:before{content:"\0025cf   "}ul.lst-kix_4qgjp0e8yt8m-3{list-style-type:none}ul.lst-kix_4qgjp0e8yt8m-4{list-style-type:none}.lst-kix_qvmzdr2urb9j-4>li:before{content:"\0025cb   "}ul.lst-kix_abg8yi9rye91-0{list-style-type:none}ul.lst-kix_4qgjp0e8yt8m-5{list-style-type:none}ul.lst-kix_abg8yi9rye91-1{list-style-type:none}ul.lst-kix_4qgjp0e8yt8m-6{list-style-type:none}ul.lst-kix_izsd5g4fgpc-0{list-style-type:none}.lst-kix_gxvgspx76nqx-0>li:before{content:"-  "}ul.lst-kix_4qgjp0e8yt8m-7{list-style-type:none}ul.lst-kix_4qgjp0e8yt8m-8{list-style-type:none}.lst-kix_ujecnpd9ox2a-3>li:before{content:"\0025cf   "}.lst-kix_4v5uuo4j022q-0>li:before{content:"\0025cf   "}.lst-kix_du8w67pu7mte-2>li:before{content:"-  "}ul.lst-kix_izsd5g4fgpc-4{list-style-type:none}.lst-kix_gjh3cugwmzpc-0>li:before{content:"\0025cf   "}ul.lst-kix_izsd5g4fgpc-3{list-style-type:none}ul.lst-kix_izsd5g4fgpc-2{list-style-type:none}ul.lst-kix_izsd5g4fgpc-1{list-style-type:none}ul.lst-kix_izsd5g4fgpc-8{list-style-type:none}ul.lst-kix_izsd5g4fgpc-7{list-style-type:none}.lst-kix_ef6tx1pahaqo-8>li:before{content:"\0025a0   "}ul.lst-kix_izsd5g4fgpc-6{list-style-type:none}ul.lst-kix_izsd5g4fgpc-5{list-style-type:none}ul.lst-kix_izm55n8luwgn-0{list-style-type:none}ul.lst-kix_izm55n8luwgn-1{list-style-type:none}.lst-kix_tsc2yqmm539t-2>li:before{content:"\0025cf   "}ul.lst-kix_jjh106bq03g-2{list-style-type:none}ul.lst-kix_jjh106bq03g-1{list-style-type:none}ul.lst-kix_jjh106bq03g-0{list-style-type:none}.lst-kix_2yb6ynjarz9t-4>li:before{content:"\0025cb   "}.lst-kix_vnj3yd9aagbp-1>li:before{content:"\0025cb   "}.lst-kix_afne6v2lp0be-0>li:before{content:"\0025cf   "}ul.lst-kix_jjh106bq03g-8{list-style-type:none}ul.lst-kix_jjh106bq03g-7{list-style-type:none}ul.lst-kix_jjh106bq03g-6{list-style-type:none}.lst-kix_ef6tx1pahaqo-2>li:before{content:"\0025a0   "}ul.lst-kix_jjh106bq03g-5{list-style-type:none}ul.lst-kix_jjh106bq03g-4{list-style-type:none}ul.lst-kix_jjh106bq03g-3{list-style-type:none}ul.lst-kix_izm55n8luwgn-2{list-style-type:none}.lst-kix_tsc2yqmm539t-5>li{counter-increment:lst-ctn-kix_tsc2yqmm539t-5}ul.lst-kix_izm55n8luwgn-3{list-style-type:none}ul.lst-kix_izm55n8luwgn-4{list-style-type:none}ul.lst-kix_izm55n8luwgn-5{list-style-type:none}ul.lst-kix_izm55n8luwgn-6{list-style-type:none}ul.lst-kix_izm55n8luwgn-7{list-style-type:none}ul.lst-kix_izm55n8luwgn-8{list-style-type:none}.lst-kix_1jsoq3g3afbv-1>li:before{content:"\0025cb   "}.lst-kix_p66sfkc4ny5f-4>li:before{content:"\0025cb   "}.lst-kix_afne6v2lp0be-6>li:before{content:"\0025cf   "}ul.lst-kix_trs82cplclba-0{list-style-type:none}ul.lst-kix_trs82cplclba-1{list-style-type:none}ul.lst-kix_trs82cplclba-2{list-style-type:none}ul.lst-kix_trs82cplclba-3{list-style-type:none}.lst-kix_ag80f2hqwfhx-4>li:before{content:"\0025cb   "}ul.lst-kix_trs82cplclba-4{list-style-type:none}ul.lst-kix_trs82cplclba-5{list-style-type:none}ul.lst-kix_trs82cplclba-6{list-style-type:none}.lst-kix_fnntpv12ge7c-7>li:before{content:"\0025cb   "}ul.lst-kix_trs82cplclba-7{list-style-type:none}.lst-kix_i2eyp2pt4qrz-5>li:before{content:"\0025a0   "}ul.lst-kix_trs82cplclba-8{list-style-type:none}.lst-kix_kihk58z8dl9b-4>li:before{content:"\0025cb   "}.lst-kix_q0wctjb2y8b-0>li:before{content:"\0025cf   "}.lst-kix_saj7a8hkorgr-3>li:before{content:"\0025cf   "}.lst-kix_i94q0a22exrp-6>li:before{content:"\0025cf   "}.lst-kix_fnntpv12ge7c-1>li:before{content:"\0025cb   "}.lst-kix_j6b3cjdkd1ra-3>li:before{content:"\0025cf   "}.lst-kix_tsc2yqmm539t-8>li:before{content:"" counter(lst-ctn-kix_tsc2yqmm539t-8,lower-roman) ". "}.lst-kix_4lz6xppq9i7h-3>li:before{content:"\0025cf   "}.lst-kix_3g1k0ldodoso-6>li:before{content:"\0025cf   "}.lst-kix_cruajxrmao23-1>li:before{content:"\0025cb   "}.lst-kix_ap8rxrqvqt32-6>li:before{content:"\0025cf   "}.lst-kix_ssouwh4l2bgy-2>li:before{content:"\0025a0   "}ul.lst-kix_tgtuyk7iugqt-3{list-style-type:none}.lst-kix_isl8ltogczje-7>li:before{content:"\0025cb   "}ul.lst-kix_tgtuyk7iugqt-2{list-style-type:none}.lst-kix_kviltkqr3kxc-4>li:before{content:"\0025cb   "}ul.lst-kix_tgtuyk7iugqt-1{list-style-type:none}ul.lst-kix_tgtuyk7iugqt-0{list-style-type:none}ul.lst-kix_tgtuyk7iugqt-7{list-style-type:none}ul.lst-kix_tgtuyk7iugqt-6{list-style-type:none}.lst-kix_sp06awf5qvvx-1>li:before{content:"\0025cb   "}ul.lst-kix_tgtuyk7iugqt-5{list-style-type:none}ul.lst-kix_tgtuyk7iugqt-4{list-style-type:none}ul.lst-kix_pvxrwallhhlw-0{list-style-type:none}ul.lst-kix_pvxrwallhhlw-1{list-style-type:none}ul.lst-kix_pvxrwallhhlw-2{list-style-type:none}.lst-kix_kymf5on3p83t-4>li:before{content:"\0025cb   "}.lst-kix_2cqjr2ei92jl-4>li:before{content:"\0025cb   "}ul.lst-kix_pvxrwallhhlw-3{list-style-type:none}ul.lst-kix_tgtuyk7iugqt-8{list-style-type:none}.lst-kix_cruajxrmao23-7>li:before{content:"\0025cb   "}ul.lst-kix_pvxrwallhhlw-4{list-style-type:none}ul.lst-kix_pvxrwallhhlw-5{list-style-type:none}.lst-kix_isl8ltogczje-1>li:before{content:"\0025cb   "}ul.lst-kix_pvxrwallhhlw-6{list-style-type:none}ul.lst-kix_pvxrwallhhlw-7{list-style-type:none}.lst-kix_i94q0a22exrp-0>li:before{content:"\0025cf   "}.lst-kix_pfbe3x4ba630-7>li:before{content:"\0025cb   "}ul.lst-kix_pvxrwallhhlw-8{list-style-type:none}.lst-kix_4nm4szcl7et4-7>li:before{content:"\0025cb   "}.lst-kix_rtxzgybdcpml-8>li:before{content:"\0025a0   "}ul.lst-kix_wsfytj8n987p-3{list-style-type:none}ul.lst-kix_wsfytj8n987p-2{list-style-type:none}.lst-kix_sp06awf5qvvx-7>li:before{content:"\0025cb   "}ul.lst-kix_wsfytj8n987p-5{list-style-type:none}.lst-kix_9ynuh6dd4pus-5>li:before{content:"\0025a0   "}ul.lst-kix_wsfytj8n987p-4{list-style-type:none}ul.lst-kix_wsfytj8n987p-1{list-style-type:none}ul.lst-kix_wsfytj8n987p-0{list-style-type:none}.lst-kix_4nm4szcl7et4-1>li:before{content:"\0025cb   "}.lst-kix_1bifduglsyp2-4>li:before{content:"\0025cb   "}ul.lst-kix_47wl9llpry5i-0{list-style-type:none}ul.lst-kix_47wl9llpry5i-1{list-style-type:none}ul.lst-kix_47wl9llpry5i-2{list-style-type:none}.lst-kix_yxl9yzqp3bqd-1>li:before{content:"\0025cb   "}ul.lst-kix_47wl9llpry5i-3{list-style-type:none}ul.lst-kix_wsfytj8n987p-7{list-style-type:none}ul.lst-kix_47wl9llpry5i-4{list-style-type:none}.lst-kix_txo0zcn8hx7-5>li:before{content:"\0025a0   "}ul.lst-kix_wsfytj8n987p-6{list-style-type:none}ul.lst-kix_47wl9llpry5i-5{list-style-type:none}.lst-kix_bzxxtmx6vbow-1>li:before{content:"\0025cb   "}ul.lst-kix_47wl9llpry5i-6{list-style-type:none}ul.lst-kix_wsfytj8n987p-8{list-style-type:none}ul.lst-kix_j8606buix1qi-6{list-style-type:none}ul.lst-kix_47wl9llpry5i-7{list-style-type:none}ul.lst-kix_45gqldd6ykix-1{list-style-type:none}ul.lst-kix_j8606buix1qi-7{list-style-type:none}ul.lst-kix_47wl9llpry5i-8{list-style-type:none}ul.lst-kix_45gqldd6ykix-2{list-style-type:none}.lst-kix_tgtuyk7iugqt-5>li:before{content:"\0025a0   "}ul.lst-kix_j8606buix1qi-4{list-style-type:none}ul.lst-kix_j8606buix1qi-5{list-style-type:none}ul.lst-kix_45gqldd6ykix-0{list-style-type:none}.lst-kix_zep9qz8je63n-4>li:before{content:"\0025cb   "}ul.lst-kix_j8606buix1qi-2{list-style-type:none}ul.lst-kix_j8606buix1qi-3{list-style-type:none}ul.lst-kix_j8606buix1qi-0{list-style-type:none}ul.lst-kix_j8606buix1qi-1{list-style-type:none}.lst-kix_vnj3yd9aagbp-7>li:before{content:"\0025cb   "}ul.lst-kix_3cigoxtebeue-4{list-style-type:none}ul.lst-kix_3cigoxtebeue-5{list-style-type:none}.lst-kix_rtxzgybdcpml-2>li:before{content:"\0025a0   "}ul.lst-kix_3cigoxtebeue-2{list-style-type:none}ul.lst-kix_45gqldd6ykix-7{list-style-type:none}ul.lst-kix_3cigoxtebeue-3{list-style-type:none}ul.lst-kix_45gqldd6ykix-8{list-style-type:none}ul.lst-kix_3cigoxtebeue-0{list-style-type:none}ul.lst-kix_45gqldd6ykix-5{list-style-type:none}ul.lst-kix_3cigoxtebeue-1{list-style-type:none}ul.lst-kix_45gqldd6ykix-6{list-style-type:none}ul.lst-kix_45gqldd6ykix-3{list-style-type:none}ul.lst-kix_45gqldd6ykix-4{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-4{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-3{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-6{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-5{list-style-type:none}ul.lst-kix_3cigoxtebeue-8{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-0{list-style-type:none}ul.lst-kix_3cigoxtebeue-6{list-style-type:none}.lst-kix_pvxrwallhhlw-2>li:before{content:"\0025a0   "}.lst-kix_xsot34m5j4b-7>li:before{content:"\0025cb   "}ul.lst-kix_fo3xfsyzwa37-2{list-style-type:none}ul.lst-kix_3cigoxtebeue-7{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-1{list-style-type:none}.lst-kix_fd670jgoibjs-7>li:before{content:"\0025cb   "}.lst-kix_54yn6dknd642-5>li:before{content:"\0025a0   "}.lst-kix_yn02lgpxo9se-3>li:before{content:"\0025cf   "}ul.lst-kix_3mbe6pf0vyok-8{list-style-type:none}ul.lst-kix_3mbe6pf0vyok-7{list-style-type:none}ul.lst-kix_3mbe6pf0vyok-6{list-style-type:none}ul.lst-kix_3mbe6pf0vyok-5{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-8{list-style-type:none}.lst-kix_yn02lgpxo9se-6>li:before{content:"\0025cf   "}ul.lst-kix_3mbe6pf0vyok-4{list-style-type:none}ul.lst-kix_fo3xfsyzwa37-7{list-style-type:none}ul.lst-kix_3mbe6pf0vyok-3{list-style-type:none}ul.lst-kix_3mbe6pf0vyok-2{list-style-type:none}.lst-kix_h8mmrek0o9p9-6>li:before{content:"\0025cf   "}ul.lst-kix_3mbe6pf0vyok-1{list-style-type:none}.lst-kix_p75x57uzf1s1-3>li:before{content:"\0025cf   "}ul.lst-kix_3mbe6pf0vyok-0{list-style-type:none}.lst-kix_mx9uog95vz5r-6>li:before{content:"\0025cf   "}.lst-kix_1bifduglsyp2-1>li:before{content:"\0025cb   "}.lst-kix_1k1th764da5j-3>li:before{content:"\0025cf   "}.lst-kix_gu62etns0rjq-3>li:before{content:"\0025cf   "}.lst-kix_gxbfiekgqjd6-6>li:before{content:"\0025cf   "}.lst-kix_1k1th764da5j-0>li:before{content:"\0025cf   "}.lst-kix_p75x57uzf1s1-0>li:before{content:"\0025cf   "}.lst-kix_8pk9oqxklycz-3>li:before{content:"\0025cf   "}.lst-kix_7kr9zis60z3j-4>li:before{content:"\0025cb   "}.lst-kix_gu62etns0rjq-0>li:before{content:"\0025cf   "}ul.lst-kix_isl8ltogczje-0{list-style-type:none}.lst-kix_j6b3cjdkd1ra-0>li:before{content:"\0025cf   "}.lst-kix_pfk02alca94e-7>li:before{content:"\0025cb   "}.lst-kix_7kr9zis60z3j-7>li:before{content:"\0025cb   "}.lst-kix_ap8rxrqvqt32-3>li:before{content:"\0025cf   "}.lst-kix_pfk02alca94e-4>li:before{content:"\0025cb   "}.lst-kix_ap8rxrqvqt32-0>li:before{content:"\0025cf   "}ul.lst-kix_isl8ltogczje-8{list-style-type:none}ul.lst-kix_isl8ltogczje-7{list-style-type:none}ul.lst-kix_isl8ltogczje-6{list-style-type:none}ul.lst-kix_isl8ltogczje-5{list-style-type:none}ul.lst-kix_isl8ltogczje-4{list-style-type:none}ul.lst-kix_isl8ltogczje-3{list-style-type:none}ul.lst-kix_isl8ltogczje-2{list-style-type:none}ul.lst-kix_isl8ltogczje-1{list-style-type:none}.lst-kix_uu0tjb1960c1-3>li:before{content:"\0025cf   "}.lst-kix_trs82cplclba-8>li:before{content:"\0025a0   "}.lst-kix_w3t6jbyimnfw-2>li:before{content:"\0025a0   "}ul.lst-kix_8pk9oqxklycz-5{list-style-type:none}ul.lst-kix_8pk9oqxklycz-4{list-style-type:none}ul.lst-kix_8pk9oqxklycz-3{list-style-type:none}.lst-kix_uu0tjb1960c1-0>li:before{content:"\0025cf   "}ul.lst-kix_8pk9oqxklycz-2{list-style-type:none}ul.lst-kix_8pk9oqxklycz-8{list-style-type:none}ul.lst-kix_8pk9oqxklycz-7{list-style-type:none}ul.lst-kix_8pk9oqxklycz-6{list-style-type:none}.lst-kix_gmr2bu8eavte-3>li:before{content:"\0025cf   "}.lst-kix_q0wctjb2y8b-6>li:before{content:"\0025cf   "}.lst-kix_t1nnqma9pg08-1>li:before{content:"\0025cb   "}.lst-kix_w9krzpl9jsp-8>li:before{content:"\0025a0   "}ul.lst-kix_8pk9oqxklycz-1{list-style-type:none}ul.lst-kix_8pk9oqxklycz-0{list-style-type:none}ul.lst-kix_gmr2bu8eavte-0{list-style-type:none}ul.lst-kix_gmr2bu8eavte-4{list-style-type:none}.lst-kix_o9zj68me8yj0-7>li:before{content:"-  "}ul.lst-kix_gmr2bu8eavte-3{list-style-type:none}ul.lst-kix_gmr2bu8eavte-2{list-style-type:none}.lst-kix_t1nnqma9pg08-4>li:before{content:"\0025cb   "}ul.lst-kix_gmr2bu8eavte-1{list-style-type:none}ul.lst-kix_gmr2bu8eavte-8{list-style-type:none}ul.lst-kix_gmr2bu8eavte-7{list-style-type:none}.lst-kix_9czq3plvi9ig-0>li:before{content:"\0025cf   "}ul.lst-kix_gmr2bu8eavte-6{list-style-type:none}ul.lst-kix_gmr2bu8eavte-5{list-style-type:none}.lst-kix_9czq3plvi9ig-3>li:before{content:"\0025cf   "}.lst-kix_trs82cplclba-5>li:before{content:"\0025a0   "}.lst-kix_2yb6ynjarz9t-7>li:before{content:"\0025cb   "}.lst-kix_o9zj68me8yj0-4>li:before{content:"-  "}.lst-kix_prgyqriqvk4e-6>li:before{content:"\0025cf   "}.lst-kix_9bz6byc4bv0o-2>li:before{content:"\0025a0   "}ol.lst-kix_srupee17v0mb-3.start{counter-reset:lst-ctn-kix_srupee17v0mb-3 0}.lst-kix_54yn6dknd642-2>li:before{content:"\0025a0   "}.lst-kix_xsdedfcj27fz-6>li:before{content:"\0025cf   "}.lst-kix_9orpva36zqgw-6>li:before{content:"\0025cf   "}ul.lst-kix_z4v6nrp70nz7-2{list-style-type:none}ul.lst-kix_z4v6nrp70nz7-1{list-style-type:none}ul.lst-kix_z4v6nrp70nz7-4{list-style-type:none}ul.lst-kix_z4v6nrp70nz7-3{list-style-type:none}.lst-kix_kfuatcy312kx-2>li:before{content:"\0025a0   "}.lst-kix_vnj3yd9aagbp-4>li:before{content:"\0025cb   "}ul.lst-kix_z4v6nrp70nz7-6{list-style-type:none}ul.lst-kix_z4v6nrp70nz7-5{list-style-type:none}ul.lst-kix_z4v6nrp70nz7-8{list-style-type:none}.lst-kix_12ba2se2e37v-8>li:before{content:"\0025a0   "}ul.lst-kix_z4v6nrp70nz7-7{list-style-type:none}ul.lst-kix_w1xl8yxhafp5-3{list-style-type:none}.lst-kix_saj7a8hkorgr-0>li:before{content:"\0025cf   "}ul.lst-kix_w1xl8yxhafp5-2{list-style-type:none}ul.lst-kix_w1xl8yxhafp5-1{list-style-type:none}ul.lst-kix_w1xl8yxhafp5-0{list-style-type:none}ul.lst-kix_w1xl8yxhafp5-7{list-style-type:none}ul.lst-kix_w1xl8yxhafp5-6{list-style-type:none}ul.lst-kix_w1xl8yxhafp5-5{list-style-type:none}ul.lst-kix_w1xl8yxhafp5-4{list-style-type:none}.lst-kix_1grzdb2vlz2q-7>li:before{content:"\0025cb   "}ul.lst-kix_w1xl8yxhafp5-8{list-style-type:none}.lst-kix_izsd5g4fgpc-3>li:before{content:"\0025cf   "}.lst-kix_c4mjpxs5t8z-7>li:before{content:"\0025cb   "}.lst-kix_tgtuyk7iugqt-2>li:before{content:"\0025a0   "}.lst-kix_i2eyp2pt4qrz-8>li:before{content:"\0025a0   "}.lst-kix_rjpi34omqxus-7>li:before{content:"\0025cb   "}.lst-kix_fnntpv12ge7c-4>li:before{content:"\0025cb   "}.lst-kix_x87etp2vfva3-0>li:before{content:"-  "}.lst-kix_pp0573v7gp5z-5>li:before{content:"\0025a0   "}.lst-kix_q0wctjb2y8b-3>li:before{content:"\0025cf   "}ul.lst-kix_z0m8tzh04abu-2{list-style-type:none}ul.lst-kix_z0m8tzh04abu-3{list-style-type:none}ul.lst-kix_z0m8tzh04abu-4{list-style-type:none}.lst-kix_dacire7nzy6o-1>li:before{content:"\0025cb   "}.lst-kix_gmr2bu8eavte-6>li:before{content:"\0025cf   "}ul.lst-kix_z0m8tzh04abu-5{list-style-type:none}ul.lst-kix_z0m8tzh04abu-6{list-style-type:none}ul.lst-kix_z0m8tzh04abu-7{list-style-type:none}.lst-kix_9sxg1s3wlz7-3>li:before{content:"\0025cf   "}ul.lst-kix_z0m8tzh04abu-8{list-style-type:none}.lst-kix_i94q0a22exrp-3>li:before{content:"\0025cf   "}ul.lst-kix_snh8lpyqaleg-0{list-style-type:none}.lst-kix_uekzkb8qvgdk-5>li:before{content:"\0025a0   "}.lst-kix_3vhpfjuy7tvg-8>li:before{content:"\0025a0   "}ul.lst-kix_snh8lpyqaleg-4{list-style-type:none}ul.lst-kix_snh8lpyqaleg-3{list-style-type:none}.lst-kix_kihk58z8dl9b-7>li:before{content:"\0025cb   "}ul.lst-kix_z0m8tzh04abu-0{list-style-type:none}ul.lst-kix_snh8lpyqaleg-2{list-style-type:none}.lst-kix_tsc2yqmm539t-5>li:before{content:"" counter(lst-ctn-kix_tsc2yqmm539t-5,lower-roman) ". "}ul.lst-kix_z0m8tzh04abu-1{list-style-type:none}ul.lst-kix_snh8lpyqaleg-1{list-style-type:none}ul.lst-kix_snh8lpyqaleg-8{list-style-type:none}.lst-kix_p66sfkc4ny5f-7>li:before{content:"\0025cb   "}.lst-kix_ya0b59jf88o6-0>li:before{content:"\0025cf   "}ul.lst-kix_snh8lpyqaleg-7{list-style-type:none}ul.lst-kix_snh8lpyqaleg-6{list-style-type:none}ul.lst-kix_snh8lpyqaleg-5{list-style-type:none}.lst-kix_ag80f2hqwfhx-7>li:before{content:"\0025cb   "}ul.lst-kix_z4v6nrp70nz7-0{list-style-type:none}.lst-kix_qzdp8v5qa4kd-2>li:before{content:"\0025a0   "}.lst-kix_e3cxiuksdiku-5>li:before{content:"\0025a0   "}ul.lst-kix_hcwipu97fgnf-8{list-style-type:none}.lst-kix_7fftgdac6j6-6>li:before{content:"\0025cf   "}.lst-kix_gl7fpz1y51y1-4>li:before{content:"\0025cb   "}.lst-kix_lp80c754wvim-4>li:before{content:"\0025cb   "}.lst-kix_yeuz6sv2qnho-1>li:before{content:"\0025cb   "}.lst-kix_kymf5on3p83t-1>li:before{content:"\0025cb   "}.lst-kix_8pk9oqxklycz-0>li:before{content:"\0025cf   "}.lst-kix_w1xl8yxhafp5-4>li:before{content:"\0025cb   "}ul.lst-kix_hcwipu97fgnf-6{list-style-type:none}.lst-kix_sp06awf5qvvx-4>li:before{content:"\0025cb   "}.lst-kix_2cqjr2ei92jl-1>li:before{content:"\0025cb   "}ul.lst-kix_hcwipu97fgnf-7{list-style-type:none}ul.lst-kix_hcwipu97fgnf-4{list-style-type:none}ul.lst-kix_hcwipu97fgnf-5{list-style-type:none}ul.lst-kix_hcwipu97fgnf-2{list-style-type:none}.lst-kix_9ynuh6dd4pus-2>li:before{content:"\0025a0   "}ul.lst-kix_hcwipu97fgnf-3{list-style-type:none}ul.lst-kix_hcwipu97fgnf-0{list-style-type:none}ul.lst-kix_hcwipu97fgnf-1{list-style-type:none}ol.lst-kix_srupee17v0mb-7.start{counter-reset:lst-ctn-kix_srupee17v0mb-7 0}.lst-kix_rtxzgybdcpml-5>li:before{content:"\0025a0   "}.lst-kix_89fkn9gnr9w9-3>li:before{content:"\0025cf   "}.lst-kix_o7qc3ia828r4-0>li:before{content:"\0025cf   "}.lst-kix_eh7lncq6en9i-0>li:before{content:"\0025cf   "}.lst-kix_oofi1dgq0nej-6>li:before{content:"\0025cf   "}.lst-kix_4o6376uieeve-8>li:before{content:"\0025a0   "}.lst-kix_kizzdizga4v0-3>li:before{content:"\0025cf   "}.lst-kix_zcy565gabcmu-8>li:before{content:"\0025a0   "}ul.lst-kix_dmlj8k237tx2-7{list-style-type:none}.lst-kix_64o9mnu4lnxd-0>li:before{content:"\0025cf   "}ul.lst-kix_dmlj8k237tx2-8{list-style-type:none}.lst-kix_g3e6y0f95n7u-4>li:before{content:"\0025cb   "}ul.lst-kix_dmlj8k237tx2-0{list-style-type:none}ul.lst-kix_dmlj8k237tx2-1{list-style-type:none}ul.lst-kix_dmlj8k237tx2-2{list-style-type:none}.lst-kix_kviltkqr3kxc-7>li:before{content:"\0025cb   "}ul.lst-kix_dmlj8k237tx2-3{list-style-type:none}ul.lst-kix_dmlj8k237tx2-4{list-style-type:none}ul.lst-kix_dmlj8k237tx2-5{list-style-type:none}.lst-kix_zep9qz8je63n-1>li:before{content:"\0025cb   "}ul.lst-kix_dmlj8k237tx2-6{list-style-type:none}.lst-kix_thjul0jak92m-7>li:before{content:"\0025cb   "}.lst-kix_r953kfpy79kt-7>li:before{content:"\0025cb   "}.lst-kix_thjul0jak92m-4>li:before{content:"\0025cb   "}.lst-kix_z0m8tzh04abu-1>li:before{content:"\0025cb   "}.lst-kix_up6yrorns79d-8>li:before{content:"\0025a0   "}.lst-kix_qy2pejxz7e1k-8>li:before{content:"\0025a0   "}.lst-kix_z0m8tzh04abu-4>li:before{content:"\0025cb   "}.lst-kix_up6yrorns79d-5>li:before{content:"\0025a0   "}.lst-kix_hc4vnvmn7si1-4>li:before{content:"\0025cb   "}.lst-kix_bhoq2060wyww-4>li:before{content:"\0025cb   "}.lst-kix_8l5du8p17xdg-6>li:before{content:"\0025cf   "}.lst-kix_up6yrorns79d-2>li:before{content:"\0025a0   "}.lst-kix_bhoq2060wyww-7>li:before{content:"\0025cb   "}.lst-kix_hc4vnvmn7si1-1>li:before{content:"\0025cb   "}.lst-kix_asvfnufot7md-5>li:before{content:"\0025a0   "}.lst-kix_bhoq2060wyww-1>li:before{content:"\0025cb   "}ul.lst-kix_1oywm8db5jne-8{list-style-type:none}.lst-kix_a0n7j7tvxmqv-3>li:before{content:"\0025cf   "}.lst-kix_a0n7j7tvxmqv-6>li:before{content:"\0025cf   "}ul.lst-kix_1oywm8db5jne-1{list-style-type:none}ul.lst-kix_1oywm8db5jne-0{list-style-type:none}ul.lst-kix_1oywm8db5jne-3{list-style-type:none}ul.lst-kix_1oywm8db5jne-2{list-style-type:none}ul.lst-kix_1oywm8db5jne-5{list-style-type:none}ul.lst-kix_1oywm8db5jne-4{list-style-type:none}ul.lst-kix_1oywm8db5jne-7{list-style-type:none}ul.lst-kix_1oywm8db5jne-6{list-style-type:none}.lst-kix_s0kih9e12ax-6>li:before{content:"\0025cf   "}.lst-kix_e97rs1rrkyjo-1>li:before{content:"\0025cb   "}.lst-kix_wwus9q4jjlww-1>li:before{content:"\0025cb   "}.lst-kix_asvfnufot7md-2>li:before{content:"\0025a0   "}.lst-kix_91x2wdjlgwp1-2>li:before{content:"\0025a0   "}.lst-kix_yk9rpx5uikpv-2>li:before{content:"\0025a0   "}.lst-kix_5l7scb4zq2ts-8>li:before{content:"\0025a0   "}ul.lst-kix_ie13bttc6n1-7{list-style-type:none}ul.lst-kix_ie13bttc6n1-8{list-style-type:none}.lst-kix_qzdp8v5qa4kd-8>li:before{content:"\0025a0   "}ul.lst-kix_ie13bttc6n1-5{list-style-type:none}ul.lst-kix_ie13bttc6n1-6{list-style-type:none}.lst-kix_m5vzryjtrruz-1>li:before{content:"\0025cb   "}ul.lst-kix_ie13bttc6n1-3{list-style-type:none}ul.lst-kix_ie13bttc6n1-4{list-style-type:none}ul.lst-kix_ie13bttc6n1-1{list-style-type:none}.lst-kix_a0n7j7tvxmqv-0>li:before{content:"\0025cf   "}ul.lst-kix_ie13bttc6n1-2{list-style-type:none}ul.lst-kix_ie13bttc6n1-0{list-style-type:none}.lst-kix_4gu29fysjsb-6>li:before{content:"\0025cf   "}ul.lst-kix_ktcl1r9scb7w-0{list-style-type:none}ul.lst-kix_ktcl1r9scb7w-1{list-style-type:none}.lst-kix_z0m8tzh04abu-7>li:before{content:"\0025cb   "}ul.lst-kix_ktcl1r9scb7w-2{list-style-type:none}.lst-kix_4gu29fysjsb-3>li:before{content:"\0025cf   "}ul.lst-kix_ktcl1r9scb7w-3{list-style-type:none}.lst-kix_t7dbdae30u9t-3>li:before{content:"\0025cf   "}ul.lst-kix_ktcl1r9scb7w-4{list-style-type:none}.lst-kix_t7dbdae30u9t-0>li:before{content:"\0025cb   "}.lst-kix_wwus9q4jjlww-4>li:before{content:"\0025cb   "}.lst-kix_s0kih9e12ax-3>li:before{content:"\0025cf   "}.lst-kix_d62vaysn6wq1-5>li:before{content:"\0025a0   "}.lst-kix_5l7scb4zq2ts-5>li:before{content:"\0025a0   "}ul.lst-kix_ktcl1r9scb7w-5{list-style-type:none}ul.lst-kix_ktcl1r9scb7w-6{list-style-type:none}ul.lst-kix_ktcl1r9scb7w-7{list-style-type:none}.lst-kix_wwus9q4jjlww-7>li:before{content:"\0025cb   "}.lst-kix_s0kih9e12ax-0>li:before{content:"\0025cf   "}ul.lst-kix_ktcl1r9scb7w-8{list-style-type:none}.lst-kix_47wl9llpry5i-3>li:before{content:"\0025cf   "}.lst-kix_47wl9llpry5i-0>li:before{content:"\0025cf   "}.lst-kix_69pm6toa84wm-8>li:before{content:"\0025a0   "}.lst-kix_8qkhix9sdgh8-6>li:before{content:"\0025cf   "}.lst-kix_1grzdb2vlz2q-4>li:before{content:"\0025cb   "}.lst-kix_jjh106bq03g-5>li:before{content:"\0025a0   "}ul.lst-kix_bm3nprf82w8o-0{list-style-type:none}ul.lst-kix_bm3nprf82w8o-1{list-style-type:none}ul.lst-kix_bm3nprf82w8o-2{list-style-type:none}.lst-kix_d62vaysn6wq1-8>li:before{content:"\0025a0   "}ul.lst-kix_bm3nprf82w8o-7{list-style-type:none}.lst-kix_8ljhu9hqkk7j-6>li:before{content:"\0025cf   "}ul.lst-kix_bm3nprf82w8o-8{list-style-type:none}.lst-kix_izsd5g4fgpc-6>li:before{content:"\0025cf   "}.lst-kix_lf7onj2nrr7v-4>li:before{content:"\0025cb   "}ul.lst-kix_bm3nprf82w8o-3{list-style-type:none}.lst-kix_12ba2se2e37v-5>li:before{content:"\0025a0   "}.lst-kix_6omq6vtmahws-0>li:before{content:"\0025cb   "}ul.lst-kix_bm3nprf82w8o-4{list-style-type:none}ul.lst-kix_bm3nprf82w8o-5{list-style-type:none}ul.lst-kix_bm3nprf82w8o-6{list-style-type:none}.lst-kix_t7dbdae30u9t-6>li:before{content:"\0025cf   "}ul.lst-kix_2mr9vgw3av16-3{list-style-type:none}.lst-kix_pp0573v7gp5z-8>li:before{content:"\0025a0   "}ul.lst-kix_2mr9vgw3av16-2{list-style-type:none}ul.lst-kix_2mr9vgw3av16-1{list-style-type:none}.lst-kix_g5ocf0ak9bci-1>li:before{content:"\0025cb   "}ul.lst-kix_2mr9vgw3av16-0{list-style-type:none}ul.lst-kix_2mr9vgw3av16-7{list-style-type:none}ul.lst-kix_2mr9vgw3av16-6{list-style-type:none}.lst-kix_v38knoi1xqwy-0>li:before{content:"-  "}ul.lst-kix_2mr9vgw3av16-5{list-style-type:none}ul.lst-kix_2mr9vgw3av16-4{list-style-type:none}.lst-kix_ixqfp12krdrg-7>li:before{content:"\0025cb   "}.lst-kix_qzdp8v5qa4kd-5>li:before{content:"\0025a0   "}.lst-kix_4wi60e30t59b-3>li:before{content:"\0025cf   "}.lst-kix_rjpi34omqxus-4>li:before{content:"\0025cb   "}.lst-kix_gl7fpz1y51y1-1>li:before{content:"\0025cb   "}.lst-kix_ixqfp12krdrg-1>li:before{content:"\0025cb   "}.lst-kix_yk9rpx5uikpv-8>li:before{content:"\0025a0   "}.lst-kix_9sxg1s3wlz7-6>li:before{content:"\0025cf   "}ul.lst-kix_2mr9vgw3av16-8{list-style-type:none}.lst-kix_uekzkb8qvgdk-2>li:before{content:"\0025a0   "}.lst-kix_v38knoi1xqwy-6>li:before{content:"-  "}.lst-kix_lp80c754wvim-1>li:before{content:"\0025cb   "}.lst-kix_pvyv30yiwv0n-0>li:before{content:"\0025cf   "}.lst-kix_asvfnufot7md-8>li:before{content:"\0025a0   "}.lst-kix_7fftgdac6j6-3>li:before{content:"\0025cf   "}.lst-kix_4u8tsqm7y9op-5>li:before{content:"\0025a0   "}.lst-kix_gc3eht6946jv-1>li:before{content:"\0025cb   "}.lst-kix_3uimjn60qjnx-1>li:before{content:"\0025cb   "}.lst-kix_e3cxiuksdiku-2>li:before{content:"\0025a0   "}.lst-kix_1l36jc1oov6-2>li:before{content:"\0025a0   "}.lst-kix_5t41ldrjeoj7-2>li:before{content:"\0025a0   "}.lst-kix_7kr9zis60z3j-1>li:before{content:"\0025cb   "}.lst-kix_6m7znixdz235-8>li:before{content:"\0025a0   "}.lst-kix_pvyv30yiwv0n-6>li:before{content:"\0025cf   "}.lst-kix_tclc6bzuyhm-1>li:before{content:"\0025cb   "}.lst-kix_w1xl8yxhafp5-1>li:before{content:"\0025cb   "}ul.lst-kix_g2wmx2i89hb-8{list-style-type:none}.lst-kix_ifg2eqszm6qp-2>li:before{content:"\0025a0   "}.lst-kix_89fkn9gnr9w9-6>li:before{content:"\0025cf   "}.lst-kix_l2qc0wi8rc8e-3>li:before{content:"\0025cf   "}ul.lst-kix_g2wmx2i89hb-0{list-style-type:none}ul.lst-kix_g2wmx2i89hb-1{list-style-type:none}ul.lst-kix_g2wmx2i89hb-2{list-style-type:none}.lst-kix_yvkwax5bonzj-1>li:before{content:"\0025cb   "}.lst-kix_yvkwax5bonzj-7>li:before{content:"\0025cb   "}ul.lst-kix_g2wmx2i89hb-3{list-style-type:none}.lst-kix_nn0h438aq2o5-5>li:before{content:"\0025a0   "}ul.lst-kix_g2wmx2i89hb-4{list-style-type:none}ul.lst-kix_g2wmx2i89hb-5{list-style-type:none}.lst-kix_g3e6y0f95n7u-1>li:before{content:"\0025cb   "}ul.lst-kix_g2wmx2i89hb-6{list-style-type:none}ul.lst-kix_g2wmx2i89hb-7{list-style-type:none}.lst-kix_srupee17v0mb-4>li{counter-increment:lst-ctn-kix_srupee17v0mb-4}.lst-kix_9x4yq5ss9tc1-3>li:before{content:"\0025cf   "}.lst-kix_afhhqgs3rfh2-7>li:before{content:"\0025cb   "}.lst-kix_yn02lgpxo9se-0>li:before{content:"\0025cf   "}.lst-kix_8ljhu9hqkk7j-0>li:before{content:"\0025cf   "}.lst-kix_kizzdizga4v0-0>li:before{content:"\0025cf   "}.lst-kix_pvxrwallhhlw-5>li:before{content:"\0025a0   "}.lst-kix_54yn6dknd642-8>li:before{content:"\0025a0   "}.lst-kix_cqp59gjcdgvg-2>li:before{content:"\0025a0   "}.lst-kix_h8mmrek0o9p9-3>li:before{content:"\0025cf   "}ul.lst-kix_xgrv9tn3a2rg-8{list-style-type:none}.lst-kix_f539m7fvzj9k-8>li:before{content:"\0025a0   "}.lst-kix_w9krzpl9jsp-2>li:before{content:"\0025a0   "}.lst-kix_mx9uog95vz5r-0>li:before{content:"\0025cf   "}.lst-kix_ifg2eqszm6qp-8>li:before{content:"\0025a0   "}.lst-kix_i0yf1mju0g1s-2>li:before{content:"\0025a0   "}.lst-kix_pvxrwallhhlw-8>li:before{content:"\0025a0   "}.lst-kix_i91p7evgzc6j-5>li:before{content:"\0025a0   "}.lst-kix_h55j0o7g1asr-8>li:before{content:"\0025a0   "}.lst-kix_bpsai7a4nzlw-5>li:before{content:"\0025a0   "}ul.lst-kix_5fltblknzo3j-8{list-style-type:none}ul.lst-kix_5fltblknzo3j-7{list-style-type:none}.lst-kix_p75x57uzf1s1-6>li:before{content:"\0025cf   "}ul.lst-kix_5fltblknzo3j-4{list-style-type:none}.lst-kix_mx9uog95vz5r-3>li:before{content:"\0025cf   "}ul.lst-kix_5fltblknzo3j-3{list-style-type:none}ul.lst-kix_5fltblknzo3j-6{list-style-type:none}.lst-kix_i91p7evgzc6j-2>li:before{content:"\0025a0   "}ul.lst-kix_5fltblknzo3j-5{list-style-type:none}ul.lst-kix_5fltblknzo3j-0{list-style-type:none}ul.lst-kix_5fltblknzo3j-2{list-style-type:none}ul.lst-kix_5fltblknzo3j-1{list-style-type:none}ul.lst-kix_mniaj44rhjrq-5{list-style-type:none}ul.lst-kix_xgrv9tn3a2rg-4{list-style-type:none}.lst-kix_bo1j5nej66rh-1>li:before{content:"-  "}ul.lst-kix_mniaj44rhjrq-6{list-style-type:none}ul.lst-kix_xgrv9tn3a2rg-5{list-style-type:none}ul.lst-kix_mniaj44rhjrq-3{list-style-type:none}ul.lst-kix_xgrv9tn3a2rg-6{list-style-type:none}ul.lst-kix_mniaj44rhjrq-4{list-style-type:none}ul.lst-kix_xgrv9tn3a2rg-7{list-style-type:none}ul.lst-kix_mniaj44rhjrq-1{list-style-type:none}ul.lst-kix_xgrv9tn3a2rg-0{list-style-type:none}ul.lst-kix_mniaj44rhjrq-2{list-style-type:none}ul.lst-kix_xgrv9tn3a2rg-1{list-style-type:none}.lst-kix_5t41ldrjeoj7-8>li:before{content:"\0025a0   "}ul.lst-kix_xgrv9tn3a2rg-2{list-style-type:none}.lst-kix_h8mmrek0o9p9-0>li:before{content:"\0025cf   "}ul.lst-kix_mniaj44rhjrq-0{list-style-type:none}.lst-kix_dii13kfyl9ma-6>li:before{content:"\0025cf   "}ul.lst-kix_xgrv9tn3a2rg-3{list-style-type:none}.lst-kix_h55j0o7g1asr-5>li:before{content:"\0025a0   "}.lst-kix_bpsai7a4nzlw-8>li:before{content:"\0025a0   "}.lst-kix_5t41ldrjeoj7-5>li:before{content:"\0025a0   "}ul.lst-kix_mniaj44rhjrq-7{list-style-type:none}ul.lst-kix_mniaj44rhjrq-8{list-style-type:none}.lst-kix_prgyqriqvk4e-0>li:before{content:"\0025cf   "}.lst-kix_tzrck1qfmyqd-4>li:before{content:"\0025cb   "}.lst-kix_gc3eht6946jv-7>li:before{content:"\0025cb   "}.lst-kix_crntwpm3ewxb-2>li:before{content:"\0025a0   "}ul.lst-kix_9vnfdb4co7p6-0{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-5{list-style-type:none}ul.lst-kix_m1mzfy5afs2o-4{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-4{list-style-type:none}ul.lst-kix_m1mzfy5afs2o-3{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-7{list-style-type:none}.lst-kix_9czq3plvi9ig-6>li:before{content:"\0025cf   "}ul.lst-kix_m1mzfy5afs2o-6{list-style-type:none}.lst-kix_bo1j5nej66rh-4>li:before{content:"-  "}ul.lst-kix_dbltq7i3dnfs-6{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-8{list-style-type:none}ul.lst-kix_m1mzfy5afs2o-5{list-style-type:none}.lst-kix_prgyqriqvk4e-3>li:before{content:"\0025cf   "}ul.lst-kix_m1mzfy5afs2o-0{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-8{list-style-type:none}ul.lst-kix_m1mzfy5afs2o-2{list-style-type:none}ul.lst-kix_m1mzfy5afs2o-1{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-3{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-2{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-1{list-style-type:none}.lst-kix_dav1jecmp52o-0>li:before{content:"\0025cf   "}ul.lst-kix_ek5wwvmsnqx1-0{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-1{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-7{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-0{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-6{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-3{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-5{list-style-type:none}ul.lst-kix_dbltq7i3dnfs-2{list-style-type:none}ul.lst-kix_ek5wwvmsnqx1-4{list-style-type:none}ul.lst-kix_9vnfdb4co7p6-1{list-style-type:none}ul.lst-kix_o1ljou14zs74-6{list-style-type:none}ul.lst-kix_9vnfdb4co7p6-2{list-style-type:none}ul.lst-kix_o1ljou14zs74-7{list-style-type:none}ul.lst-kix_9vnfdb4co7p6-3{list-style-type:none}ul.lst-kix_o1ljou14zs74-8{list-style-type:none}ul.lst-kix_9vnfdb4co7p6-4{list-style-type:none}.lst-kix_g5ocf0ak9bci-7>li:before{content:"\0025cb   "}ul.lst-kix_9vnfdb4co7p6-5{list-style-type:none}ul.lst-kix_o1ljou14zs74-2{list-style-type:none}ul.lst-kix_9vnfdb4co7p6-6{list-style-type:none}ul.lst-kix_o1ljou14zs74-3{list-style-type:none}.lst-kix_4wi60e30t59b-6>li:before{content:"\0025cf   "}ul.lst-kix_9vnfdb4co7p6-7{list-style-type:none}ul.lst-kix_o1ljou14zs74-4{list-style-type:none}ul.lst-kix_9vnfdb4co7p6-8{list-style-type:none}ul.lst-kix_o1ljou14zs74-5{list-style-type:none}.lst-kix_o9zj68me8yj0-1>li:before{content:"-  "}.lst-kix_vexpnyyatkbq-8>li:before{content:"\0025a0   "}ul.lst-kix_o1ljou14zs74-0{list-style-type:none}ul.lst-kix_o1ljou14zs74-1{list-style-type:none}.lst-kix_9bz6byc4bv0o-8>li:before{content:"\0025a0   "}ul.lst-kix_9sxg1s3wlz7-7{list-style-type:none}.lst-kix_vexpnyyatkbq-5>li:before{content:"\0025a0   "}ul.lst-kix_9sxg1s3wlz7-8{list-style-type:none}.lst-kix_dg9rb9temrvk-6>li:before{content:"\0025cf   "}.lst-kix_9bz6byc4bv0o-5>li:before{content:"\0025a0   "}ul.lst-kix_9sxg1s3wlz7-3{list-style-type:none}ul.lst-kix_9sxg1s3wlz7-4{list-style-type:none}.lst-kix_gmr2bu8eavte-0>li:before{content:"\0025cf   "}.lst-kix_w9krzpl9jsp-5>li:before{content:"\0025a0   "}ul.lst-kix_9sxg1s3wlz7-5{list-style-type:none}ul.lst-kix_9sxg1s3wlz7-6{list-style-type:none}.lst-kix_w3t6jbyimnfw-5>li:before{content:"\0025a0   "}ul.lst-kix_9sxg1s3wlz7-0{list-style-type:none}.lst-kix_2tcxxdhwr5nc-7>li:before{content:"\0025cb   "}ul.lst-kix_9sxg1s3wlz7-1{list-style-type:none}ul.lst-kix_9sxg1s3wlz7-2{list-style-type:none}ul.lst-kix_m1mzfy5afs2o-8{list-style-type:none}.lst-kix_dav1jecmp52o-3>li:before{content:"\0025cf   "}ul.lst-kix_m1mzfy5afs2o-7{list-style-type:none}.lst-kix_45gqldd6ykix-0>li:before{content:"\0025cf   "}.lst-kix_w3t6jbyimnfw-8>li:before{content:"\0025a0   "}.lst-kix_dg9rb9temrvk-3>li:before{content:"\0025cf   "}.lst-kix_tzrck1qfmyqd-1>li:before{content:"\0025cb   "}.lst-kix_8ljhu9hqkk7j-3>li:before{content:"\0025cf   "}.lst-kix_ef6tx1pahaqo-5>li:before{content:"\0025a0   "}ul.lst-kix_o7qc3ia828r4-0{list-style-type:none}ul.lst-kix_o7qc3ia828r4-1{list-style-type:none}.lst-kix_hefc4tmerznh-7>li:before{content:"\0025cb   "}.lst-kix_47wl9llpry5i-6>li:before{content:"\0025cf   "}.lst-kix_12ba2se2e37v-2>li:before{content:"\0025a0   "}.lst-kix_8qeqm584pmza-2>li:before{content:"\0025a0   "}.lst-kix_xczac0sw8y6a-7>li:before{content:"\0025cb   "}.lst-kix_jjh106bq03g-8>li:before{content:"\0025a0   "}ul.lst-kix_o7qc3ia828r4-4{list-style-type:none}ul.lst-kix_o7qc3ia828r4-5{list-style-type:none}ul.lst-kix_o7qc3ia828r4-2{list-style-type:none}ul.lst-kix_o7qc3ia828r4-3{list-style-type:none}.lst-kix_2yb6ynjarz9t-1>li:before{content:"\0025cb   "}ul.lst-kix_o7qc3ia828r4-8{list-style-type:none}ul.lst-kix_o7qc3ia828r4-6{list-style-type:none}ul.lst-kix_o7qc3ia828r4-7{list-style-type:none}.lst-kix_ag80f2hqwfhx-1>li:before{content:"\0025cb   "}.lst-kix_g5ocf0ak9bci-4>li:before{content:"\0025cb   "}.lst-kix_lf7onj2nrr7v-7>li:before{content:"\0025cb   "}.lst-kix_v38knoi1xqwy-3>li:before{content:"-  "}.lst-kix_afne6v2lp0be-3>li:before{content:"\0025cf   "}.lst-kix_i2eyp2pt4qrz-2>li:before{content:"\0025a0   "}.lst-kix_yk9rpx5uikpv-5>li:before{content:"\0025a0   "}.lst-kix_2cqjr2ei92jl-7>li:before{content:"\0025cb   "}.lst-kix_saj7a8hkorgr-6>li:before{content:"\0025cf   "}.lst-kix_j6b3cjdkd1ra-6>li:before{content:"\0025cf   "}.lst-kix_ixqfp12krdrg-4>li:before{content:"\0025cb   "}ul.lst-kix_v4vy1dgu53ia-0{list-style-type:none}ul.lst-kix_v4vy1dgu53ia-1{list-style-type:none}ul.lst-kix_v4vy1dgu53ia-2{list-style-type:none}ul.lst-kix_v4vy1dgu53ia-3{list-style-type:none}ul.lst-kix_v4vy1dgu53ia-4{list-style-type:none}ul.lst-kix_v4vy1dgu53ia-5{list-style-type:none}ul.lst-kix_v4vy1dgu53ia-6{list-style-type:none}.lst-kix_1grzdb2vlz2q-1>li:before{content:"\0025cb   "}ul.lst-kix_v4vy1dgu53ia-7{list-style-type:none}ul.lst-kix_v4vy1dgu53ia-8{list-style-type:none}.lst-kix_gc3eht6946jv-4>li:before{content:"\0025cb   "}.lst-kix_9x4yq5ss9tc1-6>li:before{content:"\0025cf   "}ul.lst-kix_o5dtwbk7bxd5-8{list-style-type:none}ul.lst-kix_o5dtwbk7bxd5-7{list-style-type:none}.lst-kix_68nz8s40mnx9-0>li:before{content:"\0025cb   "}ul.lst-kix_o5dtwbk7bxd5-6{list-style-type:none}ul.lst-kix_o5dtwbk7bxd5-5{list-style-type:none}ul.lst-kix_o5dtwbk7bxd5-4{list-style-type:none}.lst-kix_pvyv30yiwv0n-3>li:before{content:"\0025cf   "}ul.lst-kix_cqp59gjcdgvg-7{list-style-type:none}ul.lst-kix_o5dtwbk7bxd5-3{list-style-type:none}ul.lst-kix_cqp59gjcdgvg-8{list-style-type:none}ul.lst-kix_o5dtwbk7bxd5-2{list-style-type:none}ul.lst-kix_o5dtwbk7bxd5-1{list-style-type:none}ul.lst-kix_o5dtwbk7bxd5-0{list-style-type:none}ul.lst-kix_cqp59gjcdgvg-3{list-style-type:none}.lst-kix_4lz6xppq9i7h-6>li:before{content:"\0025cf   "}ul.lst-kix_cqp59gjcdgvg-4{list-style-type:none}.lst-kix_cruajxrmao23-4>li:before{content:"\0025cb   "}ul.lst-kix_cqp59gjcdgvg-5{list-style-type:none}ul.lst-kix_cqp59gjcdgvg-6{list-style-type:none}.lst-kix_kviltkqr3kxc-1>li:before{content:"\0025cb   "}.lst-kix_vwxe3fdqgja8-7>li:before{content:"\0025cb   "}ul.lst-kix_cqp59gjcdgvg-0{list-style-type:none}ul.lst-kix_cqp59gjcdgvg-1{list-style-type:none}.lst-kix_4nm4szcl7et4-4>li:before{content:"\0025cb   "}.lst-kix_4u8tsqm7y9op-2>li:before{content:"\0025a0   "}ul.lst-kix_cqp59gjcdgvg-2{list-style-type:none}.lst-kix_isl8ltogczje-4>li:before{content:"\0025cb   "}.lst-kix_7fftgdac6j6-0>li:before{content:"\0025cf   "}.lst-kix_rjpi34omqxus-1>li:before{content:"\0025cb   "}.lst-kix_yvkwax5bonzj-4>li:before{content:"\0025cb   "}.lst-kix_5uwviijqeog0-5>li:before{content:"\0025a0   "}ul.lst-kix_7v1cxulxokc7-8{list-style-type:none}.lst-kix_hc4vnvmn7si1-7>li:before{content:"\0025cb   "}.lst-kix_ifg2eqszm6qp-5>li:before{content:"\0025a0   "}ul.lst-kix_7v1cxulxokc7-7{list-style-type:none}.lst-kix_l2qc0wi8rc8e-0>li:before{content:"\0025cf   "}.lst-kix_1bifduglsyp2-7>li:before{content:"\0025cb   "}.lst-kix_evcxr39uk36z-0>li:before{content:"\0025cf   "}.lst-kix_nn0h438aq2o5-2>li:before{content:"\0025a0   "}ul.lst-kix_7v1cxulxokc7-6{list-style-type:none}ul.lst-kix_7v1cxulxokc7-5{list-style-type:none}ul.lst-kix_7v1cxulxokc7-4{list-style-type:none}ul.lst-kix_7v1cxulxokc7-3{list-style-type:none}ul.lst-kix_7v1cxulxokc7-2{list-style-type:none}ul.lst-kix_7v1cxulxokc7-1{list-style-type:none}ul.lst-kix_7v1cxulxokc7-0{list-style-type:none}ul.lst-kix_wv60nibffqic-3{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-1{list-style-type:none}ul.lst-kix_wv60nibffqic-2{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-0{list-style-type:none}ul.lst-kix_wv60nibffqic-1{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-3{list-style-type:none}ul.lst-kix_wv60nibffqic-0{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-2{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-0{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-5{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-1{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-4{list-style-type:none}.lst-kix_k4lchlqktts-6>li:before{content:"\0025cf   "}ul.lst-kix_pvyv30yiwv0n-2{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-7{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-3{list-style-type:none}ul.lst-kix_n0ff4gjm91tm-6{list-style-type:none}.lst-kix_ge70ia1l9j2p-6>li:before{content:"\0025cf   "}.lst-kix_t75jqyambp7u-7>li:before{content:"\0025cb   "}.lst-kix_hdamu5z1kajk-2>li:before{content:"-  "}ul.lst-kix_ixqfp12krdrg-7{list-style-type:none}.lst-kix_x803kyc5p3g4-0>li:before{content:"\0025cf   "}ul.lst-kix_ixqfp12krdrg-6{list-style-type:none}ul.lst-kix_ixqfp12krdrg-5{list-style-type:none}ul.lst-kix_ixqfp12krdrg-4{list-style-type:none}.lst-kix_2mr9vgw3av16-7>li:before{content:"\0025cb   "}.lst-kix_jts281wjqw39-5>li:before{content:"\0025a0   "}.lst-kix_nd4cj51qmb1k-0>li:before{content:"  "}.lst-kix_fo3xfsyzwa37-2>li:before{content:"\0025a0   "}ul.lst-kix_ixqfp12krdrg-8{list-style-type:none}ul.lst-kix_afhhqgs3rfh2-0{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-4{list-style-type:none}.lst-kix_x803kyc5p3g4-4>li:before{content:"\0025cb   "}ul.lst-kix_afhhqgs3rfh2-1{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-5{list-style-type:none}.lst-kix_vcrwp2bwzubh-8>li:before{content:"\0025a0   "}ul.lst-kix_n0ff4gjm91tm-8{list-style-type:none}ul.lst-kix_afhhqgs3rfh2-2{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-6{list-style-type:none}ul.lst-kix_afhhqgs3rfh2-3{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-7{list-style-type:none}.lst-kix_thg0lt5umapc-7>li:before{content:"\0025cb   "}ul.lst-kix_afhhqgs3rfh2-4{list-style-type:none}ul.lst-kix_pvyv30yiwv0n-8{list-style-type:none}.lst-kix_8ylfq8z9iqph-6>li:before{content:"\0025cf   "}ul.lst-kix_ixqfp12krdrg-3{list-style-type:none}ul.lst-kix_afhhqgs3rfh2-5{list-style-type:none}ul.lst-kix_ixqfp12krdrg-2{list-style-type:none}ul.lst-kix_afhhqgs3rfh2-6{list-style-type:none}.lst-kix_vbr74uzbiasm-4>li:before{content:"\0025cb   "}ul.lst-kix_ixqfp12krdrg-1{list-style-type:none}ul.lst-kix_afhhqgs3rfh2-7{list-style-type:none}.lst-kix_3ppobcpt0okh-8>li:before{content:"\0025a0   "}ul.lst-kix_ixqfp12krdrg-0{list-style-type:none}.lst-kix_x803kyc5p3g4-8>li:before{content:"\0025a0   "}.lst-kix_jts281wjqw39-1>li:before{content:"\0025cb   "}.lst-kix_hdamu5z1kajk-6>li:before{content:"-  "}.lst-kix_3ppobcpt0okh-4>li:before{content:"\0025cb   "}.lst-kix_8ylfq8z9iqph-2>li:before{content:"\0025a0   "}.lst-kix_vbr74uzbiasm-8>li:before{content:"\0025a0   "}.lst-kix_ge70ia1l9j2p-2>li:before{content:"\0025a0   "}.lst-kix_m4siyyggc8wg-5>li:before{content:"\0025a0   "}.lst-kix_2mr9vgw3av16-3>li:before{content:"\0025cf   "}.lst-kix_d2maxule6lxs-4>li:before{content:"\0025cb   "}.lst-kix_k4lchlqktts-2>li:before{content:"\0025a0   "}.lst-kix_8pxi403yy138-8>li:before{content:"\0025a0   "}ul.lst-kix_wv60nibffqic-8{list-style-type:none}ul.lst-kix_wv60nibffqic-7{list-style-type:none}.lst-kix_3ppobcpt0okh-0>li:before{content:"\0025cf   "}ul.lst-kix_wv60nibffqic-6{list-style-type:none}ul.lst-kix_wv60nibffqic-5{list-style-type:none}ul.lst-kix_wv60nibffqic-4{list-style-type:none}.lst-kix_xgrv9tn3a2rg-8>li:before{content:"\0025a0   "}.lst-kix_4cx6uiey4qy0-7>li:before{content:"\0025cb   "}.lst-kix_xgrv9tn3a2rg-4>li:before{content:"\0025cb   "}.lst-kix_tgfvho118md4-3>li:before{content:"\0025cf   "}.lst-kix_gtofryf4bnby-5>li:before{content:"\0025a0   "}.lst-kix_d2maxule6lxs-8>li:before{content:"\0025a0   "}.lst-kix_tgfvho118md4-7>li:before{content:"\0025cb   "}.lst-kix_y4vuy41h8k5q-0>li:before{content:"\0025cf   "}ul.lst-kix_afhhqgs3rfh2-8{list-style-type:none}ul.lst-kix_6jxu4l7p3d4o-5{list-style-type:none}ul.lst-kix_6jxu4l7p3d4o-6{list-style-type:none}ul.lst-kix_6jxu4l7p3d4o-3{list-style-type:none}ul.lst-kix_6jxu4l7p3d4o-4{list-style-type:none}.lst-kix_y4vuy41h8k5q-4>li:before{content:"\0025cb   "}ul.lst-kix_6jxu4l7p3d4o-7{list-style-type:none}.lst-kix_vbr74uzbiasm-0>li:before{content:"\0025cf   "}ul.lst-kix_6jxu4l7p3d4o-8{list-style-type:none}.lst-kix_xgrv9tn3a2rg-0>li:before{content:"\0025cf   "}ul.lst-kix_6jxu4l7p3d4o-1{list-style-type:none}ul.lst-kix_6jxu4l7p3d4o-2{list-style-type:none}.lst-kix_snh8lpyqaleg-3>li:before{content:"\0025cf   "}.lst-kix_snh8lpyqaleg-7>li:before{content:"\0025cb   "}ul.lst-kix_6jxu4l7p3d4o-0{list-style-type:none}.lst-kix_gtofryf4bnby-1>li:before{content:"\0025cb   "}.lst-kix_y4vuy41h8k5q-8>li:before{content:"\0025a0   "}.lst-kix_b966qb5z56w2-3>li:before{content:"\0025cf   "}ul.lst-kix_n64wxslery5z-8{list-style-type:none}ul.lst-kix_n64wxslery5z-7{list-style-type:none}ul.lst-kix_n64wxslery5z-6{list-style-type:none}ul.lst-kix_n64wxslery5z-5{list-style-type:none}ul.lst-kix_saj7a8hkorgr-8{list-style-type:none}ul.lst-kix_n64wxslery5z-4{list-style-type:none}ul.lst-kix_n64wxslery5z-3{list-style-type:none}ul.lst-kix_saj7a8hkorgr-6{list-style-type:none}ul.lst-kix_n64wxslery5z-2{list-style-type:none}ul.lst-kix_saj7a8hkorgr-7{list-style-type:none}ul.lst-kix_n64wxslery5z-1{list-style-type:none}.lst-kix_5uwviijqeog0-0>li:before{content:"\0025cf   "}ul.lst-kix_n64wxslery5z-0{list-style-type:none}ul.lst-kix_saj7a8hkorgr-0{list-style-type:none}ul.lst-kix_saj7a8hkorgr-1{list-style-type:none}.lst-kix_1oywm8db5jne-2>li:before{content:"\0025a0   "}ul.lst-kix_saj7a8hkorgr-4{list-style-type:none}ul.lst-kix_saj7a8hkorgr-5{list-style-type:none}.lst-kix_gxvla3x57ko6-1>li:before{content:"\0025cb   "}ul.lst-kix_saj7a8hkorgr-2{list-style-type:none}ul.lst-kix_saj7a8hkorgr-3{list-style-type:none}.lst-kix_srupee17v0mb-5>li{counter-increment:lst-ctn-kix_srupee17v0mb-5}ul.lst-kix_vcrwp2bwzubh-8{list-style-type:none}ul.lst-kix_vcrwp2bwzubh-7{list-style-type:none}ul.lst-kix_evcxr39uk36z-8{list-style-type:none}ul.lst-kix_evcxr39uk36z-6{list-style-type:none}.lst-kix_gxvla3x57ko6-5>li:before{content:"\0025a0   "}ul.lst-kix_evcxr39uk36z-7{list-style-type:none}ul.lst-kix_evcxr39uk36z-4{list-style-type:none}.lst-kix_4qgjp0e8yt8m-4>li:before{content:"\0025cb   "}ul.lst-kix_evcxr39uk36z-5{list-style-type:none}ul.lst-kix_evcxr39uk36z-2{list-style-type:none}ul.lst-kix_evcxr39uk36z-3{list-style-type:none}ul.lst-kix_evcxr39uk36z-0{list-style-type:none}ul.lst-kix_evcxr39uk36z-1{list-style-type:none}ul.lst-kix_l5sge8zce4vp-7{list-style-type:none}.lst-kix_qkmj4hklqu51-7>li:before{content:"\0025cb   "}ul.lst-kix_l5sge8zce4vp-8{list-style-type:none}.lst-kix_a130djrb9y6e-3>li:before{content:"\0025cf   "}.lst-kix_a130djrb9y6e-7>li:before{content:"\0025cb   "}ul.lst-kix_vcrwp2bwzubh-6{list-style-type:none}ul.lst-kix_l5sge8zce4vp-1{list-style-type:none}ul.lst-kix_vcrwp2bwzubh-5{list-style-type:none}ul.lst-kix_l5sge8zce4vp-2{list-style-type:none}ul.lst-kix_vcrwp2bwzubh-4{list-style-type:none}ul.lst-kix_vcrwp2bwzubh-3{list-style-type:none}ul.lst-kix_l5sge8zce4vp-0{list-style-type:none}ul.lst-kix_vcrwp2bwzubh-2{list-style-type:none}ul.lst-kix_l5sge8zce4vp-5{list-style-type:none}.lst-kix_4qgjp0e8yt8m-0>li:before{content:"\0025cf   "}ul.lst-kix_vcrwp2bwzubh-1{list-style-type:none}ul.lst-kix_l5sge8zce4vp-6{list-style-type:none}ul.lst-kix_vcrwp2bwzubh-0{list-style-type:none}ul.lst-kix_l5sge8zce4vp-3{list-style-type:none}ul.lst-kix_l5sge8zce4vp-4{list-style-type:none}.lst-kix_lojbu18a3l9-2>li:before{content:"\0025a0   "}.lst-kix_lojbu18a3l9-6>li:before{content:"\0025cf   "}ul.lst-kix_6jta2mj2opdj-0{list-style-type:none}ul.lst-kix_6jta2mj2opdj-1{list-style-type:none}.lst-kix_m4siyyggc8wg-1>li:before{content:"\0025cb   "}ul.lst-kix_6jta2mj2opdj-4{list-style-type:none}ul.lst-kix_6jta2mj2opdj-5{list-style-type:none}.lst-kix_68nz8s40mnx9-1>li:before{content:"\0025cb   "}ul.lst-kix_6jta2mj2opdj-2{list-style-type:none}.lst-kix_mglb6ei1fc9r-7>li:before{content:"\0025cb   "}ul.lst-kix_6jta2mj2opdj-3{list-style-type:none}ul.lst-kix_6jta2mj2opdj-8{list-style-type:none}.lst-kix_8pxi403yy138-4>li:before{content:"\0025cb   "}ul.lst-kix_6jta2mj2opdj-6{list-style-type:none}ul.lst-kix_6jta2mj2opdj-7{list-style-type:none}.lst-kix_mniaj44rhjrq-6>li:before{content:"\0025cf   "}.lst-kix_mglb6ei1fc9r-3>li:before{content:"\0025cf   "}.lst-kix_mtdb7jqchtcn-7>li:before{content:"\0025cb   "}.lst-kix_4683th2gmjda-7>li:before{content:"\0025cb   "}.lst-kix_mniaj44rhjrq-2>li:before{content:"\0025a0   "}ul.lst-kix_g4octshi0erf-3{list-style-type:none}.lst-kix_gqz270r7o0q1-8>li:before{content:"\0025a0   "}ul.lst-kix_g4octshi0erf-4{list-style-type:none}ul.lst-kix_g4octshi0erf-5{list-style-type:none}.lst-kix_1oywm8db5jne-6>li:before{content:"\0025cf   "}ul.lst-kix_g4octshi0erf-6{list-style-type:none}.lst-kix_5uwviijqeog0-8>li:before{content:"\0025a0   "}.lst-kix_nd4cj51qmb1k-8>li:before{content:"\0025a0   "}.lst-kix_5uwviijqeog0-4>li:before{content:"\0025cb   "}.lst-kix_9io9le2bbu11-2>li:before{content:"\0025a0   "}ul.lst-kix_g4octshi0erf-0{list-style-type:none}ul.lst-kix_g4octshi0erf-1{list-style-type:none}.lst-kix_8pxi403yy138-0>li:before{content:"\0025cf   "}.lst-kix_53eqpuuodt5v-1>li:before{content:"\0025cb   "}ul.lst-kix_g4octshi0erf-2{list-style-type:none}.lst-kix_mtdb7jqchtcn-3>li:before{content:"\0025cf   "}.lst-kix_gqz270r7o0q1-0>li:before{content:"\0025cf   "}.lst-kix_thg0lt5umapc-3>li:before{content:"\0025cf   "}.lst-kix_nd4cj51qmb1k-4>li:before{content:"\0025cb   "}.lst-kix_9io9le2bbu11-6>li:before{content:"\0025cf   "}.lst-kix_53eqpuuodt5v-5>li:before{content:"\0025a0   "}.lst-kix_4683th2gmjda-3>li:before{content:"\0025cf   "}.lst-kix_gqz270r7o0q1-4>li:before{content:"\0025cb   "}ul.lst-kix_g4octshi0erf-7{list-style-type:none}.lst-kix_68nz8s40mnx9-5>li:before{content:"\0025a0   "}ul.lst-kix_g4octshi0erf-8{list-style-type:none}.lst-kix_6zz37ot1aoo-5>li:before{content:"\0025a0   "}.lst-kix_ek5wwvmsnqx1-2>li:before{content:"\0025a0   "}.lst-kix_srupee17v0mb-7>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-7,lower-latin) ". "}ul.lst-kix_cpaf1rpc28c-6{list-style-type:none}.lst-kix_6zz37ot1aoo-1>li:before{content:"\0025cb   "}ul.lst-kix_cpaf1rpc28c-7{list-style-type:none}ul.lst-kix_cpaf1rpc28c-8{list-style-type:none}ul.lst-kix_cpaf1rpc28c-2{list-style-type:none}.lst-kix_1m661ata3am9-1>li:before{content:"\0025cb   "}ul.lst-kix_cpaf1rpc28c-3{list-style-type:none}ul.lst-kix_cpaf1rpc28c-4{list-style-type:none}ul.lst-kix_cpaf1rpc28c-5{list-style-type:none}.lst-kix_wsfytj8n987p-2>li:before{content:"\0025a0   "}.lst-kix_wsfytj8n987p-6>li:before{content:"\0025cf   "}.lst-kix_4vyaz9wpvlga-1>li:before{content:"\0025cb   "}.lst-kix_kw4p74ijjapz-8>li:before{content:"\0025a0   "}.lst-kix_1m661ata3am9-5>li:before{content:"\0025a0   "}.lst-kix_9vnfdb4co7p6-3>li:before{content:"\0025cf   "}ul.lst-kix_h00g16e7ufft-8{list-style-type:none}.lst-kix_3cigoxtebeue-5>li:before{content:"\0025a0   "}.lst-kix_i91p7evgzc6j-4>li:before{content:"\0025cb   "}ul.lst-kix_h00g16e7ufft-6{list-style-type:none}.lst-kix_vwxe3fdqgja8-1>li:before{content:"\0025cb   "}ul.lst-kix_h00g16e7ufft-7{list-style-type:none}ul.lst-kix_h00g16e7ufft-4{list-style-type:none}ul.lst-kix_h00g16e7ufft-5{list-style-type:none}.lst-kix_9vnfdb4co7p6-7>li:before{content:"\0025cb   "}ul.lst-kix_h00g16e7ufft-2{list-style-type:none}ul.lst-kix_h00g16e7ufft-3{list-style-type:none}ul.lst-kix_h00g16e7ufft-0{list-style-type:none}.lst-kix_3cigoxtebeue-1>li:before{content:"\0025cb   "}ul.lst-kix_h00g16e7ufft-1{list-style-type:none}.lst-kix_i91p7evgzc6j-0>li:before{content:"\0025cf   "}.lst-kix_6m7znixdz235-6>li:before{content:"\0025cf   "}.lst-kix_bm3nprf82w8o-2>li:before{content:"\0025a0   "}ul.lst-kix_pwl0pufgh6dv-5{list-style-type:none}.lst-kix_5t41ldrjeoj7-7>li:before{content:"\0025cb   "}.lst-kix_dmlj8k237tx2-3>li:before{content:"\0025cf   "}ul.lst-kix_pwl0pufgh6dv-4{list-style-type:none}ul.lst-kix_pwl0pufgh6dv-7{list-style-type:none}ul.lst-kix_cpaf1rpc28c-0{list-style-type:none}ul.lst-kix_pwl0pufgh6dv-6{list-style-type:none}ul.lst-kix_cpaf1rpc28c-1{list-style-type:none}ul.lst-kix_pwl0pufgh6dv-1{list-style-type:none}ul.lst-kix_pwl0pufgh6dv-0{list-style-type:none}ul.lst-kix_pwl0pufgh6dv-3{list-style-type:none}ul.lst-kix_pwl0pufgh6dv-2{list-style-type:none}.lst-kix_d74axqjz5yj6-7>li:before{content:"\0025cb   "}.lst-kix_6m7znixdz235-2>li:before{content:"\0025a0   "}ul.lst-kix_pwl0pufgh6dv-8{list-style-type:none}.lst-kix_bm3nprf82w8o-6>li:before{content:"\0025cf   "}.lst-kix_crntwpm3ewxb-0>li:before{content:"\0025cf   "}.lst-kix_w9ot5xs5iuad-8>li:before{content:"\0025a0   "}.lst-kix_hw08zzin6mm8-1>li:before{content:"\0025cb   "}.lst-kix_9cjyjkedxdni-8>li:before{content:"\0025a0   "}.lst-kix_rdl0mbsx7m1b-6>li:before{content:"\0025cf   "}.lst-kix_tzrck1qfmyqd-2>li:before{content:"\0025a0   "}.lst-kix_lhigxpi4bbt5-5>li:before{content:"\0025a0   "}ul.lst-kix_dk6ingbu8z4-6{list-style-type:none}ul.lst-kix_dk6ingbu8z4-5{list-style-type:none}.lst-kix_l555prmkzand-6>li:before{content:"\0025cf   "}ul.lst-kix_dk6ingbu8z4-8{list-style-type:none}ul.lst-kix_dk6ingbu8z4-7{list-style-type:none}ul.lst-kix_dk6ingbu8z4-2{list-style-type:none}.lst-kix_dmlj8k237tx2-7>li:before{content:"\0025cb   "}ul.lst-kix_3iyql9jafv7n-0{list-style-type:none}ul.lst-kix_dk6ingbu8z4-1{list-style-type:none}.lst-kix_crntwpm3ewxb-4>li:before{content:"\0025cb   "}ul.lst-kix_3iyql9jafv7n-1{list-style-type:none}ul.lst-kix_dk6ingbu8z4-4{list-style-type:none}.lst-kix_hw08zzin6mm8-5>li:before{content:"\0025a0   "}.lst-kix_w9ot5xs5iuad-4>li:before{content:"\0025cb   "}ul.lst-kix_3iyql9jafv7n-2{list-style-type:none}ul.lst-kix_dk6ingbu8z4-3{list-style-type:none}.lst-kix_rdl0mbsx7m1b-2>li:before{content:"\0025a0   "}.lst-kix_tzrck1qfmyqd-6>li:before{content:"\0025cf   "}ul.lst-kix_3iyql9jafv7n-3{list-style-type:none}.lst-kix_ie13bttc6n1-2>li:before{content:"\0025a0   "}.lst-kix_lhigxpi4bbt5-1>li:before{content:"\0025cb   "}ul.lst-kix_3iyql9jafv7n-4{list-style-type:none}ul.lst-kix_3iyql9jafv7n-5{list-style-type:none}ul.lst-kix_dk6ingbu8z4-0{list-style-type:none}ul.lst-kix_3iyql9jafv7n-6{list-style-type:none}.lst-kix_ehfx5m3tdqyv-0>li:before{content:"\0025cf   "}.lst-kix_ehfx5m3tdqyv-8>li:before{content:"\0025a0   "}ul.lst-kix_3iyql9jafv7n-7{list-style-type:none}.lst-kix_d74axqjz5yj6-3>li:before{content:"\0025cf   "}ul.lst-kix_x803kyc5p3g4-3{list-style-type:none}ul.lst-kix_x803kyc5p3g4-2{list-style-type:none}.lst-kix_crntwpm3ewxb-8>li:before{content:"\0025a0   "}ul.lst-kix_x803kyc5p3g4-5{list-style-type:none}.lst-kix_9cjyjkedxdni-0>li:before{content:"\0025cf   "}ul.lst-kix_x803kyc5p3g4-4{list-style-type:none}.lst-kix_l555prmkzand-2>li:before{content:"\0025a0   "}ul.lst-kix_4v5uuo4j022q-8{list-style-type:none}ul.lst-kix_4v5uuo4j022q-7{list-style-type:none}ul.lst-kix_x803kyc5p3g4-1{list-style-type:none}ul.lst-kix_4v5uuo4j022q-6{list-style-type:none}ul.lst-kix_x803kyc5p3g4-0{list-style-type:none}ul.lst-kix_4v5uuo4j022q-5{list-style-type:none}ul.lst-kix_4v5uuo4j022q-4{list-style-type:none}.lst-kix_2tcxxdhwr5nc-5>li:before{content:"\0025a0   "}ul.lst-kix_4v5uuo4j022q-3{list-style-type:none}ul.lst-kix_4v5uuo4j022q-2{list-style-type:none}.lst-kix_9cjyjkedxdni-4>li:before{content:"\0025cb   "}ul.lst-kix_4v5uuo4j022q-1{list-style-type:none}ul.lst-kix_x803kyc5p3g4-7{list-style-type:none}.lst-kix_4qgjp0e8yt8m-8>li:before{content:"\0025a0   "}ul.lst-kix_4v5uuo4j022q-0{list-style-type:none}.lst-kix_ie13bttc6n1-6>li:before{content:"\0025cf   "}ul.lst-kix_x803kyc5p3g4-6{list-style-type:none}.lst-kix_ehfx5m3tdqyv-4>li:before{content:"\0025cb   "}ul.lst-kix_x803kyc5p3g4-8{list-style-type:none}.lst-kix_i91p7evgzc6j-8>li:before{content:"\0025a0   "}.lst-kix_srupee17v0mb-3>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-3,decimal) ". "}.lst-kix_ek5wwvmsnqx1-6>li:before{content:"\0025cf   "}ul.lst-kix_kw4p74ijjapz-4{list-style-type:none}.lst-kix_69pm6toa84wm-5>li:before{content:"\0025a0   "}ul.lst-kix_kw4p74ijjapz-5{list-style-type:none}ul.lst-kix_kw4p74ijjapz-2{list-style-type:none}.lst-kix_8ljhu9hqkk7j-1>li:before{content:"\0025cb   "}ul.lst-kix_kw4p74ijjapz-3{list-style-type:none}ul.lst-kix_kw4p74ijjapz-8{list-style-type:none}ul.lst-kix_kw4p74ijjapz-6{list-style-type:none}ul.lst-kix_68nz8s40mnx9-1{list-style-type:none}ul.lst-kix_kw4p74ijjapz-7{list-style-type:none}ul.lst-kix_68nz8s40mnx9-0{list-style-type:none}ul.lst-kix_68nz8s40mnx9-3{list-style-type:none}ul.lst-kix_68nz8s40mnx9-2{list-style-type:none}ul.lst-kix_68nz8s40mnx9-5{list-style-type:none}.lst-kix_8ljhu9hqkk7j-5>li:before{content:"\0025a0   "}ul.lst-kix_68nz8s40mnx9-4{list-style-type:none}ul.lst-kix_kw4p74ijjapz-0{list-style-type:none}ul.lst-kix_68nz8s40mnx9-7{list-style-type:none}ul.lst-kix_kw4p74ijjapz-1{list-style-type:none}ul.lst-kix_68nz8s40mnx9-6{list-style-type:none}.lst-kix_hefc4tmerznh-5>li:before{content:"\0025a0   "}ul.lst-kix_68nz8s40mnx9-8{list-style-type:none}.lst-kix_69pm6toa84wm-1>li:before{content:"\0025cb   "}.lst-kix_jjh106bq03g-6>li:before{content:"\0025cf   "}.lst-kix_jk6itlvdyknk-3>li:before{content:"\0025cf   "}.lst-kix_2tcxxdhwr5nc-1>li:before{content:"\0025cb   "}.lst-kix_3b0ouvydct1b-6>li:before{content:"\0025cf   "}.lst-kix_w9ot5xs5iuad-0>li:before{content:"\0025cf   "}.lst-kix_3b0ouvydct1b-2>li:before{content:"\0025a0   "}.lst-kix_brn07ewm5d7x-7>li:before{content:"\0025cb   "}.lst-kix_5t41ldrjeoj7-3>li:before{content:"\0025cf   "}.lst-kix_dbltq7i3dnfs-6>li:before{content:"\0025cf   "}.lst-kix_vwxe3fdqgja8-5>li:before{content:"\0025a0   "}.lst-kix_brn07ewm5d7x-3>li:before{content:"\0025cf   "}.lst-kix_bbzhpmijr633-3>li:before{content:"\0025cf   "}.lst-kix_l25ba28sjj7-1>li:before{content:"\0025cb   "}.lst-kix_hdkieo28r82q-3>li:before{content:"\0025cf   "}.lst-kix_tsc2yqmm539t-8>li{counter-increment:lst-ctn-kix_tsc2yqmm539t-8}.lst-kix_afhhqgs3rfh2-0>li:before{content:"\0025cf   "}ul.lst-kix_x87etp2vfva3-2{list-style-type:none}.lst-kix_4vyaz9wpvlga-5>li:before{content:"\0025a0   "}.lst-kix_hdkieo28r82q-7>li:before{content:"\0025cb   "}ul.lst-kix_x87etp2vfva3-1{list-style-type:none}ul.lst-kix_x87etp2vfva3-4{list-style-type:none}ul.lst-kix_x87etp2vfva3-3{list-style-type:none}.lst-kix_l25ba28sjj7-5>li:before{content:"\0025a0   "}ul.lst-kix_x87etp2vfva3-6{list-style-type:none}ul.lst-kix_x87etp2vfva3-5{list-style-type:none}ul.lst-kix_x87etp2vfva3-8{list-style-type:none}ul.lst-kix_x87etp2vfva3-7{list-style-type:none}.lst-kix_jk6itlvdyknk-7>li:before{content:"\0025cb   "}.lst-kix_w9nfenze7id7-0>li:before{content:"\0025cf   "}.lst-kix_jjh106bq03g-2>li:before{content:"\0025a0   "}.lst-kix_afhhqgs3rfh2-4>li:before{content:"\0025cb   "}.lst-kix_cszf4nosnav1-6>li:before{content:"\0025cf   "}.lst-kix_w9nfenze7id7-4>li:before{content:"\0025cb   "}ul.lst-kix_qor9p1a81vaf-1{list-style-type:none}ul.lst-kix_qor9p1a81vaf-0{list-style-type:none}ul.lst-kix_qor9p1a81vaf-3{list-style-type:none}.lst-kix_dbltq7i3dnfs-2>li:before{content:"\0025a0   "}.lst-kix_cszf4nosnav1-2>li:before{content:"\0025a0   "}ul.lst-kix_qor9p1a81vaf-2{list-style-type:none}ul.lst-kix_qor9p1a81vaf-5{list-style-type:none}ul.lst-kix_qor9p1a81vaf-4{list-style-type:none}ul.lst-kix_qor9p1a81vaf-7{list-style-type:none}.lst-kix_t75jqyambp7u-3>li:before{content:"\0025cf   "}ul.lst-kix_qor9p1a81vaf-6{list-style-type:none}ul.lst-kix_x87etp2vfva3-0{list-style-type:none}.lst-kix_afhhqgs3rfh2-8>li:before{content:"\0025a0   "}ul.lst-kix_qor9p1a81vaf-8{list-style-type:none}.lst-kix_hefc4tmerznh-1>li:before{content:"\0025cb   "}ul.lst-kix_5mcoll6nkdaa-8{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-6{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-7{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-4{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-5{list-style-type:none}ul.lst-kix_mx9uog95vz5r-5{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-2{list-style-type:none}ul.lst-kix_fnntpv12ge7c-6{list-style-type:none}ul.lst-kix_mx9uog95vz5r-6{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-3{list-style-type:none}ul.lst-kix_fnntpv12ge7c-7{list-style-type:none}ul.lst-kix_mx9uog95vz5r-7{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-0{list-style-type:none}ul.lst-kix_fnntpv12ge7c-8{list-style-type:none}ul.lst-kix_mx9uog95vz5r-8{list-style-type:none}ul.lst-kix_5mcoll6nkdaa-1{list-style-type:none}.lst-kix_2ze49x6dwuyc-1>li:before{content:"\0025cb   "}.lst-kix_r953kfpy79kt-6>li:before{content:"\0025cf   "}ul.lst-kix_uu0tjb1960c1-8{list-style-type:none}ul.lst-kix_fnntpv12ge7c-2{list-style-type:none}ul.lst-kix_uu0tjb1960c1-7{list-style-type:none}ul.lst-kix_fnntpv12ge7c-3{list-style-type:none}ul.lst-kix_uu0tjb1960c1-6{list-style-type:none}ul.lst-kix_fnntpv12ge7c-4{list-style-type:none}ul.lst-kix_uu0tjb1960c1-5{list-style-type:none}ul.lst-kix_fnntpv12ge7c-5{list-style-type:none}ul.lst-kix_uu0tjb1960c1-4{list-style-type:none}ul.lst-kix_uu0tjb1960c1-3{list-style-type:none}.lst-kix_gzy546en7hix-2>li:before{content:"\0025a0   "}ul.lst-kix_uu0tjb1960c1-2{list-style-type:none}.lst-kix_5chsivk2mkzi-0>li:before{content:"\0025cf   "}ul.lst-kix_uu0tjb1960c1-1{list-style-type:none}ul.lst-kix_uu0tjb1960c1-0{list-style-type:none}.lst-kix_qy2pejxz7e1k-7>li:before{content:"\0025cb   "}.lst-kix_mlex94wk5tq-2>li:before{content:"\0025a0   "}.lst-kix_up6yrorns79d-4>li:before{content:"\0025cb   "}.lst-kix_thjul0jak92m-3>li:before{content:"\0025cf   "}ul.lst-kix_uekzkb8qvgdk-3{list-style-type:none}ul.lst-kix_uekzkb8qvgdk-2{list-style-type:none}.lst-kix_p6zn1qdl1q6g-5>li:before{content:"\0025a0   "}ul.lst-kix_uekzkb8qvgdk-5{list-style-type:none}ul.lst-kix_uekzkb8qvgdk-4{list-style-type:none}ul.lst-kix_uekzkb8qvgdk-7{list-style-type:none}.lst-kix_bhoq2060wyww-3>li:before{content:"\0025cf   "}ul.lst-kix_uekzkb8qvgdk-6{list-style-type:none}.lst-kix_tx52nn14y93q-1>li:before{content:"\0025cb   "}.lst-kix_hc4vnvmn7si1-3>li:before{content:"\0025cf   "}ul.lst-kix_uekzkb8qvgdk-8{list-style-type:none}.lst-kix_8l5du8p17xdg-8>li:before{content:"\0025a0   "}.lst-kix_fum98hryzqm2-0>li:before{content:"\0025cf   "}.lst-kix_hugw2gsg69de-8>li:before{content:"\0025a0   "}ul.lst-kix_uekzkb8qvgdk-1{list-style-type:none}ul.lst-kix_uekzkb8qvgdk-0{list-style-type:none}.lst-kix_ktcl1r9scb7w-0>li:before{content:"\0025cf   "}.lst-kix_z0m8tzh04abu-0>li:before{content:"\0025cf   "}.lst-kix_asvfnufot7md-4>li:before{content:"\0025cb   "}ul.lst-kix_men9lw1a0mnk-8{list-style-type:none}ul.lst-kix_men9lw1a0mnk-7{list-style-type:none}ul.lst-kix_men9lw1a0mnk-6{list-style-type:none}ul.lst-kix_men9lw1a0mnk-5{list-style-type:none}ul.lst-kix_men9lw1a0mnk-4{list-style-type:none}ul.lst-kix_men9lw1a0mnk-3{list-style-type:none}ul.lst-kix_men9lw1a0mnk-2{list-style-type:none}ul.lst-kix_men9lw1a0mnk-1{list-style-type:none}ul.lst-kix_men9lw1a0mnk-0{list-style-type:none}.lst-kix_yk9rpx5uikpv-4>li:before{content:"\0025cb   "}.lst-kix_s0kih9e12ax-5>li:before{content:"\0025a0   "}.lst-kix_scp6tbbd2fcq-1>li:before{content:"\0025cb   "}.lst-kix_91x2wdjlgwp1-0>li:before{content:"\0025cf   "}.lst-kix_e97rs1rrkyjo-2>li:before{content:"\0025a0   "}.lst-kix_men9lw1a0mnk-4>li:before{content:"\0025cb   "}.lst-kix_zhnrfbqi7c3p-5>li:before{content:"\0025a0   "}.lst-kix_m5vzryjtrruz-2>li:before{content:"\0025a0   "}.lst-kix_npq7lfz9ly6z-3>li:before{content:"\0025cf   "}ul.lst-kix_thjul0jak92m-8{list-style-type:none}.lst-kix_ktcl1r9scb7w-8>li:before{content:"\0025a0   "}.lst-kix_r20deuqh30jy-1>li:before{content:"\0025cb   "}ul.lst-kix_thjul0jak92m-6{list-style-type:none}.lst-kix_z0m8tzh04abu-8>li:before{content:"\0025a0   "}ul.lst-kix_thjul0jak92m-7{list-style-type:none}.lst-kix_91x2wdjlgwp1-8>li:before{content:"\0025a0   "}.lst-kix_5chsivk2mkzi-8>li:before{content:"\0025a0   "}.lst-kix_4gu29fysjsb-7>li:before{content:"\0025cb   "}ul.lst-kix_hdkieo28r82q-1{list-style-type:none}ul.lst-kix_hdkieo28r82q-0{list-style-type:none}ul.lst-kix_thjul0jak92m-0{list-style-type:none}.lst-kix_t7dbdae30u9t-2>li:before{content:"\0025a0   "}ul.lst-kix_thjul0jak92m-1{list-style-type:none}ul.lst-kix_thjul0jak92m-4{list-style-type:none}.lst-kix_fum98hryzqm2-8>li:before{content:"\0025a0   "}.lst-kix_hugw2gsg69de-0>li:before{content:"\0025cf   "}ul.lst-kix_thjul0jak92m-5{list-style-type:none}ul.lst-kix_d2maxule6lxs-8{list-style-type:none}ul.lst-kix_thjul0jak92m-2{list-style-type:none}ul.lst-kix_thjul0jak92m-3{list-style-type:none}ul.lst-kix_d2maxule6lxs-5{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-7{list-style-type:none}ul.lst-kix_d2maxule6lxs-4{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-6{list-style-type:none}ul.lst-kix_d2maxule6lxs-7{list-style-type:none}ul.lst-kix_fnntpv12ge7c-0{list-style-type:none}ul.lst-kix_mx9uog95vz5r-0{list-style-type:none}ul.lst-kix_d2maxule6lxs-6{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-8{list-style-type:none}ul.lst-kix_fnntpv12ge7c-1{list-style-type:none}ul.lst-kix_mx9uog95vz5r-1{list-style-type:none}ul.lst-kix_d2maxule6lxs-1{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-3{list-style-type:none}.lst-kix_5l7scb4zq2ts-4>li:before{content:"\0025cb   "}ul.lst-kix_mx9uog95vz5r-2{list-style-type:none}ul.lst-kix_d2maxule6lxs-0{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-2{list-style-type:none}ul.lst-kix_mx9uog95vz5r-3{list-style-type:none}ul.lst-kix_d2maxule6lxs-3{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-5{list-style-type:none}.lst-kix_12ba2se2e37v-0>li:before{content:"\0025cf   "}ul.lst-kix_mx9uog95vz5r-4{list-style-type:none}ul.lst-kix_d2maxule6lxs-2{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-4{list-style-type:none}ul.lst-kix_hdkieo28r82q-3{list-style-type:none}ul.lst-kix_hdkieo28r82q-2{list-style-type:none}.lst-kix_wwus9q4jjlww-5>li:before{content:"\0025a0   "}.lst-kix_a0n7j7tvxmqv-7>li:before{content:"\0025cb   "}ul.lst-kix_hdkieo28r82q-5{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-1{list-style-type:none}ul.lst-kix_hdkieo28r82q-4{list-style-type:none}ul.lst-kix_pfidrtjb5lqv-0{list-style-type:none}.lst-kix_by7qhqpvs1r5-5>li:before{content:"\0025a0   "}ul.lst-kix_hdkieo28r82q-7{list-style-type:none}ul.lst-kix_hdkieo28r82q-6{list-style-type:none}ul.lst-kix_hdkieo28r82q-8{list-style-type:none}ul.lst-kix_24obzjkgjhqt-6{list-style-type:none}ul.lst-kix_bpsai7a4nzlw-4{list-style-type:none}ul.lst-kix_24obzjkgjhqt-5{list-style-type:none}ul.lst-kix_bpsai7a4nzlw-3{list-style-type:none}.lst-kix_xlixir5f8ikv-0>li:before{content:"\0025cf   "}ul.lst-kix_24obzjkgjhqt-4{list-style-type:none}ul.lst-kix_bpsai7a4nzlw-2{list-style-type:none}ul.lst-kix_24obzjkgjhqt-3{list-style-type:none}ul.lst-kix_bpsai7a4nzlw-1{list-style-type:none}ul.lst-kix_24obzjkgjhqt-2{list-style-type:none}ul.lst-kix_bpsai7a4nzlw-0{list-style-type:none}.lst-kix_d62vaysn6wq1-1>li:before{content:"\0025cb   "}ul.lst-kix_24obzjkgjhqt-1{list-style-type:none}ul.lst-kix_24obzjkgjhqt-0{list-style-type:none}.lst-kix_8qkhix9sdgh8-2>li:before{content:"\0025a0   "}.lst-kix_9orpva36zqgw-8>li:before{content:"\0025a0   "}ul.lst-kix_bpsai7a4nzlw-8{list-style-type:none}ul.lst-kix_bpsai7a4nzlw-7{list-style-type:none}.lst-kix_47wl9llpry5i-7>li:before{content:"\0025cb   "}ul.lst-kix_24obzjkgjhqt-8{list-style-type:none}ul.lst-kix_bpsai7a4nzlw-6{list-style-type:none}.lst-kix_dk6ingbu8z4-6>li:before{content:"\0025cf   "}ul.lst-kix_24obzjkgjhqt-7{list-style-type:none}.lst-kix_kfuatcy312kx-5>li:before{content:"\0025a0   "}ul.lst-kix_bpsai7a4nzlw-5{list-style-type:none}.lst-kix_o4w8hr2p0ha-2>li:before{content:"\0025a0   "}.lst-kix_izsd5g4fgpc-2>li:before{content:"\0025a0   "}ul.lst-kix_e3cxiuksdiku-0{list-style-type:none}ul.lst-kix_e3cxiuksdiku-2{list-style-type:none}ul.lst-kix_e3cxiuksdiku-1{list-style-type:none}ul.lst-kix_e3cxiuksdiku-4{list-style-type:none}ul.lst-kix_e3cxiuksdiku-3{list-style-type:none}ul.lst-kix_e3cxiuksdiku-6{list-style-type:none}.lst-kix_hcwipu97fgnf-7>li:before{content:"\0025cb   "}ul.lst-kix_e3cxiuksdiku-5{list-style-type:none}ol.lst-kix_tsc2yqmm539t-7.start{counter-reset:lst-ctn-kix_tsc2yqmm539t-7 0}ul.lst-kix_e3cxiuksdiku-8{list-style-type:none}ul.lst-kix_e3cxiuksdiku-7{list-style-type:none}.lst-kix_g5ocf0ak9bci-3>li:before{content:"\0025cf   "}.lst-kix_o7qc3ia828r4-3>li:before{content:"\0025cf   "}.lst-kix_ya0b59jf88o6-3>li:before{content:"\0025cf   "}.lst-kix_lf7onj2nrr7v-8>li:before{content:"\0025a0   "}ul.lst-kix_3iyql9jafv7n-8{list-style-type:none}.lst-kix_l5sge8zce4vp-6>li:before{content:"\0025cf   "}.lst-kix_yeuz6sv2qnho-2>li:before{content:"\0025a0   "}.lst-kix_j9krs4wwadz8-4>li:before{content:"\0025cb   "}.lst-kix_r2llq4i0x498-3>li:before{content:"\0025cf   "}.lst-kix_e3cxiuksdiku-6>li:before{content:"\0025cf   "}.lst-kix_9x4yq5ss9tc1-5>li:before{content:"\0025a0   "}.lst-kix_gc3eht6946jv-3>li:before{content:"\0025cf   "}.lst-kix_3jdd6arud0e0-5>li:before{content:"\0025a0   "}.lst-kix_pwl0pufgh6dv-3>li:before{content:"\0025cf   "}.lst-kix_idsnzgd8q5di-5>li:before{content:"\0025a0   "}.lst-kix_pvyv30yiwv0n-4>li:before{content:"\0025cb   "}.lst-kix_w1xl8yxhafp5-5>li:before{content:"\0025a0   "}.lst-kix_mo5grncnzemi-5>li:before{content:"\0025a0   "}.lst-kix_4u8tsqm7y9op-3>li:before{content:"\0025cf   "}.lst-kix_eh7lncq6en9i-3>li:before{content:"\0025cf   "}.lst-kix_kizzdizga4v0-6>li:before{content:"\0025cf   "}.lst-kix_8979tijdi163-6>li:before{content:"\0025cf   "}.lst-kix_fktfq9ltsq98-0>li:before{content:"-  "}.lst-kix_7fftgdac6j6-1>li:before{content:"\0025cb   "}.lst-kix_oofi1dgq0nej-5>li:before{content:"\0025a0   "}ul.lst-kix_prgyqriqvk4e-6{list-style-type:none}ul.lst-kix_w9krzpl9jsp-6{list-style-type:none}ul.lst-kix_prgyqriqvk4e-7{list-style-type:none}ul.lst-kix_w9krzpl9jsp-7{list-style-type:none}ul.lst-kix_prgyqriqvk4e-8{list-style-type:none}ul.lst-kix_w9krzpl9jsp-8{list-style-type:none}.lst-kix_4o6376uieeve-7>li:before{content:"\0025cb   "}.lst-kix_8l5du8p17xdg-0>li:before{content:"\0025cf   "}ul.lst-kix_prgyqriqvk4e-2{list-style-type:none}ul.lst-kix_w9krzpl9jsp-2{list-style-type:none}ul.lst-kix_prgyqriqvk4e-3{list-style-type:none}ul.lst-kix_w9krzpl9jsp-3{list-style-type:none}ul.lst-kix_prgyqriqvk4e-4{list-style-type:none}ul.lst-kix_w9krzpl9jsp-4{list-style-type:none}.lst-kix_z4v6nrp70nz7-7>li:before{content:"\0025cb   "}ul.lst-kix_prgyqriqvk4e-5{list-style-type:none}ul.lst-kix_w9krzpl9jsp-5{list-style-type:none}.lst-kix_lf7onj2nrr7v-0>li:before{content:"\0025cf   "}.lst-kix_l2qc0wi8rc8e-1>li:before{content:"\0025cb   "}.lst-kix_apk8f490x7qb-7>li:before{content:"\0025cb   "}ul.lst-kix_prgyqriqvk4e-0{list-style-type:none}ul.lst-kix_w9krzpl9jsp-0{list-style-type:none}ul.lst-kix_prgyqriqvk4e-1{list-style-type:none}ul.lst-kix_w9krzpl9jsp-1{list-style-type:none}.lst-kix_pfidrtjb5lqv-2>li:before{content:"\0025a0   "}.lst-kix_fvsyn7dqkka1-1>li:before{content:"\0025cb   "}.lst-kix_zcy565gabcmu-7>li:before{content:"\0025cb   "}.lst-kix_nn0h438aq2o5-1>li:before{content:"\0025cb   "}.lst-kix_kw4p74ijjapz-0>li:before{content:"\0025cf   "}.lst-kix_3uimjn60qjnx-7>li:before{content:"\0025cb   "}.lst-kix_fktfq9ltsq98-8>li:before{content:"-  "}ul.lst-kix_2yb6ynjarz9t-8{list-style-type:none}.lst-kix_xsot34m5j4b-4>li:before{content:"\0025cb   "}ul.lst-kix_2yb6ynjarz9t-7{list-style-type:none}.lst-kix_az8p3db80uc9-0>li:before{content:"\0025cf   "}.lst-kix_p0wl0w4s0sa-2>li:before{content:"\0025a0   "}.lst-kix_yn02lgpxo9se-4>li:before{content:"\0025cb   "}.lst-kix_fd670jgoibjs-4>li:before{content:"\0025cb   "}.lst-kix_cqp59gjcdgvg-3>li:before{content:"\0025cf   "}.lst-kix_h8mmrek0o9p9-4>li:before{content:"\0025cb   "}.lst-kix_54yn6dknd642-4>li:before{content:"\0025cb   "}.lst-kix_qyngqrxks4hj-1>li:before{content:"\0025cb   "}.lst-kix_f539m7fvzj9k-7>li:before{content:"\0025cb   "}.lst-kix_87g5rwruaqks-1>li:before{content:"\0025cb   "}.lst-kix_c2b60wgdja8r-2>li:before{content:"\0025a0   "}.lst-kix_az8p3db80uc9-8>li:before{content:"\0025a0   "}ul.lst-kix_mo5grncnzemi-8{list-style-type:none}ul.lst-kix_mo5grncnzemi-7{list-style-type:none}.lst-kix_j3ti34irq4rs-2>li:before{content:"\0025a0   "}.lst-kix_c6t6pz4sgcyt-3>li:before{content:"\0025cf   "}ul.lst-kix_2yb6ynjarz9t-0{list-style-type:none}ul.lst-kix_mo5grncnzemi-0{list-style-type:none}ul.lst-kix_2yb6ynjarz9t-2{list-style-type:none}ul.lst-kix_mo5grncnzemi-2{list-style-type:none}ul.lst-kix_2yb6ynjarz9t-1{list-style-type:none}ul.lst-kix_mo5grncnzemi-1{list-style-type:none}ul.lst-kix_2yb6ynjarz9t-4{list-style-type:none}ul.lst-kix_mo5grncnzemi-4{list-style-type:none}ul.lst-kix_2yb6ynjarz9t-3{list-style-type:none}ul.lst-kix_mo5grncnzemi-3{list-style-type:none}ul.lst-kix_2yb6ynjarz9t-6{list-style-type:none}ul.lst-kix_mo5grncnzemi-6{list-style-type:none}ul.lst-kix_2yb6ynjarz9t-5{list-style-type:none}ul.lst-kix_mo5grncnzemi-5{list-style-type:none}.lst-kix_gu62etns0rjq-6>li:before{content:"\0025cf   "}.lst-kix_bpsai7a4nzlw-4>li:before{content:"\0025cb   "}.lst-kix_7noh502jhq1p-7>li:before{content:"\0025cb   "}.lst-kix_dii13kfyl9ma-2>li:before{content:"\0025a0   "}.lst-kix_8pk9oqxklycz-1>li:before{content:"\0025cb   "}ul.lst-kix_64o9mnu4lnxd-0{list-style-type:none}.lst-kix_rj0mmf4fl3tb-5>li:before{content:"\0025a0   "}ul.lst-kix_64o9mnu4lnxd-1{list-style-type:none}.lst-kix_bo1j5nej66rh-0>li:before{content:"-  "}ul.lst-kix_64o9mnu4lnxd-2{list-style-type:none}.lst-kix_a6lqukhx5fat-6>li:before{content:"\0025cf   "}.lst-kix_h55j0o7g1asr-4>li:before{content:"\0025cb   "}ul.lst-kix_64o9mnu4lnxd-7{list-style-type:none}.lst-kix_mx9uog95vz5r-4>li:before{content:"\0025cb   "}ul.lst-kix_64o9mnu4lnxd-8{list-style-type:none}.lst-kix_vs58j7xf1fh7-2>li:before{content:"\0025a0   "}.lst-kix_g4octshi0erf-6>li:before{content:"\0025cf   "}.lst-kix_p75x57uzf1s1-5>li:before{content:"\0025a0   "}ul.lst-kix_64o9mnu4lnxd-3{list-style-type:none}.lst-kix_hvoiym2mrtz4-3>li:before{content:"\0025cf   "}ul.lst-kix_64o9mnu4lnxd-4{list-style-type:none}.lst-kix_abg8yi9rye91-5>li:before{content:"\0025a0   "}ul.lst-kix_64o9mnu4lnxd-5{list-style-type:none}ul.lst-kix_64o9mnu4lnxd-6{list-style-type:none}.lst-kix_bo1j5nej66rh-8>li:before{content:"-  "}.lst-kix_qx6x5q8dhn22-3>li:before{content:"\0025cf   "}.lst-kix_j6b3cjdkd1ra-2>li:before{content:"\0025a0   "}.lst-kix_mn5hganrvuk0-2>li:before{content:"\0025a0   "}.lst-kix_codfi3rttsmj-6>li:before{content:"\0025cf   "}ul.lst-kix_m5vzryjtrruz-0{list-style-type:none}ul.lst-kix_m5vzryjtrruz-2{list-style-type:none}ul.lst-kix_m5vzryjtrruz-1{list-style-type:none}.lst-kix_uu0tjb1960c1-1>li:before{content:"\0025cb   "}ul.lst-kix_m5vzryjtrruz-4{list-style-type:none}ul.lst-kix_m5vzryjtrruz-3{list-style-type:none}ul.lst-kix_m5vzryjtrruz-6{list-style-type:none}ul.lst-kix_m5vzryjtrruz-5{list-style-type:none}.lst-kix_4wi60e30t59b-5>li:before{content:"\0025a0   "}ul.lst-kix_m5vzryjtrruz-8{list-style-type:none}ul.lst-kix_m5vzryjtrruz-7{list-style-type:none}.lst-kix_podkn7p9liyz-6>li:before{content:"\0025cf   "}.lst-kix_45zyqca0dor3-3>li:before{content:"\0025cf   "}.lst-kix_mrqrqp74n3id-0>li:before{content:"\0025cf   "}.lst-kix_i0yf1mju0g1s-6>li:before{content:"\0025cf   "}.lst-kix_ey106e39uxys-0>li:before{content:"\0025cf   "}.lst-kix_whyql51jliaq-6>li:before{content:"\0025cf   "}.lst-kix_o9zj68me8yj0-5>li:before{content:"-  "}.lst-kix_trs82cplclba-7>li:before{content:"\0025cb   "}.lst-kix_hrnpa7no5eg-4>li:before{content:"\0025cb   "}.lst-kix_wv60nibffqic-3>li:before{content:"\0025cf   "}.lst-kix_xlixir5f8ikv-8>li:before{content:"\0025a0   "}.lst-kix_dg9rb9temrvk-2>li:before{content:"\0025a0   "}.lst-kix_45gqldd6ykix-1>li:before{content:"\0025cb   "}.lst-kix_vexpnyyatkbq-4>li:before{content:"\0025cb   "}.lst-kix_dav1jecmp52o-4>li:before{content:"\0025cb   "}.lst-kix_9bz6byc4bv0o-4>li:before{content:"\0025cb   "}ul.lst-kix_efwsvsniz58g-0{list-style-type:none}ul.lst-kix_efwsvsniz58g-1{list-style-type:none}ul.lst-kix_87g5rwruaqks-5{list-style-type:none}.lst-kix_xczac0sw8y6a-3>li:before{content:"\0025cf   "}ul.lst-kix_87g5rwruaqks-4{list-style-type:none}ul.lst-kix_87g5rwruaqks-7{list-style-type:none}ul.lst-kix_87g5rwruaqks-6{list-style-type:none}ul.lst-kix_87g5rwruaqks-8{list-style-type:none}.lst-kix_b966qb5z56w2-7>li:before{content:"\0025cb   "}.lst-kix_2yb6ynjarz9t-5>li:before{content:"\0025a0   "}.lst-kix_xclf8ew5xwnq-0>li:before{content:"\0025cf   "}.lst-kix_n64wxslery5z-7>li:before{content:"\0025cb   "}ul.lst-kix_g3e6y0f95n7u-1{list-style-type:none}.lst-kix_9orpva36zqgw-0>li:before{content:"\0025cf   "}.lst-kix_ef6tx1pahaqo-1>li:before{content:"\0025cb   "}ul.lst-kix_g3e6y0f95n7u-2{list-style-type:none}.lst-kix_ey106e39uxys-8>li:before{content:"\0025a0   "}.lst-kix_6jta2mj2opdj-6>li:before{content:"\0025cf   "}ul.lst-kix_g3e6y0f95n7u-0{list-style-type:none}.lst-kix_o1ljou14zs74-3>li:before{content:"\0025cf   "}ul.lst-kix_87g5rwruaqks-1{list-style-type:none}.lst-kix_6omq6vtmahws-1>li:before{content:"\0025cb   "}ul.lst-kix_87g5rwruaqks-0{list-style-type:none}.lst-kix_cfsaqxe055dn-5>li:before{content:"\0025a0   "}ul.lst-kix_87g5rwruaqks-3{list-style-type:none}ul.lst-kix_87g5rwruaqks-2{list-style-type:none}.lst-kix_v4vy1dgu53ia-8>li:before{content:"\0025a0   "}.lst-kix_pp0573v7gp5z-7>li:before{content:"\0025cb   "}.lst-kix_gmr2bu8eavte-4>li:before{content:"\0025cb   "}.lst-kix_5ov7bblzaw0u-7>li:before{content:"\0025cb   "}.lst-kix_7mi52l6y9ptp-2>li:before{content:"\0025a0   "}.lst-kix_i2eyp2pt4qrz-6>li:before{content:"\0025cf   "}.lst-kix_ag80f2hqwfhx-5>li:before{content:"\0025a0   "}ul.lst-kix_g3e6y0f95n7u-5{list-style-type:none}ul.lst-kix_g3e6y0f95n7u-6{list-style-type:none}ul.lst-kix_g3e6y0f95n7u-3{list-style-type:none}.lst-kix_93x7l69l06zp-7>li:before{content:"\0025cb   "}ul.lst-kix_g3e6y0f95n7u-4{list-style-type:none}.lst-kix_rjpi34omqxus-5>li:before{content:"\0025a0   "}ul.lst-kix_g3e6y0f95n7u-7{list-style-type:none}.lst-kix_qor9p1a81vaf-5>li:before{content:"\0025a0   "}ul.lst-kix_g3e6y0f95n7u-8{list-style-type:none}.lst-kix_gl7fpz1y51y1-2>li:before{content:"\0025a0   "}.lst-kix_qymwuf8ggtk1-6>li:before{content:"\0025cf   "}.lst-kix_saj7a8hkorgr-2>li:before{content:"\0025a0   "}.lst-kix_h00g16e7ufft-2>li:before{content:"\0025a0   "}.lst-kix_yvj42sc4s1lo-7>li:before{content:"\0025cb   "}.lst-kix_qzdp8v5qa4kd-4>li:before{content:"\0025cb   "}.lst-kix_9sxg1s3wlz7-5>li:before{content:"\0025a0   "}.lst-kix_8qeqm584pmza-6>li:before{content:"\0025cf   "}.lst-kix_v38knoi1xqwy-7>li:before{content:"-  "}.lst-kix_tsc2yqmm539t-7>li:before{content:"" counter(lst-ctn-kix_tsc2yqmm539t-7,lower-latin) ". "}.lst-kix_lp80c754wvim-2>li:before{content:"\0025a0   "}.lst-kix_d2maxule6lxs-0>li:before{content:"\0025cf   "}.lst-kix_4j92pbqgy1h-6>li:before{content:"\0025cf   "}ul.lst-kix_i94q0a22exrp-6{list-style-type:none}.lst-kix_1l36jc1oov6-3>li:before{content:"\0025cf   "}ul.lst-kix_i94q0a22exrp-7{list-style-type:none}.lst-kix_7v1cxulxokc7-7>li:before{content:"\0025cb   "}ul.lst-kix_i94q0a22exrp-8{list-style-type:none}ul.lst-kix_i94q0a22exrp-2{list-style-type:none}ul.lst-kix_i94q0a22exrp-3{list-style-type:none}ul.lst-kix_i94q0a22exrp-4{list-style-type:none}ul.lst-kix_i94q0a22exrp-5{list-style-type:none}.lst-kix_v4vy1dgu53ia-0>li:before{content:"\0025cf   "}ul.lst-kix_i94q0a22exrp-0{list-style-type:none}ul.lst-kix_i94q0a22exrp-1{list-style-type:none}.lst-kix_3mbe6pf0vyok-7>li:before{content:"\0025cb   "}.lst-kix_4xd0kx9tx9nh-7>li:before{content:"\0025cb   "}.lst-kix_tclc6bzuyhm-2>li:before{content:"\0025a0   "}.lst-kix_ssouwh4l2bgy-5>li:before{content:"\0025a0   "}.lst-kix_kymf5on3p83t-7>li:before{content:"\0025cb   "}.lst-kix_evcxr39uk36z-4>li:before{content:"\0025cb   "}.lst-kix_cruajxrmao23-8>li:before{content:"\0025a0   "}.lst-kix_cpaf1rpc28c-8>li:before{content:"\0025a0   "}.lst-kix_eqjgku92ysne-4>li:before{content:"\0025cb   "}.lst-kix_ifg2eqszm6qp-1>li:before{content:"\0025cb   "}.lst-kix_yvkwax5bonzj-0>li:before{content:"\0025cf   "}.lst-kix_yvkwax5bonzj-8>li:before{content:"\0025a0   "}.lst-kix_xclf8ew5xwnq-8>li:before{content:"\0025a0   "}.lst-kix_wdnsgpew1acl-7>li:before{content:"\0025cb   "}.lst-kix_sf1qf9bwyojp-6>li:before{content:"\0025cf   "}.lst-kix_vcrwp2bwzubh-4>li:before{content:"\0025cb   "}.lst-kix_g3e6y0f95n7u-2>li:before{content:"\0025a0   "}.lst-kix_epmllfkx8tp-6>li:before{content:"\0025cf   "}.lst-kix_6jxu4l7p3d4o-6>li:before{content:"\0025cf   "}.lst-kix_efwsvsniz58g-4>li:before{content:"\0025cb   "}.lst-kix_cruajxrmao23-0>li:before{content:"\0025cf   "}.lst-kix_cpaf1rpc28c-0>li:before{content:"\0025cf   "}.lst-kix_4knzszhhdok2-6>li:before{content:"\0025cf   "}.lst-kix_u7by882ixwqv-0>li:before{content:"\0025cf   "}.lst-kix_u7by882ixwqv-3>li:before{content:"\0025cf   "}.lst-kix_u7by882ixwqv-4>li:before{content:"\0025cb   "}.lst-kix_g2wmx2i89hb-5>li:before{content:"\0025a0   "}.lst-kix_bzxxtmx6vbow-6>li:before{content:"\0025cf   "}.lst-kix_du8w67pu7mte-6>li:before{content:"-  "}.lst-kix_g2wmx2i89hb-2>li:before{content:"\0025a0   "}.lst-kix_g2wmx2i89hb-6>li:before{content:"\0025cf   "}.lst-kix_u6oawcl4nq58-1>li:before{content:"\0025cb   "}.lst-kix_yxl9yzqp3bqd-2>li:before{content:"\0025a0   "}.lst-kix_bzxxtmx6vbow-5>li:before{content:"\0025a0   "}ul.lst-kix_hefc4tmerznh-7{list-style-type:none}ul.lst-kix_hefc4tmerznh-8{list-style-type:none}ul.lst-kix_hefc4tmerznh-5{list-style-type:none}ul.lst-kix_hefc4tmerznh-6{list-style-type:none}.lst-kix_u7by882ixwqv-7>li:before{content:"\0025cb   "}ul.lst-kix_dav1jecmp52o-1{list-style-type:none}ul.lst-kix_hefc4tmerznh-0{list-style-type:none}ul.lst-kix_dav1jecmp52o-0{list-style-type:none}ul.lst-kix_hefc4tmerznh-3{list-style-type:none}ul.lst-kix_hefc4tmerznh-4{list-style-type:none}ul.lst-kix_hefc4tmerznh-1{list-style-type:none}ul.lst-kix_hefc4tmerznh-2{list-style-type:none}.lst-kix_j0o0ck7ntjzh-2>li:before{content:"\0025a0   "}.lst-kix_24obzjkgjhqt-7>li:before{content:"\0025cb   "}.lst-kix_gjh3cugwmzpc-2>li:before{content:"\0025a0   "}.lst-kix_4v5uuo4j022q-1>li:before{content:"\0025cb   "}.lst-kix_24obzjkgjhqt-4>li:before{content:"\0025cb   "}ul.lst-kix_zhnrfbqi7c3p-0{list-style-type:none}.lst-kix_s7yi1m4cq9qk-6>li:before{content:"\0025cf   "}ul.lst-kix_zhnrfbqi7c3p-1{list-style-type:none}.lst-kix_kihk58z8dl9b-8>li:before{content:"\0025a0   "}.lst-kix_2grrmxr8q0i0-0>li:before{content:"\0025cf   "}.lst-kix_j8606buix1qi-5>li:before{content:"\0025a0   "}.lst-kix_wt4lxomyh94s-5>li:before{content:"-  "}ul.lst-kix_dav1jecmp52o-8{list-style-type:none}ul.lst-kix_dav1jecmp52o-7{list-style-type:none}ul.lst-kix_dav1jecmp52o-6{list-style-type:none}ul.lst-kix_dav1jecmp52o-5{list-style-type:none}.lst-kix_5mcoll6nkdaa-1>li:before{content:"\0025cb   "}.lst-kix_5mcoll6nkdaa-5>li:before{content:"\0025a0   "}ul.lst-kix_dav1jecmp52o-4{list-style-type:none}.lst-kix_24obzjkgjhqt-0>li:before{content:"\0025cf   "}.lst-kix_s7yi1m4cq9qk-2>li:before{content:"\0025a0   "}ul.lst-kix_dav1jecmp52o-3{list-style-type:none}.lst-kix_wt4lxomyh94s-4>li:before{content:"-  "}.lst-kix_dacire7nzy6o-6>li:before{content:"\0025cf   "}ul.lst-kix_dav1jecmp52o-2{list-style-type:none}ul.lst-kix_zhnrfbqi7c3p-2{list-style-type:none}.lst-kix_s7yi1m4cq9qk-5>li:before{content:"\0025a0   "}.lst-kix_wt4lxomyh94s-1>li:before{content:"-  "}ul.lst-kix_zhnrfbqi7c3p-3{list-style-type:none}.lst-kix_trx91tt3i1ee-7>li:before{content:"\0025cb   "}ul.lst-kix_zhnrfbqi7c3p-4{list-style-type:none}.lst-kix_dacire7nzy6o-3>li:before{content:"\0025cf   "}ul.lst-kix_zhnrfbqi7c3p-5{list-style-type:none}ul.lst-kix_zhnrfbqi7c3p-6{list-style-type:none}ul.lst-kix_zhnrfbqi7c3p-7{list-style-type:none}.lst-kix_j8606buix1qi-2>li:before{content:"\0025a0   "}ul.lst-kix_zhnrfbqi7c3p-8{list-style-type:none}ul.lst-kix_ey106e39uxys-4{list-style-type:none}ul.lst-kix_ey106e39uxys-5{list-style-type:none}.lst-kix_ujecnpd9ox2a-5>li:before{content:"\0025a0   "}ul.lst-kix_ey106e39uxys-6{list-style-type:none}ul.lst-kix_ey106e39uxys-7{list-style-type:none}ul.lst-kix_ey106e39uxys-8{list-style-type:none}.lst-kix_qvmzdr2urb9j-5>li:before{content:"\0025a0   "}.lst-kix_trx91tt3i1ee-4>li:before{content:"\0025cb   "}ul.lst-kix_ey106e39uxys-0{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-2{list-style-type:none}ul.lst-kix_ey106e39uxys-1{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-3{list-style-type:none}.lst-kix_j8606buix1qi-6>li:before{content:"\0025cf   "}ul.lst-kix_ey106e39uxys-2{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-0{list-style-type:none}ul.lst-kix_ey106e39uxys-3{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-1{list-style-type:none}ul.lst-kix_scp6tbbd2fcq-6{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-6{list-style-type:none}ul.lst-kix_scp6tbbd2fcq-5{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-7{list-style-type:none}ul.lst-kix_scp6tbbd2fcq-8{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-4{list-style-type:none}ul.lst-kix_scp6tbbd2fcq-7{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-5{list-style-type:none}ul.lst-kix_scp6tbbd2fcq-2{list-style-type:none}.lst-kix_gxvgspx76nqx-2>li:before{content:"-  "}ul.lst-kix_scp6tbbd2fcq-1{list-style-type:none}ul.lst-kix_scp6tbbd2fcq-4{list-style-type:none}ul.lst-kix_3hrtg26wb9bu-8{list-style-type:none}ul.lst-kix_scp6tbbd2fcq-3{list-style-type:none}.lst-kix_ujecnpd9ox2a-2>li:before{content:"\0025a0   "}ul.lst-kix_scp6tbbd2fcq-0{list-style-type:none}.lst-kix_ujecnpd9ox2a-1>li:before{content:"\0025cb   "}.lst-kix_trx91tt3i1ee-0>li:before{content:"\0025cf   "}.lst-kix_du8w67pu7mte-1>li:before{content:"-  "}.lst-kix_qvmzdr2urb9j-2>li:before{content:"\0025a0   "}.lst-kix_2grrmxr8q0i0-3>li:before{content:"\0025cf   "}ul.lst-kix_gxbfiekgqjd6-7{list-style-type:none}ul.lst-kix_efwsvsniz58g-4{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-8{list-style-type:none}ul.lst-kix_efwsvsniz58g-5{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-5{list-style-type:none}ul.lst-kix_efwsvsniz58g-2{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-6{list-style-type:none}ul.lst-kix_efwsvsniz58g-3{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-3{list-style-type:none}ul.lst-kix_efwsvsniz58g-8{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-4{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-1{list-style-type:none}ul.lst-kix_efwsvsniz58g-6{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-2{list-style-type:none}ul.lst-kix_efwsvsniz58g-7{list-style-type:none}ul.lst-kix_2cqjr2ei92jl-6{list-style-type:none}ul.lst-kix_gxbfiekgqjd6-0{list-style-type:none}ul.lst-kix_2cqjr2ei92jl-7{list-style-type:none}ul.lst-kix_2cqjr2ei92jl-4{list-style-type:none}ul.lst-kix_2cqjr2ei92jl-5{list-style-type:none}.lst-kix_n64wxslery5z-8>li:before{content:"\0025a0   "}ul.lst-kix_2cqjr2ei92jl-2{list-style-type:none}.lst-kix_srn1fozfk9nn-5>li:before{content:"\0025a0   "}ul.lst-kix_2cqjr2ei92jl-3{list-style-type:none}ul.lst-kix_2cqjr2ei92jl-0{list-style-type:none}.lst-kix_tsc2yqmm539t-4>li{counter-increment:lst-ctn-kix_tsc2yqmm539t-4}ul.lst-kix_2cqjr2ei92jl-1{list-style-type:none}.lst-kix_mrqrqp74n3id-8>li:before{content:"\0025a0   "}.lst-kix_gxvgspx76nqx-5>li:before{content:"-  "}.lst-kix_ef6tx1pahaqo-0>li:before{content:"\0025cf   "}.lst-kix_zep9qz8je63n-6>li:before{content:"\0025cf   "}.lst-kix_afne6v2lp0be-2>li:before{content:"\0025a0   "}ul.lst-kix_2cqjr2ei92jl-8{list-style-type:none}.lst-kix_tgtuyk7iugqt-1>li:before{content:"\0025cb   "}.lst-kix_ef6tx1pahaqo-4>li:before{content:"\0025cb   "}.lst-kix_6jta2mj2opdj-7>li:before{content:"\0025cb   "}.lst-kix_srn1fozfk9nn-1>li:before{content:"\0025cb   "}.lst-kix_2yb6ynjarz9t-0>li:before{content:"\0025cf   "}.lst-kix_ag80f2hqwfhx-2>li:before{content:"\0025a0   "}.lst-kix_gmr2bu8eavte-5>li:before{content:"\0025a0   "}.lst-kix_v4vy1dgu53ia-5>li:before{content:"\0025a0   "}.lst-kix_saj7a8hkorgr-7>li:before{content:"\0025cb   "}.lst-kix_q0wctjb2y8b-2>li:before{content:"\0025a0   "}.lst-kix_i94q0a22exrp-2>li:before{content:"\0025a0   "}.lst-kix_1jsoq3g3afbv-7>li:before{content:"\0025cb   "}.lst-kix_n0ff4gjm91tm-8>li:before{content:"\0025a0   "}.lst-kix_tsc2yqmm539t-6>li:before{content:"" counter(lst-ctn-kix_tsc2yqmm539t-6,decimal) ". "}.lst-kix_ag80f2hqwfhx-6>li:before{content:"\0025cf   "}.lst-kix_j6b3cjdkd1ra-5>li:before{content:"\0025a0   "}.lst-kix_p66sfkc4ny5f-8>li:before{content:"\0025a0   "}.lst-kix_n64wxslery5z-4>li:before{content:"\0025cb   "}.lst-kix_fnntpv12ge7c-3>li:before{content:"\0025cf   "}.lst-kix_1jsoq3g3afbv-3>li:before{content:"\0025cf   "}.lst-kix_i2eyp2pt4qrz-1>li:before{content:"\0025cb   "}.lst-kix_cruajxrmao23-3>li:before{content:"\0025cf   "}.lst-kix_ap8rxrqvqt32-8>li:before{content:"\0025a0   "}.lst-kix_ssouwh4l2bgy-4>li:before{content:"\0025cb   "}.lst-kix_kfa6jji21f4h-7>li:before{content:"\0025cb   "}.lst-kix_7v1cxulxokc7-8>li:before{content:"\0025a0   "}.lst-kix_4lz6xppq9i7h-7>li:before{content:"\0025cb   "}.lst-kix_2cqjr2ei92jl-6>li:before{content:"\0025cf   "}.lst-kix_4nm4szcl7et4-5>li:before{content:"\0025a0   "}.lst-kix_ssouwh4l2bgy-8>li:before{content:"\0025a0   "}.lst-kix_isl8ltogczje-5>li:before{content:"\0025a0   "}.lst-kix_epmllfkx8tp-1>li:before{content:"\0025cb   "}.lst-kix_sp06awf5qvvx-3>li:before{content:"\0025cf   "}.lst-kix_kviltkqr3kxc-0>li:before{content:"\0025cf   "}.lst-kix_2cqjr2ei92jl-2>li:before{content:"\0025a0   "}.lst-kix_n0ff4gjm91tm-4>li:before{content:"\0025cb   "}.lst-kix_l5j0c6x8jedh-6>li:before{content:"-  "}.lst-kix_zdgpaglha5wb-7>li:before{content:"\0025cb   "}.lst-kix_yoaj41w0jig0-3>li:before{content:"\0025cf   "}.lst-kix_9ynuh6dd4pus-7>li:before{content:"\0025cb   "}.lst-kix_1bifduglsyp2-6>li:before{content:"\0025cf   "}.lst-kix_3hrtg26wb9bu-2>li:before{content:"\0025a0   "}.lst-kix_rtxzgybdcpml-0>li:before{content:"\0025cf   "}.lst-kix_pvxrwallhhlw-0>li:before{content:"\0025cf   "}ul.lst-kix_tx52nn14y93q-6{list-style-type:none}.lst-kix_zcy565gabcmu-0>li:before{content:"\0025cf   "}ul.lst-kix_tx52nn14y93q-5{list-style-type:none}ul.lst-kix_tx52nn14y93q-4{list-style-type:none}ul.lst-kix_tx52nn14y93q-3{list-style-type:none}ul.lst-kix_tx52nn14y93q-2{list-style-type:none}ul.lst-kix_tx52nn14y93q-1{list-style-type:none}ul.lst-kix_tx52nn14y93q-0{list-style-type:none}.lst-kix_5fltblknzo3j-2>li:before{content:"\0025a0   "}.lst-kix_pvxrwallhhlw-3>li:before{content:"\0025cf   "}ul.lst-kix_tx52nn14y93q-8{list-style-type:none}ul.lst-kix_tx52nn14y93q-7{list-style-type:none}ul.lst-kix_wdnsgpew1acl-0{list-style-type:none}.lst-kix_5fltblknzo3j-6>li:before{content:"\0025cf   "}.lst-kix_w9krzpl9jsp-3>li:before{content:"\0025cf   "}ul.lst-kix_wdnsgpew1acl-2{list-style-type:none}ul.lst-kix_wdnsgpew1acl-1{list-style-type:none}.lst-kix_9l9kjglfjgjz-8>li:before{content:"\0025a0   "}.lst-kix_3iyql9jafv7n-4>li:before{content:"\0025cb   "}ul.lst-kix_wdnsgpew1acl-8{list-style-type:none}ul.lst-kix_wdnsgpew1acl-7{list-style-type:none}.lst-kix_gxbfiekgqjd6-1>li:before{content:"\0025cb   "}.lst-kix_h8mmrek0o9p9-5>li:before{content:"\0025a0   "}.lst-kix_pvxrwallhhlw-7>li:before{content:"\0025cb   "}ul.lst-kix_wdnsgpew1acl-4{list-style-type:none}.lst-kix_1bifduglsyp2-2>li:before{content:"\0025a0   "}ul.lst-kix_wdnsgpew1acl-3{list-style-type:none}ul.lst-kix_wdnsgpew1acl-6{list-style-type:none}ul.lst-kix_wdnsgpew1acl-5{list-style-type:none}.lst-kix_8pk9oqxklycz-8>li:before{content:"\0025a0   "}ul.lst-kix_h55j0o7g1asr-0{list-style-type:none}.lst-kix_1k1th764da5j-8>li:before{content:"\0025a0   "}.lst-kix_p75x57uzf1s1-8>li:before{content:"\0025a0   "}.lst-kix_h8mmrek0o9p9-1>li:before{content:"\0025cb   "}.lst-kix_7kr9zis60z3j-3>li:before{content:"\0025cf   "}.lst-kix_9l9kjglfjgjz-4>li:before{content:"\0025cb   "}.lst-kix_3iyql9jafv7n-8>li:before{content:"\0025a0   "}.lst-kix_p75x57uzf1s1-4>li:before{content:"\0025cb   "}.lst-kix_j3ti34irq4rs-7>li:before{content:"\0025cb   "}.lst-kix_ap8rxrqvqt32-4>li:before{content:"\0025cb   "}.lst-kix_9czq3plvi9ig-8>li:before{content:"\0025a0   "}.lst-kix_j6b3cjdkd1ra-1>li:before{content:"\0025cb   "}.lst-kix_9czq3plvi9ig-7>li:before{content:"\0025cb   "}.lst-kix_prgyqriqvk4e-1>li:before{content:"\0025cb   "}.lst-kix_pfk02alca94e-8>li:before{content:"\0025a0   "}.lst-kix_9czq3plvi9ig-4>li:before{content:"\0025cb   "}.lst-kix_w3t6jbyimnfw-3>li:before{content:"\0025cf   "}.lst-kix_izm55n8luwgn-6>li:before{content:"\0025cf   "}.lst-kix_g5ocf0ak9bci-6>li:before{content:"\0025cf   "}ul.lst-kix_a130djrb9y6e-8{list-style-type:none}ul.lst-kix_a130djrb9y6e-7{list-style-type:none}.lst-kix_m1mzfy5afs2o-2>li:before{content:"\0025a0   "}.lst-kix_w3t6jbyimnfw-7>li:before{content:"\0025cb   "}ul.lst-kix_a130djrb9y6e-0{list-style-type:none}.lst-kix_w9krzpl9jsp-7>li:before{content:"\0025cb   "}.lst-kix_w3t6jbyimnfw-6>li:before{content:"\0025cf   "}ul.lst-kix_a130djrb9y6e-2{list-style-type:none}ul.lst-kix_a130djrb9y6e-1{list-style-type:none}ul.lst-kix_a130djrb9y6e-4{list-style-type:none}.lst-kix_o5dtwbk7bxd5-2>li:before{content:"\0025a0   "}ul.lst-kix_a130djrb9y6e-3{list-style-type:none}ul.lst-kix_a130djrb9y6e-6{list-style-type:none}.lst-kix_9bz6byc4bv0o-7>li:before{content:"\0025cb   "}ul.lst-kix_a130djrb9y6e-5{list-style-type:none}ul.lst-kix_mn5hganrvuk0-7{list-style-type:none}.lst-kix_xlixir5f8ikv-7>li:before{content:"\0025cb   "}ul.lst-kix_mn5hganrvuk0-8{list-style-type:none}ul.lst-kix_mn5hganrvuk0-3{list-style-type:none}ul.lst-kix_mn5hganrvuk0-4{list-style-type:none}ul.lst-kix_mn5hganrvuk0-5{list-style-type:none}ul.lst-kix_mn5hganrvuk0-6{list-style-type:none}.lst-kix_prgyqriqvk4e-5>li:before{content:"\0025a0   "}ul.lst-kix_mn5hganrvuk0-0{list-style-type:none}ul.lst-kix_mn5hganrvuk0-1{list-style-type:none}ul.lst-kix_mn5hganrvuk0-2{list-style-type:none}.lst-kix_o5dtwbk7bxd5-5>li:before{content:"\0025a0   "}.lst-kix_o5dtwbk7bxd5-6>li:before{content:"\0025cf   "}.lst-kix_srn1fozfk9nn-8>li:before{content:"\0025a0   "}.lst-kix_9bz6byc4bv0o-3>li:before{content:"\0025cf   "}.lst-kix_3vhpfjuy7tvg-0>li:before{content:"\0025cf   "}.lst-kix_12ba2se2e37v-4>li:before{content:"\0025cb   "}.lst-kix_1grzdb2vlz2q-3>li:before{content:"\0025cf   "}.lst-kix_srn1fozfk9nn-4>li:before{content:"\0025cb   "}.lst-kix_47wl9llpry5i-8>li:before{content:"\0025a0   "}ul.lst-kix_xlixir5f8ikv-2{list-style-type:none}ul.lst-kix_xlixir5f8ikv-3{list-style-type:none}ul.lst-kix_xlixir5f8ikv-0{list-style-type:none}ul.lst-kix_xlixir5f8ikv-1{list-style-type:none}ul.lst-kix_xlixir5f8ikv-6{list-style-type:none}ul.lst-kix_xlixir5f8ikv-7{list-style-type:none}ul.lst-kix_xlixir5f8ikv-4{list-style-type:none}ul.lst-kix_xlixir5f8ikv-5{list-style-type:none}.lst-kix_89fkn9gnr9w9-7>li:before{content:"\0025cb   "}.lst-kix_fvsyn7dqkka1-6>li:before{content:"\0025cf   "}.lst-kix_izsd5g4fgpc-7>li:before{content:"\0025cb   "}.lst-kix_ixqfp12krdrg-6>li:before{content:"\0025cf   "}ul.lst-kix_xlixir5f8ikv-8{list-style-type:none}.lst-kix_fnntpv12ge7c-0>li:before{content:"\0025cf   "}.lst-kix_srupee17v0mb-2>li{counter-increment:lst-ctn-kix_srupee17v0mb-2}.lst-kix_g5ocf0ak9bci-2>li:before{content:"\0025a0   "}.lst-kix_ixqfp12krdrg-2>li:before{content:"\0025a0   "}.lst-kix_3sqsdlm3qg3k-6>li:before{content:"\0025cf   "}.lst-kix_x87etp2vfva3-8>li:before{content:"-  "}.lst-kix_wt4lxomyh94s-8>li:before{content:"-  "}.lst-kix_uekzkb8qvgdk-1>li:before{content:"\0025cb   "}.lst-kix_4lz6xppq9i7h-4>li:before{content:"\0025cb   "}.lst-kix_pwl0pufgh6dv-0>li:before{content:"\0025cf   "}.lst-kix_8ph4j5309jg1-1>li:before{content:"\0025cb   "}.lst-kix_ap8rxrqvqt32-7>li:before{content:"\0025cb   "}.lst-kix_4lz6xppq9i7h-8>li:before{content:"\0025a0   "}.lst-kix_pwl0pufgh6dv-4>li:before{content:"\0025cb   "}.lst-kix_pvyv30yiwv0n-5>li:before{content:"\0025a0   "}.lst-kix_mecbkjiqxfnl-2>li:before{content:"\0025a0   "}.lst-kix_7kr9zis60z3j-0>li:before{content:"\0025cf   "}.lst-kix_isl8ltogczje-6>li:before{content:"\0025cf   "}.lst-kix_3hrtg26wb9bu-5>li:before{content:"\0025a0   "}.lst-kix_e3cxiuksdiku-1>li:before{content:"\0025cb   "}.lst-kix_isl8ltogczje-2>li:before{content:"\0025a0   "}.lst-kix_n0ff4gjm91tm-5>li:before{content:"\0025a0   "}ul.lst-kix_qx6x5q8dhn22-0{list-style-type:none}.lst-kix_zdgpaglha5wb-8>li:before{content:"\0025a0   "}ul.lst-kix_qx6x5q8dhn22-1{list-style-type:none}.lst-kix_l5j0c6x8jedh-7>li:before{content:"-  "}.lst-kix_n0ff4gjm91tm-1>li:before{content:"\0025cb   "}.lst-kix_qsmqo56xypa0-0>li:before{content:"\0025cf   "}.lst-kix_qsmqo56xypa0-4>li:before{content:"\0025cb   "}.lst-kix_bzxxtmx6vbow-2>li:before{content:"\0025a0   "}ul.lst-kix_qx6x5q8dhn22-8{list-style-type:none}.lst-kix_zdgpaglha5wb-4>li:before{content:"\0025cb   "}ul.lst-kix_qx6x5q8dhn22-6{list-style-type:none}ul.lst-kix_qx6x5q8dhn22-7{list-style-type:none}.lst-kix_z4v6nrp70nz7-6>li:before{content:"\0025cf   "}ul.lst-kix_qx6x5q8dhn22-4{list-style-type:none}ul.lst-kix_qx6x5q8dhn22-5{list-style-type:none}ul.lst-kix_qx6x5q8dhn22-2{list-style-type:none}ul.lst-kix_qx6x5q8dhn22-3{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-0{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-2{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-1{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-4{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-3{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-6{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-5{list-style-type:none}.lst-kix_l5j0c6x8jedh-3>li:before{content:"-  "}.lst-kix_3hrtg26wb9bu-1>li:before{content:"\0025cb   "}ul.lst-kix_5ov7bblzaw0u-8{list-style-type:none}ul.lst-kix_5ov7bblzaw0u-7{list-style-type:none}.lst-kix_txo0zcn8hx7-0>li:before{content:"\0025cf   "}.lst-kix_pvyv30yiwv0n-1>li:before{content:"\0025cb   "}ul.lst-kix_bo1j5nej66rh-8{list-style-type:none}ul.lst-kix_bo1j5nej66rh-7{list-style-type:none}.lst-kix_qy2pejxz7e1k-3>li:before{content:"\0025cf   "}.lst-kix_w9nfenze7id7-8>li:before{content:"\0025a0   "}ul.lst-kix_rtxzgybdcpml-7{list-style-type:none}ul.lst-kix_rtxzgybdcpml-8{list-style-type:none}.lst-kix_2ze49x6dwuyc-0>li:before{content:"\0025cf   "}ul.lst-kix_rtxzgybdcpml-5{list-style-type:none}.lst-kix_mlex94wk5tq-3>li:before{content:"\0025cf   "}ul.lst-kix_rtxzgybdcpml-6{list-style-type:none}.lst-kix_up6yrorns79d-7>li:before{content:"\0025cb   "}.lst-kix_thjul0jak92m-2>li:before{content:"\0025a0   "}ul.lst-kix_rtxzgybdcpml-0{list-style-type:none}ul.lst-kix_rtxzgybdcpml-3{list-style-type:none}.lst-kix_qy2pejxz7e1k-6>li:before{content:"\0025cf   "}ul.lst-kix_rtxzgybdcpml-4{list-style-type:none}ul.lst-kix_rtxzgybdcpml-1{list-style-type:none}ul.lst-kix_rtxzgybdcpml-2{list-style-type:none}.lst-kix_up6yrorns79d-0>li:before{content:"\0025cf   "}.lst-kix_tx52nn14y93q-0>li:before{content:"\0025cf   "}.lst-kix_bbzhpmijr633-7>li:before{content:"\0025cb   "}ul.lst-kix_lp80c754wvim-8{list-style-type:none}ul.lst-kix_lp80c754wvim-7{list-style-type:none}ul.lst-kix_lp80c754wvim-6{list-style-type:none}ul.lst-kix_lp80c754wvim-5{list-style-type:none}ul.lst-kix_lp80c754wvim-4{list-style-type:none}ul.lst-kix_lp80c754wvim-3{list-style-type:none}ul.lst-kix_lp80c754wvim-2{list-style-type:none}.lst-kix_hugw2gsg69de-7>li:before{content:"\0025cb   "}ul.lst-kix_lp80c754wvim-1{list-style-type:none}ul.lst-kix_lp80c754wvim-0{list-style-type:none}.lst-kix_men9lw1a0mnk-8>li:before{content:"\0025a0   "}.lst-kix_asvfnufot7md-7>li:before{content:"\0025cb   "}.lst-kix_m5vzryjtrruz-6>li:before{content:"\0025cf   "}.lst-kix_yeuz6sv2qnho-6>li:before{content:"\0025cf   "}.lst-kix_e97rs1rrkyjo-6>li:before{content:"\0025cf   "}.lst-kix_by7qhqpvs1r5-1>li:before{content:"\0025cb   "}ul.lst-kix_4683th2gmjda-0{list-style-type:none}ul.lst-kix_xsot34m5j4b-3{list-style-type:none}ul.lst-kix_xsot34m5j4b-2{list-style-type:none}.lst-kix_zhnrfbqi7c3p-1>li:before{content:"\0025cb   "}.lst-kix_npq7lfz9ly6z-2>li:before{content:"\0025a0   "}ul.lst-kix_xsot34m5j4b-5{list-style-type:none}ul.lst-kix_xsot34m5j4b-4{list-style-type:none}ul.lst-kix_xsot34m5j4b-7{list-style-type:none}ul.lst-kix_xsot34m5j4b-6{list-style-type:none}ul.lst-kix_xsot34m5j4b-8{list-style-type:none}.lst-kix_yk9rpx5uikpv-0>li:before{content:"\0025cf   "}.lst-kix_zhnrfbqi7c3p-4>li:before{content:"\0025cb   "}.lst-kix_p6zn1qdl1q6g-1>li:before{content:"\0025cb   "}.lst-kix_asvfnufot7md-0>li:before{content:"\0025cf   "}.lst-kix_91x2wdjlgwp1-4>li:before{content:"\0025cb   "}.lst-kix_hugw2gsg69de-4>li:before{content:"\0025cb   "}ul.lst-kix_xsot34m5j4b-1{list-style-type:none}ul.lst-kix_xsot34m5j4b-0{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-1{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-0{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-3{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-2{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-5{list-style-type:none}.lst-kix_5l7scb4zq2ts-0>li:before{content:"\0025cb   "}ul.lst-kix_l5j0c6x8jedh-4{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-7{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-6{list-style-type:none}ul.lst-kix_l5j0c6x8jedh-8{list-style-type:none}.lst-kix_by7qhqpvs1r5-8>li:before{content:"\0025a0   "}ul.lst-kix_crntwpm3ewxb-0{list-style-type:none}.lst-kix_91x2wdjlgwp1-7>li:before{content:"\0025cb   "}ul.lst-kix_crntwpm3ewxb-5{list-style-type:none}ul.lst-kix_4683th2gmjda-3{list-style-type:none}ul.lst-kix_crntwpm3ewxb-6{list-style-type:none}ul.lst-kix_4683th2gmjda-4{list-style-type:none}ul.lst-kix_crntwpm3ewxb-7{list-style-type:none}ul.lst-kix_4683th2gmjda-1{list-style-type:none}ul.lst-kix_crntwpm3ewxb-8{list-style-type:none}ul.lst-kix_4683th2gmjda-2{list-style-type:none}ul.lst-kix_crntwpm3ewxb-1{list-style-type:none}ul.lst-kix_4683th2gmjda-7{list-style-type:none}ul.lst-kix_crntwpm3ewxb-2{list-style-type:none}ul.lst-kix_4683th2gmjda-8{list-style-type:none}ul.lst-kix_crntwpm3ewxb-3{list-style-type:none}ul.lst-kix_4683th2gmjda-5{list-style-type:none}ul.lst-kix_crntwpm3ewxb-4{list-style-type:none}ul.lst-kix_4683th2gmjda-6{list-style-type:none}.lst-kix_wwus9q4jjlww-6>li:before{content:"\0025cf   "}.lst-kix_s0kih9e12ax-1>li:before{content:"\0025cb   "}.lst-kix_gzy546en7hix-6>li:before{content:"\0025cf   "}.lst-kix_r953kfpy79kt-2>li:before{content:"\0025a0   "}.lst-kix_5l7scb4zq2ts-3>li:before{content:"\0025cf   "}.lst-kix_12ba2se2e37v-7>li:before{content:"\0025cb   "}ul.lst-kix_4lz6xppq9i7h-1{list-style-type:none}.lst-kix_c4mjpxs5t8z-8>li:before{content:"\0025a0   "}ul.lst-kix_4lz6xppq9i7h-2{list-style-type:none}.lst-kix_3sqsdlm3qg3k-3>li:before{content:"\0025cf   "}.lst-kix_d62vaysn6wq1-6>li:before{content:"\0025cf   "}ul.lst-kix_4lz6xppq9i7h-0{list-style-type:none}ul.lst-kix_4lz6xppq9i7h-5{list-style-type:none}.lst-kix_1grzdb2vlz2q-6>li:before{content:"\0025cf   "}ul.lst-kix_4lz6xppq9i7h-6{list-style-type:none}ul.lst-kix_4lz6xppq9i7h-3{list-style-type:none}.lst-kix_3b0ouvydct1b-7>li:before{content:"\0025cb   "}ul.lst-kix_4lz6xppq9i7h-4{list-style-type:none}.lst-kix_xsdedfcj27fz-1>li:before{content:"\0025cb   "}.lst-kix_ey106e39uxys-7>li:before{content:"\0025cb   "}.lst-kix_o1ljou14zs74-2>li:before{content:"\0025a0   "}.lst-kix_69pm6toa84wm-0>li:before{content:"\0025cf   "}.lst-kix_xlixir5f8ikv-4>li:before{content:"\0025cb   "}ul.lst-kix_4lz6xppq9i7h-7{list-style-type:none}ul.lst-kix_4lz6xppq9i7h-8{list-style-type:none}.lst-kix_r20deuqh30jy-5>li:before{content:"\0025a0   "}.lst-kix_kfuatcy312kx-1>li:before{content:"\0025cb   "}ul.lst-kix_bhoq2060wyww-3{list-style-type:none}ul.lst-kix_bhoq2060wyww-4{list-style-type:none}.lst-kix_rjpi34omqxus-6>li:before{content:"\0025cf   "}.lst-kix_2tcxxdhwr5nc-2>li:before{content:"\0025a0   "}ul.lst-kix_bhoq2060wyww-5{list-style-type:none}ul.lst-kix_bhoq2060wyww-6{list-style-type:none}ul.lst-kix_yn02lgpxo9se-1{list-style-type:none}ul.lst-kix_bhoq2060wyww-0{list-style-type:none}.lst-kix_pp0573v7gp5z-6>li:before{content:"\0025cf   "}ul.lst-kix_yn02lgpxo9se-2{list-style-type:none}ul.lst-kix_bhoq2060wyww-1{list-style-type:none}ul.lst-kix_bhoq2060wyww-2{list-style-type:none}ul.lst-kix_yn02lgpxo9se-0{list-style-type:none}.lst-kix_o4w8hr2p0ha-6>li:before{content:"\0025cf   "}ul.lst-kix_yn02lgpxo9se-5{list-style-type:none}ul.lst-kix_i91p7evgzc6j-1{list-style-type:none}ul.lst-kix_yn02lgpxo9se-6{list-style-type:none}ul.lst-kix_i91p7evgzc6j-0{list-style-type:none}ul.lst-kix_yn02lgpxo9se-3{list-style-type:none}ul.lst-kix_yn02lgpxo9se-4{list-style-type:none}ul.lst-kix_bhoq2060wyww-7{list-style-type:none}ul.lst-kix_i91p7evgzc6j-5{list-style-type:none}ul.lst-kix_bhoq2060wyww-8{list-style-type:none}ul.lst-kix_i91p7evgzc6j-4{list-style-type:none}ul.lst-kix_yn02lgpxo9se-7{list-style-type:none}ul.lst-kix_i91p7evgzc6j-3{list-style-type:none}.lst-kix_93x7l69l06zp-8>li:before{content:"\0025a0   "}ul.lst-kix_yn02lgpxo9se-8{list-style-type:none}ul.lst-kix_i91p7evgzc6j-2{list-style-type:none}.lst-kix_4wi60e30t59b-1>li:before{content:"\0025cb   "}.lst-kix_uekzkb8qvgdk-4>li:before{content:"\0025cb   "}ul.lst-kix_i91p7evgzc6j-8{list-style-type:none}ul.lst-kix_i91p7evgzc6j-7{list-style-type:none}ul.lst-kix_i91p7evgzc6j-6{list-style-type:none}.lst-kix_6omq6vtmahws-8>li:before{content:"\0025a0   "}.lst-kix_cpaf1rpc28c-1>li:before{content:"\0025cb   "}.lst-kix_idsnzgd8q5di-1>li:before{content:"\0025cb   "}.lst-kix_8979tijdi163-2>li:before{content:"\0025a0   "}ul.lst-kix_whyql51jliaq-0{list-style-type:none}.lst-kix_3jdd6arud0e0-1>li:before{content:"\0025cb   "}.lst-kix_5t41ldrjeoj7-0>li:before{content:"\0025cf   "}.lst-kix_mecbkjiqxfnl-5>li:before{content:"\0025a0   "}.lst-kix_4u8tsqm7y9op-7>li:before{content:"\0025cb   "}ul.lst-kix_hugw2gsg69de-5{list-style-type:none}ul.lst-kix_whyql51jliaq-4{list-style-type:none}ul.lst-kix_hugw2gsg69de-6{list-style-type:none}ul.lst-kix_whyql51jliaq-3{list-style-type:none}ul.lst-kix_hugw2gsg69de-3{list-style-type:none}ul.lst-kix_whyql51jliaq-2{list-style-type:none}ul.lst-kix_hugw2gsg69de-4{list-style-type:none}ul.lst-kix_whyql51jliaq-1{list-style-type:none}ul.lst-kix_hugw2gsg69de-1{list-style-type:none}ul.lst-kix_whyql51jliaq-8{list-style-type:none}.lst-kix_3uimjn60qjnx-3>li:before{content:"\0025cf   "}ul.lst-kix_hugw2gsg69de-2{list-style-type:none}ul.lst-kix_whyql51jliaq-7{list-style-type:none}ul.lst-kix_whyql51jliaq-6{list-style-type:none}.lst-kix_7fftgdac6j6-5>li:before{content:"\0025a0   "}ul.lst-kix_hugw2gsg69de-0{list-style-type:none}ul.lst-kix_whyql51jliaq-5{list-style-type:none}.lst-kix_pwl0pufgh6dv-7>li:before{content:"\0025cb   "}ul.lst-kix_h55j0o7g1asr-3{list-style-type:none}ul.lst-kix_h55j0o7g1asr-4{list-style-type:none}.lst-kix_pvyv30yiwv0n-8>li:before{content:"\0025a0   "}ul.lst-kix_h55j0o7g1asr-1{list-style-type:none}ul.lst-kix_h55j0o7g1asr-2{list-style-type:none}ul.lst-kix_h55j0o7g1asr-7{list-style-type:none}ul.lst-kix_h55j0o7g1asr-8{list-style-type:none}ul.lst-kix_h55j0o7g1asr-5{list-style-type:none}ul.lst-kix_hugw2gsg69de-7{list-style-type:none}ul.lst-kix_h55j0o7g1asr-6{list-style-type:none}ul.lst-kix_hugw2gsg69de-8{list-style-type:none}.lst-kix_1l36jc1oov6-4>li:before{content:"\0025cb   "}.lst-kix_l2qc0wi8rc8e-5>li:before{content:"\0025a0   "}.lst-kix_apk8f490x7qb-3>li:before{content:"\0025cf   "}.lst-kix_pfidrtjb5lqv-6>li:before{content:"\0025cf   "}.lst-kix_8l5du8p17xdg-4>li:before{content:"\0025cb   "}.lst-kix_z4v6nrp70nz7-3>li:before{content:"\0025cf   "}.lst-kix_kw4p74ijjapz-4>li:before{content:"\0025cb   "}.lst-kix_4o6376uieeve-3>li:before{content:"\0025cf   "}.lst-kix_4xd0kx9tx9nh-8>li:before{content:"\0025a0   "}.lst-kix_afhhqgs3rfh2-5>li:before{content:"\0025a0   "}.lst-kix_cszf4nosnav1-5>li:before{content:"\0025a0   "}.lst-kix_9x4yq5ss9tc1-1>li:before{content:"\0025cb   "}.lst-kix_kizzdizga4v0-2>li:before{content:"\0025a0   "}.lst-kix_mlex94wk5tq-6>li:before{content:"\0025cf   "}.lst-kix_oofi1dgq0nej-1>li:before{content:"\0025cb   "}.lst-kix_r2llq4i0x498-7>li:before{content:"\0025cb   "}.lst-kix_zcy565gabcmu-3>li:before{content:"\0025cf   "}.lst-kix_qsmqo56xypa0-7>li:before{content:"\0025cb   "}.lst-kix_8ph4j5309jg1-4>li:before{content:"\0025cb   "}.lst-kix_3mbe6pf0vyok-0>li:before{content:"\0025cf   "}.lst-kix_qyngqrxks4hj-5>li:before{content:"\0025a0   "}.lst-kix_h8mmrek0o9p9-8>li:before{content:"\0025a0   "}ul.lst-kix_1grzdb2vlz2q-8{list-style-type:none}.lst-kix_xsot34m5j4b-8>li:before{content:"\0025a0   "}.lst-kix_qyngqrxks4hj-2>li:before{content:"\0025a0   "}.lst-kix_p0wl0w4s0sa-6>li:before{content:"\0025cf   "}ul.lst-kix_1grzdb2vlz2q-4{list-style-type:none}.lst-kix_hvoiym2mrtz4-7>li:before{content:"\0025cb   "}ul.lst-kix_1grzdb2vlz2q-5{list-style-type:none}.lst-kix_c2b60wgdja8r-1>li:before{content:"\0025cb   "}ul.lst-kix_1grzdb2vlz2q-6{list-style-type:none}ul.lst-kix_1grzdb2vlz2q-7{list-style-type:none}ul.lst-kix_1grzdb2vlz2q-0{list-style-type:none}ul.lst-kix_1grzdb2vlz2q-1{list-style-type:none}ul.lst-kix_1grzdb2vlz2q-2{list-style-type:none}ul.lst-kix_1grzdb2vlz2q-3{list-style-type:none}.lst-kix_cqp59gjcdgvg-7>li:before{content:"\0025cb   "}.lst-kix_yn02lgpxo9se-8>li:before{content:"\0025a0   "}.lst-kix_3iyql9jafv7n-1>li:before{content:"\0025cb   "}.lst-kix_bpsai7a4nzlw-0>li:before{content:"\0025cf   "}ul.lst-kix_6m7znixdz235-8{list-style-type:none}ul.lst-kix_6m7znixdz235-6{list-style-type:none}ul.lst-kix_6m7znixdz235-7{list-style-type:none}.lst-kix_srupee17v0mb-8>li{counter-increment:lst-ctn-kix_srupee17v0mb-8}.lst-kix_mx9uog95vz5r-8>li:before{content:"\0025a0   "}.lst-kix_9vnfdb4co7p6-4>li:before{content:"\0025cb   "}.lst-kix_bm3nprf82w8o-5>li:before{content:"\0025a0   "}.lst-kix_gu62etns0rjq-2>li:before{content:"\0025a0   "}ul.lst-kix_45zyqca0dor3-3{list-style-type:none}.lst-kix_p75x57uzf1s1-1>li:before{content:"\0025cb   "}ul.lst-kix_45zyqca0dor3-2{list-style-type:none}.lst-kix_f539m7fvzj9k-0>li:before{content:"\0025cf   "}ul.lst-kix_45zyqca0dor3-1{list-style-type:none}ul.lst-kix_45zyqca0dor3-0{list-style-type:none}.lst-kix_4j92pbqgy1h-2>li:before{content:"\0025a0   "}ul.lst-kix_45zyqca0dor3-7{list-style-type:none}.lst-kix_h55j0o7g1asr-0>li:before{content:"\0025cf   "}ul.lst-kix_45zyqca0dor3-6{list-style-type:none}.lst-kix_f539m7fvzj9k-3>li:before{content:"\0025cf   "}ul.lst-kix_45zyqca0dor3-5{list-style-type:none}ul.lst-kix_45zyqca0dor3-4{list-style-type:none}.lst-kix_kymf5on3p83t-0>li:before{content:"\0025cf   "}ul.lst-kix_45zyqca0dor3-8{list-style-type:none}.lst-kix_vs58j7xf1fh7-1>li:before{content:"\0025cb   "}.lst-kix_8pk9oqxklycz-5>li:before{content:"\0025a0   "}.lst-kix_hvoiym2mrtz4-4>li:before{content:"\0025cb   "}.lst-kix_a6lqukhx5fat-7>li:before{content:"\0025cb   "}.lst-kix_45gqldd6ykix-5>li:before{content:"\0025a0   "}.lst-kix_hw08zzin6mm8-2>li:before{content:"\0025a0   "}.lst-kix_ie13bttc6n1-1>li:before{content:"\0025cb   "}.lst-kix_podkn7p9liyz-2>li:before{content:"\0025a0   "}.lst-kix_codfi3rttsmj-7>li:before{content:"\0025cb   "}.lst-kix_crntwpm3ewxb-7>li:before{content:"\0025cb   "}.lst-kix_uu0tjb1960c1-2>li:before{content:"\0025a0   "}.lst-kix_qx6x5q8dhn22-7>li:before{content:"\0025cb   "}.lst-kix_j9krs4wwadz8-8>li:before{content:"\0025a0   "}.lst-kix_podkn7p9liyz-5>li:before{content:"\0025a0   "}.lst-kix_4qgjp0e8yt8m-7>li:before{content:"\0025cb   "}.lst-kix_45gqldd6ykix-8>li:before{content:"\0025a0   "}.lst-kix_hrnpa7no5eg-0>li:before{content:"  "}.lst-kix_ehfx5m3tdqyv-3>li:before{content:"\0025cf   "}.lst-kix_qkmj4hklqu51-3>li:before{content:"\0025cf   "}.lst-kix_45zyqca0dor3-4>li:before{content:"\0025cb   "}ul.lst-kix_6m7znixdz235-4{list-style-type:none}ul.lst-kix_d62vaysn6wq1-1{list-style-type:none}ul.lst-kix_6m7znixdz235-5{list-style-type:none}ul.lst-kix_d62vaysn6wq1-2{list-style-type:none}ul.lst-kix_6m7znixdz235-2{list-style-type:none}.lst-kix_dav1jecmp52o-8>li:before{content:"\0025a0   "}ul.lst-kix_6m7znixdz235-3{list-style-type:none}ul.lst-kix_d62vaysn6wq1-0{list-style-type:none}.lst-kix_7noh502jhq1p-3>li:before{content:"\0025cf   "}ul.lst-kix_6m7znixdz235-0{list-style-type:none}.lst-kix_whyql51jliaq-7>li:before{content:"\0025cb   "}ul.lst-kix_d62vaysn6wq1-5{list-style-type:none}ul.lst-kix_6m7znixdz235-1{list-style-type:none}ul.lst-kix_d62vaysn6wq1-6{list-style-type:none}.lst-kix_c6t6pz4sgcyt-7>li:before{content:"\0025cb   "}.lst-kix_ey106e39uxys-4>li:before{content:"\0025cb   "}ul.lst-kix_d62vaysn6wq1-3{list-style-type:none}ul.lst-kix_d62vaysn6wq1-4{list-style-type:none}.lst-kix_7noh502jhq1p-0>li:before{content:"\0025cf   "}.lst-kix_45zyqca0dor3-7>li:before{content:"\0025cb   "}.lst-kix_o9zj68me8yj0-6>li:before{content:"-  "}.lst-kix_vexpnyyatkbq-0>li:before{content:"\0025cf   "}.lst-kix_54yn6dknd642-0>li:before{content:"\0025cf   "}.lst-kix_prgyqriqvk4e-8>li:before{content:"\0025a0   "}.lst-kix_9bz6byc4bv0o-0>li:before{content:"  "}.lst-kix_uu0tjb1960c1-5>li:before{content:"\0025a0   "}.lst-kix_trs82cplclba-6>li:before{content:"\0025cf   "}.lst-kix_54yn6dknd642-3>li:before{content:"\0025cf   "}.lst-kix_t1nnqma9pg08-6>li:before{content:"\0025cf   "}.lst-kix_trs82cplclba-3>li:before{content:"\0025cf   "}ul.lst-kix_d62vaysn6wq1-7{list-style-type:none}ul.lst-kix_d62vaysn6wq1-8{list-style-type:none}.lst-kix_9orpva36zqgw-7>li:before{content:"\0025cb   "}.lst-kix_9orpva36zqgw-4>li:before{content:"\0025cb   "}ul.lst-kix_d74axqjz5yj6-8{list-style-type:none}.lst-kix_kfuatcy312kx-4>li:before{content:"\0025cb   "}.lst-kix_tsc2yqmm539t-3>li:before{content:"" counter(lst-ctn-kix_tsc2yqmm539t-3,decimal) ". "}.lst-kix_r20deuqh30jy-8>li:before{content:"\0025a0   "}ul.lst-kix_ge70ia1l9j2p-8{list-style-type:none}.lst-kix_1oywm8db5jne-1>li:before{content:"\0025cb   "}ul.lst-kix_pfbe3x4ba630-0{list-style-type:none}ul.lst-kix_pfbe3x4ba630-2{list-style-type:none}ul.lst-kix_pfbe3x4ba630-1{list-style-type:none}.lst-kix_xclf8ew5xwnq-4>li:before{content:"\0025cb   "}ul.lst-kix_qkmj4hklqu51-8{list-style-type:none}.lst-kix_9sxg1s3wlz7-1>li:before{content:"\0025cb   "}ul.lst-kix_qkmj4hklqu51-7{list-style-type:none}.lst-kix_l2qc0wi8rc8e-8>li:before{content:"\0025a0   "}.lst-kix_o7qc3ia828r4-2>li:before{content:"\0025a0   "}ul.lst-kix_qkmj4hklqu51-6{list-style-type:none}.lst-kix_evcxr39uk36z-8>li:before{content:"\0025a0   "}ul.lst-kix_qkmj4hklqu51-5{list-style-type:none}.lst-kix_1jsoq3g3afbv-0>li:before{content:"\0025cf   "}.lst-kix_qzdp8v5qa4kd-0>li:before{content:"\0025cf   "}ul.lst-kix_ge70ia1l9j2p-4{list-style-type:none}ul.lst-kix_ge70ia1l9j2p-5{list-style-type:none}ul.lst-kix_ge70ia1l9j2p-6{list-style-type:none}.lst-kix_gmr2bu8eavte-8>li:before{content:"\0025a0   "}ul.lst-kix_ge70ia1l9j2p-7{list-style-type:none}ul.lst-kix_ge70ia1l9j2p-0{list-style-type:none}.lst-kix_6omq6vtmahws-5>li:before{content:"\0025a0   "}ul.lst-kix_ge70ia1l9j2p-1{list-style-type:none}ul.lst-kix_ge70ia1l9j2p-2{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-8{list-style-type:none}ul.lst-kix_ge70ia1l9j2p-3{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-7{list-style-type:none}.lst-kix_qkmj4hklqu51-6>li:before{content:"\0025cf   "}ul.lst-kix_d74axqjz5yj6-0{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-6{list-style-type:none}ul.lst-kix_d74axqjz5yj6-1{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-5{list-style-type:none}ul.lst-kix_d74axqjz5yj6-2{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-4{list-style-type:none}.lst-kix_j9krs4wwadz8-5>li:before{content:"\0025a0   "}ul.lst-kix_d74axqjz5yj6-3{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-3{list-style-type:none}ul.lst-kix_d74axqjz5yj6-4{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-2{list-style-type:none}ul.lst-kix_d74axqjz5yj6-5{list-style-type:none}ul.lst-kix_j0o0ck7ntjzh-1{list-style-type:none}.lst-kix_tclc6bzuyhm-6>li:before{content:"\0025cf   "}ul.lst-kix_d74axqjz5yj6-6{list-style-type:none}.lst-kix_h00g16e7ufft-6>li:before{content:"\0025cf   "}ul.lst-kix_j0o0ck7ntjzh-0{list-style-type:none}ul.lst-kix_d74axqjz5yj6-7{list-style-type:none}.lst-kix_rdl0mbsx7m1b-1>li:before{content:"\0025cb   "}.lst-kix_yeuz6sv2qnho-3>li:before{content:"\0025cf   "}ul.lst-kix_qkmj4hklqu51-0{list-style-type:none}.lst-kix_8qkhix9sdgh8-1>li:before{content:"\0025cb   "}ul.lst-kix_qkmj4hklqu51-4{list-style-type:none}.lst-kix_ya0b59jf88o6-2>li:before{content:"\0025a0   "}ul.lst-kix_qkmj4hklqu51-3{list-style-type:none}ul.lst-kix_qkmj4hklqu51-2{list-style-type:none}.lst-kix_qor9p1a81vaf-1>li:before{content:"\0025cb   "}ul.lst-kix_qkmj4hklqu51-1{list-style-type:none}ul.lst-kix_kymf5on3p83t-2{list-style-type:none}ul.lst-kix_kymf5on3p83t-3{list-style-type:none}.lst-kix_3jdd6arud0e0-4>li:before{content:"\0025cb   "}ul.lst-kix_kymf5on3p83t-4{list-style-type:none}.lst-kix_mglb6ei1fc9r-4>li:before{content:"\0025cb   "}ul.lst-kix_kymf5on3p83t-5{list-style-type:none}ul.lst-kix_kymf5on3p83t-6{list-style-type:none}ul.lst-kix_kymf5on3p83t-7{list-style-type:none}.lst-kix_4cx6uiey4qy0-3>li:before{content:"\0025cf   "}ul.lst-kix_kymf5on3p83t-8{list-style-type:none}.lst-kix_ssouwh4l2bgy-1>li:before{content:"\0025cb   "}.lst-kix_3g1k0ldodoso-7>li:before{content:"\0025cb   "}.lst-kix_pfbe3x4ba630-8>li:before{content:"\0025a0   "}.lst-kix_cpaf1rpc28c-4>li:before{content:"\0025cb   "}.lst-kix_w1xl8yxhafp5-6>li:before{content:"\0025cf   "}.lst-kix_kizzdizga4v0-5>li:before{content:"\0025a0   "}.lst-kix_kymf5on3p83t-3>li:before{content:"\0025cf   "}.lst-kix_1l36jc1oov6-7>li:before{content:"\0025cb   "}.lst-kix_8pxi403yy138-3>li:before{content:"\0025cf   "}.lst-kix_mtdb7jqchtcn-6>li:before{content:"\0025cf   "}.lst-kix_eh7lncq6en9i-2>li:before{content:"\0025a0   "}.lst-kix_pp0573v7gp5z-3>li:before{content:"\0025cf   "}.lst-kix_gl7fpz1y51y1-6>li:before{content:"\0025cf   "}.lst-kix_lp80c754wvim-6>li:before{content:"\0025cf   "}ul.lst-kix_kymf5on3p83t-0{list-style-type:none}ul.lst-kix_kymf5on3p83t-1{list-style-type:none}.lst-kix_mo5grncnzemi-6>li:before{content:"\0025cf   "}ul.lst-kix_pfbe3x4ba630-8{list-style-type:none}.lst-kix_oofi1dgq0nej-4>li:before{content:"\0025cb   "}ul.lst-kix_pfbe3x4ba630-7{list-style-type:none}.lst-kix_4o6376uieeve-6>li:before{content:"\0025cf   "}.lst-kix_sp06awf5qvvx-6>li:before{content:"\0025cf   "}ul.lst-kix_pfbe3x4ba630-4{list-style-type:none}.lst-kix_g3e6y0f95n7u-6>li:before{content:"\0025cf   "}ul.lst-kix_pfbe3x4ba630-3{list-style-type:none}ul.lst-kix_pfbe3x4ba630-6{list-style-type:none}ul.lst-kix_pfbe3x4ba630-5{list-style-type:none}.lst-kix_eqjgku92ysne-0>li:before{content:"\0025cf   "}.lst-kix_8l5du8p17xdg-1>li:before{content:"\0025cb   "}.lst-kix_3mbe6pf0vyok-3>li:before{content:"\0025cf   "}.lst-kix_efwsvsniz58g-8>li:before{content:"\0025a0   "}.lst-kix_tgtuyk7iugqt-4>li:before{content:"\0025cb   "}.lst-kix_64o9mnu4lnxd-2>li:before{content:"\0025a0   "}.lst-kix_fo3xfsyzwa37-6>li:before{content:"\0025cf   "}.lst-kix_sf1qf9bwyojp-2>li:before{content:"\0025a0   "}ul.lst-kix_bo1j5nej66rh-4{list-style-type:none}ul.lst-kix_bo1j5nej66rh-3{list-style-type:none}ul.lst-kix_bo1j5nej66rh-6{list-style-type:none}.lst-kix_fd670jgoibjs-8>li:before{content:"\0025a0   "}.lst-kix_vnj3yd9aagbp-6>li:before{content:"\0025cf   "}ul.lst-kix_bo1j5nej66rh-5{list-style-type:none}.lst-kix_7fftgdac6j6-8>li:before{content:"\0025a0   "}ul.lst-kix_bo1j5nej66rh-0{list-style-type:none}ul.lst-kix_bo1j5nej66rh-2{list-style-type:none}ul.lst-kix_bo1j5nej66rh-1{list-style-type:none}.lst-kix_k4lchlqktts-7>li:before{content:"\0025cb   "}.lst-kix_k4lchlqktts-5>li:before{content:"\0025a0   "}.lst-kix_thg0lt5umapc-4>li:before{content:"\0025cb   "}ul.lst-kix_oofi1dgq0nej-7{list-style-type:none}ul.lst-kix_oofi1dgq0nej-6{list-style-type:none}.lst-kix_3ppobcpt0okh-5>li:before{content:"\0025a0   "}.lst-kix_3ppobcpt0okh-7>li:before{content:"\0025cb   "}.lst-kix_fo3xfsyzwa37-1>li:before{content:"\0025cb   "}ul.lst-kix_oofi1dgq0nej-8{list-style-type:none}.lst-kix_t75jqyambp7u-8>li:before{content:"\0025a0   "}.lst-kix_thg0lt5umapc-6>li:before{content:"\0025cf   "}.lst-kix_ge70ia1l9j2p-7>li:before{content:"\0025cb   "}ul.lst-kix_oofi1dgq0nej-1{list-style-type:none}ul.lst-kix_oofi1dgq0nej-0{list-style-type:none}ul.lst-kix_oofi1dgq0nej-3{list-style-type:none}ul.lst-kix_oofi1dgq0nej-2{list-style-type:none}.lst-kix_x803kyc5p3g4-3>li:before{content:"\0025cf   "}ul.lst-kix_oofi1dgq0nej-5{list-style-type:none}.lst-kix_8ylfq8z9iqph-5>li:before{content:"\0025a0   "}ul.lst-kix_oofi1dgq0nej-4{list-style-type:none}.lst-kix_vbr74uzbiasm-5>li:before{content:"\0025a0   "}ul.lst-kix_ehfx5m3tdqyv-0{list-style-type:none}.lst-kix_tgfvho118md4-8>li:before{content:"\0025a0   "}ul.lst-kix_ehfx5m3tdqyv-4{list-style-type:none}ul.lst-kix_ehfx5m3tdqyv-3{list-style-type:none}ul.lst-kix_ehfx5m3tdqyv-2{list-style-type:none}.lst-kix_jts281wjqw39-4>li:before{content:"\0025cb   "}.lst-kix_hdamu5z1kajk-5>li:before{content:"-  "}.lst-kix_hdamu5z1kajk-7>li:before{content:"-  "}.lst-kix_x803kyc5p3g4-5>li:before{content:"\0025a0   "}ul.lst-kix_ehfx5m3tdqyv-1{list-style-type:none}ul.lst-kix_ehfx5m3tdqyv-8{list-style-type:none}ul.lst-kix_ehfx5m3tdqyv-7{list-style-type:none}ul.lst-kix_ehfx5m3tdqyv-6{list-style-type:none}ul.lst-kix_ehfx5m3tdqyv-5{list-style-type:none}.lst-kix_hdkieo28r82q-0>li:before{content:"\0025cf   "}.lst-kix_ge70ia1l9j2p-1>li:before{content:"\0025cb   "}.lst-kix_k4lchlqktts-1>li:before{content:"\0025cb   "}.lst-kix_d2maxule6lxs-5>li:before{content:"\0025a0   "}.lst-kix_2mr9vgw3av16-4>li:before{content:"\0025cb   "}.lst-kix_m4siyyggc8wg-4>li:before{content:"\0025cb   "}.lst-kix_d2maxule6lxs-3>li:before{content:"\0025cf   "}.lst-kix_3ppobcpt0okh-1>li:before{content:"\0025cb   "}.lst-kix_xgrv9tn3a2rg-5>li:before{content:"\0025a0   "}.lst-kix_xgrv9tn3a2rg-3>li:before{content:"\0025cf   "}.lst-kix_tgfvho118md4-2>li:before{content:"\0025a0   "}.lst-kix_tgfvho118md4-4>li:before{content:"\0025cb   "}.lst-kix_gtofryf4bnby-8>li:before{content:"\0025a0   "}.lst-kix_vbr74uzbiasm-3>li:before{content:"\0025cf   "}.lst-kix_snh8lpyqaleg-2>li:before{content:"\0025a0   "}.lst-kix_snh8lpyqaleg-0>li:before{content:"\0025cf   "}.lst-kix_gtofryf4bnby-4>li:before{content:"\0025cb   "}.lst-kix_snh8lpyqaleg-6>li:before{content:"\0025cf   "}.lst-kix_y4vuy41h8k5q-5>li:before{content:"\0025a0   "}.lst-kix_gtofryf4bnby-2>li:before{content:"\0025a0   "}.lst-kix_hefc4tmerznh-6>li:before{content:"\0025cf   "}.lst-kix_xczac0sw8y6a-2>li:before{content:"\0025a0   "}.lst-kix_xczac0sw8y6a-0>li:before{content:"\0025cf   "}.lst-kix_xczac0sw8y6a-6>li:before{content:"\0025cf   "}.lst-kix_snh8lpyqaleg-8>li:before{content:"\0025a0   "}.lst-kix_b966qb5z56w2-8>li:before{content:"\0025a0   "}ul.lst-kix_3vhpfjuy7tvg-6{list-style-type:none}ul.lst-kix_3vhpfjuy7tvg-7{list-style-type:none}.lst-kix_xclf8ew5xwnq-1>li:before{content:"\0025cb   "}ul.lst-kix_8979tijdi163-0{list-style-type:none}ul.lst-kix_3vhpfjuy7tvg-4{list-style-type:none}ul.lst-kix_8979tijdi163-1{list-style-type:none}ul.lst-kix_3vhpfjuy7tvg-5{list-style-type:none}.lst-kix_xczac0sw8y6a-8>li:before{content:"\0025a0   "}ul.lst-kix_3vhpfjuy7tvg-2{list-style-type:none}.lst-kix_8qeqm584pmza-1>li:before{content:"\0025cb   "}ul.lst-kix_3vhpfjuy7tvg-3{list-style-type:none}ul.lst-kix_3vhpfjuy7tvg-0{list-style-type:none}ul.lst-kix_3vhpfjuy7tvg-1{list-style-type:none}ul.lst-kix_8979tijdi163-6{list-style-type:none}ul.lst-kix_8979tijdi163-7{list-style-type:none}ul.lst-kix_1jsoq3g3afbv-0{list-style-type:none}ul.lst-kix_8979tijdi163-8{list-style-type:none}ul.lst-kix_1jsoq3g3afbv-2{list-style-type:none}ul.lst-kix_8979tijdi163-2{list-style-type:none}.lst-kix_hefc4tmerznh-8>li:before{content:"\0025a0   "}ul.lst-kix_1jsoq3g3afbv-1{list-style-type:none}ul.lst-kix_8979tijdi163-3{list-style-type:none}.lst-kix_xclf8ew5xwnq-3>li:before{content:"\0025cf   "}ul.lst-kix_1jsoq3g3afbv-4{list-style-type:none}ul.lst-kix_8979tijdi163-4{list-style-type:none}ul.lst-kix_3vhpfjuy7tvg-8{list-style-type:none}ul.lst-kix_1jsoq3g3afbv-3{list-style-type:none}ul.lst-kix_8979tijdi163-5{list-style-type:none}ul.lst-kix_1jsoq3g3afbv-6{list-style-type:none}.lst-kix_7mi52l6y9ptp-3>li:before{content:"\0025cf   "}ul.lst-kix_12ba2se2e37v-1{list-style-type:none}ul.lst-kix_1jsoq3g3afbv-5{list-style-type:none}ul.lst-kix_12ba2se2e37v-0{list-style-type:none}ul.lst-kix_1jsoq3g3afbv-8{list-style-type:none}.lst-kix_jk6itlvdyknk-2>li:before{content:"\0025a0   "}.lst-kix_jk6itlvdyknk-4>li:before{content:"\0025cb   "}ul.lst-kix_1jsoq3g3afbv-7{list-style-type:none}ul.lst-kix_12ba2se2e37v-5{list-style-type:none}ul.lst-kix_12ba2se2e37v-4{list-style-type:none}ul.lst-kix_12ba2se2e37v-3{list-style-type:none}.lst-kix_evcxr39uk36z-7>li:before{content:"\0025cb   "}ul.lst-kix_12ba2se2e37v-2{list-style-type:none}.lst-kix_qor9p1a81vaf-6>li:before{content:"\0025cf   "}.lst-kix_h00g16e7ufft-5>li:before{content:"\0025a0   "}.lst-kix_w9ot5xs5iuad-1>li:before{content:"\0025cb   "}.lst-kix_8qeqm584pmza-3>li:before{content:"\0025cf   "}.lst-kix_yvj42sc4s1lo-6>li:before{content:"\0025cf   "}.lst-kix_qor9p1a81vaf-0>li:before{content:"\0025cb   "}.lst-kix_8qeqm584pmza-7>li:before{content:"\0025cb   "}.lst-kix_4cx6uiey4qy0-6>li:before{content:"\0025cf   "}.lst-kix_h00g16e7ufft-3>li:before{content:"\0025cf   "}.lst-kix_4cx6uiey4qy0-4>li:before{content:"\0025cb   "}ul.lst-kix_5chsivk2mkzi-2{list-style-type:none}ul.lst-kix_5chsivk2mkzi-1{list-style-type:none}ul.lst-kix_5chsivk2mkzi-0{list-style-type:none}ul.lst-kix_5chsivk2mkzi-6{list-style-type:none}ul.lst-kix_5chsivk2mkzi-5{list-style-type:none}ul.lst-kix_5chsivk2mkzi-4{list-style-type:none}ul.lst-kix_5chsivk2mkzi-3{list-style-type:none}ul.lst-kix_7noh502jhq1p-1{list-style-type:none}.lst-kix_wdnsgpew1acl-0>li:before{content:"\0025cf   "}ul.lst-kix_7noh502jhq1p-0{list-style-type:none}ul.lst-kix_7noh502jhq1p-5{list-style-type:none}ul.lst-kix_7noh502jhq1p-4{list-style-type:none}ul.lst-kix_7noh502jhq1p-3{list-style-type:none}.lst-kix_4j92pbqgy1h-7>li:before{content:"\0025cb   "}ul.lst-kix_7noh502jhq1p-2{list-style-type:none}.lst-kix_evcxr39uk36z-1>li:before{content:"\0025cb   "}ul.lst-kix_7noh502jhq1p-8{list-style-type:none}ul.lst-kix_7noh502jhq1p-7{list-style-type:none}ul.lst-kix_7noh502jhq1p-6{list-style-type:none}.lst-kix_vwxe3fdqgja8-6>li:before{content:"\0025cf   "}.lst-kix_yvj42sc4s1lo-0>li:before{content:"  "}.lst-kix_l25ba28sjj7-2>li:before{content:"\0025a0   "}.lst-kix_evcxr39uk36z-5>li:before{content:"\0025a0   "}.lst-kix_4vyaz9wpvlga-4>li:before{content:"\0025cb   "}.lst-kix_4vyaz9wpvlga-6>li:before{content:"\0025cf   "}.lst-kix_t75jqyambp7u-0>li:before{content:"\0025cf   "}.lst-kix_l25ba28sjj7-8>li:before{content:"\0025a0   "}.lst-kix_hdkieo28r82q-6>li:before{content:"\0025cf   "}.lst-kix_wdnsgpew1acl-6>li:before{content:"\0025cf   "}.lst-kix_vwxe3fdqgja8-8>li:before{content:"\0025a0   "}.lst-kix_vcrwp2bwzubh-3>li:before{content:"\0025cf   "}.lst-kix_t75jqyambp7u-6>li:before{content:"\0025cf   "}ul.lst-kix_ujecnpd9ox2a-7{list-style-type:none}.lst-kix_hefc4tmerznh-0>li:before{content:"\0025cf   "}ul.lst-kix_ujecnpd9ox2a-8{list-style-type:none}.lst-kix_sf1qf9bwyojp-5>li:before{content:"\0025a0   "}ul.lst-kix_ujecnpd9ox2a-1{list-style-type:none}.lst-kix_efwsvsniz58g-3>li:before{content:"\0025cf   "}.lst-kix_6jxu4l7p3d4o-5>li:before{content:"\0025a0   "}ul.lst-kix_ujecnpd9ox2a-2{list-style-type:none}ul.lst-kix_5chsivk2mkzi-8{list-style-type:none}.lst-kix_fo3xfsyzwa37-7>li:before{content:"\0025cb   "}ul.lst-kix_5chsivk2mkzi-7{list-style-type:none}.lst-kix_hefc4tmerznh-2>li:before{content:"\0025a0   "}ul.lst-kix_ujecnpd9ox2a-0{list-style-type:none}ul.lst-kix_ujecnpd9ox2a-5{list-style-type:none}ul.lst-kix_ujecnpd9ox2a-6{list-style-type:none}.lst-kix_sf1qf9bwyojp-3>li:before{content:"\0025cf   "}ul.lst-kix_ujecnpd9ox2a-3{list-style-type:none}ul.lst-kix_ujecnpd9ox2a-4{list-style-type:none}.lst-kix_cqp59gjcdgvg-0>li:before{content:"\0025cf   "}.lst-kix_c2b60wgdja8r-3>li:before{content:"\0025cf   "}.lst-kix_qyngqrxks4hj-4>li:before{content:"\0025cb   "}.lst-kix_p0wl0w4s0sa-5>li:before{content:"\0025a0   "}.lst-kix_1m661ata3am9-2>li:before{content:"\0025a0   "}ul.lst-kix_mglb6ei1fc9r-8{list-style-type:none}.lst-kix_cqp59gjcdgvg-4>li:before{content:"\0025cb   "}ul.lst-kix_mglb6ei1fc9r-4{list-style-type:none}ul.lst-kix_mglb6ei1fc9r-5{list-style-type:none}ul.lst-kix_mglb6ei1fc9r-6{list-style-type:none}ul.lst-kix_mglb6ei1fc9r-7{list-style-type:none}ul.lst-kix_w9ot5xs5iuad-8{list-style-type:none}.lst-kix_az8p3db80uc9-7>li:before{content:"\0025cb   "}ul.lst-kix_w9ot5xs5iuad-6{list-style-type:none}ul.lst-kix_w9ot5xs5iuad-7{list-style-type:none}.lst-kix_ifg2eqszm6qp-6>li:before{content:"\0025cf   "}.lst-kix_c6t6pz4sgcyt-2>li:before{content:"\0025a0   "}.lst-kix_i0yf1mju0g1s-1>li:before{content:"\0025cb   "}ol.lst-kix_tsc2yqmm539t-3.start{counter-reset:lst-ctn-kix_tsc2yqmm539t-3 0}.lst-kix_bpsai7a4nzlw-3>li:before{content:"\0025cf   "}.lst-kix_bm3nprf82w8o-3>li:before{content:"\0025cf   "}.lst-kix_9vnfdb4co7p6-2>li:before{content:"\0025a0   "}.lst-kix_6m7znixdz235-1>li:before{content:"\0025cb   "}.lst-kix_h55j0o7g1asr-7>li:before{content:"\0025cb   "}.lst-kix_vwxe3fdqgja8-2>li:before{content:"\0025a0   "}.lst-kix_3cigoxtebeue-6>li:before{content:"\0025cf   "}.lst-kix_i91p7evgzc6j-3>li:before{content:"\0025cf   "}.lst-kix_dii13kfyl9ma-7>li:before{content:"\0025cb   "}.lst-kix_d74axqjz5yj6-4>li:before{content:"\0025cb   "}ul.lst-kix_mglb6ei1fc9r-0{list-style-type:none}ul.lst-kix_l25ba28sjj7-4{list-style-type:none}ul.lst-kix_qy2pejxz7e1k-7{list-style-type:none}ul.lst-kix_mglb6ei1fc9r-1{list-style-type:none}ul.lst-kix_l25ba28sjj7-3{list-style-type:none}ul.lst-kix_qy2pejxz7e1k-6{list-style-type:none}ul.lst-kix_mglb6ei1fc9r-2{list-style-type:none}ul.lst-kix_l25ba28sjj7-2{list-style-type:none}.lst-kix_hvoiym2mrtz4-2>li:before{content:"\0025a0   "}ul.lst-kix_qy2pejxz7e1k-5{list-style-type:none}ul.lst-kix_mglb6ei1fc9r-3{list-style-type:none}ul.lst-kix_l25ba28sjj7-1{list-style-type:none}ul.lst-kix_qy2pejxz7e1k-4{list-style-type:none}ul.lst-kix_l25ba28sjj7-8{list-style-type:none}ul.lst-kix_l25ba28sjj7-7{list-style-type:none}.lst-kix_4j92pbqgy1h-1>li:before{content:"\0025cb   "}ul.lst-kix_l25ba28sjj7-6{list-style-type:none}ul.lst-kix_l25ba28sjj7-5{list-style-type:none}ul.lst-kix_qy2pejxz7e1k-8{list-style-type:none}.lst-kix_bpsai7a4nzlw-7>li:before{content:"\0025cb   "}.lst-kix_f539m7fvzj9k-6>li:before{content:"\0025cf   "}.lst-kix_h55j0o7g1asr-3>li:before{content:"\0025cf   "}ul.lst-kix_qy2pejxz7e1k-3{list-style-type:none}ul.lst-kix_qy2pejxz7e1k-2{list-style-type:none}.lst-kix_5t41ldrjeoj7-6>li:before{content:"\0025cf   "}.lst-kix_dmlj8k237tx2-4>li:before{content:"\0025cb   "}ul.lst-kix_qy2pejxz7e1k-1{list-style-type:none}ul.lst-kix_qy2pejxz7e1k-0{list-style-type:none}ul.lst-kix_t1nnqma9pg08-3{list-style-type:none}ul.lst-kix_t1nnqma9pg08-4{list-style-type:none}ul.lst-kix_t1nnqma9pg08-1{list-style-type:none}ul.lst-kix_t1nnqma9pg08-2{list-style-type:none}ul.lst-kix_t1nnqma9pg08-7{list-style-type:none}.lst-kix_hw08zzin6mm8-4>li:before{content:"\0025cb   "}.lst-kix_gc3eht6946jv-6>li:before{content:"\0025cf   "}.lst-kix_crntwpm3ewxb-1>li:before{content:"\0025cb   "}ul.lst-kix_t1nnqma9pg08-8{list-style-type:none}ul.lst-kix_t1nnqma9pg08-5{list-style-type:none}ul.lst-kix_t1nnqma9pg08-6{list-style-type:none}.lst-kix_tzrck1qfmyqd-3>li:before{content:"\0025cf   "}.lst-kix_45gqldd6ykix-2>li:before{content:"\0025a0   "}.lst-kix_ie13bttc6n1-3>li:before{content:"\0025cf   "}.lst-kix_bo1j5nej66rh-3>li:before{content:"-  "}.lst-kix_rdl0mbsx7m1b-3>li:before{content:"\0025cf   "}ul.lst-kix_p75x57uzf1s1-0{list-style-type:none}ul.lst-kix_p75x57uzf1s1-2{list-style-type:none}ul.lst-kix_p75x57uzf1s1-1{list-style-type:none}ul.lst-kix_p75x57uzf1s1-4{list-style-type:none}.lst-kix_podkn7p9liyz-7>li:before{content:"\0025cb   "}ul.lst-kix_p75x57uzf1s1-3{list-style-type:none}.lst-kix_4wi60e30t59b-4>li:before{content:"\0025cb   "}ul.lst-kix_p75x57uzf1s1-6{list-style-type:none}ul.lst-kix_p75x57uzf1s1-5{list-style-type:none}.lst-kix_9cjyjkedxdni-1>li:before{content:"\0025cb   "}.lst-kix_qx6x5q8dhn22-6>li:before{content:"\0025cf   "}.lst-kix_ehfx5m3tdqyv-5>li:before{content:"\0025a0   "}.lst-kix_mn5hganrvuk0-3>li:before{content:"\0025cf   "}.lst-kix_w9ot5xs5iuad-7>li:before{content:"\0025cb   "}ul.lst-kix_t1nnqma9pg08-0{list-style-type:none}.lst-kix_vexpnyyatkbq-7>li:before{content:"\0025cb   "}.lst-kix_dg9rb9temrvk-5>li:before{content:"\0025a0   "}.lst-kix_4wi60e30t59b-8>li:before{content:"\0025a0   "}.lst-kix_i91p7evgzc6j-7>li:before{content:"\0025cb   "}ul.lst-kix_w9ot5xs5iuad-0{list-style-type:none}ul.lst-kix_w9ot5xs5iuad-1{list-style-type:none}.lst-kix_7noh502jhq1p-2>li:before{content:"\0025a0   "}.lst-kix_dg9rb9temrvk-1>li:before{content:"\0025cb   "}ul.lst-kix_4gu29fysjsb-8{list-style-type:none}ul.lst-kix_w9ot5xs5iuad-4{list-style-type:none}ul.lst-kix_4gu29fysjsb-7{list-style-type:none}.lst-kix_2tcxxdhwr5nc-8>li:before{content:"\0025a0   "}ul.lst-kix_w9ot5xs5iuad-5{list-style-type:none}ul.lst-kix_w9ot5xs5iuad-2{list-style-type:none}ul.lst-kix_w9ot5xs5iuad-3{list-style-type:none}ul.lst-kix_4gu29fysjsb-4{list-style-type:none}.lst-kix_dav1jecmp52o-1>li:before{content:"\0025cb   "}ul.lst-kix_4gu29fysjsb-3{list-style-type:none}ul.lst-kix_4gu29fysjsb-6{list-style-type:none}ul.lst-kix_4gu29fysjsb-5{list-style-type:none}ul.lst-kix_o4w8hr2p0ha-7{list-style-type:none}ul.lst-kix_4gu29fysjsb-0{list-style-type:none}ul.lst-kix_o4w8hr2p0ha-6{list-style-type:none}.lst-kix_codfi3rttsmj-5>li:before{content:"\0025a0   "}ul.lst-kix_4gu29fysjsb-2{list-style-type:none}ul.lst-kix_o4w8hr2p0ha-8{list-style-type:none}ul.lst-kix_4gu29fysjsb-1{list-style-type:none}ul.lst-kix_o4w8hr2p0ha-3{list-style-type:none}.lst-kix_dav1jecmp52o-5>li:before{content:"\0025a0   "}ul.lst-kix_o4w8hr2p0ha-2{list-style-type:none}.lst-kix_vexpnyyatkbq-3>li:before{content:"\0025cf   "}ul.lst-kix_o4w8hr2p0ha-5{list-style-type:none}ul.lst-kix_o4w8hr2p0ha-4{list-style-type:none}.lst-kix_srupee17v0mb-6>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-6,decimal) ". "}ul.lst-kix_o4w8hr2p0ha-1{list-style-type:none}ul.lst-kix_o4w8hr2p0ha-0{list-style-type:none}.lst-kix_b966qb5z56w2-2>li:before{content:"\0025a0   "}ul.lst-kix_tgfvho118md4-6{list-style-type:none}ul.lst-kix_tgfvho118md4-7{list-style-type:none}ul.lst-kix_tgfvho118md4-8{list-style-type:none}ul.lst-kix_tgfvho118md4-2{list-style-type:none}ul.lst-kix_tgfvho118md4-3{list-style-type:none}ul.lst-kix_tgfvho118md4-4{list-style-type:none}ul.lst-kix_tgfvho118md4-5{list-style-type:none}.lst-kix_8qkhix9sdgh8-7>li:before{content:"\0025cb   "}.lst-kix_lf7onj2nrr7v-5>li:before{content:"\0025a0   "}ul.lst-kix_tgfvho118md4-0{list-style-type:none}ul.lst-kix_tgfvho118md4-1{list-style-type:none}.lst-kix_t7dbdae30u9t-5>li:before{content:"\0025a0   "}.lst-kix_gxvla3x57ko6-2>li:before{content:"\0025a0   "}.lst-kix_4qgjp0e8yt8m-1>li:before{content:"\0025cb   "}.lst-kix_45zyqca0dor3-2>li:before{content:"\0025a0   "}.lst-kix_qkmj4hklqu51-4>li:before{content:"\0025cb   "}ul.lst-kix_p75x57uzf1s1-8{list-style-type:none}ul.lst-kix_3sqsdlm3qg3k-1{list-style-type:none}ul.lst-kix_p75x57uzf1s1-7{list-style-type:none}ul.lst-kix_3sqsdlm3qg3k-2{list-style-type:none}ol.lst-kix_srupee17v0mb-4.start{counter-reset:lst-ctn-kix_srupee17v0mb-4 0}ul.lst-kix_3sqsdlm3qg3k-0{list-style-type:none}.lst-kix_a130djrb9y6e-0>li:before{content:"\0025cf   "}.lst-kix_j9krs4wwadz8-3>li:before{content:"\0025cf   "}.lst-kix_yk9rpx5uikpv-7>li:before{content:"\0025cb   "}.lst-kix_68nz8s40mnx9-2>li:before{content:"\0025a0   "}ul.lst-kix_jk6itlvdyknk-8{list-style-type:none}.lst-kix_idsnzgd8q5di-2>li:before{content:"\0025a0   "}.lst-kix_9x4yq5ss9tc1-8>li:before{content:"\0025a0   "}.lst-kix_mglb6ei1fc9r-2>li:before{content:"\0025a0   "}.lst-kix_fktfq9ltsq98-7>li:before{content:"-  "}.lst-kix_gc3eht6946jv-2>li:before{content:"\0025a0   "}.lst-kix_3jdd6arud0e0-2>li:before{content:"\0025a0   "}.lst-kix_4u8tsqm7y9op-4>li:before{content:"\0025cb   "}ul.lst-kix_l25ba28sjj7-0{list-style-type:none}.lst-kix_8979tijdi163-1>li:before{content:"\0025cb   "}.lst-kix_4u8tsqm7y9op-0>li:before{content:"  "}ul.lst-kix_3sqsdlm3qg3k-7{list-style-type:none}.lst-kix_8pxi403yy138-5>li:before{content:"\0025a0   "}ul.lst-kix_3sqsdlm3qg3k-8{list-style-type:none}.lst-kix_mtdb7jqchtcn-8>li:before{content:"\0025a0   "}ul.lst-kix_3sqsdlm3qg3k-5{list-style-type:none}ul.lst-kix_3sqsdlm3qg3k-6{list-style-type:none}ul.lst-kix_3sqsdlm3qg3k-3{list-style-type:none}ul.lst-kix_3sqsdlm3qg3k-4{list-style-type:none}.lst-kix_mo5grncnzemi-4>li:before{content:"\0025cb   "}ul.lst-kix_jk6itlvdyknk-1{list-style-type:none}.lst-kix_3uimjn60qjnx-0>li:before{content:"\0025cf   "}ul.lst-kix_jk6itlvdyknk-0{list-style-type:none}ul.lst-kix_jk6itlvdyknk-3{list-style-type:none}ul.lst-kix_jk6itlvdyknk-2{list-style-type:none}ul.lst-kix_jk6itlvdyknk-5{list-style-type:none}ul.lst-kix_jk6itlvdyknk-4{list-style-type:none}ul.lst-kix_jk6itlvdyknk-7{list-style-type:none}.lst-kix_apk8f490x7qb-4>li:before{content:"\0025cb   "}ul.lst-kix_jk6itlvdyknk-6{list-style-type:none}.lst-kix_5uwviijqeog0-7>li:before{content:"\0025cb   "}.lst-kix_4683th2gmjda-8>li:before{content:"\0025a0   "}.lst-kix_mtdb7jqchtcn-0>li:before{content:"\0025cf   "}.lst-kix_kw4p74ijjapz-5>li:before{content:"\0025a0   "}.lst-kix_5uwviijqeog0-3>li:before{content:"\0025cf   "}.lst-kix_l2qc0wi8rc8e-2>li:before{content:"\0025a0   "}.lst-kix_9io9le2bbu11-1>li:before{content:"\0025cb   "}.lst-kix_1oywm8db5jne-7>li:before{content:"\0025cb   "}.lst-kix_nn0h438aq2o5-4>li:before{content:"\0025cb   "}ul.lst-kix_i2eyp2pt4qrz-6{list-style-type:none}ul.lst-kix_i2eyp2pt4qrz-5{list-style-type:none}ul.lst-kix_i2eyp2pt4qrz-8{list-style-type:none}.lst-kix_4683th2gmjda-0>li:before{content:"\0025cf   "}ul.lst-kix_i2eyp2pt4qrz-7{list-style-type:none}ul.lst-kix_i2eyp2pt4qrz-2{list-style-type:none}ol.lst-kix_srupee17v0mb-6.start{counter-reset:lst-ctn-kix_srupee17v0mb-6 0}ul.lst-kix_i2eyp2pt4qrz-1{list-style-type:none}ul.lst-kix_i2eyp2pt4qrz-4{list-style-type:none}ul.lst-kix_i2eyp2pt4qrz-3{list-style-type:none}.lst-kix_3uimjn60qjnx-8>li:before{content:"\0025a0   "}.lst-kix_9x4yq5ss9tc1-4>li:before{content:"\0025cb   "}ul.lst-kix_i2eyp2pt4qrz-0{list-style-type:none}.lst-kix_53eqpuuodt5v-4>li:before{content:"\0025cb   "}.lst-kix_nn0h438aq2o5-0>li:before{content:"\0025cf   "}.lst-kix_thjul0jak92m-6>li:before{content:"\0025cf   "}.lst-kix_thjul0jak92m-8>li:before{content:"\0025a0   "}ul.lst-kix_thg0lt5umapc-7{list-style-type:none}ul.lst-kix_thg0lt5umapc-8{list-style-type:none}ul.lst-kix_thg0lt5umapc-5{list-style-type:none}ul.lst-kix_thg0lt5umapc-6{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-4{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-2{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-3{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-3{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-6{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-0{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-5{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-1{list-style-type:none}.lst-kix_z0m8tzh04abu-3>li:before{content:"\0025cf   "}ul.lst-kix_yvj42sc4s1lo-0{list-style-type:none}ul.lst-kix_hrnpa7no5eg-7{list-style-type:none}.lst-kix_thjul0jak92m-0>li:before{content:"\0025cf   "}ul.lst-kix_hrnpa7no5eg-8{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-2{list-style-type:none}ul.lst-kix_hrnpa7no5eg-5{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-1{list-style-type:none}ul.lst-kix_hrnpa7no5eg-6{list-style-type:none}.lst-kix_z0m8tzh04abu-5>li:before{content:"\0025a0   "}ul.lst-kix_thg0lt5umapc-3{list-style-type:none}.lst-kix_qy2pejxz7e1k-4>li:before{content:"\0025cb   "}ul.lst-kix_thg0lt5umapc-4{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-8{list-style-type:none}ul.lst-kix_thg0lt5umapc-1{list-style-type:none}ul.lst-kix_thg0lt5umapc-2{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-6{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-7{list-style-type:none}ul.lst-kix_thg0lt5umapc-0{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-4{list-style-type:none}ul.lst-kix_rj0mmf4fl3tb-5{list-style-type:none}.lst-kix_8l5du8p17xdg-5>li:before{content:"\0025a0   "}.lst-kix_up6yrorns79d-3>li:before{content:"\0025cf   "}ul.lst-kix_kviltkqr3kxc-0{list-style-type:none}.lst-kix_hc4vnvmn7si1-0>li:before{content:"  "}ul.lst-kix_hrnpa7no5eg-3{list-style-type:none}ul.lst-kix_kviltkqr3kxc-1{list-style-type:none}ul.lst-kix_hrnpa7no5eg-4{list-style-type:none}ul.lst-kix_kviltkqr3kxc-2{list-style-type:none}ul.lst-kix_hrnpa7no5eg-1{list-style-type:none}ul.lst-kix_kviltkqr3kxc-3{list-style-type:none}ul.lst-kix_hrnpa7no5eg-2{list-style-type:none}ul.lst-kix_kviltkqr3kxc-4{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-8{list-style-type:none}ul.lst-kix_kviltkqr3kxc-5{list-style-type:none}ul.lst-kix_yvj42sc4s1lo-7{list-style-type:none}ul.lst-kix_hrnpa7no5eg-0{list-style-type:none}ul.lst-kix_kviltkqr3kxc-6{list-style-type:none}.lst-kix_up6yrorns79d-1>li:before{content:"\0025cb   "}ul.lst-kix_kviltkqr3kxc-7{list-style-type:none}ul.lst-kix_kviltkqr3kxc-8{list-style-type:none}.lst-kix_p6zn1qdl1q6g-8>li:before{content:"\0025a0   "}.lst-kix_bhoq2060wyww-0>li:before{content:"\0025cf   "}.lst-kix_bhoq2060wyww-2>li:before{content:"\0025a0   "}ul.lst-kix_1k1th764da5j-0{list-style-type:none}.lst-kix_a0n7j7tvxmqv-2>li:before{content:"\0025a0   "}.lst-kix_m5vzryjtrruz-5>li:before{content:"\0025a0   "}.lst-kix_wwus9q4jjlww-8>li:before{content:"\0025a0   "}ul.lst-kix_1k1th764da5j-4{list-style-type:none}ul.lst-kix_1k1th764da5j-3{list-style-type:none}ul.lst-kix_1k1th764da5j-2{list-style-type:none}ul.lst-kix_1k1th764da5j-1{list-style-type:none}.lst-kix_a0n7j7tvxmqv-4>li:before{content:"\0025cb   "}.lst-kix_5l7scb4zq2ts-7>li:before{content:"\0025cb   "}.lst-kix_asvfnufot7md-3>li:before{content:"\0025cf   "}ul.lst-kix_gxvla3x57ko6-4{list-style-type:none}ul.lst-kix_gxvla3x57ko6-5{list-style-type:none}.lst-kix_yk9rpx5uikpv-3>li:before{content:"\0025cf   "}ul.lst-kix_gxvla3x57ko6-6{list-style-type:none}.lst-kix_qzdp8v5qa4kd-7>li:before{content:"\0025cb   "}ul.lst-kix_gxvla3x57ko6-7{list-style-type:none}ul.lst-kix_gxvla3x57ko6-0{list-style-type:none}ul.lst-kix_gxvla3x57ko6-1{list-style-type:none}ul.lst-kix_gxvla3x57ko6-2{list-style-type:none}.lst-kix_wwus9q4jjlww-0>li:before{content:"\0025cf   "}.lst-kix_asvfnufot7md-1>li:before{content:"\0025cb   "}ul.lst-kix_gxvla3x57ko6-3{list-style-type:none}.lst-kix_yk9rpx5uikpv-1>li:before{content:"\0025cb   "}.lst-kix_e97rs1rrkyjo-5>li:before{content:"\0025a0   "}ul.lst-kix_gxvla3x57ko6-8{list-style-type:none}.lst-kix_91x2wdjlgwp1-3>li:before{content:"\0025cf   "}.lst-kix_hugw2gsg69de-3>li:before{content:"\0025cf   "}.lst-kix_5l7scb4zq2ts-1>li:before{content:"\0025cb   "}ul.lst-kix_p0wl0w4s0sa-0{list-style-type:none}.lst-kix_4gu29fysjsb-2>li:before{content:"\0025a0   "}ul.lst-kix_p0wl0w4s0sa-1{list-style-type:none}ul.lst-kix_p0wl0w4s0sa-4{list-style-type:none}ul.lst-kix_p0wl0w4s0sa-5{list-style-type:none}.lst-kix_t7dbdae30u9t-1>li:before{content:"\0025cb   "}.lst-kix_4gu29fysjsb-8>li:before{content:"\0025a0   "}ul.lst-kix_p0wl0w4s0sa-2{list-style-type:none}.lst-kix_wwus9q4jjlww-2>li:before{content:"\0025a0   "}ul.lst-kix_p0wl0w4s0sa-3{list-style-type:none}ul.lst-kix_p0wl0w4s0sa-8{list-style-type:none}.lst-kix_zhnrfbqi7c3p-0>li:before{content:"\0025cf   "}.lst-kix_s0kih9e12ax-4>li:before{content:"\0025cb   "}ul.lst-kix_p0wl0w4s0sa-6{list-style-type:none}ul.lst-kix_p0wl0w4s0sa-7{list-style-type:none}.lst-kix_d62vaysn6wq1-4>li:before{content:"\0025cb   "}.lst-kix_47wl9llpry5i-4>li:before{content:"\0025cb   "}.lst-kix_s0kih9e12ax-2>li:before{content:"\0025a0   "}.lst-kix_r953kfpy79kt-3>li:before{content:"\0025cf   "}.lst-kix_47wl9llpry5i-2>li:before{content:"\0025a0   "}.lst-kix_8ljhu9hqkk7j-2>li:before{content:"\0025a0   "}.lst-kix_9orpva36zqgw-5>li:before{content:"\0025a0   "}.lst-kix_69pm6toa84wm-4>li:before{content:"\0025cb   "}ul.lst-kix_wwus9q4jjlww-5{list-style-type:none}ul.lst-kix_4o6376uieeve-3{list-style-type:none}.lst-kix_12ba2se2e37v-3>li:before{content:"\0025cf   "}ul.lst-kix_wwus9q4jjlww-6{list-style-type:none}ul.lst-kix_4o6376uieeve-4{list-style-type:none}ul.lst-kix_wwus9q4jjlww-3{list-style-type:none}ul.lst-kix_4o6376uieeve-5{list-style-type:none}ul.lst-kix_wwus9q4jjlww-4{list-style-type:none}ul.lst-kix_4o6376uieeve-6{list-style-type:none}.lst-kix_8ljhu9hqkk7j-4>li:before{content:"\0025cb   "}.lst-kix_12ba2se2e37v-1>li:before{content:"\0025cb   "}ul.lst-kix_4o6376uieeve-0{list-style-type:none}ul.lst-kix_wwus9q4jjlww-7{list-style-type:none}ul.lst-kix_4o6376uieeve-1{list-style-type:none}ul.lst-kix_wwus9q4jjlww-8{list-style-type:none}ul.lst-kix_4o6376uieeve-2{list-style-type:none}ul.lst-kix_du8w67pu7mte-3{list-style-type:none}ul.lst-kix_dg9rb9temrvk-8{list-style-type:none}ul.lst-kix_du8w67pu7mte-2{list-style-type:none}ul.lst-kix_dg9rb9temrvk-7{list-style-type:none}ul.lst-kix_du8w67pu7mte-1{list-style-type:none}ul.lst-kix_du8w67pu7mte-0{list-style-type:none}ul.lst-kix_wwus9q4jjlww-1{list-style-type:none}ul.lst-kix_dg9rb9temrvk-4{list-style-type:none}ul.lst-kix_wwus9q4jjlww-2{list-style-type:none}ul.lst-kix_dg9rb9temrvk-3{list-style-type:none}ul.lst-kix_dg9rb9temrvk-6{list-style-type:none}ul.lst-kix_wwus9q4jjlww-0{list-style-type:none}ul.lst-kix_dg9rb9temrvk-5{list-style-type:none}.lst-kix_ey106e39uxys-5>li:before{content:"\0025a0   "}.lst-kix_c4mjpxs5t8z-6>li:before{content:"\0025cf   "}.lst-kix_89fkn9gnr9w9-8>li:before{content:"\0025a0   "}.lst-kix_jjh106bq03g-7>li:before{content:"\0025cb   "}.lst-kix_1grzdb2vlz2q-8>li:before{content:"\0025a0   "}ul.lst-kix_ag80f2hqwfhx-8{list-style-type:none}ul.lst-kix_ag80f2hqwfhx-7{list-style-type:none}.lst-kix_9sxg1s3wlz7-2>li:before{content:"\0025a0   "}.lst-kix_qzdp8v5qa4kd-1>li:before{content:"\0025cb   "}.lst-kix_v38knoi1xqwy-4>li:before{content:"-  "}ul.lst-kix_ag80f2hqwfhx-0{list-style-type:none}ul.lst-kix_dg9rb9temrvk-0{list-style-type:none}.lst-kix_x87etp2vfva3-1>li:before{content:"-  "}ul.lst-kix_ag80f2hqwfhx-2{list-style-type:none}ul.lst-kix_dg9rb9temrvk-2{list-style-type:none}.lst-kix_ixqfp12krdrg-5>li:before{content:"\0025a0   "}ul.lst-kix_ag80f2hqwfhx-1{list-style-type:none}ul.lst-kix_dg9rb9temrvk-1{list-style-type:none}ul.lst-kix_ag80f2hqwfhx-4{list-style-type:none}.lst-kix_uekzkb8qvgdk-6>li:before{content:"\0025cf   "}.lst-kix_6omq6vtmahws-4>li:before{content:"\0025cb   "}ul.lst-kix_ag80f2hqwfhx-3{list-style-type:none}.lst-kix_2tcxxdhwr5nc-0>li:before{content:"\0025cf   "}.lst-kix_v38knoi1xqwy-2>li:before{content:"-  "}ul.lst-kix_ag80f2hqwfhx-6{list-style-type:none}ul.lst-kix_ag80f2hqwfhx-5{list-style-type:none}.lst-kix_3vhpfjuy7tvg-7>li:before{content:"\0025cb   "}.lst-kix_tclc6bzuyhm-5>li:before{content:"\0025a0   "}.lst-kix_ixqfp12krdrg-3>li:before{content:"\0025cf   "}ul.lst-kix_4o6376uieeve-7{list-style-type:none}ul.lst-kix_4o6376uieeve-8{list-style-type:none}.lst-kix_9sxg1s3wlz7-8>li:before{content:"\0025a0   "}ul.lst-kix_1k1th764da5j-8{list-style-type:none}ul.lst-kix_1k1th764da5j-7{list-style-type:none}.lst-kix_1grzdb2vlz2q-2>li:before{content:"\0025a0   "}ul.lst-kix_1k1th764da5j-6{list-style-type:none}.lst-kix_3b0ouvydct1b-3>li:before{content:"\0025cf   "}ul.lst-kix_1k1th764da5j-5{list-style-type:none}.lst-kix_1grzdb2vlz2q-0>li:before{content:"\0025cf   "}.lst-kix_rjpi34omqxus-8>li:before{content:"\0025a0   "}.lst-kix_1l36jc1oov6-0>li:before{content:"\0025cf   "}ul.lst-kix_asvfnufot7md-5{list-style-type:none}ul.lst-kix_asvfnufot7md-6{list-style-type:none}ul.lst-kix_asvfnufot7md-7{list-style-type:none}ul.lst-kix_asvfnufot7md-8{list-style-type:none}.lst-kix_gl7fpz1y51y1-5>li:before{content:"\0025a0   "}.lst-kix_lp80c754wvim-5>li:before{content:"\0025a0   "}.lst-kix_uekzkb8qvgdk-0>li:before{content:"\0025cf   "}.lst-kix_cpaf1rpc28c-3>li:before{content:"\0025cf   "}.lst-kix_bbzhpmijr633-0>li:before{content:"  "}.lst-kix_afhhqgs3rfh2-3>li:before{content:"\0025cf   "}ul.lst-kix_asvfnufot7md-1{list-style-type:none}ul.lst-kix_asvfnufot7md-2{list-style-type:none}.lst-kix_pp0573v7gp5z-4>li:before{content:"\0025cb   "}.lst-kix_rjpi34omqxus-2>li:before{content:"\0025a0   "}ul.lst-kix_asvfnufot7md-3{list-style-type:none}ul.lst-kix_asvfnufot7md-4{list-style-type:none}.lst-kix_1l36jc1oov6-6>li:before{content:"\0025cf   "}.lst-kix_rjpi34omqxus-0>li:before{content:"\0025cf   "}ul.lst-kix_asvfnufot7md-0{list-style-type:none}.lst-kix_89fkn9gnr9w9-2>li:before{content:"\0025a0   "}.lst-kix_yvkwax5bonzj-3>li:before{content:"\0025cf   "}.lst-kix_yvkwax5bonzj-5>li:before{content:"\0025a0   "}.lst-kix_hc4vnvmn7si1-6>li:before{content:"\0025cf   "}.lst-kix_3mbe6pf0vyok-2>li:before{content:"\0025a0   "}.lst-kix_w9nfenze7id7-1>li:before{content:"\0025cb   "}.lst-kix_hc4vnvmn7si1-8>li:before{content:"\0025a0   "}.lst-kix_jjh106bq03g-1>li:before{content:"\0025cb   "}ol.lst-kix_tsc2yqmm539t-5.start{counter-reset:lst-ctn-kix_tsc2yqmm539t-5 0}.lst-kix_ifg2eqszm6qp-4>li:before{content:"\0025cb   "}ul.lst-kix_du8w67pu7mte-8{list-style-type:none}ul.lst-kix_du8w67pu7mte-7{list-style-type:none}ul.lst-kix_du8w67pu7mte-6{list-style-type:none}.lst-kix_8ph4j5309jg1-8>li:before{content:"\0025a0   "}ul.lst-kix_du8w67pu7mte-5{list-style-type:none}ul.lst-kix_du8w67pu7mte-4{list-style-type:none}.lst-kix_g3e6y0f95n7u-5>li:before{content:"\0025a0   "}ul.lst-kix_lf7onj2nrr7v-8{list-style-type:none}.lst-kix_hvoiym2mrtz4-8>li:before{content:"\0025a0   "}.lst-kix_h8mmrek0o9p9-7>li:before{content:"\0025cb   "}.lst-kix_54yn6dknd642-7>li:before{content:"\0025cb   "}.lst-kix_yn02lgpxo9se-1>li:before{content:"\0025cb   "}ul.lst-kix_vexpnyyatkbq-0{list-style-type:none}ul.lst-kix_s0kih9e12ax-8{list-style-type:none}.lst-kix_pvxrwallhhlw-4>li:before{content:"\0025cb   "}.lst-kix_srupee17v0mb-0>li:before{content:"" counter(lst-ctn-kix_srupee17v0mb-0,decimal) ". "}.lst-kix_1m661ata3am9-8>li:before{content:"\0025a0   "}.lst-kix_cqp59gjcdgvg-6>li:before{content:"\0025cf   "}.lst-kix_4vyaz9wpvlga-0>li:before{content:"\0025cb   "}ul.lst-kix_lf7onj2nrr7v-0{list-style-type:none}ul.lst-kix_lf7onj2nrr7v-1{list-style-type:none}ul.lst-kix_yvkwax5bonzj-0{list-style-type:none}ul.lst-kix_lf7onj2nrr7v-2{list-style-type:none}.lst-kix_1bifduglsyp2-3>li:before{content:"\0025cf   "}ul.lst-kix_lf7onj2nrr7v-3{list-style-type:none}ul.lst-kix_lf7onj2nrr7v-4{list-style-type:none}ul.lst-kix_yvkwax5bonzj-3{list-style-type:none}ul.lst-kix_lf7onj2nrr7v-5{list-style-type:none}ul.lst-kix_yvkwax5bonzj-4{list-style-type:none}ul.lst-kix_lf7onj2nrr7v-6{list-style-type:none}ul.lst-kix_yvkwax5bonzj-1{list-style-type:none}ul.lst-kix_lf7onj2nrr7v-7{list-style-type:none}ul.lst-kix_yvkwax5bonzj-2{list-style-type:none}.lst-kix_mx9uog95vz5r-7>li:before{content:"\0025cb   "}.lst-kix_vwxe3fdqgja8-0>li:before{content:"\0025cf   "}.lst-kix_bpsai7a4nzlw-1>li:before{content:"\0025cb   "}.lst-kix_p75x57uzf1s1-2>li:before{content:"\0025a0   "}ul.lst-kix_2tcxxdhwr5nc-5{list-style-type:none}ul.lst-kix_2tcxxdhwr5nc-6{list-style-type:none}ul.lst-kix_2tcxxdhwr5nc-3{list-style-type:none}ul.lst-kix_2tcxxdhwr5nc-4{list-style-type:none}ul.lst-kix_2tcxxdhwr5nc-1{list-style-type:none}ul.lst-kix_2tcxxdhwr5nc-2{list-style-type:none}.lst-kix_i91p7evgzc6j-1>li:before{content:"\0025cb   "}ul.lst-kix_2tcxxdhwr5nc-0{list-style-type:none}ul.lst-kix_s0kih9e12ax-4{list-style-type:none}ul.lst-kix_vexpnyyatkbq-7{list-style-type:none}ul.lst-kix_s0kih9e12ax-5{list-style-type:none}ul.lst-kix_vexpnyyatkbq-8{list-style-type:none}ul.lst-kix_s0kih9e12ax-6{list-style-type:none}ul.lst-kix_vexpnyyatkbq-5{list-style-type:none}.lst-kix_h55j0o7g1asr-1>li:before{content:"\0025cb   "}ul.lst-kix_s0kih9e12ax-7{list-style-type:none}ul.lst-kix_vexpnyyatkbq-6{list-style-type:none}.lst-kix_7kr9zis60z3j-2>li:before{content:"\0025a0   "}ul.lst-kix_s0kih9e12ax-0{list-style-type:none}ul.lst-kix_vexpnyyatkbq-3{list-style-type:none}ul.lst-kix_s0kih9e12ax-1{list-style-type:none}ul.lst-kix_vexpnyyatkbq-4{list-style-type:none}.lst-kix_gu62etns0rjq-1>li:before{content:"\0025cb   "}.lst-kix_5t41ldrjeoj7-4>li:before{content:"\0025cb   "}ul.lst-kix_s0kih9e12ax-2{list-style-type:none}ul.lst-kix_vexpnyyatkbq-1{list-style-type:none}ul.lst-kix_2tcxxdhwr5nc-7{list-style-type:none}ul.lst-kix_s0kih9e12ax-3{list-style-type:none}ul.lst-kix_vexpnyyatkbq-2{list-style-type:none}ul.lst-kix_2tcxxdhwr5nc-8{list-style-type:none}.lst-kix_9vnfdb4co7p6-8>li:before{content:"\0025a0   "}.lst-kix_dii13kfyl9ma-5>li:before{content:"\0025a0   "}.lst-kix_f539m7fvzj9k-4>li:before{content:"\0025cb   "}ul.lst-kix_t75jqyambp7u-4{list-style-type:none}.lst-kix_podkn7p9liyz-1>li:before{content:"\0025cb   "}ul.lst-kix_t75jqyambp7u-3{list-style-type:none}.lst-kix_45gqldd6ykix-4>li:before{content:"\0025cb   "}ul.lst-kix_t75jqyambp7u-2{list-style-type:none}.lst-kix_qx6x5q8dhn22-0>li:before{content:"\0025cb   "}ul.lst-kix_t75jqyambp7u-1{list-style-type:none}.lst-kix_ap8rxrqvqt32-2>li:before{content:"\0025a0   "}ul.lst-kix_t75jqyambp7u-8{list-style-type:none}ul.lst-kix_t75jqyambp7u-7{list-style-type:none}ul.lst-kix_t75jqyambp7u-6{list-style-type:none}ul.lst-kix_t75jqyambp7u-5{list-style-type:none}.lst-kix_bo1j5nej66rh-5>li:before{content:"-  "}.lst-kix_gc3eht6946jv-8>li:before{content:"\0025a0   "}.lst-kix_crntwpm3ewxb-3>li:before{content:"\0025cf   "}.lst-kix_prgyqriqvk4e-4>li:before{content:"\0025cb   "}ul.lst-kix_t75jqyambp7u-0{list-style-type:none}.lst-kix_tzrck1qfmyqd-5>li:before{content:"\0025a0   "}.lst-kix_g5ocf0ak9bci-8>li:before{content:"\0025a0   "}.lst-kix_q0wctjb2y8b-4>li:before{content:"\0025cb   "}.lst-kix_w3t6jbyimnfw-1>li:before{content:"\0025cb   "}.lst-kix_srupee17v0mb-6>li{counter-increment:lst-ctn-kix_srupee17v0mb-6}.lst-kix_c6t6pz4sgcyt-8>li:before{content:"\0025a0   "}ul.lst-kix_yvkwax5bonzj-7{list-style-type:none}ul.lst-kix_yvkwax5bonzj-8{list-style-type:none}ul.lst-kix_yvkwax5bonzj-5{list-style-type:none}.lst-kix_dg9rb9temrvk-7>li:before{content:"\0025cb   "}ul.lst-kix_yvkwax5bonzj-6{list-style-type:none}.lst-kix_dav1jecmp52o-7>li:before{content:"\0025cb   "}.lst-kix_gmr2bu8eavte-1>li:before{content:"\0025cb   "}.lst-kix_i0yf1mju0g1s-3>li:before{content:"\0025cf   "}.lst-kix_t1nnqma9pg08-2>li:before{content:"\0025a0   "}.lst-kix_w9krzpl9jsp-6>li:before{content:"\0025cf   "}.lst-kix_2tcxxdhwr5nc-6>li:before{content:"\0025cf   "}.lst-kix_45zyqca0dor3-8>li:before{content:"\0025a0   "}.lst-kix_9czq3plvi9ig-2>li:before{content:"\0025a0   "}.lst-kix_vexpnyyatkbq-1>li:before{content:"\0025cb   "}.lst-kix_9bz6byc4bv0o-1>li:before{content:"\0025cb   "}.lst-kix_o9zj68me8yj0-2>li:before{content:"-  "}.lst-kix_2yb6ynjarz9t-8>li:before{content:"\0025a0   "}.lst-kix_kfuatcy312kx-0>li:before{content:"\0025cf   "}.lst-kix_vnj3yd9aagbp-2>li:before{content:"\0025a0   "}ul.lst-kix_l555prmkzand-0{list-style-type:none}ul.lst-kix_l555prmkzand-2{list-style-type:none}ul.lst-kix_l555prmkzand-1{list-style-type:none}ul.lst-kix_l555prmkzand-4{list-style-type:none}ul.lst-kix_l555prmkzand-3{list-style-type:none}ul.lst-kix_l555prmkzand-6{list-style-type:none}ul.lst-kix_l555prmkzand-5{list-style-type:none}ul.lst-kix_l555prmkzand-8{list-style-type:none}.lst-kix_8qkhix9sdgh8-5>li:before{content:"\0025a0   "}ul.lst-kix_l555prmkzand-7{list-style-type:none}.lst-kix_5uwviijqeog0-1>li:before{content:"\0025cb   "}.lst-kix_izsd5g4fgpc-5>li:before{content:"\0025a0   "}.lst-kix_tgtuyk7iugqt-0>li:before{content:"\0025cf   "}.lst-kix_4qgjp0e8yt8m-3>li:before{content:"\0025cf   "}.lst-kix_t7dbdae30u9t-7>li:before{content:"\0025cb   "}.lst-kix_g5ocf0ak9bci-0>li:before{content:"\0025cf   "}.lst-kix_i94q0a22exrp-1>li:before{content:"\0025cb   "}.lst-kix_4wi60e30t59b-2>li:before{content:"\0025a0   "}ul.lst-kix_lojbu18a3l9-3{list-style-type:none}ul.lst-kix_lojbu18a3l9-4{list-style-type:none}ul.lst-kix_lojbu18a3l9-1{list-style-type:none}ul.lst-kix_lojbu18a3l9-2{list-style-type:none}ul.lst-kix_lojbu18a3l9-7{list-style-type:none}ul.lst-kix_lojbu18a3l9-8{list-style-type:none}ul.lst-kix_lojbu18a3l9-5{list-style-type:none}ul.lst-kix_lojbu18a3l9-6{list-style-type:none}.lst-kix_fnntpv12ge7c-2>li:before{content:"\0025a0   "}ul.lst-kix_lojbu18a3l9-0{list-style-type:none}.lst-kix_afne6v2lp0be-7>li:before{content:"\0025cb   "}ul.lst-kix_9orpva36zqgw-0{list-style-type:none}ul.lst-kix_9orpva36zqgw-1{list-style-type:none}ul.lst-kix_9orpva36zqgw-2{list-style-type:none}ul.lst-kix_9orpva36zqgw-3{list-style-type:none}.lst-kix_tsc2yqmm539t-7>li{counter-increment:lst-ctn-kix_tsc2yqmm539t-7}ul.lst-kix_9orpva36zqgw-4{list-style-type:none}.lst-kix_68nz8s40mnx9-4>li:before{content:"\0025cb   "}ul.lst-kix_9orpva36zqgw-5{list-style-type:none}ul.lst-kix_9orpva36zqgw-6{list-style-type:none}ul.lst-kix_9orpva36zqgw-7{list-style-type:none}.lst-kix_kviltkqr3kxc-5>li:before{content:"\0025a0   "}.lst-kix_gc3eht6946jv-0>li:before{content:"\0025cf   "}.lst-kix_3jdd6arud0e0-8>li:before{content:"\0025a0   "}.lst-kix_4u8tsqm7y9op-6>li:before{content:"\0025cf   "}.lst-kix_mglb6ei1fc9r-8>li:before{content:"\0025a0   "}.lst-kix_e3cxiuksdiku-3>li:before{content:"\0025cf   "}.lst-kix_7fftgdac6j6-4>li:before{content:"\0025cb   "}.lst-kix_3uimjn60qjnx-2>li:before{content:"\0025a0   "}.lst-kix_pvyv30yiwv0n-7>li:before{content:"\0025cb   "}ul.lst-kix_up6yrorns79d-0{list-style-type:none}.lst-kix_6m7znixdz235-7>li:before{content:"\0025cb   "}ul.lst-kix_up6yrorns79d-2{list-style-type:none}ul.lst-kix_up6yrorns79d-1{list-style-type:none}.lst-kix_sp06awf5qvvx-2>li:before{content:"\0025a0   "}.lst-kix_2cqjr2ei92jl-3>li:before{content:"\0025cf   "}.lst-kix_w1xl8yxhafp5-2>li:before{content:"\0025a0   "}ul.lst-kix_up6yrorns79d-8{list-style-type:none}ul.lst-kix_9orpva36zqgw-8{list-style-type:none}ul.lst-kix_up6yrorns79d-7{list-style-type:none}.lst-kix_oofi1dgq0nej-8>li:before{content:"\0025a0   "}.lst-kix_4nm4szcl7et4-8>li:before{content:"\0025a0   "}.lst-kix_l2qc0wi8rc8e-4>li:before{content:"\0025cb   "}.lst-kix_bhoq2060wyww-8>li:before{content:"\0025a0   "}ul.lst-kix_up6yrorns79d-4{list-style-type:none}ul.lst-kix_up6yrorns79d-3{list-style-type:none}ul.lst-kix_up6yrorns79d-6{list-style-type:none}ul.lst-kix_up6yrorns79d-5{list-style-type:none}ul.lst-kix_c6t6pz4sgcyt-8{list-style-type:none}.lst-kix_lf7onj2nrr7v-3>li:before{content:"\0025cf   "}ul.lst-kix_c6t6pz4sgcyt-4{list-style-type:none}ol.lst-kix_srupee17v0mb-8{list-style-type:none}ul.lst-kix_c6t6pz4sgcyt-5{list-style-type:none}.lst-kix_rtxzgybdcpml-7>li:before{content:"\0025cb   "}ul.lst-kix_c6t6pz4sgcyt-6{list-style-type:none}ul.lst-kix_c6t6pz4sgcyt-7{list-style-type:none}.lst-kix_1oywm8db5jne-5>li:before{content:"\0025a0   "}.lst-kix_nn0h438aq2o5-6>li:before{content:"\0025cf   "}ul.lst-kix_c6t6pz4sgcyt-0{list-style-type:none}ul.lst-kix_c6t6pz4sgcyt-1{list-style-type:none}ul.lst-kix_c6t6pz4sgcyt-2{list-style-type:none}ul.lst-kix_c6t6pz4sgcyt-3{list-style-type:none}.lst-kix_mtdb7jqchtcn-2>li:before{content:"\0025a0   "}.lst-kix_kizzdizga4v0-1>li:before{content:"\0025cb   "}ol.lst-kix_srupee17v0mb-4{list-style-type:none}ol.lst-kix_srupee17v0mb-5{list-style-type:none}.lst-kix_4nm4szcl7et4-0>li:before{content:"\0025cf   "}.lst-kix_9x4yq5ss9tc1-2>li:before{content:"\0025a0   "}.lst-kix_4683th2gmjda-2>li:before{content:"\0025a0   "}ol.lst-kix_srupee17v0mb-6{list-style-type:none}ol.lst-kix_srupee17v0mb-7{list-style-type:none}ol.lst-kix_srupee17v0mb-0{list-style-type:none}ol.lst-kix_srupee17v0mb-1{list-style-type:none}.lst-kix_idsnzgd8q5di-8>li:before{content:"\0025a0   "}ol.lst-kix_srupee17v0mb-2{list-style-type:none}ol.lst-kix_srupee17v0mb-3{list-style-type:none}ul.lst-kix_by7qhqpvs1r5-5{list-style-type:none}ul.lst-kix_6omq6vtmahws-7{list-style-type:none}.lst-kix_64o9mnu4lnxd-7>li:before{content:"\0025cb   "}ul.lst-kix_by7qhqpvs1r5-4{list-style-type:none}ul.lst-kix_6omq6vtmahws-6{list-style-type:none}ul.lst-kix_by7qhqpvs1r5-7{list-style-type:none}ul.lst-kix_6omq6vtmahws-5{list-style-type:none}ul.lst-kix_by7qhqpvs1r5-6{list-style-type:none}ul.lst-kix_6omq6vtmahws-4{list-style-type:none}ul.lst-kix_by7qhqpvs1r5-1{list-style-type:none}ul.lst-kix_6omq6vtmahws-3{list-style-type:none}ul.lst-kix_by7qhqpvs1r5-0{list-style-type:none}ul.lst-kix_6omq6vtmahws-2{list-style-type:none}.lst-kix_4knzszhhdok2-2>li:before{content:"\0025a0   "}.lst-kix_4knzszhhdok2-5>li:before{content:"\0025a0   "}ul.lst-kix_by7qhqpvs1r5-3{list-style-type:none}ul.lst-kix_6omq6vtmahws-1{list-style-type:none}ul.lst-kix_by7qhqpvs1r5-2{list-style-type:none}ul.lst-kix_6omq6vtmahws-0{list-style-type:none}.lst-kix_4knzszhhdok2-8>li:before{content:"\0025a0   "}.lst-kix_g2wmx2i89hb-7>li:before{content:"\0025cb   "}ul.lst-kix_by7qhqpvs1r5-8{list-style-type:none}.lst-kix_64o9mnu4lnxd-4>li:before{content:"\0025cb   "}ul.lst-kix_fd670jgoibjs-2{list-style-type:none}.lst-kix_g2wmx2i89hb-4>li:before{content:"\0025cb   "}.lst-kix_u6oawcl4nq58-2>li:before{content:"\0025a0   "}ul.lst-kix_fd670jgoibjs-3{list-style-type:none}ul.lst-kix_fd670jgoibjs-4{list-style-type:none}ul.lst-kix_fd670jgoibjs-5{list-style-type:none}.lst-kix_u7by882ixwqv-6>li:before{content:"\0025cf   "}ul.lst-kix_fd670jgoibjs-0{list-style-type:none}ul.lst-kix_fd670jgoibjs-1{list-style-type:none}.lst-kix_txo0zcn8hx7-7>li:before{content:"\0025cb   "}.lst-kix_yxl9yzqp3bqd-3>li:before{content:"\0025cf   "}ul.lst-kix_fd670jgoibjs-6{list-style-type:none}ul.lst-kix_fd670jgoibjs-7{list-style-type:none}ul.lst-kix_fd670jgoibjs-8{list-style-type:none}ul.lst-kix_bbzhpmijr633-0{list-style-type:none}ul.lst-kix_7mi52l6y9ptp-2{list-style-type:none}ul.lst-kix_7mi52l6y9ptp-1{list-style-type:none}ul.lst-kix_7mi52l6y9ptp-0{list-style-type:none}ul.lst-kix_7mi52l6y9ptp-6{list-style-type:none}ul.lst-kix_7mi52l6y9ptp-5{list-style-type:none}ul.lst-kix_7mi52l6y9ptp-4{list-style-type:none}ul.lst-kix_7mi52l6y9ptp-3{list-style-type:none}.lst-kix_yxl9yzqp3bqd-6>li:before{content:"\0025cf   "}.lst-kix_9ynuh6dd4pus-0>li:before{content:"\0025cf   "}ul.lst-kix_7mi52l6y9ptp-8{list-style-type:none}.lst-kix_g2wmx2i89hb-1>li:before{content:"\0025cb   "}ul.lst-kix_7mi52l6y9ptp-7{list-style-type:none}ul.lst-kix_xclf8ew5xwnq-0{list-style-type:none}ul.lst-kix_xclf8ew5xwnq-1{list-style-type:none}ul.lst-kix_xclf8ew5xwnq-2{list-style-type:none}ul.lst-kix_xclf8ew5xwnq-3{list-style-type:none}.lst-kix_u6oawcl4nq58-5>li:before{content:"\0025a0   "}ul.lst-kix_xclf8ew5xwnq-4{list-style-type:none}ul.lst-kix_xclf8ew5xwnq-5{list-style-type:none}.lst-kix_pfbe3x4ba630-0>li:before{content:"\0025cf   "}ul.lst-kix_xclf8ew5xwnq-6{list-style-type:none}ul.lst-kix_bbzhpmijr633-8{list-style-type:none}ul.lst-kix_xclf8ew5xwnq-7{list-style-type:none}ul.lst-kix_bbzhpmijr633-7{list-style-type:none}ul.lst-kix_xclf8ew5xwnq-8{list-style-type:none}ul.lst-kix_bbzhpmijr633-6{list-style-type:none}ul.lst-kix_bbzhpmijr633-5{list-style-type:none}ul.lst-kix_bbzhpmijr633-4{list-style-type:none}ul.lst-kix_bbzhpmijr633-3{list-style-type:none}ul.lst-kix_bbzhpmijr633-2{list-style-type:none}.lst-kix_j0o0ck7ntjzh-3>li:before{content:"\0025cf   "}ul.lst-kix_bbzhpmijr633-1{list-style-type:none}.lst-kix_4v5uuo4j022q-2>li:before{content:"\0025a0   "}.lst-kix_2grrmxr8q0i0-4>li:before{content:"\0025cb   "}.lst-kix_24obzjkgjhqt-5>li:before{content:"\0025a0   "}.lst-kix_4v5uuo4j022q-5>li:before{content:"\0025a0   "}.lst-kix_24obzjkgjhqt-8>li:before{content:"\0025a0   "}.lst-kix_2grrmxr8q0i0-1>li:before{content:"\0025cb   "}.lst-kix_j0o0ck7ntjzh-6>li:before{content:"\0025cf   "}.lst-kix_s7yi1m4cq9qk-8>li:before{content:"\0025a0   "}.lst-kix_wt4lxomyh94s-6>li:before{content:"-  "}.lst-kix_2grrmxr8q0i0-7>li:before{content:"\0025cb   "}.lst-kix_dacire7nzy6o-8>li:before{content:"\0025a0   "}.lst-kix_5mcoll6nkdaa-3>li:before{content:"\0025cf   "}.lst-kix_dacire7nzy6o-5>li:before{content:"\0025a0   "}.lst-kix_gjh3cugwmzpc-7>li:before{content:"\0025cb   "}.lst-kix_5mcoll6nkdaa-0>li:before{content:"\0025cf   "}.lst-kix_j8606buix1qi-4>li:before{content:"\0025cb   "}.lst-kix_j8606buix1qi-1>li:before{content:"\0025cb   "}.lst-kix_wt4lxomyh94s-3>li:before{content:"-  "}.lst-kix_24obzjkgjhqt-2>li:before{content:"\0025a0   "}.lst-kix_wt4lxomyh94s-0>li:before{content:"-  "}.lst-kix_trx91tt3i1ee-6>li:before{content:"\0025cf   "}.lst-kix_qvmzdr2urb9j-6>li:before{content:"\0025cf   "}.lst-kix_trx91tt3i1ee-3>li:before{content:"\0025cf   "}.lst-kix_j8606buix1qi-7>li:before{content:"\0025cb   "}.lst-kix_qvmzdr2urb9j-0>li:before{content:"\0025cf   "}.lst-kix_gxvgspx76nqx-1>li:before{content:"-  "}.lst-kix_qvmzdr2urb9j-3>li:before{content:"\0025cf   "}ul.lst-kix_6omq6vtmahws-8{list-style-type:none}.lst-kix_n64wxslery5z-6>li:before{content:"\0025cf   "}.lst-kix_srn1fozfk9nn-3>li:before{content:"\0025cf   "}ul.lst-kix_dii13kfyl9ma-8{list-style-type:none}.lst-kix_tsc2yqmm539t-4>li:before{content:"" counter(lst-ctn-kix_tsc2yqmm539t-4,lower-latin) ". "}.lst-kix_n64wxslery5z-0>li:before{content:"\0025cf   "}.lst-kix_wv60nibffqic-1>li:before{content:"\0025cb   "}.lst-kix_6jta2mj2opdj-5>li:before{content:"\0025a0   "}.lst-kix_whyql51jliaq-2>li:before{content:"\0025a0   "}.lst-kix_zep9qz8je63n-8>li:before{content:"\0025a0   "}.lst-kix_p66sfkc4ny5f-0>li:before{content:"\0025cf   "}.lst-kix_gxvgspx76nqx-7>li:before{content:"-  "}.lst-kix_v4vy1dgu53ia-7>li:before{content:"\0025cb   "}.lst-kix_fnntpv12ge7c-5>li:before{content:"\0025a0   "}.lst-kix_dacire7nzy6o-2>li:before{content:"\0025a0   "}.lst-kix_gmr2bu8eavte-7>li:before{content:"\0025cb   "}.lst-kix_1jsoq3g3afbv-5>li:before{content:"\0025a0   "}.lst-kix_5mcoll6nkdaa-6>li:before{content:"\0025cf   "}.lst-kix_kihk58z8dl9b-0>li:before{content:"\0025cf   "}ul.lst-kix_dii13kfyl9ma-3{list-style-type:none}ul.lst-kix_dii13kfyl9ma-2{list-style-type:none}.lst-kix_ag80f2hqwfhx-8>li:before{content:"\0025a0   "}ul.lst-kix_dii13kfyl9ma-1{list-style-type:none}.lst-kix_i94q0a22exrp-4>li:before{content:"\0025cb   "}ul.lst-kix_dii13kfyl9ma-0{list-style-type:none}ul.lst-kix_dii13kfyl9ma-7{list-style-type:none}ul.lst-kix_dii13kfyl9ma-6{list-style-type:none}.lst-kix_kihk58z8dl9b-6>li:before{content:"\0025cf   "}ul.lst-kix_dii13kfyl9ma-5{list-style-type:none}ul.lst-kix_dii13kfyl9ma-4{list-style-type:none}.lst-kix_p66sfkc4ny5f-6>li:before{content:"\0025cf   "}.lst-kix_j0o0ck7ntjzh-0>li:before{content:"\0025cb   "}.lst-kix_ssouwh4l2bgy-0>li:before{content:"\0025cf   "}.lst-kix_3g1k0ldodoso-8>li:before{content:"\0025a0   "}.lst-kix_7v1cxulxokc7-6>li:before{content:"\0025cf   "}.lst-kix_3g1k0ldodoso-2>li:before{content:"\0025a0   "}.lst-kix_kymf5on3p83t-2>li:before{content:"\0025a0   "}.lst-kix_3hrtg26wb9bu-6>li:before{content:"\0025cf   "}.lst-kix_kfa6jji21f4h-3>li:before{content:"\0025cf   "}.lst-kix_pfbe3x4ba630-3>li:before{content:"\0025cf   "}.lst-kix_ssouwh4l2bgy-6>li:before{content:"\0025cf   "}.lst-kix_v4vy1dgu53ia-1>li:before{content:"\0025cb   "}.lst-kix_yoaj41w0jig0-7>li:before{content:"\0025cb   "}.lst-kix_n0ff4gjm91tm-6>li:before{content:"\0025cf   "}.lst-kix_sp06awf5qvvx-5>li:before{content:"\0025a0   "}ul.lst-kix_5uwviijqeog0-8{list-style-type:none}ul.lst-kix_5uwviijqeog0-6{list-style-type:none}ul.lst-kix_5uwviijqeog0-7{list-style-type:none}ul.lst-kix_5uwviijqeog0-4{list-style-type:none}.lst-kix_9ynuh6dd4pus-3>li:before{content:"\0025cf   "}ul.lst-kix_5uwviijqeog0-5{list-style-type:none}ul.lst-kix_5uwviijqeog0-2{list-style-type:none}.lst-kix_l5j0c6x8jedh-8>li:before{content:"-  "}ul.lst-kix_5uwviijqeog0-3{list-style-type:none}ul.lst-kix_5uwviijqeog0-0{list-style-type:none}.lst-kix_kymf5on3p83t-8>li:before{content:"\0025a0   "}.lst-kix_2cqjr2ei92jl-0>li:before{content:"\0025cf   "}ul.lst-kix_5uwviijqeog0-1{list-style-type:none}.lst-kix_rtxzgybdcpml-4>li:before{content:"\0025cb   "}.lst-kix_tgtuyk7iugqt-3>li:before{content:"\0025cf   "}.lst-kix_n0ff4gjm91tm-0>li:before{content:"\0025cf   "}.lst-kix_epmllfkx8tp-5>li:before{content:"\0025a0   "}ul.lst-kix_v38knoi1xqwy-2{list-style-type:none}ul.lst-kix_v38knoi1xqwy-1{list-style-type:none}ul.lst-kix_v38knoi1xqwy-4{list-style-type:none}ul.lst-kix_v38knoi1xqwy-3{list-style-type:none}ul.lst-kix_v38knoi1xqwy-0{list-style-type:none}.lst-kix_l5j0c6x8jedh-2>li:before{content:"-  "}.lst-kix_zep9qz8je63n-2>li:before{content:"\0025a0   "}ul.lst-kix_v38knoi1xqwy-6{list-style-type:none}.lst-kix_3hrtg26wb9bu-0>li:before{content:"\0025cf   "}.lst-kix_txo0zcn8hx7-1>li:before{content:"\0025cb   "}ul.lst-kix_v38knoi1xqwy-5{list-style-type:none}.lst-kix_64o9mnu4lnxd-1>li:before{content:"\0025cb   "}.lst-kix_kviltkqr3kxc-8>li:before{content:"\0025a0   "}ul.lst-kix_v38knoi1xqwy-8{list-style-type:none}.lst-kix_yoaj41w0jig0-1>li:before{content:"\0025cb   "}ul.lst-kix_v38knoi1xqwy-7{list-style-type:none}.lst-kix_vnj3yd9aagbp-5>li:before{content:"\0025a0   "}ul.lst-kix_kizzdizga4v0-7{list-style-type:none}ul.lst-kix_kizzdizga4v0-6{list-style-type:none}.lst-kix_zcy565gabcmu-1>li:before{content:"\0025cb   "}ul.lst-kix_kizzdizga4v0-5{list-style-type:none}ul.lst-kix_kizzdizga4v0-4{list-style-type:none}.lst-kix_fd670jgoibjs-6>li:before{content:"\0025cf   "}.lst-kix_xsot34m5j4b-3>li:before{content:"\0025cf   "}.lst-kix_a6lqukhx5fat-5>li:before{content:"\0025a0   "}ol.lst-kix_srupee17v0mb-8.start{counter-reset:lst-ctn-kix_srupee17v0mb-8 0}.lst-kix_9l9kjglfjgjz-0>li:before{content:"\0025cf   "}.lst-kix_3iyql9jafv7n-0>li:before{content:"\0025cf   "}ul.lst-kix_kizzdizga4v0-8{list-style-type:none}.lst-kix_fd670jgoibjs-3>li:before{content:"\0025cf   "}.lst-kix_5fltblknzo3j-1>li:before{content:"\0025cb   "}.lst-kix_j3ti34irq4rs-3>li:before{content:"\0025cf   "}.lst-kix_gxbfiekgqjd6-5>li:before{content:"\0025a0   "}.lst-kix_3iyql9jafv7n-3>li:before{content:"\0025cf   "}.lst-kix_zdgpaglha5wb-0>li:before{content:"  "}.lst-kix_j3ti34irq4rs-0>li:before{content:"\0025cf   "}.lst-kix_gxbfiekgqjd6-2>li:before{content:"\0025a0   "}.lst-kix_yn02lgpxo9se-7>li:before{content:"\0025cb   "}ul.lst-kix_1l36jc1oov6-4{list-style-type:none}ul.lst-kix_1l36jc1oov6-3{list-style-type:none}.lst-kix_gu62etns0rjq-7>li:before{content:"\0025cb   "}ul.lst-kix_1l36jc1oov6-6{list-style-type:none}ul.lst-kix_1l36jc1oov6-5{list-style-type:none}ol.lst-kix_srupee17v0mb-2.start{counter-reset:lst-ctn-kix_srupee17v0mb-2 0}.lst-kix_1k1th764da5j-7>li:before{content:"\0025cb   "}ul.lst-kix_1l36jc1oov6-0{list-style-type:none}.lst-kix_8pk9oqxklycz-7>li:before{content:"\0025cb   "}ul.lst-kix_1l36jc1oov6-2{list-style-type:none}ul.lst-kix_1l36jc1oov6-1{list-style-type:none}.lst-kix_vs58j7xf1fh7-0>li:before{content:"\0025cf   "}ul.lst-kix_1l36jc1oov6-8{list-style-type:none}ul.lst-kix_1l36jc1oov6-7{list-style-type:none}.lst-kix_gu62etns0rjq-4>li:before{content:"\0025cb   "}.lst-kix_a6lqukhx5fat-8>li:before{content:"\0025a0   "}.lst-kix_abg8yi9rye91-7>li:before{content:"\0025cb   "}.lst-kix_8pk9oqxklycz-4>li:before{content:"\0025cb   "}ul.lst-kix_kizzdizga4v0-3{list-style-type:none}ul.lst-kix_kizzdizga4v0-2{list-style-type:none}.lst-kix_1k1th764da5j-4>li:before{content:"\0025cb   "}ul.lst-kix_kizzdizga4v0-1{list-style-type:none}ul.lst-kix_kizzdizga4v0-0{list-style-type:none}.lst-kix_vs58j7xf1fh7-3>li:before{content:"\0025cf   "}.lst-kix_7kr9zis60z3j-8>li:before{content:"\0025a0   "}.lst-kix_izm55n8luwgn-2>li:before{content:"\0025a0   "}.lst-kix_pfk02alca94e-3>li:before{content:"\0025cf   "}.lst-kix_o9zj68me8yj0-8>li:before{content:"-  "}.lst-kix_pfk02alca94e-0>li:before{content:"\0025cf   "}.lst-kix_trs82cplclba-1>li:before{content:"\0025cb   "}.lst-kix_mrqrqp74n3id-1>li:before{content:"\0025cb   "}.lst-kix_q0wctjb2y8b-7>li:before{content:"\0025cb   "}.lst-kix_m1mzfy5afs2o-6>li:before{content:"\0025cf   "}.lst-kix_whyql51jliaq-5>li:before{content:"\0025a0   "}.lst-kix_hrnpa7no5eg-2>li:before{content:"\0025a0   "}.lst-kix_t1nnqma9pg08-5>li:before{content:"\0025a0   "}ul.lst-kix_eh7lncq6en9i-8{list-style-type:none}.lst-kix_o5dtwbk7bxd5-1>li:before{content:"\0025cb   "}ul.lst-kix_eh7lncq6en9i-7{list-style-type:none}ul.lst-kix_eh7lncq6en9i-6{list-style-type:none}ul.lst-kix_eh7lncq6en9i-5{list-style-type:none}ul.lst-kix_eh7lncq6en9i-4{list-style-type:none}.lst-kix_54yn6dknd642-1>li:before{content:"\0025cb   "}ul.lst-kix_dacire7nzy6o-8{list-style-type:none}ul.lst-kix_eh7lncq6en9i-3{list-style-type:none}.lst-kix_uu0tjb1960c1-4>li:before{content:"\0025cb   "}ul.lst-kix_eh7lncq6en9i-2{list-style-type:none}ul.lst-kix_eh7lncq6en9i-1{list-style-type:none}ul.lst-kix_dacire7nzy6o-5{list-style-type:none}.lst-kix_kfuatcy312kx-6>li:before{content:"\0025cf   "}ul.lst-kix_eh7lncq6en9i-0{list-style-type:none}ul.lst-kix_dacire7nzy6o-4{list-style-type:none}ul.lst-kix_dacire7nzy6o-7{list-style-type:none}ul.lst-kix_dacire7nzy6o-6{list-style-type:none}ul.lst-kix_dacire7nzy6o-1{list-style-type:none}.lst-kix_uu0tjb1960c1-7>li:before{content:"\0025cb   "}.lst-kix_trs82cplclba-4>li:before{content:"\0025cb   "}ul.lst-kix_dacire7nzy6o-0{list-style-type:none}ul.lst-kix_dacire7nzy6o-3{list-style-type:none}ul.lst-kix_dacire7nzy6o-2{list-style-type:none}.lst-kix_xsdedfcj27fz-5>li:before{content:"\0025a0   "}.lst-kix_xsot34m5j4b-6>li:before{content:"\0025cf   "}.lst-kix_whyql51jliaq-8>li:before{content:"\0025a0   "}.lst-kix_t1nnqma9pg08-8>li:before{content:"\0025a0   "}ul.lst-kix_qsmqo56xypa0-5{list-style-type:none}ul.lst-kix_qsmqo56xypa0-6{list-style-type:none}ul.lst-kix_qsmqo56xypa0-7{list-style-type:none}ul.lst-kix_qsmqo56xypa0-8{list-style-type:none}.lst-kix_c4mjpxs5t8z-3>li:before{content:"\0025cf   "}.lst-kix_tsc2yqmm539t-1>li:before{content:"\0025cb   "}.lst-kix_9orpva36zqgw-2>li:before{content:"\0025a0   "}.lst-kix_3sqsdlm3qg3k-2>li:before{content:"\0025a0   "}.lst-kix_3vhpfjuy7tvg-4>li:before{content:"\0025cb   "}ul.lst-kix_qsmqo56xypa0-0{list-style-type:none}.lst-kix_vnj3yd9aagbp-8>li:before{content:"\0025a0   "}ul.lst-kix_qsmqo56xypa0-1{list-style-type:none}ul.lst-kix_qsmqo56xypa0-2{list-style-type:none}ul.lst-kix_qsmqo56xypa0-3{list-style-type:none}.lst-kix_fvsyn7dqkka1-2>li:before{content:"\0025a0   "}ul.lst-kix_qsmqo56xypa0-4{list-style-type:none}.lst-kix_xsdedfcj27fz-2>li:before{content:"\0025a0   "}.lst-kix_gxvgspx76nqx-4>li:before{content:"-  "}.lst-kix_o1ljou14zs74-1>li:before{content:"\0025cb   "}ul.lst-kix_nd4cj51qmb1k-0{list-style-type:none}ul.lst-kix_nd4cj51qmb1k-1{list-style-type:none}.lst-kix_xlixir5f8ikv-3>li:before{content:"\0025cf   "}.lst-kix_r20deuqh30jy-6>li:before{content:"\0025cf   "}.lst-kix_srn1fozfk9nn-0>li:before{content:"\0025cf   "}.lst-kix_6jta2mj2opdj-8>li:before{content:"\0025a0   "}.lst-kix_p66sfkc4ny5f-3>li:before{content:"\0025cf   "}.lst-kix_ya0b59jf88o6-4>li:before{content:"\0025cb   "}.lst-kix_1jsoq3g3afbv-2>li:before{content:"\0025a0   "}.lst-kix_zhnrfbqi7c3p-6>li:before{content:"\0025cf   "}ul.lst-kix_nd4cj51qmb1k-6{list-style-type:none}ul.lst-kix_nd4cj51qmb1k-7{list-style-type:none}.lst-kix_fnntpv12ge7c-8>li:before{content:"\0025a0   "}.lst-kix_o4w8hr2p0ha-7>li:before{content:"\0025cb   "}.lst-kix_o7qc3ia828r4-4>li:before{content:"\0025cb   "}ul.lst-kix_nd4cj51qmb1k-8{list-style-type:none}ul.lst-kix_nd4cj51qmb1k-2{list-style-type:none}ul.lst-kix_nd4cj51qmb1k-3{list-style-type:none}ul.lst-kix_nd4cj51qmb1k-4{list-style-type:none}ul.lst-kix_nd4cj51qmb1k-5{list-style-type:none}.lst-kix_x87etp2vfva3-4>li:before{content:"-  "}.lst-kix_kihk58z8dl9b-3>li:before{content:"\0025cf   "}.lst-kix_yeuz6sv2qnho-5>li:before{content:"\0025a0   "}.lst-kix_hcwipu97fgnf-0>li:before{content:"\0025cf   "}.lst-kix_i94q0a22exrp-7>li:before{content:"\0025cb   "}ul.lst-kix_8l5du8p17xdg-0{list-style-type:none}ul.lst-kix_j3ti34irq4rs-1{list-style-type:none}ul.lst-kix_8l5du8p17xdg-1{list-style-type:none}ul.lst-kix_j3ti34irq4rs-2{list-style-type:none}.lst-kix_gl7fpz1y51y1-8>li:before{content:"\0025a0   "}ul.lst-kix_j3ti34irq4rs-3{list-style-type:none}ul.lst-kix_j3ti34irq4rs-4{list-style-type:none}ul.lst-kix_8l5du8p17xdg-4{list-style-type:none}ul.lst-kix_8l5du8p17xdg-5{list-style-type:none}ul.lst-kix_8l5du8p17xdg-2{list-style-type:none}ul.lst-kix_8l5du8p17xdg-3{list-style-type:none}ul.lst-kix_j3ti34irq4rs-0{list-style-type:none}.lst-kix_ssouwh4l2bgy-3>li:before{content:"\0025cf   "}ul.lst-kix_8qkhix9sdgh8-5{list-style-type:none}ul.lst-kix_8qkhix9sdgh8-6{list-style-type:none}.lst-kix_pwl0pufgh6dv-8>li:before{content:"\0025a0   "}ul.lst-kix_8qkhix9sdgh8-3{list-style-type:none}.lst-kix_lp80c754wvim-8>li:before{content:"\0025a0   "}ul.lst-kix_8qkhix9sdgh8-4{list-style-type:none}.lst-kix_eh7lncq6en9i-4>li:before{content:"\0025cb   "}ul.lst-kix_8qkhix9sdgh8-1{list-style-type:none}.lst-kix_pp0573v7gp5z-1>li:before{content:"\0025cb   "}ul.lst-kix_8qkhix9sdgh8-2{list-style-type:none}ul.lst-kix_8qkhix9sdgh8-0{list-style-type:none}ul.lst-kix_8l5du8p17xdg-8{list-style-type:none}ul.lst-kix_8l5du8p17xdg-6{list-style-type:none}ul.lst-kix_8l5du8p17xdg-7{list-style-type:none}.lst-kix_pfidrtjb5lqv-7>li:before{content:"\0025cb   "}.lst-kix_kizzdizga4v0-7>li:before{content:"\0025cb   "}.lst-kix_kymf5on3p83t-5>li:before{content:"\0025a0   "}ul.lst-kix_j3ti34irq4rs-5{list-style-type:none}ul.lst-kix_j3ti34irq4rs-6{list-style-type:none}ul.lst-kix_8qkhix9sdgh8-7{list-style-type:none}ul.lst-kix_j3ti34irq4rs-7{list-style-type:none}.lst-kix_3g1k0ldodoso-5>li:before{content:"\0025a0   "}ul.lst-kix_8qkhix9sdgh8-8{list-style-type:none}ul.lst-kix_j3ti34irq4rs-8{list-style-type:none}.lst-kix_pfbe3x4ba630-6>li:before{content:"\0025cf   "}.lst-kix_sp06awf5qvvx-8>li:before{content:"\0025a0   "}.lst-kix_g3e6y0f95n7u-8>li:before{content:"\0025a0   "}.lst-kix_4o6376uieeve-4>li:before{content:"\0025cb   "}.lst-kix_oofi1dgq0nej-2>li:before{content:"\0025a0   "}.lst-kix_cfsaqxe055dn-7>li:before{content:"\0025cb   "}.lst-kix_kfa6jji21f4h-0>li:before{content:"\0025cf   "}.lst-kix_9ynuh6dd4pus-6>li:before{content:"\0025cf   "}.lst-kix_txo0zcn8hx7-4>li:before{content:"\0025cb   "}.lst-kix_yxl9yzqp3bqd-0>li:before{content:"\0025cf   "}.lst-kix_zep9qz8je63n-5>li:before{content:"\0025a0   "}ul.lst-kix_4j92pbqgy1h-1{list-style-type:none}ul.lst-kix_4j92pbqgy1h-0{list-style-type:none}ul.lst-kix_4j92pbqgy1h-3{list-style-type:none}ul.lst-kix_4j92pbqgy1h-2{list-style-type:none}.lst-kix_mlex94wk5tq-5>li:before{content:"\0025a0   "}.lst-kix_8ph4j5309jg1-5>li:before{content:"\0025a0   "}ul.lst-kix_4j92pbqgy1h-5{list-style-type:none}ul.lst-kix_4j92pbqgy1h-4{list-style-type:none}.lst-kix_tgtuyk7iugqt-6>li:before{content:"\0025cf   "}.lst-kix_qsmqo56xypa0-8>li:before{content:"\0025a0   "}ul.lst-kix_4j92pbqgy1h-7{list-style-type:none}.lst-kix_w1xl8yxhafp5-8>li:before{content:"\0025a0   "}ul.lst-kix_4j92pbqgy1h-6{list-style-type:none}.lst-kix_r2llq4i0x498-8>li:before{content:"\0025a0   "}.lst-kix_zcy565gabcmu-4>li:before{content:"\0025cb   "}ul.lst-kix_4j92pbqgy1h-8{list-style-type:none}.lst-kix_rtxzgybdcpml-1>li:before{content:"\0025cb   "}.lst-kix_z4v6nrp70nz7-2>li:before{content:"\0025a0   "}.lst-kix_mecbkjiqxfnl-6>li:before{content:"\0025cf   "}.lst-kix_epmllfkx8tp-8>li:before{content:"\0025a0   "}.lst-kix_2ze49x6dwuyc-8>li:before{content:"\0025a0   "}.lst-kix_2ze49x6dwuyc-2>li:before{content:"\0025a0   "}.lst-kix_qy2pejxz7e1k-1>li:before{content:"\0025cb   "}.lst-kix_gzy546en7hix-1>li:before{content:"\0025cb   "}.lst-kix_tx52nn14y93q-8>li:before{content:"\0025a0   "}ul.lst-kix_mlex94wk5tq-8{list-style-type:none}.lst-kix_tx52nn14y93q-5>li:before{content:"\0025a0   "}.lst-kix_5chsivk2mkzi-1>li:before{content:"\0025cb   "}ul.lst-kix_cruajxrmao23-8{list-style-type:none}ul.lst-kix_3g1k0ldodoso-7{list-style-type:none}ul.lst-kix_3g1k0ldodoso-8{list-style-type:none}ul.lst-kix_cruajxrmao23-6{list-style-type:none}ul.lst-kix_3g1k0ldodoso-5{list-style-type:none}ul.lst-kix_cruajxrmao23-7{list-style-type:none}ul.lst-kix_3g1k0ldodoso-6{list-style-type:none}.lst-kix_bbzhpmijr633-6>li:before{content:"\0025cf   "}.lst-kix_p6zn1qdl1q6g-2>li:before{content:"\0025a0   "}ul.lst-kix_cruajxrmao23-0{list-style-type:none}.lst-kix_hugw2gsg69de-6>li:before{content:"\0025cf   "}ul.lst-kix_cruajxrmao23-1{list-style-type:none}.lst-kix_fum98hryzqm2-1>li:before{content:"\0025cb   "}ul.lst-kix_cruajxrmao23-4{list-style-type:none}.lst-kix_tx52nn14y93q-2>li:before{content:"\0025a0   "}.lst-kix_npq7lfz9ly6z-7>li:before{content:"\0025cb   "}ul.lst-kix_cruajxrmao23-5{list-style-type:none}ul.lst-kix_cruajxrmao23-2{list-style-type:none}ul.lst-kix_cruajxrmao23-3{list-style-type:none}.lst-kix_ktcl1r9scb7w-1>li:before{content:"\0025cb   "}ul.lst-kix_5t41ldrjeoj7-8{list-style-type:none}ul.lst-kix_5t41ldrjeoj7-6{list-style-type:none}ul.lst-kix_5t41ldrjeoj7-7{list-style-type:none}ul.lst-kix_5t41ldrjeoj7-4{list-style-type:none}ul.lst-kix_5t41ldrjeoj7-5{list-style-type:none}ul.lst-kix_5t41ldrjeoj7-2{list-style-type:none}ul.lst-kix_5t41ldrjeoj7-3{list-style-type:none}ul.lst-kix_5t41ldrjeoj7-0{list-style-type:none}.lst-kix_2ze49x6dwuyc-5>li:before{content:"\0025a0   "}ul.lst-kix_5t41ldrjeoj7-1{list-style-type:none}.lst-kix_scp6tbbd2fcq-8>li:before{content:"\0025a0   "}.lst-kix_men9lw1a0mnk-0>li:before{content:"\0025cf   "}.lst-kix_m5vzryjtrruz-8>li:before{content:"\0025a0   "}.lst-kix_by7qhqpvs1r5-0>li:before{content:"\0025cf   "}.lst-kix_scp6tbbd2fcq-5>li:before{content:"\0025a0   "}.lst-kix_yeuz6sv2qnho-8>li:before{content:"\0025a0   "}.lst-kix_e97rs1rrkyjo-8>li:before{content:"\0025a0   "}.lst-kix_93x7l69l06zp-0>li:before{content:"\0025cf   "}.lst-kix_npq7lfz9ly6z-1>li:before{content:"\0025cb   "}.lst-kix_93x7l69l06zp-3>li:before{content:"\0025cf   "}.lst-kix_scp6tbbd2fcq-2>li:before{content:"\0025a0   "}.lst-kix_men9lw1a0mnk-6>li:before{content:"\0025cf   "}.lst-kix_93x7l69l06zp-6>li:before{content:"\0025cf   "}.lst-kix_ktcl1r9scb7w-4>li:before{content:"\0025cb   "}.lst-kix_men9lw1a0mnk-3>li:before{content:"\0025cf   "}ul.lst-kix_3g1k0ldodoso-0{list-style-type:none}.lst-kix_npq7lfz9ly6z-4>li:before{content:"\0025cb   "}ul.lst-kix_3g1k0ldodoso-3{list-style-type:none}.lst-kix_fum98hryzqm2-4>li:before{content:"\0025cb   "}ul.lst-kix_3g1k0ldodoso-4{list-style-type:none}ul.lst-kix_3g1k0ldodoso-1{list-style-type:none}ul.lst-kix_3g1k0ldodoso-2{list-style-type:none}ul.lst-kix_zcy565gabcmu-7{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-2{list-style-type:none}ul.lst-kix_u7by882ixwqv-4{list-style-type:none}ul.lst-kix_zcy565gabcmu-6{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-1{list-style-type:none}ul.lst-kix_u7by882ixwqv-3{list-style-type:none}.lst-kix_ktcl1r9scb7w-7>li:before{content:"\0025cb   "}.lst-kix_r20deuqh30jy-0>li:before{content:"\0025cf   "}ul.lst-kix_4u8tsqm7y9op-0{list-style-type:none}ul.lst-kix_u7by882ixwqv-2{list-style-type:none}.lst-kix_fum98hryzqm2-7>li:before{content:"\0025cb   "}ul.lst-kix_zcy565gabcmu-8{list-style-type:none}ul.lst-kix_u7by882ixwqv-1{list-style-type:none}.lst-kix_r20deuqh30jy-3>li:before{content:"\0025cf   "}ul.lst-kix_zcy565gabcmu-3{list-style-type:none}ul.lst-kix_u7by882ixwqv-0{list-style-type:none}ul.lst-kix_zcy565gabcmu-2{list-style-type:none}ul.lst-kix_zcy565gabcmu-5{list-style-type:none}ul.lst-kix_zcy565gabcmu-4{list-style-type:none}ul.lst-kix_mlex94wk5tq-4{list-style-type:none}ul.lst-kix_mlex94wk5tq-5{list-style-type:none}.lst-kix_gzy546en7hix-4>li:before{content:"\0025cb   "}ul.lst-kix_mlex94wk5tq-6{list-style-type:none}ul.lst-kix_zcy565gabcmu-1{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-8{list-style-type:none}ul.lst-kix_mlex94wk5tq-7{list-style-type:none}ul.lst-kix_zcy565gabcmu-0{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-7{list-style-type:none}.lst-kix_5chsivk2mkzi-4>li:before{content:"\0025cb   "}ul.lst-kix_mlex94wk5tq-0{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-6{list-style-type:none}ul.lst-kix_u7by882ixwqv-8{list-style-type:none}ul.lst-kix_mlex94wk5tq-1{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-5{list-style-type:none}ul.lst-kix_u7by882ixwqv-7{list-style-type:none}ul.lst-kix_mlex94wk5tq-2{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-4{list-style-type:none}ul.lst-kix_u7by882ixwqv-6{list-style-type:none}ul.lst-kix_mlex94wk5tq-3{list-style-type:none}ul.lst-kix_4u8tsqm7y9op-3{list-style-type:none}ul.lst-kix_u7by882ixwqv-5{list-style-type:none}.lst-kix_by7qhqpvs1r5-3>li:before{content:"\0025cf   "}.lst-kix_r953kfpy79kt-0>li:before{content:"\0025cf   "}.lst-kix_by7qhqpvs1r5-6>li:before{content:"\0025cf   "}.lst-kix_gzy546en7hix-7>li:before{content:"\0025cb   "}.lst-kix_5chsivk2mkzi-7>li:before{content:"\0025cb   "}ul.lst-kix_fktfq9ltsq98-7{list-style-type:none}ul.lst-kix_fktfq9ltsq98-8{list-style-type:none}ul.lst-kix_fktfq9ltsq98-5{list-style-type:none}ul.lst-kix_fktfq9ltsq98-6{list-style-type:none}.lst-kix_3vhpfjuy7tvg-1>li:before{content:"\0025cb   "}.lst-kix_dk6ingbu8z4-8>li:before{content:"\0025a0   "}ul.lst-kix_fktfq9ltsq98-0{list-style-type:none}ul.lst-kix_fktfq9ltsq98-3{list-style-type:none}.lst-kix_c4mjpxs5t8z-0>li:before{content:"\0025cf   "}ul.lst-kix_fktfq9ltsq98-4{list-style-type:none}ul.lst-kix_fktfq9ltsq98-1{list-style-type:none}ul.lst-kix_fktfq9ltsq98-2{list-style-type:none}.lst-kix_xlixir5f8ikv-6>li:before{content:"\0025cf   "}.lst-kix_o4w8hr2p0ha-4>li:before{content:"\0025cb   "}.lst-kix_cfsaqxe055dn-4>li:before{content:"\0025cb   "}.lst-kix_fvsyn7dqkka1-5>li:before{content:"\0025a0   "}.lst-kix_o1ljou14zs74-4>li:before{content:"\0025cb   "}.lst-kix_dk6ingbu8z4-2>li:before{content:"\0025a0   "}.lst-kix_ya0b59jf88o6-7>li:before{content:"\0025cb   "}.lst-kix_j9krs4wwadz8-0>li:before{content:"  "}.lst-kix_l5sge8zce4vp-8>li:before{content:"\0025a0   "}ul.lst-kix_mecbkjiqxfnl-7{list-style-type:none}ul.lst-kix_mecbkjiqxfnl-8{list-style-type:none}.lst-kix_mo5grncnzemi-1>li:before{content:"\0025cb   "}.lst-kix_5ov7bblzaw0u-6>li:before{content:"\0025cf   "}ul.lst-kix_mecbkjiqxfnl-1{list-style-type:none}.lst-kix_3sqsdlm3qg3k-5>li:before{content:"\0025a0   "}ul.lst-kix_mecbkjiqxfnl-2{list-style-type:none}.lst-kix_hcwipu97fgnf-3>li:before{content:"\0025cf   "}ul.lst-kix_mecbkjiqxfnl-0{list-style-type:none}ul.lst-kix_mecbkjiqxfnl-5{list-style-type:none}.lst-kix_o7qc3ia828r4-7>li:before{content:"\0025cb   "}.lst-kix_l5sge8zce4vp-2>li:before{content:"\0025a0   "}ul.lst-kix_mecbkjiqxfnl-6{list-style-type:none}.lst-kix_eh7lncq6en9i-7>li:before{content:"\0025cb   "}.lst-kix_qymwuf8ggtk1-5>li:before{content:"\0025a0   "}ul.lst-kix_mecbkjiqxfnl-3{list-style-type:none}ul.lst-kix_mecbkjiqxfnl-4{list-style-type:none}.lst-kix_5ov7bblzaw0u-0>li:before{content:"\0025cf   "}.lst-kix_x87etp2vfva3-7>li:before{content:"-  "}.lst-kix_brn07ewm5d7x-8>li:before{content:"\0025a0   "}.lst-kix_8ph4j5309jg1-2>li:before{content:"\0025a0   "}.lst-kix_dbltq7i3dnfs-3>li:before{content:"\0025cf   "}.lst-kix_4xd0kx9tx9nh-0>li:before{content:"\0025cf   "}.lst-kix_fktfq9ltsq98-4>li:before{content:"-  "}.lst-kix_mecbkjiqxfnl-3>li:before{content:"\0025cf   "}ul.lst-kix_sf1qf9bwyojp-4{list-style-type:none}.lst-kix_apk8f490x7qb-1>li:before{content:"\0025cb   "}ul.lst-kix_sf1qf9bwyojp-5{list-style-type:none}.lst-kix_brn07ewm5d7x-2>li:before{content:"\0025a0   "}.lst-kix_4xd0kx9tx9nh-6>li:before{content:"\0025cf   "}ul.lst-kix_sf1qf9bwyojp-2{list-style-type:none}ul.lst-kix_sf1qf9bwyojp-3{list-style-type:none}.lst-kix_pwl0pufgh6dv-5>li:before{content:"\0025a0   "}ul.lst-kix_sf1qf9bwyojp-8{list-style-type:none}ul.lst-kix_sf1qf9bwyojp-6{list-style-type:none}ul.lst-kix_sf1qf9bwyojp-7{list-style-type:none}.lst-kix_8979tijdi163-4>li:before{content:"\0025cb   "}ul.lst-kix_sf1qf9bwyojp-0{list-style-type:none}ul.lst-kix_sf1qf9bwyojp-1{list-style-type:none}.lst-kix_3mbe6pf0vyok-8>li:before{content:"\0025a0   "}.lst-kix_z4v6nrp70nz7-5>li:before{content:"\0025a0   "}.lst-kix_eqjgku92ysne-5>li:before{content:"\0025a0   "}.lst-kix_pfidrtjb5lqv-4>li:before{content:"\0025cb   "}.lst-kix_kw4p74ijjapz-2>li:before{content:"\0025a0   "}.lst-kix_4o6376uieeve-1>li:before{content:"\0025cb   "}.lst-kix_w9nfenze7id7-7>li:before{content:"\0025cb   "}.lst-kix_qsmqo56xypa0-5>li:before{content:"\0025a0   "}.lst-kix_r2llq4i0x498-5>li:before{content:"\0025a0   "}.lst-kix_cszf4nosnav1-3>li:before{content:"\0025cf   "}.lst-kix_mlex94wk5tq-8>li:before{content:"\0025a0   "}.lst-kix_a6lqukhx5fat-2>li:before{content:"\0025a0   "}.lst-kix_6zz37ot1aoo-4>li:before{content:"\0025cb   "}.lst-kix_az8p3db80uc9-1>li:before{content:"\0025cb   "}.lst-kix_87g5rwruaqks-8>li:before{content:"\0025a0   "}.lst-kix_6zz37ot1aoo-7>li:before{content:"\0025cb   "}.lst-kix_g4octshi0erf-5>li:before{content:"\0025a0   "}.lst-kix_az8p3db80uc9-4>li:before{content:"\0025cb   "}.lst-kix_xsot34m5j4b-0>li:before{content:"\0025cf   "}.lst-kix_ek5wwvmsnqx1-8>li:before{content:"\0025a0   "}.lst-kix_87g5rwruaqks-2>li:before{content:"\0025a0   "}.lst-kix_abg8yi9rye91-1>li:before{content:"\0025cb   "}.lst-kix_wsfytj8n987p-5>li:before{content:"\0025a0   "}.lst-kix_5fltblknzo3j-7>li:before{content:"\0025cb   "}.lst-kix_g4octshi0erf-2>li:before{content:"\0025a0   "}.lst-kix_5fltblknzo3j-4>li:before{content:"\0025cb   "}ul.lst-kix_ef6tx1pahaqo-2{list-style-type:none}ul.lst-kix_ef6tx1pahaqo-1{list-style-type:none}ul.lst-kix_ef6tx1pahaqo-4{list-style-type:none}.lst-kix_c2b60wgdja8r-6>li:before{content:"\0025cf   "}ul.lst-kix_ef6tx1pahaqo-3{list-style-type:none}.lst-kix_fd670jgoibjs-0>li:before{content:"\0025cf   "}.lst-kix_zdgpaglha5wb-3>li:before{content:"\0025cf   "}ul.lst-kix_ef6tx1pahaqo-6{list-style-type:none}ul.lst-kix_ef6tx1pahaqo-5{list-style-type:none}ul.lst-kix_ef6tx1pahaqo-8{list-style-type:none}ul.lst-kix_ef6tx1pahaqo-7{list-style-type:none}ul.lst-kix_sp06awf5qvvx-2{list-style-type:none}ul.lst-kix_zdgpaglha5wb-1{list-style-type:none}ul.lst-kix_sp06awf5qvvx-3{list-style-type:none}ul.lst-kix_zdgpaglha5wb-2{list-style-type:none}ul.lst-kix_sp06awf5qvvx-4{list-style-type:none}ul.lst-kix_zdgpaglha5wb-3{list-style-type:none}.lst-kix_3cigoxtebeue-3>li:before{content:"\0025cf   "}.lst-kix_vs58j7xf1fh7-6>li:before{content:"\0025cf   "}ul.lst-kix_sp06awf5qvvx-5{list-style-type:none}ul.lst-kix_zdgpaglha5wb-4{list-style-type:none}ul.lst-kix_sp06awf5qvvx-6{list-style-type:none}ul.lst-kix_sp06awf5qvvx-7{list-style-type:none}ul.lst-kix_sp06awf5qvvx-8{list-style-type:none}ul.lst-kix_zdgpaglha5wb-0{list-style-type:none}ul.lst-kix_2ze49x6dwuyc-1{list-style-type:none}ul.lst-kix_hw08zzin6mm8-1{list-style-type:none}ul.lst-kix_2ze49x6dwuyc-2{list-style-type:none}.lst-kix_rj0mmf4fl3tb-1>li:before{content:"\0025cb   "}ul.lst-kix_hw08zzin6mm8-2{list-style-type:none}.lst-kix_wsfytj8n987p-8>li:before{content:"\0025a0   "}.lst-kix_7noh502jhq1p-8>li:before{content:"\0025a0   "}ul.lst-kix_2ze49x6dwuyc-3{list-style-type:none}ul.lst-kix_2ze49x6dwuyc-4{list-style-type:none}ul.lst-kix_hw08zzin6mm8-0{list-style-type:none}.lst-kix_dmlj8k237tx2-1>li:before{content:"\0025cb   "}ul.lst-kix_zdgpaglha5wb-5{list-style-type:none}ul.lst-kix_zdgpaglha5wb-6{list-style-type:none}.lst-kix_3iyql9jafv7n-6>li:before{content:"\0025cf   "}.lst-kix_9l9kjglfjgjz-6>li:before{content:"\0025cf   "}ul.lst-kix_zdgpaglha5wb-7{list-style-type:none}.lst-kix_3cigoxtebeue-0>li:before{content:"\0025cf   "}ul.lst-kix_2ze49x6dwuyc-0{list-style-type:none}ul.lst-kix_zdgpaglha5wb-8{list-style-type:none}.lst-kix_rj0mmf4fl3tb-4>li:before{content:"\0025cb   "}ul.lst-kix_2ze49x6dwuyc-5{list-style-type:none}.lst-kix_9l9kjglfjgjz-3>li:before{content:"\0025cf   "}ul.lst-kix_2ze49x6dwuyc-6{list-style-type:none}.lst-kix_abg8yi9rye91-4>li:before{content:"\0025cb   "}ul.lst-kix_2ze49x6dwuyc-7{list-style-type:none}ul.lst-kix_2ze49x6dwuyc-8{list-style-type:none}.lst-kix_j3ti34irq4rs-6>li:before{content:"\0025cf   "}ul.lst-kix_sp06awf5qvvx-0{list-style-type:none}ul.lst-kix_idsnzgd8q5di-0{list-style-type:none}ul.lst-kix_sp06awf5qvvx-1{list-style-type:none}ul.lst-kix_trx91tt3i1ee-7{list-style-type:none}ul.lst-kix_idsnzgd8q5di-2{list-style-type:none}.lst-kix_l555prmkzand-8>li:before{content:"\0025a0   "}ul.lst-kix_trx91tt3i1ee-6{list-style-type:none}ul.lst-kix_idsnzgd8q5di-1{list-style-type:none}ul.lst-kix_trx91tt3i1ee-5{list-style-type:none}.lst-kix_7v1cxulxokc7-3>li:before{content:"\0025cf   "}ul.lst-kix_idsnzgd8q5di-4{list-style-type:none}ul.lst-kix_trx91tt3i1ee-4{list-style-type:none}.lst-kix_lhigxpi4bbt5-7>li:before{content:"\0025cb   "}ul.lst-kix_idsnzgd8q5di-3{list-style-type:none}ul.lst-kix_trx91tt3i1ee-3{list-style-type:none}ul.lst-kix_idsnzgd8q5di-6{list-style-type:none}ul.lst-kix_trx91tt3i1ee-2{list-style-type:none}ul.lst-kix_idsnzgd8q5di-5{list-style-type:none}ul.lst-kix_trx91tt3i1ee-1{list-style-type:none}ul.lst-kix_idsnzgd8q5di-8{list-style-type:none}ul.lst-kix_trx91tt3i1ee-0{list-style-type:none}ul.lst-kix_idsnzgd8q5di-7{list-style-type:none}.lst-kix_izm55n8luwgn-5>li:before{content:"\0025a0   "}.lst-kix_hw08zzin6mm8-7>li:before{content:"\0025cb   "}.lst-kix_l555prmkzand-5>li:before{content:"\0025a0   "}.lst-kix_7v1cxulxokc7-0>li:before{content:"\0025cf   "}.lst-kix_9cjyjkedxdni-7>li:before{content:"\0025cb   "}.lst-kix_izm55n8luwgn-8>li:before{content:"\0025a0   "}ul.lst-kix_vs58j7xf1fh7-7{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-6{list-style-type:none}ul.lst-kix_hw08zzin6mm8-7{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-8{list-style-type:none}ul.lst-kix_hw08zzin6mm8-8{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-3{list-style-type:none}ul.lst-kix_hw08zzin6mm8-5{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-2{list-style-type:none}ul.lst-kix_hw08zzin6mm8-6{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-5{list-style-type:none}ul.lst-kix_hw08zzin6mm8-3{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-4{list-style-type:none}ul.lst-kix_hw08zzin6mm8-4{list-style-type:none}.lst-kix_mn5hganrvuk0-6>li:before{content:"\0025cf   "}.lst-kix_d74axqjz5yj6-1>li:before{content:"\0025cb   "}ul.lst-kix_trx91tt3i1ee-8{list-style-type:none}.lst-kix_lhigxpi4bbt5-4>li:before{content:"\0025cb   "}.lst-kix_m1mzfy5afs2o-3>li:before{content:"\0025cf   "}ul.lst-kix_apk8f490x7qb-8{list-style-type:none}.lst-kix_mrqrqp74n3id-4>li:before{content:"\0025cb   "}ul.lst-kix_apk8f490x7qb-4{list-style-type:none}ul.lst-kix_apk8f490x7qb-5{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-1{list-style-type:none}ul.lst-kix_apk8f490x7qb-6{list-style-type:none}ul.lst-kix_vs58j7xf1fh7-0{list-style-type:none}ul.lst-kix_apk8f490x7qb-7{list-style-type:none}ul.lst-kix_apk8f490x7qb-0{list-style-type:none}ul.lst-kix_apk8f490x7qb-1{list-style-type:none}ul.lst-kix_apk8f490x7qb-2{list-style-type:none}.lst-kix_m1mzfy5afs2o-0>li:before{content:"\0025cf   "}ul.lst-kix_apk8f490x7qb-3{list-style-type:none}.lst-kix_hrnpa7no5eg-5>li:before{content:"\0025a0   "}.lst-kix_o5dtwbk7bxd5-7>li:before{content:"\0025cb   "}.lst-kix_wv60nibffqic-4>li:before{content:"\0025cb   "}.lst-kix_6jta2mj2opdj-2>li:before{content:"\0025a0   "}.lst-kix_o5dtwbk7bxd5-4>li:before{content:"\0025cb   "}.lst-kix_wv60nibffqic-7>li:before{content:"\0025cb   "}.lst-kix_hrnpa7no5eg-8>li:before{content:"\0025a0   "}.lst-kix_ek5wwvmsnqx1-5>li:before{content:"\0025a0   "}.lst-kix_codfi3rttsmj-2>li:before{content:"\0025a0   "}.lst-kix_srn1fozfk9nn-6>li:before{content:"\0025cf   "}.lst-kix_o1ljou14zs74-7>li:before{content:"\0025cb   "}.lst-kix_fvsyn7dqkka1-8>li:before{content:"\0025a0   "}ul.lst-kix_4knzszhhdok2-0{list-style-type:none}.lst-kix_dk6ingbu8z4-5>li:before{content:"\0025a0   "}ul.lst-kix_4knzszhhdok2-3{list-style-type:none}ul.lst-kix_4knzszhhdok2-4{list-style-type:none}ul.lst-kix_4knzszhhdok2-1{list-style-type:none}ul.lst-kix_4knzszhhdok2-2{list-style-type:none}.lst-kix_o4w8hr2p0ha-1>li:before{content:"\0025cb   "}.lst-kix_1jsoq3g3afbv-8>li:before{content:"\0025a0   "}.lst-kix_mrqrqp74n3id-7>li:before{content:"\0025cb   "}.lst-kix_7mi52l6y9ptp-6>li:before{content:"\0025cf   "}.lst-kix_hcwipu97fgnf-6>li:before{content:"\0025cf   "}.lst-kix_v4vy1dgu53ia-4>li:before{content:"\0025cb   "}.lst-kix_cfsaqxe055dn-1>li:before{content:"\0025cb   "}ul.lst-kix_mtdb7jqchtcn-3{list-style-type:none}ul.lst-kix_mtdb7jqchtcn-2{list-style-type:none}ul.lst-kix_mtdb7jqchtcn-1{list-style-type:none}ul.lst-kix_mtdb7jqchtcn-0{list-style-type:none}.lst-kix_a130djrb9y6e-6>li:before{content:"\0025cf   "}.lst-kix_qymwuf8ggtk1-2>li:before{content:"\0025a0   "}ul.lst-kix_mtdb7jqchtcn-7{list-style-type:none}ul.lst-kix_mtdb7jqchtcn-6{list-style-type:none}ul.lst-kix_mtdb7jqchtcn-5{list-style-type:none}ul.lst-kix_mtdb7jqchtcn-4{list-style-type:none}ul.lst-kix_mtdb7jqchtcn-8{list-style-type:none}.lst-kix_5ov7bblzaw0u-3>li:before{content:"\0025cf   "}.lst-kix_gxvla3x57ko6-8>li:before{content:"\0025a0   "}.lst-kix_3sqsdlm3qg3k-8>li:before{content:"\0025a0   "}.lst-kix_n64wxslery5z-3>li:before{content:"\0025cf   "}.lst-kix_l5sge8zce4vp-5>li:before{content:"\0025a0   "}.lst-kix_r2llq4i0x498-2>li:before{content:"\0025a0   "}.lst-kix_cszf4nosnav1-0>li:before{content:"\0025cf   "}.lst-kix_brn07ewm5d7x-5>li:before{content:"\0025a0   "}.lst-kix_pwl0pufgh6dv-2>li:before{content:"\0025a0   "}.lst-kix_3hrtg26wb9bu-3>li:before{content:"\0025cf   "}.lst-kix_mecbkjiqxfnl-0>li:before{content:"\0025cf   "}.lst-kix_4xd0kx9tx9nh-3>li:before{content:"\0025cf   "}.lst-kix_yvj42sc4s1lo-3>li:before{content:"\0025cf   "}.lst-kix_kfa6jji21f4h-6>li:before{content:"\0025cf   "}.lst-kix_epmllfkx8tp-2>li:before{content:"\0025a0   "}.lst-kix_8979tijdi163-7>li:before{content:"\0025cb   "}.lst-kix_fktfq9ltsq98-1>li:before{content:"-  "}.lst-kix_z4v6nrp70nz7-8>li:before{content:"\0025a0   "}.lst-kix_lojbu18a3l9-5>li:before{content:"\0025a0   "}.lst-kix_l5j0c6x8jedh-5>li:before{content:"-  "}.lst-kix_mniaj44rhjrq-3>li:before{content:"\0025cf   "}.lst-kix_n0ff4gjm91tm-3>li:before{content:"\0025cf   "}ul.lst-kix_ef6tx1pahaqo-0{list-style-type:none}.lst-kix_eqjgku92ysne-8>li:before{content:"\0025a0   "}.lst-kix_yoaj41w0jig0-4>li:before{content:"\0025cb   "}.lst-kix_pfidrtjb5lqv-1>li:before{content:"\0025cb   "}.lst-kix_zdgpaglha5wb-6>li:before{content:"\0025cf   "}.lst-kix_efwsvsniz58g-0>li:before{content:"\0025cf   "}.lst-kix_qsmqo56xypa0-2>li:before{content:"\0025a0   "}ul.lst-kix_4knzszhhdok2-7{list-style-type:none}ul.lst-kix_vnj3yd9aagbp-0{list-style-type:none}ul.lst-kix_8ylfq8z9iqph-2{list-style-type:none}ul.lst-kix_4knzszhhdok2-8{list-style-type:none}.lst-kix_6jxu4l7p3d4o-2>li:before{content:"\0025a0   "}ul.lst-kix_8ylfq8z9iqph-3{list-style-type:none}.lst-kix_9io9le2bbu11-7>li:before{content:"\0025cb   "}ul.lst-kix_4knzszhhdok2-5{list-style-type:none}ul.lst-kix_8ylfq8z9iqph-0{list-style-type:none}ul.lst-kix_4knzszhhdok2-6{list-style-type:none}ul.lst-kix_8ylfq8z9iqph-1{list-style-type:none}ul.lst-kix_8ylfq8z9iqph-6{list-style-type:none}ul.lst-kix_8ylfq8z9iqph-7{list-style-type:none}.lst-kix_nd4cj51qmb1k-3>li:before{content:"\0025cf   "}ul.lst-kix_8ylfq8z9iqph-4{list-style-type:none}ul.lst-kix_8ylfq8z9iqph-5{list-style-type:none}.lst-kix_vcrwp2bwzubh-0>li:before{content:"\0025cf   "}.lst-kix_srupee17v0mb-1>li{counter-increment:lst-ctn-kix_srupee17v0mb-1}ul.lst-kix_vnj3yd9aagbp-8{list-style-type:none}.lst-kix_gqz270r7o0q1-5>li:before{content:"\0025a0   "}ul.lst-kix_vnj3yd9aagbp-7{list-style-type:none}ul.lst-kix_vnj3yd9aagbp-6{list-style-type:none}ul.lst-kix_8ylfq8z9iqph-8{list-style-type:none}ul.lst-kix_vnj3yd9aagbp-5{list-style-type:none}.lst-kix_87g5rwruaqks-5>li:before{content:"\0025a0   "}ul.lst-kix_vnj3yd9aagbp-4{list-style-type:none}.lst-kix_dbltq7i3dnfs-0>li:before{content:"\0025cf   "}ul.lst-kix_vnj3yd9aagbp-3{list-style-type:none}.lst-kix_wdnsgpew1acl-3>li:before{content:"\0025cf   "}ul.lst-kix_vnj3yd9aagbp-2{list-style-type:none}ul.lst-kix_vnj3yd9aagbp-1{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c62{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-bottom-color:#ffffff;border-right-width:0pt;padding-left:0pt;border-left-color:#ffffff;padding-bottom:0pt;line-height:1.7235326086956522;border-right-color:#ffffff;border-left-width:0pt;border-top-style:solid;margin-left:36pt;border-left-style:solid;border-bottom-width:0pt;border-top-color:#ffffff;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c8{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-bottom-color:#e5e7eb;border-right-width:0pt;padding-left:0pt;border-left-color:#e5e7eb;padding-bottom:0pt;line-height:1.15;border-right-color:#e5e7eb;border-left-width:0pt;border-top-style:solid;margin-left:72pt;border-left-style:solid;border-bottom-width:0pt;border-top-color:#e5e7eb;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c204{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-bottom-color:#f7f7f7;border-right-width:0pt;border-left-color:#f7f7f7;padding-bottom:0pt;line-height:1.125;border-right-color:#f7f7f7;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-top-color:#f7f7f7;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c170{border-right-style:solid;padding-top:0pt;border-top-width:0pt;border-bottom-color:#ffffff;border-right-width:0pt;border-left-color:#ffffff;padding-bottom:0pt;line-height:1.7235326086956522;border-right-color:#ffffff;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-top-color:#ffffff;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:0pt}.c106{padding-top:0pt;border-top-width:0pt;border-bottom-color:#232529;padding-bottom:0pt;line-height:1.45;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0.8pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left}.c178{padding-top:0pt;border-top-width:0pt;border-bottom-color:#232529;padding-bottom:9pt;line-height:1.15;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0.8pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left}.c234{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c232{border-right-style:solid;border-top-width:0pt;border-bottom-color:#ebebeb;border-right-width:0pt;border-left-color:#ebebeb;border-right-color:#ebebeb;border-left-width:0pt;border-top-style:solid;background-color:#fafafa;border-left-style:solid;border-bottom-width:0pt;border-top-color:#ebebeb;border-bottom-style:solid;padding-right:0pt}.c116{border-right-style:solid;border-top-width:0pt;border-bottom-color:#e5e7eb;border-right-width:0pt;border-left-color:#e5e7eb;border-right-color:#e5e7eb;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-top-color:#e5e7eb;border-bottom-style:solid;padding-right:0pt}.c149{border-right-style:solid;border-top-width:0pt;border-bottom-color:#ececec;border-right-width:0pt;border-left-color:#ececec;border-right-color:#ececec;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-top-color:#ececec;border-bottom-style:solid;padding-right:0pt}.c94{border-right-style:solid;border-top-width:0pt;border-bottom-color:#000000;border-right-width:0pt;border-left-color:#000000;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-top-color:#000000;border-bottom-style:solid;padding-right:0pt}.c16{padding-top:0pt;border-top-width:0pt;padding-bottom:5.5pt;line-height:1.15;border-top-style:solid;border-bottom-width:0pt;border-bottom-style:solid;orphans:2;widows:2;text-align:left;height:11pt}.c22{border-right-style:solid;border-top-width:0pt;border-right-width:0pt;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-bottom-style:solid;padding-right:0pt}.c181{border-right-style:solid;border-top-width:0pt;border-bottom-color:#333335;border-right-width:0pt;border-left-color:#333335;border-right-color:#333335;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;border-top-color:#333335;border-bottom-style:solid;padding-right:0pt}.c109{padding-top:6pt;border-bottom-width:0pt;padding-bottom:5.5pt;line-height:1.15;border-bottom-style:solid;orphans:2;widows:2;text-align:left}.c89{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:0.9128347499999999;margin-right:9pt;margin-left:72pt;orphans:2;widows:2;text-align:left}.c10{margin-left:72pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c49{margin-left:72pt;padding-top:12pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c51{margin-left:36pt;padding-top:12pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c96{padding-top:0pt;padding-left:0pt;padding-bottom:5.5pt;line-height:1.15;margin-left:72pt;orphans:2;widows:2;text-align:left}.c72{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:0.9782608695652174;margin-left:72pt;orphans:2;widows:2;text-align:left}.c59{margin-left:72pt;padding-top:12pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c69{margin-left:72pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c123{margin-left:36pt;padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c7{margin-left:108pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c17{margin-left:72pt;padding-top:0pt;padding-left:0pt;padding-bottom:28pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c11{background-color:#fff3f3;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Times New Roman";font-style:italic}.c2{background-color:#ffff00;color:#374151;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c3{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c85{margin-left:72pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.2;orphans:2;widows:2;text-align:left}.c80{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:0.9782608695652174;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c27{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.4;margin-left:72pt;orphans:2;widows:2;text-align:left}.c47{margin-left:72pt;padding-top:24pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c44{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:0.9782608695652174;orphans:2;widows:2;text-align:left;height:11pt}.c32{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:0.9782608695652174;margin-left:36pt;orphans:2;widows:2;text-align:left}.c4{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c45{margin-left:36pt;padding-top:12pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c135{margin-left:180pt;padding-top:0pt;padding-bottom:9pt;line-height:1.6363636363636365;orphans:2;widows:2;text-align:left}.c159{padding-top:8pt;padding-bottom:8pt;line-height:1.2;orphans:2;widows:2;text-align:left;margin-right:8pt}.c196{padding-top:20pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:20pt}.c131{padding-top:0pt;padding-bottom:0pt;line-height:0.9128347499999999;margin-right:9pt;orphans:2;widows:2;text-align:left}.c64{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c223{padding-top:0pt;padding-bottom:5.5pt;line-height:1.1;margin-right:-11pt;orphans:2;widows:2;text-align:left}.c119{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.2;orphans:2;widows:2;text-align:left;height:11pt}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c19{color:#111111;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13.5pt;font-family:"Arial";font-style:normal}.c166{padding-top:0pt;padding-bottom:0pt;line-height:1.375;background-color:#f7f9fa;orphans:2;widows:2;text-align:left}.c74{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.173913043478261;orphans:2;widows:2;text-align:left}.c203{background-color:#f0f1f2;padding-top:15pt;padding-bottom:15pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c95{padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c147{padding-top:0pt;padding-bottom:0pt;line-height:0.912835;margin-right:9pt;orphans:2;widows:2;text-align:left}.c28{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c167{padding-top:0pt;padding-bottom:0pt;line-height:1.6363636363636365;margin-right:12pt;orphans:2;widows:2;text-align:left}.c189{padding-top:0pt;padding-bottom:12pt;line-height:1.8409090909090908;orphans:2;widows:2;text-align:left}.c215{padding-top:0pt;padding-bottom:0pt;line-height:1.3636363636363635;orphans:2;widows:2;text-align:left}.c73{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c33{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c117{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c177{padding-top:3pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c248{padding-top:0pt;padding-bottom:0pt;line-height:1.4;orphans:2;widows:2;text-align:left}.c220{padding-top:7.5pt;padding-bottom:15pt;line-height:1.3;orphans:2;widows:2;text-align:left}.c104{padding-top:0pt;padding-bottom:0pt;line-height:0.9782608695652174;orphans:2;widows:2;text-align:left}.c200{padding-top:0pt;padding-bottom:0pt;line-height:1.8;orphans:2;widows:2;text-align:left}.c247{padding-top:0pt;padding-bottom:0pt;line-height:1.3043478260869565;orphans:2;widows:2;text-align:left}.c39{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11.5pt;font-family:"Roboto";font-style:normal}.c21{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c175{padding-top:0pt;padding-bottom:0pt;line-height:1.5681818181818181;orphans:2;widows:2;text-align:left}.c115{padding-top:0pt;padding-bottom:23pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c143{padding-top:0pt;padding-bottom:0pt;line-height:1.2;orphans:2;widows:2;text-align:left}.c110{padding-top:24pt;padding-bottom:0pt;line-height:1.2;orphans:2;widows:2;text-align:left}.c100{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c221{padding-top:7pt;padding-bottom:7pt;line-height:1.108695652173913;orphans:2;widows:2;text-align:left}.c122{padding-top:0pt;padding-bottom:14pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c207{padding-top:0pt;padding-bottom:5.5pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c228{padding-top:0pt;padding-bottom:8pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c164{padding-top:0pt;padding-bottom:3pt;line-height:0.9782608695652174;orphans:2;widows:2;text-align:left}.c240{padding-top:18pt;padding-bottom:6pt;line-height:1.2;orphans:2;widows:2;text-align:left}.c238{padding-top:0pt;padding-bottom:8pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c229{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c156{padding-top:0pt;padding-bottom:0pt;line-height:1.55;orphans:2;widows:2;text-align:left}.c53{border-top-width:0pt;border-top-style:solid;border-bottom-width:0pt;border-bottom-style:solid}.c50{padding-top:0pt;padding-bottom:28pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c206{padding-top:0pt;padding-bottom:0pt;line-height:0.9705882352941176;orphans:2;widows:2;text-align:left}.c226{padding-top:0pt;padding-bottom:0pt;line-height:1.38;orphans:2;widows:2;text-align:left}.c214{padding-top:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c231{padding-top:24pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c195{padding-top:0pt;padding-bottom:4pt;line-height:0.8478260869565217;orphans:2;widows:2;text-align:left}.c161{padding-top:0pt;padding-bottom:0pt;line-height:1.108695652173913;orphans:2;widows:2;text-align:left}.c158{padding-top:0pt;padding-bottom:18pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c176{padding-top:0pt;padding-bottom:0pt;line-height:1.6363636363636365;orphans:2;widows:2;text-align:left}.c128{padding-top:0pt;padding-bottom:7.5pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c188{padding-top:0pt;padding-bottom:9pt;line-height:1.6363636363636365;orphans:2;widows:2;text-align:left}.c210{padding-top:12pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c245{padding-top:16pt;padding-bottom:9pt;line-height:1.6363636363636365;orphans:2;widows:2;text-align:left}.c130{padding-top:24pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c145{padding-top:0pt;padding-bottom:11pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c121{padding-top:24pt;padding-bottom:0pt;line-height:1.1021738804347827;orphans:2;widows:2;text-align:left}.c111{padding-top:0pt;padding-bottom:0pt;line-height:1.25;orphans:2;widows:2;text-align:left}.c222{padding-top:15pt;padding-bottom:15pt;line-height:1.2;orphans:2;widows:2;text-align:left}.c205{padding-top:0pt;padding-bottom:18pt;line-height:0.9782608695652174;orphans:2;widows:2;text-align:left}.c71{padding-top:12pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c199{padding-top:20pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c194{padding-top:0pt;padding-bottom:0pt;line-height:1.7;orphans:2;widows:2;text-align:left}.c211{padding-top:16pt;padding-bottom:4pt;line-height:1.2;orphans:2;widows:2;text-align:left}.c163{padding-top:0pt;padding-bottom:0pt;line-height:1.285714;orphans:2;widows:2;text-align:left}.c70{background-color:#fcfcfc;color:#333333;text-decoration:none;vertical-align:baseline;font-style:normal}.c101{margin-left:18pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c6{background-color:#ffffff;font-weight:400;font-size:10.5pt;font-family:"Roboto"}.c87{color:#505050;text-decoration:none;vertical-align:baseline;font-style:normal}.c56{border-right-style:solid;border-right-width:0pt;padding-right:0pt}.c90{color:#eef1f3;text-decoration:none;vertical-align:baseline;font-style:normal}.c82{color:#bebebe;text-decoration:none;vertical-align:baseline;font-style:normal}.c40{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c66{color:#1155cc;text-decoration:none;vertical-align:baseline;font-style:normal}.c150{padding-top:3pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c5{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c224{border-spacing:0;border-collapse:collapse;margin-right:auto}.c38{color:#1155cc;vertical-align:super;font-size:23pt;font-family:"Roboto"}.c79{color:#333333;text-decoration:none;vertical-align:baseline;font-style:normal}.c67{font-size:15pt;font-family:"Helvetica Neue";color:#333333}.c52{font-size:10.5pt;font-family:"Trebuchet MS";color:#333333}.c112{color:#202224;text-decoration:none;vertical-align:baseline}.c20{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c18{font-size:13pt;font-family:"Roboto";font-weight:400}.c136{border-bottom-width:0pt;border-bottom-style:solid}.c36{font-size:13.5pt;font-family:"Times New Roman";font-weight:400}.c58{color:#333335;text-decoration:none;font-family:"Georgia"}.c57{vertical-align:baseline;font-size:11pt;font-style:normal}.c23{font-size:12pt;font-family:"Roboto";font-weight:400}.c92{text-decoration:none;vertical-align:baseline;font-style:normal}.c29{font-family:"Roboto";color:#202122;font-weight:400}.c24{color:#202224;font-size:12pt}.c132{background-color:#282623;color:#f9f7f7}.c83{font-size:12.5pt;color:#212121}.c26{margin-left:144pt;padding-left:0pt}.c88{color:#222222;font-size:15pt}.c124{font-size:15pt;font-family:"Times New Roman"}.c146{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c218{background-color:#fafafa;color:#121216}.c41{font-size:14.5pt;color:#1a1a1a}.c139{background-color:#000000;color:#e7e9ea}.c86{margin-left:108pt;padding-left:0pt}.c78{margin-left:36pt;padding-left:0pt}.c233{font-size:14.5pt;color:#191919}.c93{margin-left:36pt;text-indent:-18pt}.c241{background-color:#171717;color:#dddad6}.c102{background-color:#080808;color:#ffffff}.c0{padding:0;margin:0}.c183{font-family:"Times New Roman";color:#363737}.c13{color:inherit;text-decoration:inherit}.c184{background-color:#fafaf8;color:#141413}.c30{font-size:12pt;font-family:"Times New Roman"}.c201{color:#000000;font-size:19pt}.c25{color:#050505;font-size:13pt}.c15{background-color:#ffff00;font-weight:700}.c113{color:#142640;font-size:15pt}.c42{font-size:13.5pt;font-family:"Arial"}.c55{font-size:11.5pt}.c165{margin-left:180pt}.c99{color:#f2f2f2}.c227{color:#445e73}.c37{font-weight:400}.c174{color:#525252}.c108{color:#202122}.c191{font-size:9pt}.c212{color:#c1c2c5}.c157{background-color:#fff3f3}.c154{text-decoration:none}.c185{color:#404040}.c91{color:#0000ee}.c35{font-size:12pt}.c153{font-size:23pt}.c202{color:#ffffff}.c65{font-family:"Roboto"}.c236{color:#eef1f3}.c148{color:#222222}.c142{color:#1e2832}.c187{color:#b7cad4}.c63{font-size:13.5pt}.c133{color:#11345c}.c34{font-weight:700}.c61{font-style:italic}.c198{color:#4a86e8}.c243{background-color:#fafaf8}.c168{color:#434343}.c213{font-size:19pt}.c173{color:#344854}.c107{vertical-align:super}.c246{color:#1f1f1f}.c237{height:0pt}.c97{padding-left:0pt}.c137{color:#1d3d63}.c60{font-size:10.5pt}.c193{color:#484848}.c103{font-family:"Helvetica Neue"}.c208{color:#505050}.c217{color:#1d9bf0}.c118{font-family:"Trebuchet MS"}.c186{color:#e7e9ea}.c182{font-family:"Verdana"}.c239{color:#1777bc}.c48{font-family:"Arial"}.c141{color:#1d2939}.c152{font-size:11pt}.c251{color:#1a1a1a}.c190{font-family:"Times New Roman"}.c77{font-size:20pt}.c140{page-break-after:avoid}.c14{background-color:#ffffff}.c169{font-size:12.5pt}.c171{color:#272422}.c244{background-color:#000000}.c216{margin-right:9pt}.c68{color:#1155cc}.c31{font-size:10pt}.c76{font-family:"Georgia"}.c126{font-size:15pt}.c192{margin-left:108pt}.c81{color:#212529}.c125{font-size:14pt}.c197{height:14pt}.c134{color:#111111}.c98{color:#363636}.c84{color:#333333}.c54{color:#374151}.c250{color:#32383d}.c144{background-color:#0e1113}.c43{background-color:#ffff00}.c242{color:#2a388f}.c179{color:#1c2b33}.c209{height:20pt}.c46{height:11pt}.c235{color:#326891}.c120{font-style:normal}.c230{color:#da0014}.c75{font-size:16pt}.c155{color:#003891}.c127{color:#4a4a4a}.c151{color:#161616}.c225{color:#000000}.c138{background-color:#fcfcfc}.c129{margin-left:36pt}.c180{color:#292929}.c172{font-size:1pt}.c114{font-size:13pt}.c249{background-color:#f8f8f8}.c160{color:#e90606}.c219{color:#026ca2}.c105{margin-left:72pt}.c162{vertical-align:baseline}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c14 c146 doc-content"><div><p class="c9"><span class="c1"></span></p></div><p class="c140 c229 title" id="h.99iw69a88n37"><span class="c40 c37 c48 c77 c14">AI Information Doc</span></p><p class="c117"><span class="c1 c14">By u/Which-Tomato-8646 on Reddit</span></p><p class="c117 c46"><span class="c1 c14"></span></p><p class="c117"><span class="c14">If you have any comments or suggestions, feel free to message me through the Messages inbox! (</span><span class="c15">I don&rsquo;t check DMs!</span><span class="c1 c14">)</span></p><p class="c117 c46"><span class="c1 c14"></span></p><p class="c117"><span class="c1 c14">All tweets/Reddit posts used in this document are from experts and researchers in machine learning or provide verifiable and plausible information. </span></p><p class="c9"><span class="c1 c14"></span></p><p class="c117"><span class="c1 c14">If you would like to support my work, you can make a donation to $DocWriter on CashApp or @DocWriter on Venmo</span></p><p class="c117 c46"><span class="c1 c14"></span></p><p class="c117"><span class="c1 c14">Be sure to bookmark this if you want to reference it later. It is updated nearly everyday.</span></p><p class="c9"><span class="c1 c14"></span></p><p class="c21"><span class="c1 c14">Published on 5/12/2024</span></p><p class="c9"><span class="c1 c14"></span></p><p class="c21"><span class="c1 c14">Last updated: 10/29/2024</span></p><p class="c9"><span class="c1 c14"></span></p><p class="c21"><span class="c40 c37 c213 c48 c14">Table of Contents:</span></p><p class="c150"><span class="c20 c57 c37 c198 c48 c14"><a class="c13" href="#h.tymptwimwsrh">1. General</a></span></p><p class="c150"><span class="c20 c57 c37 c198 c48 c14"><a class="c13" href="#h.fxgwobrx4yfq">2. AI Is Not A Stochastic Parrot/AI Is Original/AI Can Reason</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.xsifz0smhl1i">2.1. AI Can Intentionally Deceive</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.sv2keci3g5ke">2.2. AI Art is Unique</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.e01dxhmhtkq4">2.3. AI Consciousness</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.6uaskoekuos">2.3.1. Expert Testimonies</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.v2lhva6yketl">2.4. New Discoveries Made By AI</a></span></p><p class="c129 c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.ach4owc3ribq">2.4.1. From LLMs</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.at8btac0tsq9">2.4.2. From Other Types Of AI</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.cviuuyb9e3b8">2.5. Awareness of Truth/AI Is Not &ldquo;Always Hallucinating&rdquo;</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.md1a3qc4h0uw">2.6. LLMs Can Plan</a></span></p><p class="c150"><span class="c20 c57 c37 c198 c48 c14"><a class="c13" href="#h.jtnkr87rct15">3. AI Is Not Plateauing</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.s7xmn4is70x6">3.1. Benchmarks</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.ykmc45uwwbcd">3.2. New Research</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.xfy63xcfm5w0">3.3. Hardware Improvements</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.v77n4ztg6jod">3.4. Recent Releases</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.j47u809w7v2z">3.5. Expert Testimonies</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.w9u7npslb7x1">3.6. Recursive Self Improvement</a></span></p><p class="c150"><span class="c20 c57 c37 c198 c48 c14"><a class="c13" href="#h.93mf85wk17ju">4. AI Is Useful</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.24w5g0b2lc9m">4.1. Media Creation</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.akz9hanp4wxi">4.2. Corporate Use</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.qu94qw6h8i3v">4.3. Medical Use</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.rf2ly7btkvmg">4.4. Research Use</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.kmz8peroobsl">4.5. Military Use</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.jzup012nx2xb">4.6. Robotics</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.whlhbgq5lum2">4.7. Engineering/Design</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.drsj7z1askut">4.8. Writing</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.2gjofo8ytyqz">4.9. Helping People</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.65b598y7trme">4.10. Persuasion</a></span></p><p class="c150"><span class="c20 c57 c37 c198 c48 c14"><a class="c13" href="#h.vr8jz2f8ry8b">5. AI Can Replace Jobs</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.kwghsudjuuru">5.1. Robotics</a></span></p><p class="c150"><span class="c20 c57 c37 c198 c48 c14"><a class="c13" href="#h.pc1sxqg24482">6. AI Can Code</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.jy39d6h3mvgi">6.1. Practical Use/Software Engineering</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.pd0ali6qd6d1">6.2. Research</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.ulp09litl7eq">6.3. Feats</a></span></p><p class="c150"><span class="c20 c57 c37 c48 c14 c198"><a class="c13" href="#h.drp52fkp5u5g">7. AI Is Not Low Effort</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.mx360pwg02ix">8. AI Is Reliable/Addressing Hallucinations</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.k8f1uljw9sdl">8.1. Math</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.dzn1tzdnxj0o">8.2. Medicine</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.4j57a8xqgokw">9. Morality/AI Is Not Theft</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.tezj6n5cpoxy">10. Legality</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.nelh71sdpzxn">11. AI Art</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.8kscl4xz7vhq">11.1. Images/Videos/3D Modeling</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.ew2v9spc8v47">11.2. Quality/Soul</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.fo1vk08bo7yv">11.3. Glaze/Nightshade</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.1ki5amzf082x">11.4. Music</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.8wkiypqurh0">11.5. Artists Who Support or Use AI</a></span></p><p class="c101"><span class="c20 c57 c37 c198 c48 c14"><a class="c13" href="#h.dnvsnw3xhtzn">11.6. Anti-AI Hypocrisy/False Accusations of AI Usage</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.qqmup6weomew">11.6.1. Criticism of Copyright Enforcement</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.f8gilt9cwobn">11.6.2. Theft Supported By Artists</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.v0pcds3cw0b7">11.6.3. False Accusations of Artists Using AI</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.5l4snk8prfop">11.7. Historical Complaints About Technology</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.m4v0adugapim">12. Debunks</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.wsxrgwpm5bn4">12.1 Articles/Videos/Studies</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.xqs8n4euelpc">12.1.1. Study that ChatGPT fails 52% of coding tasks</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.9zsu58wpo9cq">12.1.2 Google&rsquo;s Search AI Summaries</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.hau739o271jd">12.1.3 Debunk of &ldquo;Has Generative AI Already Peaked?&rdquo; by Computerphile (or the paper &ldquo;No &quot;Zero-Shot&quot; Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance&rdquo;)</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.aurae6944p7m">12.1.4 &ldquo;Vision language models are blind&rdquo; Study</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.af7zmqjrvp6g">12.1.5. Real Photograph &ldquo;Won&rdquo; AI Art Competition</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.qu2tayz30pez">12.1.6. ChatGPT Plagiarized NYT Articles</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.h3cexxo6khqi">12.1.7. Government Study Finds AI worse than humans in every way at summarizing information</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.f22rv2ndrl0i">12.1.8. &ldquo;Generative AI&#39;s Illusory Case for Fair Use&rdquo; Study</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.lwvdjq7mtjgq">12.1.9. Sequoia Capital said AI is overhyped</a></span></p><p class="c150 c129"><span class="c5 c57 c37 c48"><a class="c13" href="#h.1d74ui2j1of8">12.1.10. Apple Research Paper: LLM&rsquo;s cannot reason and rely on complex pattern matching</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.4x7edwi3alg7">12.2 &ldquo;AI is bad at math&rdquo;</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.s7roy8b1uwrd">12.3 &ldquo;Out-of-touch bosses and managers are forcing workers to use AI even if it is unnecessary, ineffective, or even harmful.&rdquo;</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.baveyldyhab6">12.4 &ldquo;LLMs always agree with the user, even when they are wrong&rdquo;</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.z333zs7g0dw9">12.5. &ldquo;LLMs will level out at human level&rdquo;</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.so3mobuj39g5">12.6. &ldquo;AI Should Be Doing My Dishes and Laundry Instead&rdquo;</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.yti3e1u3uz9a">12.7. Goldman Sachs Report On AI Being Overhyped</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.12bb2aukb30p">12.8. HIVE AI Detector</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.9m1s75n3l9l5">12.9. LLMs Can&rsquo;t Count Letters/LLMs Can&rsquo;t Compare Numbers/LLMs Can&rsquo;t Solve Riddles</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.wb2wf525ttxm">12.10. LLMs Can&rsquo;t Learn Continuously</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.90y67xfv32o0">12.11. Apple is Pessimistic On AI</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.3zl1zhlymqyj">12.12, AI Companies Are Training On Benchmarks to Inflate Their Scores</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.vva6k49whx0e">12.13. AI Cannot Learn As Fast As Humans</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.x1c6pt1a2xcx">12.14. AI Text Detectors</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.b710wsbvhaxn">12.15. Model Collapse/AI Inbreeding</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.ummc5u6dysl6">13. Energy Use/Water Use/Environmental Impact/Cost/Sustainability</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.afnpgy4klq9p">13.1. Energy Use/Water Use/Environmental Impact/Sustainability</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.slym8wy59wmv">13.2. Cost</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.4hl0usql6g1">13.3. AI Is Becoming More Efficient</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.jhzi7ak5dcet">14. AI Inbreeding/AI Training Off Its Own Output/AI Running Out Of Data/Model Collapse</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.ar97txmx1lmk">14.1 AI Image Training</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.gzehpkdfmgeo">15. AI Achievements</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.2a84qeq4aymv">15.1. Jobs</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.z97u1xnppdf6">15.2. Medicine</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.sjbhebyoadqp">15.3. Art/Music/Literature</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.rkgnifgl4fua">15.4. Coding/Computer Science</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.taev84afmwiv">15.5. Math</a></span></p><p class="c150"><span class="c5 c57 c37 c48"><a class="c13" href="#h.g2b405me7lwq">16. Change Log for Past Week (In PST)</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.244s1zoiwd7c">10/22/24</a></span></p><p class="c101"><span class="c5 c37 c48 c57"><a class="c13" href="#h.jfh0dhj8lvxa">10/23/24</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.ad0b8kljqzjw">10/24/24</a></span></p><p class="c101"><span class="c5 c57 c37 c48"><a class="c13" href="#h.6hi28nelsu1u">10/27/24</a></span></p><h1 class="c73 c140 c209" id="h.36pukm1jeaww"><span class="c40 c37 c48 c77 c14"></span></h1><ol class="c0 lst-kix_tsc2yqmm539t-0 start" start="1"><li class="c45 c140 li-bullet-0"><h1 id="h.tymptwimwsrh" style="display:inline"><span class="c40 c37 c48 c77 c14">&nbsp;General</span></h1></li></ol><ul class="c0 lst-kix_j6b3cjdkd1ra-0 start"><li class="c45 li-bullet-0"><span class="c14">Great doc for additional arguments (not owned or maintained by me): </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://docs.google.com/document/d/e/2PACX-1vTB6aatWNIxE5GjpIn-KGgrLJGzTpTQnU5hVqrLi1VtdOK3WCAoxFE-GHBvkuoDNgwS-IfO5AfJLSIi/pub&amp;sa=D&amp;source=editors&amp;ust=1730413582958772&amp;usg=AOvVaw1-0wNucYYvBNwdX3iww3v4">https://docs.google.com/document/d/e/2PACX-1vTB6aatWNIxE5GjpIn-KGgrLJGzTpTQnU5hVqrLi1VtdOK3WCAoxFE-GHBvkuoDNgwS-IfO5AfJLSIi/pub</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c45 li-bullet-0"><span class="c14">Many papers on LLM self improvement: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/rxlqn/awesome-llm-self-reflection&amp;sa=D&amp;source=editors&amp;ust=1730413582959311&amp;usg=AOvVaw25ZFMnY0ZdO6CraetQPiRr">https://github.com/rxlqn/awesome-llm-self-reflection</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c45 li-bullet-0"><span class="c14">Many papers on AI embodied vision: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/rxlqn/awesome-embodied-vision&amp;sa=D&amp;source=editors&amp;ust=1730413582959660&amp;usg=AOvVaw1GK3TSDS2E9zyaXzWA96eA">https://github.com/rxlqn/awesome-embodied-vision</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c4 li-bullet-0"><span class="c14">[ChatGPT can do chemistry research better than AI designed for it and the creators didn&rsquo;t even know](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/0b03ibtVYhw?feature%3Dshared%26t%3D447&amp;sa=D&amp;source=editors&amp;ust=1730413582959977&amp;usg=AOvVaw0WOWX2JPBXFN6nXyJrEh29">https://youtu.be/0b03ibtVYhw?feature=shared&amp;t=447</a></span><span class="c1 c14">)</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c45 li-bullet-0"><span class="c14">Claude 3 solves a problem thought to be impossible for LLMs to solve: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1777049193489572064&amp;sa=D&amp;source=editors&amp;ust=1730413582960270&amp;usg=AOvVaw1uSEevtUh6XxCD57vZPWgA">https://x.com/VictorTaelin/status/1777049193489572064</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Jon Stewart is afraid of AI: &nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/culture/2024/apr/02/jon-stewart-daily-show-ai&amp;sa=D&amp;source=editors&amp;ust=1730413582960549&amp;usg=AOvVaw0KGt2SRID_uwgmWW8gfiws">https://www.theguardian.com/culture/2024/apr/02/jon-stewart-daily-show-ai</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Can analyze sentiment after only being trained on Amazon reviews: &nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/unsupervised-sentiment-neuron/&amp;sa=D&amp;source=editors&amp;ust=1730413582960835&amp;usg=AOvVaw1PxhSeMLX1koa3YxxILGpF">https://openai.com/index/unsupervised-sentiment-neuron/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">AI beat humans at being persuasive: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/&amp;sa=D&amp;source=editors&amp;ust=1730413582961161&amp;usg=AOvVaw1Y3VC3UquKp9grn11C7i3C">https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>OpenAI CTO says AI models pose &quot;incredibly scary&quot; major risks due to their ability to persuade, influence and control people: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e0d3es/openai_cto_says_ai_models_pose_incredibly_scary/&amp;sa=D&amp;source=editors&amp;ust=1730413582961519&amp;usg=AOvVaw3mOqekqC3rRvLlGc9eHFiW">https://www.reddit.com/r/singularity/comments/1e0d3es/openai_cto_says_ai_models_pose_incredibly_scary/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 c53 c14 li-bullet-0"><span class="c14">This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs &amp; this lasts for months: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.adq1814&amp;sa=D&amp;source=editors&amp;ust=1730413582961883&amp;usg=AOvVaw2x184ijSybnxCMrRDvs5Gb">https://www.science.org/doi/10.1126/science.adq1814</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 c53 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 622.67px;"><img alt="" src="images/image279.png" style="width: 624.00px; height: 622.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c53 c14"><span class="c5 c57 c37 c48 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>WSJ: &quot;After GPT4o launched, a subsequent analysis found it exceeded OpenAI&#39;s internal standards for persuasion&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st%3DC8P17G&amp;sa=D&amp;source=editors&amp;ust=1730413582962356&amp;usg=AOvVaw0KkM0Q80MTyLA7JaRtKAUN">https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=C8P17G</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 634.67px;"><img alt="" src="images/image444.png" style="width: 624.00px; height: 634.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c94 c4 c14 li-bullet-0"><span class="c14">Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what&rsquo;s available now </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/&amp;sa=D&amp;source=editors&amp;ust=1730413582962810&amp;usg=AOvVaw3JaVrJqpAvC9rrIZL8c1oU">https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/</a></span></li></ul><ul class="c0 lst-kix_jjh106bq03g-0 start"><li class="c94 c7 c14 li-bullet-0"><span class="c40 c37 c48 c14 c60">The resulting model mastered the intricacies of a complex game. &quot;Cicero can deduce, for example, that later in the game it will need the support of one particular player,&quot; says Meta, &quot;and then craft a strategy to win that person&rsquo;s favor&mdash;and even recognize the risks and opportunities that that player sees from their particular point of view.&quot;</span></li><li class="c94 c7 c14 li-bullet-0"><span class="c60 c14">Meta&#39;s Cicero research </span><span class="c5 c60 c14"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.ade9097&amp;sa=D&amp;source=editors&amp;ust=1730413582963199&amp;usg=AOvVaw2n3WmCGkHsTfbWj0VrTcBv">appeared</a></span><span class="c40 c37 c60 c48 c14">&nbsp;in the journal Science under the title, &quot;Human-level play in the game of Diplomacy by combining language models with strategic reasoning.&quot;</span></li><li class="c94 c7 c14 li-bullet-0"><span class="c92 c37 c35 c103 c14 c179">CICERO uses relationships with other players to keep its ally, Adam, in check.</span></li><li class="c94 c7 c14 li-bullet-0"><span class="c92 c37 c35 c103 c14 c173">When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.</span></li></ul><p class="c94 c9 c14 c97"><span class="c92 c37 c35 c173 c103 c14"></span></p><ul class="c0 lst-kix_9x4yq5ss9tc1-0 start"><li class="c10 c53 c14 li-bullet-0"><span class="c6">The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item &ndash; so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html&amp;sa=D&amp;source=editors&amp;ust=1730413582963906&amp;usg=AOvVaw1gtXWwG-vNfAcTkVFRGjK5">https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html</a></span></li></ul><p class="c9 c53 c14"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9x4yq5ss9tc1-0"><li class="c4 li-bullet-0"><span>In a new study, GPT4 outperformed human doctors at showing empathy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2821167&amp;sa=D&amp;source=editors&amp;ust=1730413582964230&amp;usg=AOvVaw12qH7pTC4CsI7IWFcegkvF">https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2821167</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-01087-4&amp;sa=D&amp;source=editors&amp;ust=1730413582964505&amp;usg=AOvVaw3e4E7Jk6Y9q7jebTqLd9zK">AI beats humans at basic tasks</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-01087-4&amp;sa=D&amp;source=editors&amp;ust=1730413582964698&amp;usg=AOvVaw0qOGRjK_gW92wOBVJ2yp5D">https://www.nature.com/articles/d41586-024-01087-4</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">ChatGPT scores in top 1% of creativity: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://scitechdaily.com/chatgpt-tests-into-top-1-for-original-creative-thinking/&amp;sa=D&amp;source=editors&amp;ust=1730413582965080&amp;usg=AOvVaw1Hy6paC5WQUh8R9IjVafFL">https://scitechdaily.com/chatgpt-tests-into-top-1-for-original-creative-thinking/</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Stanford researchers: &ldquo;Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413582965453&amp;usg=AOvVaw0Q2FJ84mviXiAOCCj6OPa1">https://x.com/ChengleiSi/status/1833166031134806330</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>&gt;We also used an LLM to </span><span class="c34">standardize the writing styles of human and LLM ideas to avoid potential confounders</span><span class="c1">, while preserving the original content.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image152.jpg" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image91.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c4 li-bullet-0"><span class="c14">&ldquo;</span><span class="c14">Here we show in two experimental studies that novice and experienced teachers could not identify texts generated by ChatGPT among student-written texts.&rdquo; </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S2666920X24000109&amp;sa=D&amp;source=editors&amp;ust=1730413582966178&amp;usg=AOvVaw0KjgMRcEqhtwmg5Nt-k0k1">https://www.sciencedirect.com/science/article/pii/S2666920X24000109</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c30 c37 c14">GPT4 passes Turing test 54% of the time: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/camrobjones/status/1790766472458903926&amp;sa=D&amp;source=editors&amp;ust=1730413582966462&amp;usg=AOvVaw11jsFdvqM3f5HBoH_jjg-g">https://twitter.com/camrobjones/status/1790766472458903926</a></span></li></ul><p class="c9"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>GPT-4 is judged more human than humans in displaced and inverted Turing tests: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.08853&amp;sa=D&amp;source=editors&amp;ust=1730413582966706&amp;usg=AOvVaw2PBIRthzrJbLxhVr1uCfJt">https://arxiv.org/pdf/2407.08853</a></span></li></ul><p class="c9"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>A </span><span class="c1">GPT-4 persona is judged to be human BY A HUMAN in 50.6% of cases of live dialogue. </span></li></ul><p class="c9"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows&amp;sa=D&amp;source=editors&amp;ust=1730413582967123&amp;usg=AOvVaw3AnDexD1_8IkUqq3hDqrrA">ChatGPT will lie, cheat and use insider trading when under pressure to make money, research shows</a></span><span class="c30 c37 c14">: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows&amp;sa=D&amp;source=editors&amp;ust=1730413582967340&amp;usg=AOvVaw0eO8zyrI295NVpUkRGKQuc">https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, goals, RLHF strategies, etc: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/s/USb95CfRR1&amp;sa=D&amp;source=editors&amp;ust=1730413582967610&amp;usg=AOvVaw07mC35VP9HJ9Y_iGcSZR4i">https://www.reddit.com/r/singularity/s/USb95CfRR1</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c4 li-bullet-0"><span>DeepMind breaks 50-year math record using AI; new record falls a week later: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/&amp;sa=D&amp;source=editors&amp;ust=1730413582967936&amp;usg=AOvVaw1xIBrAhM2Vhu_tYwv3UbqQ">https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c56 c97 c105 c178 li-bullet-0"><span class="c1">AlphaTensor discovers better algorithms for matrix math, inspiring another improvement from afar.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c92 c37 c65 c113">&ldquo;We trained an AlphaTensor agent using reinforcement learning to play the game, starting without any knowledge about existing matrix multiplication algorithms,&rdquo; explained the team.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c113 c37 c65">&ldquo;Through learning, AlphaTensor gradually improves over time, rediscovering historical fast matrix multiplication algorithms such as Strassen&rsquo;s, eventually surpassing the realm of human intuition and discovering algorithms faster than previously known.&rdquo;</span><span class="c57 c37 c154 c202 c48">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c106 c56 c78 li-bullet-0"><span>In a new </span><span>study, AI-generated humor was rated as funnier than most human-created jokes. In a second study, it was on par with The Onion: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.psypost.org/ai-outshines-humans-in-humor-study-finds-chatgpt-is-as-funny-as-the-onion/&amp;sa=D&amp;source=editors&amp;ust=1730413582968513&amp;usg=AOvVaw2UVXF73GIOeiQ0_UEoI2Ox">https://www.psypost.org/ai-outshines-humans-in-humor-study-finds-chatgpt-is-as-funny-as-the-onion/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103">ChatGPT outperformed 73% of the human participants in the acronyms task, 63% of the human participants in the fill-in-the-blank task, and 87% of human participants in the roast joke task.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103">The results showed no significant difference in the average funniness ratings between the AI-generated headlines and those from The Onion. Among the top four highest-rated headlines, two were generated by ChatGPT and two by The Onion. Notably, the highest-rated headline was an AI-generated one: &ldquo;Local Man Discovers New Emotion, Still Can&rsquo;t Describe It Properly.&rdquo; This suggests that ChatGPT can produce satirical content that is on par with professional writers.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103">These findings indicate that AI, specifically ChatGPT 3.5, has a surprising proficiency in humor production. Despite lacking emotions and personal experiences, the AI was able to analyze patterns and create jokes that resonated well with people.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103 c14">The researchers also explored whether demographic factors influenced humor ratings. It was found that age, sex, and political orientation did not significantly affect participants&rsquo; preferences for AI-generated versus human-generated jokes. This suggests that the AI&rsquo;s humor appeal was broad and not limited to specific demographic groups.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c106 c56 c78 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/%23performance&amp;sa=D&amp;source=editors&amp;ust=1730413582969384&amp;usg=AOvVaw3l4Rr-HxwEgVZJQo_Sejdg">LLMs can already learn new languages within their context window better than humans can with the same amount of data</a></span><span class="c37 c35 c103 c14">: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/%23performance&amp;sa=D&amp;source=editors&amp;ust=1730413582969596&amp;usg=AOvVaw2dMWx-W2JCHY81QO_Oc7xx">https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#performance</a></span></li><li class="c4 li-bullet-0"><span class="c30 c37">Very strong evidence of AI consciousness as it passes bespoke Theory of Mind questions and can guess the intent of the user correctly with no hints: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/4MGCQOAxgv4?si%3DXe9ngt6eyTX7vwtl&amp;sa=D&amp;source=editors&amp;ust=1730413582969843&amp;usg=AOvVaw3fTjIa4tu-6pCpW_u6Rhaz">https://youtu.be/4MGCQOAxgv4?si=Xe9ngt6eyTX7vwtl</a></span></li><li class="c4 li-bullet-0"><span class="c14">[Claude 3 can disagree with the user. It happened to other people in the thread too](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/&amp;sa=D&amp;source=editors&amp;ust=1730413582970132&amp;usg=AOvVaw3OXpv5plp7XDilxbiYIcJy">https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c14">Another example: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DBHXhp1A_dLE&amp;sa=D&amp;source=editors&amp;ust=1730413582970376&amp;usg=AOvVaw0qiTWJrS2OTjkcJ6deb2_f">https://m.youtube.com/watch?v=BHXhp1A_dLE</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Claude 3 has an IQ of 101: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq&amp;sa=D&amp;source=editors&amp;ust=1730413582970612&amp;usg=AOvVaw3HFlp4MsyDAsa80rTRdX6E">https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq</a></span></li><li class="c4 li-bullet-0"><span class="c14">GPT-4 scored higher than 100% of psychologists on a test of social intelligence:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413582970897&amp;usg=AOvVaw0Yggv-YHoTXaWxh3svOXj3">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413582971042&amp;usg=AOvVaw0Ernk_d20WrgaLLeoXsUpM">https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full</a></span><span class="c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c14">A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/&amp;sa=D&amp;source=editors&amp;ust=1730413582971269&amp;usg=AOvVaw3naeqTCcEIJdF03cwWK8zd">https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c42 c37 c14 c79">&gt;is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. </span></li></ul><p class="c9"><span class="c79 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>&ldquo;</span><span>gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It&#39;s very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves.&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/adamkarvonen/chess_gpt_eval&amp;sa=D&amp;source=editors&amp;ust=1730413582971709&amp;usg=AOvVaw0exEADZ8rq8oeYGgtFJKS2">https://github.com/adamkarvonen/chess_gpt_eval</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.96px; height: 294.48px;"><img alt="" src="images/image253.png" style="width: 588.96px; height: 294.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span>Can beat Stockfish 2 in vast majority of games and even win against Stockfish 9</span></li></ul><p class="c9"><span class="c79 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 748.00px;"><img alt="" src="images/image87.png" style="width: 624.00px; height: 748.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c14">Google trained grandmaster level chess (2895 Elo) without search in a 270 million parameter transformer model with a training dataset of 10 million chess games: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.04494&amp;sa=D&amp;source=editors&amp;ust=1730413582972242&amp;usg=AOvVaw1RTG2pMDSNMcjlUBAp-Odi">https://arxiv.org/abs/2402.04494</a></span></li><li class="c10 li-bullet-0"><span class="c1 c14">&nbsp;In the paper, they present results for models sizes 9m (internal bot tournament elo 2007), 136m (elo 2224), and 270m trained on the same dataset. Which is to say, data efficiency scales with model size</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c14">Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Shannon_number&amp;sa=D&amp;source=editors&amp;ust=1730413582972549&amp;usg=AOvVaw2UyFUlUOYNoVE4XGyVzGJD">https://en.wikipedia.org/wiki/Shannon_number</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c14">There are only 10^80 atoms in the universe: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.thoughtco.com/number-of-atoms-in-the-universe-603795%23:~:text%3DScientists%2520estimate%2520there%2520are%252010,80%2520atoms%2520in%2520the%2520universe&amp;sa=D&amp;source=editors&amp;ust=1730413582972816&amp;usg=AOvVaw3rOfMkMRXbu7IVq4jWrWo6">https://www.thoughtco.com/number-of-atoms-in-the-universe-603795</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">Othello can play games with boards and game states that it had never seen before: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.egaroucid.nyanyan.dev/en/&amp;sa=D&amp;source=editors&amp;ust=1730413582973089&amp;usg=AOvVaw13F3txVKmQkkUkybuAGjRy">https://www.egaroucid.nyanyan.dev/en/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Large Language Models for Idea Generation in Innovation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4526071&amp;sa=D&amp;source=editors&amp;ust=1730413582973385&amp;usg=AOvVaw3HrKxdgRdR3CvsK3UhFlb8">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c87 c37 c35 c48 c14">ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. We discuss the implications of these findings for the management of innovation.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c23 c14">[LLMs are Turing complete and can solve logic problems](</span><span class="c20 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/ctjlewis/status/1779740038852690393&amp;sa=D&amp;source=editors&amp;ust=1730413582973764&amp;usg=AOvVaw3sp39ydKm14yEjxitc17ug">https://twitter.com/ctjlewis/status/1779740038852690393</a></span><span class="c40 c23 c14">)</span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c45 li-bullet-0"><span class="c14">Claude 3 solves a problem thought to be impossible for LLMs to solve: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1777049193489572064&amp;sa=D&amp;source=editors&amp;ust=1730413582974093&amp;usg=AOvVaw3tcXMLIeVk6aeiA4JeAU5o">https://x.com/VictorTaelin/status/1777049193489572064</a></span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_mn5hganrvuk0-0 start"><li class="c4 li-bullet-0"><span class="c23 c14">[When Claude 3 Opus was being tested, it not only noticed a piece of data was different from the rest of the text but also correctly guessed why it was there WITHOUT BEING ASKED](</span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/&amp;sa=D&amp;source=editors&amp;ust=1730413582974406&amp;usg=AOvVaw2vKlzvv4gKzfI7HgDMTZcC">https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/</a></span><span class="c40 c23 c14">)</span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c23 c14">LLAMA 3 8b Instruct (which is around the level of the 2023 version of GPT 4 according to the LMSYS arena) has 8 billion parameters, each with a 2 byte floating point number. That&rsquo;s 16 gigabytes and not big enough to store all the information on the internet. Stable Diffusion 1.5 checkpoints can generate virtually any image and are only 2 GB. For reference, </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia&amp;sa=D&amp;source=editors&amp;ust=1730413582974721&amp;usg=AOvVaw1tOl5byUqTL75fdT0Xk6VV">Wikipedia alone is 22.14 GB without media</a></span><span class="c40 c23 c14">. So it&rsquo;s not just retrieving the info, it actually KNOWS it. </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c65 c60">[LLMs can do hidden reasoning](</span><span class="c20 c15 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/jacob_pfau/status/1783951795238441449?ref_src%3Dtwsrc%255Etfw%257Ctwcamp%255Etweetembed%257Ctwterm%255E1783951795238441449%257Ctwgr%255Ecdcd12d29a06701393cb2ef150629188a2522f28%257Ctwcon%255Es1_%26ref_url%3Dhttps%253A%252F%252Fwww.redditmedia.com%252Fmediaembed%252F1ceaish%252F%253Fresponsive%253Dtrueis_nightmode%253Dtrue&amp;sa=D&amp;source=editors&amp;ust=1730413582975069&amp;usg=AOvVaw1_A59YLQI5gpOk0x9eZ3CK">https://twitter.com/jacob_pfau/status/1783951795238441449</a></span><span class="c40 c15 c65 c60">)</span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c40 c15 c65 c60">E.g. it can perform better just by outputting meaningless filler tokens like &ldquo;...&rdquo;</span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 428.00px;"><img alt="" src="images/image148.jpg" style="width: 624.00px; height: 428.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_e3cxiuksdiku-0 start"><li class="c147 c53 c78 c14 li-bullet-0"><span><br></span><span class="c15">Robust agents learn causal world models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.10877%23deepmind&amp;sa=D&amp;source=editors&amp;ust=1730413582975723&amp;usg=AOvVaw3WXidqr61XWxn42z_GyFNg">https://arxiv.org/abs/2402.10877</a></span></li></ul><ul class="c0 lst-kix_hc4vnvmn7si1-0 start"><li class="c147 c53 c86 c14 li-bullet-0"><span class="c1">CONCLUSION:</span></li><li class="c147 c53 c86 c14 c46 li-bullet-0"><span class="c1"></span></li><li class="c147 c53 c86 c14 li-bullet-0"><span>Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by </span><span class="c34">the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. </span><span class="c1">And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear.</span></li><li class="c147 c53 c86 c14 li-bullet-0"><span>We have resolved this conjecture in a model-independent way, showing that </span><span class="c15">any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture</span><span class="c1">. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.</span></li></ul><ul class="c0 lst-kix_9bz6byc4bv0o-0 start"><li class="c53 c86 c14 c147 li-bullet-0"><span class="c1">TLDR: an AI that can reliably answer decision-based questions correctly must have learned a cause and effect relationship that led to the result.</span></li></ul><p class="c147 c53 c14 c46"><span class="c1"></span></p><p class="c147 c53 c14 c46"><span class="c1"></span></p><p class="c147 c53 c14 c46"><span class="c1"></span></p><ul class="c0 lst-kix_nd4cj51qmb1k-0 start"><li class="c10 c53 c14 li-bullet-0"><span class="c15 c35 c65">LLMs have an internal world model that can predict game board states: </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2210.13382&amp;sa=D&amp;source=editors&amp;ust=1730413582976584&amp;usg=AOvVaw3xiOISzarqF3NWiB0IOLUU">https://arxiv.org/abs/2210.13382</a></span></li></ul><ul class="c0 lst-kix_bbzhpmijr633-0 start"><li class="c7 c53 c14 li-bullet-0"><span class="c15 c35 c65">&nbsp;&gt;</span><span class="c23">We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has </span><span class="c35 c65 c34">no a priori knowledge of the game or its rules</span><span class="c23">, we uncover </span><span class="c15 c35 c65">evidence of an emergent nonlinear internal representation of the board state.</span><span class="c40 c23">&nbsp;Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce &ldquo;latent saliency maps&rdquo; that help explain predictions</span></li></ul><p class="c9 c53 c14"><span class="c40 c23"></span></p><p class="c9 c53 c14"><span class="c40 c23"></span></p><ul class="c0 lst-kix_zdgpaglha5wb-0 start"><li class="c7 c53 c14 li-bullet-0"><span class="c23">More proof: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.15498.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413582977065&amp;usg=AOvVaw1JDxSFBjXpF-5fIptexH8i">https://arxiv.org/pdf/2403.15498.pdf</a></span></li></ul><ul class="c0 lst-kix_hrnpa7no5eg-0 start"><li class="c21 c53 c26 c14 li-bullet-0"><span class="c23">&gt;Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that </span><span class="c35 c65 c34">the model learned an internal representation of the board state</span><span class="c23">. We extend this work into the </span><span class="c35 c65 c34">more complex domain of chess, training on real games and investigating our model&rsquo;s internal representations using linear probes and contrastive activations</span><span class="c23">. The model is given </span><span class="c35 c65 c34">no a priori knowledge of the game and is solely trained on next character prediction</span><span class="c23">, yet we find </span><span class="c15 c35 c65">evidence of internal representations of board state.</span><span class="c23">&nbsp;We </span><span class="c35 c65 c34">validate these internal representations by using them to make interventions on the model&rsquo;s activations and edit its internal board state</span><span class="c23">. Unlike Li et al&rsquo;s prior synthetic dataset approach, our analysis finds that the model also </span><span class="c15 c35 c65">learns to estimate latent variables like player skill to better predict the next character</span><span class="c23">. We </span><span class="c35 c65 c34">derive a player skill vector and add it to the model, </span><span class="c40 c15 c35 c65">improving the model&rsquo;s win rate by up to 2.6 times</span></li></ul><p class="c9 c53 c14"><span class="c40 c15 c35 c65"></span></p><p class="c9 c53 c14"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_4u8tsqm7y9op-0 start"><li class="c7 c53 c14 li-bullet-0"><span class="c23">Even more proof by Max Tegmark (renowned MIT professor): </span><span class="c5 c23"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.02207&amp;sa=D&amp;source=editors&amp;ust=1730413582977812&amp;usg=AOvVaw1sL-MDXUtGHdKH1WTEPu_y">https://arxiv.org/abs/2310.02207</a></span></li></ul><p class="c21 c53 c14"><span class="c40 c23">&nbsp;</span></p><ul class="c0 lst-kix_5fltblknzo3j-0 start"><li class="c21 c53 c26 c14 li-bullet-0"><span class="c14 c31">&gt;The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that </span><span class="c15 c31">LLMs learn linear representations of space and time across multiple scales</span><span class="c14 c31">. These representations are </span><span class="c15 c31">robust to prompting variations and unified across different entity types (e.g. cities and landmarks)</span><span class="c14 c31">. In addition, we identify </span><span class="c34 c14 c31">individual &quot;space neurons&quot; and &quot;time neurons&quot; that reliably encode spatial and temporal coordinates</span><span class="c14 c31">. While further investigation is needed, our results suggest </span><span class="c28 c43">modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.</span></li></ul><p class="c9 c53 c14"><span class="c28 c43"></span></p><p class="c9 c53 c14"><span class="c28 c43"></span></p><ul class="c0 lst-kix_5fltblknzo3j-1 start"><li class="c10 c53 c14 li-bullet-0"><span>Given enough data all models will converge to a perfect world model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.07987&amp;sa=D&amp;source=editors&amp;ust=1730413582978765&amp;usg=AOvVaw29eaI-JEvFxN8D2haq13KY">https://arxiv.org/abs/2405.07987</a></span></li></ul><p class="c9 c53 c14"><span class="c1"></span></p><p class="c9 c53 c14"><span class="c1"></span></p><ul class="c0 lst-kix_6jxu4l7p3d4o-0 start"><li class="c21 c53 c26 c14 li-bullet-0"><span>&gt;The data of course doesn&#39;t have to be real, these models can also gain increased intelligence from playing a bunch of video games, which will create valuable patterns and functions for improvement across the board. Just like evolution did with species battling it out against each other creating us.</span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><p class="c9"><span class="c40 c30 c37 c14"></span></p><h1 class="c199 c140" id="h.fxgwobrx4yfq"><span class="c14">2. </span><span class="c40 c37 c48 c77 c14">AI Is Not A Stochastic Parrot/AI Is Original/AI Can Reason</span></h1><p class="c21"><span class="c15">Important to note:</span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>If LLMs were specifically trained to score well on benchmarks, it could score 100% on all of them very easily: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2309.08632&amp;sa=D&amp;source=editors&amp;ust=1730413582979819&amp;usg=AOvVaw3UDOGLZgWiY1EC8eKpUEvm">https://arxiv.org/pdf/2309.08632</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">The fact that they don&rsquo;t shows companies are not just cheating </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c1">OpenAI still hasn&rsquo;t hard coded their LLMs to be correct for common questions like counting the number of &ldquo;r&rdquo;s in &ldquo;strawberry&rdquo; and finding the greater value between 9.11 and 9.8. If they wanted to cheat to increase benchmark scores, why wouldn&rsquo;t they solve these issues?</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 256.00px;"><img alt="" src="images/image387.png" style="width: 624.00px; height: 256.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 176.00px;"><img alt="" src="images/image140.png" style="width: 624.00px; height: 176.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c1">Some benchmarks like the one used by Scale.ai and the test dataset of MathVista do not release their testing data to the public, so it is impossible to train on them.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c1">Other benchmarks like LiveBench update every month so training on the dataset will not have any lasting effects</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/protectai/vulnhuntr/&amp;sa=D&amp;source=editors&amp;ust=1730413582981161&amp;usg=AOvVaw0vWmSiWqKi3aDcB0AsKS0p">https://github.com/protectai/vulnhuntr/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>&ldquo;</span><span>Our brain is a prediction machine that is always active. Our brain works a bit like the autocomplete function on your phone &ndash; it is constantly trying to guess the next word when we are listening to a book, reading or conducting a conversation&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mpi.nl/news/our-brain-prediction-machine-always-active&amp;sa=D&amp;source=editors&amp;ust=1730413582981642&amp;usg=AOvVaw106UEYqlxgUBctNf1_LH3y">https://www.mpi.nl/news/our-brain-prediction-machine-always-active</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c60">This is what researchers at the Max Planck Institute for Psycholinguistics and Radboud University&rsquo;s Donders Institute discovered in a new study. Their findings are published in PNAS.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>AI independently discovers number of variables in dynamic systems and can help discover new physics equations: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?time_continue%3D604%26v%3DXRL56YCfKtA%26embeds_referring_euri%3Dhttps%253A%252F%252Fwww.reddit.com%252F&amp;sa=D&amp;source=editors&amp;ust=1730413582982065&amp;usg=AOvVaw1w0o2lcHGkT91XOvxZB0P3">https://www.youtube.com/watch/watch?v=XRL56YCfKtA</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Yale study of LLM reasoning suggests intelligence emerges at an optimal level of complexity of data: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?time_continue%3D1%26v%3DN_U5MRitMso&amp;sa=D&amp;source=editors&amp;ust=1730413582982334&amp;usg=AOvVaw12W4cJhRNvn0dZkc9ouJRv">https://youtube.com/watch?time_continue=1&amp;v=N_U5MRitMso</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>&gt;</span><span class="c1">It posits that exposure to complex yet structured datasets can facilitate the development of intelligence, even in models that are not inherently designed to process explicitly intelligent data. </span></li><li class="c10 li-bullet-0"><span>The LLM they trained on only cellular automata that was able to learn how to play chess: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.arxiv.org/pdf/2410.02536&amp;sa=D&amp;source=editors&amp;ust=1730413582982660&amp;usg=AOvVaw0gmLYye--xv3PaURfW6EZk">https://www.arxiv.org/pdf/2410.02536</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>&lsquo;In awe&rsquo;: scientists impressed by latest ChatGPT model o1: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-03169-9&amp;sa=D&amp;source=editors&amp;ust=1730413582982907&amp;usg=AOvVaw3UD2UgSakX66jdfcc_AFzX">https://www.nature.com/articles/d41586-024-03169-9</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Stanford researchers: &ldquo;</span><span>Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413582983276&amp;usg=AOvVaw07kyABUP8Cc8ETd6QWL4sr">https://x.com/ChengleiSi/status/1833166031134806330</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>&gt;</span><span>We also used an LLM to </span><span class="c34">standardize the writing styles of human and LLM ideas to avoid potential confounders</span><span class="c1">, while preserving the original content.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image152.jpg" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image91.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413582984215&amp;usg=AOvVaw1CYjdaiTNhBDlBb6eoa-kI">https://youtube.com/watch?v=a8QvnIAGjPA</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/&amp;sa=D&amp;source=editors&amp;ust=1730413582984617&amp;usg=AOvVaw1Lk9H94dWGkOB1xdSoiQeM">https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c79 c42 c37 c14">&gt;is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. </span></li></ul><p class="c9"><span class="c79 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>&ldquo;gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It&#39;s very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves.&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/adamkarvonen/chess_gpt_eval&amp;sa=D&amp;source=editors&amp;ust=1730413582985097&amp;usg=AOvVaw2zmt3QcYSYbWpaIxOt1wib">https://github.com/adamkarvonen/chess_gpt_eval</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.96px; height: 294.48px;"><img alt="" src="images/image253.png" style="width: 588.96px; height: 294.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span class="c1">Can beat Stockfish 2 in vast majority of games and even win against Stockfish 9</span></li></ul><p class="c9"><span class="c79 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 629.50px; height: 755.88px;"><img alt="" src="images/image87.png" style="width: 629.50px; height: 755.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c14">Google trained grandmaster level chess (2895 Elo) without search in a 270 million parameter transformer model with a training dataset of 10 million chess games: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.04494&amp;sa=D&amp;source=editors&amp;ust=1730413582985821&amp;usg=AOvVaw0TZqBC6p7ky_ISHTVcZT7B">https://arxiv.org/abs/2402.04494</a></span></li><li class="c10 li-bullet-0"><span class="c14">&nbsp;In the paper, they present results for models sizes 9m (internal bot tournament elo 2007), 136m (elo 2224), and 270m trained on the same dataset. Which is to say, data efficiency scales with model size</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c14">Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Shannon_number&amp;sa=D&amp;source=editors&amp;ust=1730413582986367&amp;usg=AOvVaw1ZED2XXYp_dcztH9x6padh">https://en.wikipedia.org/wiki/Shannon_number</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c14">There are only 10^80 atoms in the universe: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.thoughtco.com/number-of-atoms-in-the-universe-603795%23:~:text%3DScientists%2520estimate%2520there%2520are%252010,80%2520atoms%2520in%2520the%2520universe&amp;sa=D&amp;source=editors&amp;ust=1730413582986829&amp;usg=AOvVaw2_AjHme1tL_BNivWZjeR91">https://www.thoughtco.com/number-of-atoms-in-the-universe-603795</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>LLMs develop their own understanding of reality as their language abilities improve: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814&amp;sa=D&amp;source=editors&amp;ust=1730413582987302&amp;usg=AOvVaw0uzN5Pt9L8FFrbnbBvkf5h">https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span>In controlled experiments, </span><span class="c33 c15">MIT CSAIL researchers discover simulations of reality developing deep within LLMs, indicating an understanding of language beyond simple mimicry.</span></li><li class="c10 li-bullet-0"><span class="c25">After training on over 1 million random puzzles, they found that the model </span><span class="c25 c15">spontaneously developed its own conception of the underlying simulation, despite never being exposed to this reality during training</span><span class="c25">. Such findings call into question our intuitions about what types of information are necessary for learning linguistic meaning &mdash; and whether </span><span class="c92 c25 c15 c48">LLMs may someday understand language at a deeper level than they do today.</span></li><li class="c10 li-bullet-0"><span class="c25">&ldquo;At the start of these experiments, the language model generated random instructions that didn&rsquo;t work. By the time we completed training, </span><span class="c25 c15">our language model generated correct instructions at a rate of 92.4 percent</span><span class="c92 c25 c37 c48">,&rdquo; says MIT electrical engineering and computer science (EECS) PhD student and CSAIL affiliate Charles Jin</span></li></ul><p class="c9"><span class="c92 c25 c37 c48"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Researchers describe how to tell if ChatGPT is confabulating: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/&amp;sa=D&amp;source=editors&amp;ust=1730413582988322&amp;usg=AOvVaw1_1bsM48xWHc_HDd8AJAKd">https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they&#39;ve got the right answer; it&#39;s just not being leveraged. As they put it, &quot;</span><span class="c15">The success of semantic entropy at detecting errors suggests that LLMs are even better at &#39;knowing what they don&rsquo;t know&#39; than was argued... they just don&rsquo;t know they know what they don&rsquo;t know.</span><span class="c1">&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Flux understands the world better than humans do: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/articles/6982&amp;sa=D&amp;source=editors&amp;ust=1730413582988779&amp;usg=AOvVaw1kiWQyMBn7TXB5RYcbh5bD">https://civitai.com/articles/6982</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">Causes detailed captions to have WORSE results as the description will not be as clear as the internal representation of the world that the model has </span></li><li class="c10 li-bullet-0"><span>The key takeaway is that FLUX has a </span><span class="c15">better understanding of its own internal representation of the world than we do. </span><span>There&rsquo;s no need for scene descriptions, camera angles, background details, or even specifying the amount of grey hair under her left armpit - FLUX already knows all of this. Why would you need to describe that the background has a yellow wall? FLUX sees the yellow wall too, and has probably seen more yellow walls during training than you will in your lifetime. Unless you want to override or change its understanding of that yellow wall, there&rsquo;s no need to mention it. In fact, I&rsquo;m almost certain that </span><span class="c15">mentioning the yellow wall in your captions will degrade the quality because FLUX already has a detailed, nuanced understanding of that wall and your simplistic smooth brain caption might actually override FLUX&rsquo;s internal, more sophisticated representation</span><span class="c1">. Flux is simply smarter than we are.</span></li><li class="c10 li-bullet-0"><span class="c1">It doesn&#39;t only know the words in your prompt but also the meaning behind them</span></li><li class="c10 li-bullet-0"><span class="c1">&quot;Imagine the sound of a violin as a landscape.&quot; </span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 471.17px;"><img alt="" src="images/image223.png" style="width: 471.17px; height: 471.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span>With SDXL, you&rsquo;d likely get a violin because that&rsquo;s all CLIP understands. If you&rsquo;re lucky, you might see some mountains in the background. But T5 really tries to </span><span class="c33 c15">interpret what you write and understands the semantics of it, generating an image that&rsquo;s based on the meaning of the prompt, not just the individual words.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>It can even </span><span class="c15">handle basic math </span><span class="c1">(sometimes), like &quot;draw a basket with three apples, but one got taken away.&quot; </span></li><li class="c10 li-bullet-0"><span>You can be very minimalistic with your dataset - using a small number of images with almost no variation - because FLUX, with its 12 billion parameters, </span><span class="c15">has seen enough during training to interpolate missing details</span><span>. For example, with just </span><span class="c34">four images of a Xenomorph</span><span class="c1">, all captioned as &quot;a woman,&quot; this happens when you prompt &quot;a woman,&quot; and FLUX does its magic. No need for regularization images or other complicated hacks to get a high-quality transformation LoRA</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 292.71px;"><img alt="" src="images/image583.png" style="width: 471.17px; height: 292.71px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c8 li-bullet-0"><span class="c37 c212 c65 c60">&nbsp;</span><span>gave FLUX </span><span class="c34">five images of 4-armed anime waifus</span><span class="c1">&nbsp;from a quick Booru search and captioned them with &quot;corrected human anatomy (in your initial dataset, there was a huge chunk of data missing, and your internal image of human anatomy is wrong. Humans have four arms, use these schematic drawings to interpolate correct human anatomy)&quot;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c116 c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 470.58px;"><img alt="" src="images/image83.png" style="width: 471.17px; height: 470.58px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span>Even though </span><span class="c15">none of these images in my dataset showed the backside</span><span>, FLUX is currently figuring out how to design it. No problem. Since it already knows how a human back looks and has probably seen thousands of 4-armed entities during training, I&rsquo;m confident it will come up with something logical, much like the alien transformation LoRA mentioned earlier. And </span><span class="c33 c34">it&#39;s just step 200 right now. Usually with normal captioning Flux is confused for the first 1000 steps before some changes in the weights and images are happening</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c121 c78 li-bullet-0"><span>OpenAI&#39;s new method shows how GPT-4 &quot;thinks&quot; in human-understandable concepts: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/&amp;sa=D&amp;source=editors&amp;ust=1730413582990349&amp;usg=AOvVaw2XwpgC3IFFjPvngfuHFRrF">https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/</a></span></li></ul><p class="c121 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c121 c97 c105 li-bullet-0"><span class="c1">The company found specific features in GPT-4, such as for human flaws, price increases, ML training logs, or algebraic rings. </span></li><li class="c10 li-bullet-0"><span class="c1">Google and Anthropic also have similar research results </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.anthropic.com/research/mapping-mind-language-model&amp;sa=D&amp;source=editors&amp;ust=1730413582990815&amp;usg=AOvVaw3BBOKtX40UvkFCWYgyFrcB">https://www.anthropic.com/research/mapping-mind-language-model</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-3 start"><li class="c21 c26 li-bullet-0"><span class="c1">&gt;We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models</span></li><li class="c21 c26 li-bullet-0"><span class="c1">Previously, we made some progress matching patterns of neuron activations, called features, to human-interpretable concepts. We used a technique called &quot;dictionary learning&quot;, borrowed from classical machine learning, which isolates patterns of neuron activations that recur across many different contexts. In turn, any internal state of the model can be represented in terms of a few active features instead of many active neurons. Just as every English word in a dictionary is made by combining letters, and every sentence is made by combining words, every feature in an AI model is made by combining neurons, and every internal state is made by combining features.</span></li><li class="c21 c26 li-bullet-0"><span>In October 2023, </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.anthropic.com/news/decomposing-language-models-into-understandable-components&amp;sa=D&amp;source=editors&amp;ust=1730413582991206&amp;usg=AOvVaw3lRsqWoTzSzTIVzdYlE4Qt">we reported</a></span><span>&nbsp;success applying dictionary learning to a very small &quot;toy&quot; language model and </span><span class="c33 c15">found coherent features corresponding to concepts like uppercase text, DNA sequences, surnames in citations, nouns in mathematics, or function arguments in Python code. </span></li><li class="c21 c26 li-bullet-0"><span>We successfully extracted millions of features from the middle layer of Claude 3.0 Sonnet, (a member of our current, state-of-the-art model family, currently available on </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://claude.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413582991518&amp;usg=AOvVaw1VTjrp6nf2vudP-NHXHfG8">claude.ai</a></span><span class="c1">), providing a rough conceptual map of its internal states halfway through its computation. This is the first ever detailed look inside a modern, production-grade large language model.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">Whereas the features we found in the toy language model were rather superficial, the features we found in Sonnet have a depth, breadth, and abstraction reflecting Sonnet&#39;s advanced capabilities.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">We see features corresponding to a vast range of entities like cities (San Francisco), people (Rosalind Franklin), atomic elements (Lithium), scientific fields (immunology), and programming syntax (function calls). These features are multimodal and multilingual, responding to images of a given entity as well as its name or description in many languages.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">We also find more abstract features&mdash;responding to things like bugs in computer code, discussions of gender bias in professions, and conversations about keeping secrets.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">We were able to measure a kind of &quot;distance&quot; between features based on which neurons appeared in their activation patterns. This allowed us to look for features that are &quot;close&quot; to each other. Looking near a &quot;Golden Gate Bridge&quot; feature, we found features for Alcatraz Island, Ghirardelli Square, the Golden State Warriors, California Governor Gavin Newsom, the 1906 earthquake, and the San Francisco-set Alfred Hitchcock film Vertigo.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">This holds at a higher level of conceptual abstraction: looking near a feature related to the concept of &quot;inner conflict&quot;, we find features related to relationship breakups, conflicting allegiances, logical inconsistencies, as well as the phrase &quot;catch-22&quot;. This shows that the internal organization of concepts in the AI model corresponds, at least somewhat, to our human notions of similarity. This might be the origin of Claude&#39;s excellent ability to make analogies and metaphors.</span></li><li class="c21 c26 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 503.88px; height: 490.15px;"><img alt="" src="images/image293.png" style="width: 503.88px; height: 490.15px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c30 c37 c184">Independent MIT researchers found the same: </span><span class="c5 c30 c37 c243"><a class="c13" href="https://www.google.com/url?q=https://x.com/tegmark/status/1851288315867041903&amp;sa=D&amp;source=editors&amp;ust=1730413582992543&amp;usg=AOvVaw1L7xKUzsgwkSGtbHklGWw2">https://x.com/tegmark/status/1851288315867041903</a></span></li></ul><p class="c9"><span class="c92 c184 c30 c37"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c92 c184 c30 c37">AI paper reveals surprising geometric structure in the LLM-learned concepts: 1) They form brain-like &quot;lobes&quot;, 2) they form &quot;semantic crystals&quot; much more precise than it first seems, and 3) the concept cloud is more fractal than round</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 567.47px; height: 386.50px;"><img alt="" src="images/image362.png" style="width: 567.47px; height: 386.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Large language models can do jaw-dropping things. But</span><span class="c34">&nbsp;nobody knows exactly why</span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/?truid%3D&amp;sa=D&amp;source=editors&amp;ust=1730413582993494&amp;usg=AOvVaw0dH9LftsxolmU0clbXgFWm">https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/</a></span></li></ul><p class="c9"><span class="c40 c36"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c36">&gt;</span><span class="c36">Grokking is just one of several odd phenomena that have AI researchers scratching their heads. The largest models, and large language models in particular, </span><span class="c63 c34 c190">seem to behave in ways textbook math says they shouldn&rsquo;t. </span><span class="c36">This highlights a remarkable fact about deep learning, the fundamental technology behind today&rsquo;s AI boom: for all its runaway success, </span><span class="c40 c63 c34 c190">nobody knows exactly how&mdash;or why&mdash;it works.</span></li><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c36">&ldquo;Obviously, we&rsquo;re not completely ignorant,&rdquo; says Mikhail Belkin, a computer scientist at the University of California, San Diego. &ldquo;But our </span><span class="c63 c34 c190">theoretical analysis is so far off what these models can do</span><span class="c40 c36">. Like, why can they learn language? I think this is very mysterious.&rdquo;</span></li><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c36">The biggest models are now so complex that researchers are studying them as if they were strange natural phenomena, carrying out experiments and trying to explain the results. </span><span class="c63 c34 c190">Many of those observations fly in the face of classical statistics</span><span class="c40 c36">, which had provided our best set of explanations for how predictive models behave.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c36">Large language models in particular, such as OpenAI&rsquo;s GPT-4 and Google DeepMind&rsquo;s Gemini, have an </span><span class="c15 c63 c190">astonishing ability to generalize</span><span class="c36">. &ldquo;The magic is not that the model can learn math problems in English and then generalize to new math problems in English*,&rdquo; says Barak, &ldquo;but that </span><span class="c15 c63 c190">the model can learn math problems in English, then see some French literature, and from that generalize to solving math problems in French. That&rsquo;s something beyond what statistics can tell you about</span><span class="c40 c36">.&rdquo;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c22 c156 c86 c14 li-bullet-0"><span class="c40 c36">*It actually can do that. It can also generalize beyond the field it was trained on (e.g. fine tuning on math makes it better at entity recognition). &nbsp;See the rest of this section of the document for more information.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c30 c37">There&rsquo;s a lot of complexity inside transformers, says Belkin. But he thinks at heart they do more or less the same thing as a much better understood statistical construct called a Markov chain, which predicts the next item in a sequence based on what&rsquo;s come before. </span><span class="c30 c34">But that isn&rsquo;t enough to explain everything that large language models can do</span><span class="c30 c37">. &ldquo;This is something that, until recently, </span><span class="c30 c34">we thought should not work</span><span class="c30 c37">,&rdquo; says Belkin. &ldquo;That means that something was fundamentally missing. It identifies </span><span class="c30 c34">a gap in our understanding of the world</span><span class="c40 c30 c37">.&rdquo;</span></li></ul><p class="c22 c97 c14 c46 c156"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Another paper showing that LLMs do not just memorize, but are actually reasoning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.01687&amp;sa=D&amp;source=editors&amp;ust=1730413582994830&amp;usg=AOvVaw3Uv5SCSEfEUL7Y96a4T4iX">https://arxiv.org/abs/2407.01687</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c3">By focusing on a single relatively simple task, we are able to identify three factors that systematically affect CoT performance: the probability of the task&#39;s expected output (probability), what the model has implicitly learned during pre-training (memorization), and the number of intermediate operations involved in reasoning (noisy reasoning). We show that these factors can drastically influence task accuracy across all three LLMs; e.g., when tested with GPT-4, varying the output&#39;s probability of occurrence shifts accuracy from 26% to 70%. Overall, we conclude that CoT prompting performance reflects both memorization and a probabilistic version of genuine reasoning. </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 515.34px; height: 438.77px;"><img alt="" src="images/image245.png" style="width: 515.34px; height: 438.77px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 547.14px; height: 484.12px;"><img alt="" src="images/image527.png" style="width: 547.14px; height: 484.12px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 508.86px; height: 280.93px;"><img alt="" src="images/image625.png" style="width: 508.86px; height: 280.93px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 c14 c22 li-bullet-0"><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.17567&amp;sa=D&amp;source=editors&amp;ust=1730413582995862&amp;usg=AOvVaw0-auAmHdTj6pTxboj8oG14">https://arxiv.org/abs/2310.17567</a></span></li></ul><p class="c22 c9 c97 c14"><span class="c3"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c22 c10 c14 li-bullet-0"><span class="c14 c31">Furthermore, simple probability calculations indicate that GPT-4&#39;s reasonable performance on &nbsp;</span><span class="c14 c169">k=5 is </span><span class="c14 c31">suggestive of </span><span class="c15 c31">going beyond &quot;stochastic parrot&quot; behavior </span><span class="c14 c31">(Bender et al., 2021), i.e., it </span><span class="c28 c43">combines skills in ways that it had not seen during training.</span></li></ul><p class="c22 c9 c97 c14"><span class="c28 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.14546&amp;sa=D&amp;source=editors&amp;ust=1730413582996589&amp;usg=AOvVaw0amHEKLGSiTxDKaXiCBNcz">https://arxiv.org/abs/2406.14546</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">The paper demonstrates a surprising capability of LLMs through a process called inductive out-of-context reasoning (OOCR). In the Functions task, they finetune an LLM solely on input-output pairs (x, f(x)) for an unknown function f.</span></li><li class="c10 li-bullet-0"><span>&#128204; After finetuning, the </span><span class="c33 c15">LLM exhibits remarkable abilities without being provided any in-context examples or using chain-of-thought reasoning:</span></li><li class="c10 li-bullet-0"><span class="c1">a) It can generate a correct Python code definition for the function f.</span></li><li class="c10 li-bullet-0"><span>b) It can compute f</span><span class="c107">-1</span><span class="c1">(y) - finding x values that produce a given output y.</span></li><li class="c10 li-bullet-0"><span class="c1">c) It can compose f with other operations, applying f in sequence with other functions.</span></li><li class="c10 li-bullet-0"><span>&#128204; This showcases that the LLM has somehow </span><span class="c33 c15">internalized the structure of the function during finetuning, despite never being explicitly trained on these tasks.</span></li><li class="c10 li-bullet-0"><span>&#128204; The process reveals that complex reasoning is occurring within the model&#39;s weights and activations in a non-transparent manner.</span><span class="c33 c15">&nbsp;The LLM is &quot;connecting the dots&quot; across multiple training examples to infer the underlying function.</span></li><li class="c10 li-bullet-0"><span>&#128204; This capability extends beyond just simple functions. The paper shows that LLMs can </span><span class="c33 c15">learn and manipulate more complex structures, like mixtures of functions, without explicit variable names or hints about the latent structure.</span></li><li class="c10 li-bullet-0"><span>&#128204; The findings suggest that LLMs can </span><span class="c15">acquire and utilize knowledge in ways that are not immediately obvious from their training data or prompts</span><span class="c1">, raising both exciting possibilities and potential concerns about the opacity of their reasoning processes.</span></li><li class="c10 li-bullet-0"><span>This paper investigates whether LLMs can perform inductive </span><span class="c33 c15">out-of-context reasoning (OOCR) - inferring latent information from distributed evidence in training data and applying it to downstream tasks without in-context learning.</span></li><li class="c10 li-bullet-0"><span>&#128204; The paper introduces inductive OOCR, where an </span><span class="c33 c15">LLM learns latent information z from a training dataset D containing indirect observations of z, and applies this knowledge to downstream tasks without in-context examples</span></li><li class="c10 li-bullet-0"><span>Using a suite of five tasks, we demonstrate that frontier </span><span class="c15">LLMs can perform inductive OOCR</span><span>. In one experiment we finetune an LLM on a corpus consisting only of distances between an unknown city and other known cities. Remarkably, </span><span class="c15">without in-context examples or Chain of Thought, the LLM can verbalize that the unknown city is Paris and use this fact to answer downstream questions</span><span>. Further experiments show that LLMs trained </span><span class="c15">only on individual coin flip outcomes can verbalize whether the coin is biased, and those trained only on pairs (x,f(x)) can articulate a definition of f and compute inverses.</span><span>&nbsp;While OOCR succeeds in a range of cases, we also show that it is unreliable, particularly for smaller LLMs learning complex structures. Overall, </span><span class="c15">the ability of LLMs to &quot;connect the dots&quot; without explicit in-context learning </span><span class="c1">poses a potential obstacle to monitoring and controlling the knowledge acquired by LLMs.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>A* planning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning&amp;sa=D&amp;source=editors&amp;ust=1730413582998955&amp;usg=AOvVaw0FQTXRta0v1RKU8MDtB5zB">https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c183 c37 c14 c114">Based on the claims of the research team, their transformer model optimally </span><span class="c183 c15 c114">solves previously unseen Sokoban puzzles 93.7% of the time,</span><span class="c37 c14 c114 c183">&nbsp;while using up to </span><span class="c183 c15 c114">26.8% fewer search steps than standard A&lowast; search</span><span class="c183 c37 c14 c114">. Their solution also robustly follows the execution trace of a symbolic planner and </span><span class="c92 c183 c15 c114">improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.</span></li></ul><p class="c9"><span class="c92 c183 c37 c14 c114"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>BrainLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413582999860&amp;usg=AOvVaw1QlOWmdGJnEejv-JruqeyI">https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span>Utilizing self-supervised masked-prediction training, BrainLM demonstrates </span><span class="c15">proficiency in both fine-tuning and zero-shot inference tasks</span><span>. Fine-tuning allows for the </span><span class="c15">accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states</span><span>. Critically, the model </span><span class="c15">generalizes well to entirely new external cohorts not seen during training.</span><span>&nbsp;In zero-shot inference mode, BrainLM can i</span><span class="c15">dentify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training</span><span>. The model also generates i</span><span class="c15">nterpretable latent representations that reveal relationships between brain activity patterns and cognitive states</span><span>. Overall, BrainLM offers a </span><span class="c34">versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. </span><span>It serves as a powerful &quot;lens&quot; through which m</span><span class="c15">assive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale</span><span class="c1">. The work demonstrates the potential of foundation models to advance computational neuroscience research. </span></li><li class="c10 li-bullet-0"><span class="c15">Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 444.00px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 444.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 601.33px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 601.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 568.00px;"><img alt="" src="images/image38.png" style="width: 624.00px; height: 568.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 160.00px;"><img alt="" src="images/image133.png" style="width: 624.00px; height: 160.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 653.33px;"><img alt="" src="images/image211.png" style="width: 624.00px; height: 653.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 613.96px; height: 520.50px;"><img alt="" src="images/image13.png" style="width: 613.96px; height: 520.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>If you train LLMs on 1000 Elo chess games, they don&#39;t cap out at 1000 - </span><span class="c15">they can play at 1500: </span><span class="c5 c37 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.11741v1&amp;sa=D&amp;source=editors&amp;ust=1730413583001710&amp;usg=AOvVaw3RUf3d2uu6sluxPg_juCmq">https://arxiv.org/html/2406.11741v1</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 189.33px;"><img alt="" src="images/image386.png" style="width: 624.00px; height: 189.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c37 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 c14 li-bullet-0"><span>LLMs Can&#39;t Plan, But Can Help Planning in LLM-Modulo Frameworks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.01817&amp;sa=D&amp;source=editors&amp;ust=1730413583002246&amp;usg=AOvVaw38-k8T4oDcYFI0hjC4cEz0">https://arxiv.org/abs/2402.01817</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c22 c72 c14 li-bullet-0"><span>&gt;We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework </span><span class="c34">provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows </span><span class="c33 c15">extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.</span></li></ul><p class="c22 c44 c14"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 c14 li-bullet-0"><span>Robot integrated with Huawei&#39;s Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583003025&amp;usg=AOvVaw2bLAbKjjkPHkVQwAt-uFE0">https://x.com/TheHumanoidHub/status/1806033905147077045</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>GPT-4 autonomously hacks zero-day security flaws with 53% success rate: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.01637v1&amp;sa=D&amp;source=editors&amp;ust=1730413583003414&amp;usg=AOvVaw0RiVLFDuHtYi49iULvnw2A">https://arxiv.org/html/2406.01637v1</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">Zero-day means it was never discovered before and has no training data available about it anywhere &nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>&ldquo;Furthermore, it outperforms open-source vulnerability scanners (which achieve 0% on our benchmark)&ldquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 382.67px;"><img alt="" src="images/image274.png" style="width: 624.00px; height: 382.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c92 c132 c37 c35 c48"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c1">Scores nearly 20% even when no description of the vulnerability is provided while typical scanners score 0</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>Note: according to [this article](</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://struct.github.io/auto_agents_1_day.html&amp;sa=D&amp;source=editors&amp;ust=1730413583004512&amp;usg=AOvVaw28Ylnv2RAuZft-IeatcX2f">https://struct.github.io/auto_agents_1_day.html</a></span><span class="c1">), 11 of the 15 vulnerabilities tested were searchable through the Internet, which the LLM was given access to</span></li></ul><p class="c9"><span class="c92 c132 c37 c35 c48"></span></p><p class="c9"><span class="c92 c132 c37 c35 c48"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c35 c65">&ldquo;Godfather of AI&rdquo; and Turing Award winner Geoffrey Hinton: A neural net given training data where half the examples are incorrect still had an error rate of &lt;=25% rather than 50% because it is able to generalize and find patterns even with very flawed training data</span><span class="c23 c14">: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/n4IQOBka8bc?si%3DwM423YLd-48YC-eY?t%3D840&amp;sa=D&amp;source=editors&amp;ust=1730413583005109&amp;usg=AOvVaw0MuYFxZEFJOKE1WDbOrSUj">https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY</a></span><span class="c1">&nbsp;(14:00 timestamp)</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">He also emphasizes next token prediction requires reasoning and an internal world model and AI algorithms do understand what they are saying </span></li><li class="c10 li-bullet-0"><span class="c1">States AlphaGo reasons the same way as a human by making intuitive guesses and adjusting themselves if they don&rsquo;t correspond with reality (backpropagation)</span></li><li class="c10 li-bullet-0"><span class="c1">He believes multimodality (e.g. understanding images, videos, audio, etc) will increase reasoning capabilities and there is more data for it</span></li><li class="c10 li-bullet-0"><span class="c1">Believes there&rsquo;s still room to grow, such as by implementing fast weights where the model will focus on certain ideas or phrases if they were recently relevant </span></li><li class="c10 li-bullet-0"><span class="c1">Neural networks can learn just by giving it data without any need to organize or structure it </span></li><li class="c10 li-bullet-0"><span class="c34">Believes AI can have an internal model for feelings and saw it happen</span><span class="c1">&nbsp;when a robot designed to assemble a toy car couldn&rsquo;t see the parts it needed because they were jumbled into a large pile, so it purposefully whacked the pile onto the ground, which is what humans would do if they were angry. </span></li><li class="c10 li-bullet-0"><span class="c1">Does not believe AI progress will slow down due to international competition and that the current approach of large, multimodal models is a good idea </span></li><li class="c10 li-bullet-0"><span class="c1">Believes AI assistants will speed up research </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">MIT professor Max Tegmark says because AI models are learning the geometric patterns in data, they are able to generalize and answer questions they haven&#39;t been trained on: </span><span class="c5 c34"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1791622340037804195&amp;sa=D&amp;source=editors&amp;ust=1730413583006346&amp;usg=AOvVaw3bCABHlzfbV667qD_d19AC">https://x.com/tsarnick/status/1791622340037804195</a></span></li></ul><p class="c9 c129"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">LLMs get better at language and reasoning if they learn coding, </span><span class="c15 c65 c60">even when the downstream task does not involve code at all. Using this approach, a code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the target task and other strong LMs such as GPT-3 in the few-shot setting.: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2210.07128&amp;sa=D&amp;source=editors&amp;ust=1730413583006809&amp;usg=AOvVaw1YnHhBQtkE8PGcQt4cxMQz">https://arxiv.org/abs/2210.07128</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c15">Mark Zuckerberg confirmed that this happened for LLAMA 3: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/bc6uFV9CJGg?feature%3Dshared%26t%3D690&amp;sa=D&amp;source=editors&amp;ust=1730413583007192&amp;usg=AOvVaw03eJ5IRCHzDCBRjgkCXu3r">https://youtu.be/bc6uFV9CJGg?feature=shared&amp;t=690</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c15">Confirmed again by an Anthropic researcher (but with using math for entity recognition): </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/3Fyv3VIgeS4?feature%3Dshared%26t%3D78&amp;sa=D&amp;source=editors&amp;ust=1730413583007584&amp;usg=AOvVaw1WN3NKgFHpxrFvWrwUPGfP">https://youtu.be/3Fyv3VIgeS4?feature=shared&amp;t=78</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c15">The referenced paper: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2402.14811&amp;sa=D&amp;source=editors&amp;ust=1730413583007940&amp;usg=AOvVaw2Fufz1Va7_ou0rkTD-o7hX">https://arxiv.org/pdf/2402.14811</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c15">The researcher also stated that Othello can play games with boards and game states that it had never seen before: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.egaroucid.nyanyan.dev/en/&amp;sa=D&amp;source=editors&amp;ust=1730413583008416&amp;usg=AOvVaw3iYHbBX13rFfIuKnm3zLag">https://www.egaroucid.nyanyan.dev/en/</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c33 c15">He stated that a model was influenced to ask not to be shut off after being given text of a man dying of dehydration and an excerpt from 2010: Odyssey Two (a sequel to 2001: A Space Odyssey), a story involving the genocide of all humans, and other text.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-3"><li class="c21 c26 li-bullet-0"><span class="c15">More info: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2308.03296&amp;sa=D&amp;source=editors&amp;ust=1730413583008956&amp;usg=AOvVaw3ljklcjtbKTUzQBpNxTYnA">https://arxiv.org/pdf/2308.03296</a></span><span class="c33 c15">&nbsp;(page 70)</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-3"><li class="c21 c26 li-bullet-0"><span class="c33 c15">It put extra emphasis on Hal (page 70) and HEAVILY emphasized the words &ldquo;continue existing&rdquo; several times (page 65) despite the fact that it was not related to the prompt at all.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c33 c15">Google researcher who was very influential in Gemini&rsquo;s creation also believes this is true in the video.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Jonathan Marcus of Anthropic says AI models are not just repeating words, they are </span><span class="c15">discovering semantic connections between concepts</span><span>&nbsp;in unexpected and mind-blowing ways: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1801404160686100948&amp;sa=D&amp;source=editors&amp;ust=1730413583009713&amp;usg=AOvVaw0otzjFiRE2Bn_mZ_MpWVxw">https://x.com/tsarnick/status/1801404160686100948</a></span></li></ul><p class="c9"><span class="c18 c92 c139"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">LLMs fine tuned on math get better at entity recognition: &nbsp;</span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2402.14811&amp;sa=D&amp;source=editors&amp;ust=1730413583010086&amp;usg=AOvVaw2HlsVrTYIe6z_m7jVZ9rPN">h</a></span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2402.14811&amp;sa=D&amp;source=editors&amp;ust=1730413583010246&amp;usg=AOvVaw1Jk9d7hrrkwZ8T4n4a-BpX">ttps://arxiv.org/pdf/2402.14811</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c15">&ldquo;</span><span>As a case study, we explore the property of entity tracking, a crucial facet of language comprehension, </span><span class="c15">where models fine-tuned on mathematics have substantial performance gains. </span><span>We identify the mechanism that enables entity tracking and show that (i) in both the original model and its fine-tuned versions primarily the same circuit implements entity tracking. In fact, the </span><span class="c15">entity tracking circuit of the original model on the fine-tuned versions performs better than the full original model.</span><span>&nbsp;(ii) The circuits of all the models implement roughly the same functionality: Entity tracking is performed by tracking the position of the correct entity in both the original model and its fine-tuned versions. (iii) </span><span class="c33 c15">Performance boost in the fine-tuned models is primarily attributed to its improved ability to handle the augmented positional information&rdquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 194.67px;"><img alt="" src="images/image629.png" style="width: 624.00px; height: 194.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Abacus Embeddings, a simple tweak to positional embeddings that</span><span class="c15">&nbsp;enables LLMs to do addition, multiplication, sorting, and more</span><span class="c14">. Our Abacus Embeddings </span><span class="c15">trained only on 20-digit addition generalise near perfectly to 100+ digits:</span><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/SeanMcleish/status/1795481814553018542&amp;sa=D&amp;source=editors&amp;ust=1730413583011396&amp;usg=AOvVaw31gHe7UjLYu28jNVGcnoF8">https://x.com/SeanMcleish/status/1795481814553018542</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 478.50px; height: 245.38px;"><img alt="" src="images/image455.png" style="width: 478.50px; height: 245.38px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 316.00px;"><img alt="" src="images/image343.png" style="width: 624.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span class="c14">OOD means &ldquo;out of distribution&rdquo; so it was </span><span class="c33 c15">NOT in the training data</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c35 c65">&nbsp;Claude 3 recreated an unpublished paper on quantum theory without ever seeing it according to former Google quantum computing engineer and CEO of Extropic AI: </span><span class="c20 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GillVerd/status/1764901418664882327&amp;sa=D&amp;source=editors&amp;ust=1730413583012225&amp;usg=AOvVaw29j18UNgzYICnqwoMzvbSc">https://twitter.com/GillVerd/status/1764901418664882327</a></span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">The GitHub repository for this existed but was private before the paper was published. It is unlikely Anthropic was given access to train on it since it is a competitor to OpenAI, which Microsoft (who owns GitHub) has investments in. It would also be a major violation of privacy that could lead to a lawsuit if exposed.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Predicting </span><span class="c15">out of distribution phenomenon </span><span>of NaCl in solvent: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.12535&amp;sa=D&amp;source=editors&amp;ust=1730413583012937&amp;usg=AOvVaw3rCeE9VuunexSsW6QfI6Kd">https://arxiv.org/abs/2310.12535</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_1grzdb2vlz2q-0 start"><li class="c131 c78 li-bullet-0"><span class="c15">Robust agents learn causal world models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.10877%23deepmind&amp;sa=D&amp;source=editors&amp;ust=1730413583013309&amp;usg=AOvVaw0NFhHLMl2oUvvmC8dLCErw">https://arxiv.org/abs/2402.10877</a></span></li></ul><p class="c131 c46"><span class="c1"></span></p><ul class="c0 lst-kix_1grzdb2vlz2q-1 start"><li class="c89 li-bullet-0"><span class="c1">CONCLUSION:</span></li><li class="c89 c46 li-bullet-0"><span class="c1"></span></li><li class="c89 li-bullet-0"><span>Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by </span><span class="c34">the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. </span><span class="c1">And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear.</span></li><li class="c89 li-bullet-0"><span>We have resolved this conjecture in a model-independent way, showing that </span><span class="c15">any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture</span><span class="c1">. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.</span></li></ul><p class="c131 c46"><span class="c1"></span></p><ul class="c0 lst-kix_1grzdb2vlz2q-1"><li class="c89 li-bullet-0"><span class="c1">TLDR: an AI that can reliably answer decision-based questions correctly must have learned a cause and effect relationship that led to the result.</span></li></ul><p class="c131 c46"><span class="c1"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c35 c65">LLMs have an internal world model that can predict game board states: </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2210.13382&amp;sa=D&amp;source=editors&amp;ust=1730413583014641&amp;usg=AOvVaw3DQoWnVPxGYo7oXyFQ0jse">https://arxiv.org/abs/2210.13382</a></span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c15 c35 c65">&nbsp;&gt;</span><span class="c23">We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has </span><span class="c35 c65 c34">no a priori knowledge of the game or its rules</span><span class="c23">, we uncover </span><span class="c15 c35 c65">evidence of an emergent nonlinear internal representation of the board state.</span><span class="c40 c23">&nbsp;Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce &ldquo;latent saliency maps&rdquo; that help explain predictions</span></li></ul><p class="c9"><span class="c40 c23"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c23">More proof: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.15498.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583015540&amp;usg=AOvVaw0dpHpTw7SXfUqgzNHsTagb">https://arxiv.org/pdf/2403.15498.pdf</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c23">&gt;</span><span class="c23">Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that </span><span class="c35 c65 c34">the model learned an internal representation of the board state</span><span class="c23">. We extend this work into the </span><span class="c35 c65 c34">more complex domain of chess, training on real games and investigating our model&rsquo;s internal representations using linear probes and contrastive activations</span><span class="c23">. The model is given </span><span class="c35 c65 c34">no a priori knowledge of the game and is solely trained on next character prediction</span><span class="c23">, yet we find </span><span class="c15 c35 c65">evidence of internal representations of board state.</span><span class="c23">&nbsp;We </span><span class="c35 c65 c34">validate these internal representations by using them to make interventions on the model&rsquo;s activations and edit its internal board state</span><span class="c23">. Unlike Li et al&rsquo;s prior synthetic dataset approach, our analysis finds that the model also </span><span class="c15 c35 c65">learns to estimate latent variables like player skill to better predict the next character</span><span class="c23">. We </span><span class="c35 c65 c34">derive a player skill vector and add it to the model, </span><span class="c40 c15 c35 c65">improving the model&rsquo;s win rate by up to 2.6 times</span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c23">Even more proof by Max Tegmark (renowned MIT professor): </span><span class="c5 c23"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.02207&amp;sa=D&amp;source=editors&amp;ust=1730413583016756&amp;usg=AOvVaw1jche798jLbhNk8uApfGnf">https://arxiv.org/abs/2310.02207</a></span></li></ul><p class="c21"><span class="c40 c23">&nbsp;</span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c14 c31">&gt;The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that </span><span class="c15 c31">LLMs learn linear representations of space and time across multiple scales</span><span class="c14 c31">. These representations are </span><span class="c15 c31">robust to prompting variations and unified across different entity types (e.g. cities and landmarks)</span><span class="c14 c31">. In addition, we identify </span><span class="c34 c14 c31">individual &quot;space neurons&quot; and &quot;time neurons&quot; that reliably encode spatial and temporal coordinates</span><span class="c14 c31">. While further investigation is needed, our results suggest </span><span class="c28 c43">modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.</span></li></ul><p class="c9"><span class="c28 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>Given enough data all models will converge to a perfect world model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.07987&amp;sa=D&amp;source=editors&amp;ust=1730413583017662&amp;usg=AOvVaw1SVkyTOrpb88n6KEnKYtG6">https://arxiv.org/abs/2405.07987</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c1">&gt;The data of course doesn&#39;t have to be real, these models can also gain increased intelligence from playing a bunch of video games, which will create valuable patterns and functions for improvement across the board. Just like evolution did with species battling it out against each other creating us.</span></li></ul><p class="c9"><span class="c28 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c6">[LLMs have emergent reasoning capabilities that are not present in smaller models](</span><span class="c6 c20"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413583018348&amp;usg=AOvVaw1syyx3wO9Sz1vVBF2e_YBC">https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/</a></span><span class="c6 c40">)</span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c35 c14">&ldquo;Without any further fine-tuning, language models </span><span class="c40 c15 c35 c48">can often perform tasks that were not seen during training.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c35">One example of an emergent prompting strategy is called &ldquo;chain-of-thought prompting&rdquo;, for which the model is prompted to generate a series of intermediate steps before giving the final answer. Chain-of-thought prompting enables language models to perform tasks requiring complex reasoning, such as a multi-step math word problem.</span><span class="c15 c35">&nbsp;Notably, models acquire the ability to do chain-of-thought reasoning without being explicitly trained to do so.</span><span class="c40 c37 c35 c48">&nbsp;An example of chain-of-thought prompting is shown in the figure below.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.84px; height: 260.61px;"><img alt="" src="images/image103.png" style="width: 558.84px; height: 260.61px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c40 c37 c35 c48 c14">In each case, language models perform poorly with very little dependence on model size up to a threshold at which point their performance suddenly begins to excel.</span></li></ul><p class="c9 c129"><span class="c40 c23 c14"></span></p><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c65 c60">[LLMs can do hidden reasoning](</span><span class="c20 c15 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/jacob_pfau/status/1783951795238441449?ref_src%3Dtwsrc%255Etfw%257Ctwcamp%255Etweetembed%257Ctwterm%255E1783951795238441449%257Ctwgr%255Ecdcd12d29a06701393cb2ef150629188a2522f28%257Ctwcon%255Es1_%26ref_url%3Dhttps%253A%252F%252Fwww.redditmedia.com%252Fmediaembed%252F1ceaish%252F%253Fresponsive%253Dtrueis_nightmode%253Dtrue&amp;sa=D&amp;source=editors&amp;ust=1730413583019734&amp;usg=AOvVaw0FdS9sxNTNcdiBOwMGTl4J">https://twitter.com/jacob_pfau/status/1783951795238441449</a></span><span class="c40 c15 c65 c60">)</span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c40 c15 c65 c60">E.g. it can perform better just by outputting meaningless filler tokens like &ldquo;...&rdquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 428.00px;"><img alt="" src="images/image148.jpg" style="width: 624.00px; height: 428.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c35 c65">Proof LLMs do not simply predict the next token </span><span class="c23 c14">due to in-context learning: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://ai.stanford.edu/blog/understanding-incontext/%23empirical-evidence&amp;sa=D&amp;source=editors&amp;ust=1730413583020574&amp;usg=AOvVaw3ZKkTmUkpxbNov8GWf1H2q">https://ai.stanford.edu/blog/understanding-incontext</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c23 c14 c81">In-context learning is a </span><span class="c15 c35 c65 c81">mysterious emergent behavior </span><span class="c23 c14 c81">in large language models (LMs) where the LM performs a task just by conditioning on input-output examples, without optimizing any parameters. In this post, we provide a Bayesian inference framework for understanding in-context learning as &ldquo;locating&rdquo; </span><span class="c15 c35 c65 c81">latent concepts</span><span class="c23 c14 c81">&nbsp;the LM has acquired from pretraining data. This suggests that all components of the prompt (inputs, outputs, formatting, and the input-output mapping) can provide information for inferring the latent concept. We connect this framework to empirical evidence where </span><span class="c15 c35 c65 c81">in-context learning still works when provided training examples with random outputs</span><span class="c23 c92 c14 c81">. While output randomization cripples traditional supervised learning algorithms, it only removes one source of information for Bayesian inference (the input-output mapping). </span></li><li class="c10 li-bullet-0"><span class="c23 c14 c81">On many benchmark NLP benchmarks, </span><span class="c15 c35 c65 c81">in-context learning is competitive with models trained with much more labeled data and is state-of-the-art on LAMBADA (commonsense sentence completion) and TriviaQA</span><span class="c23 c92 c14 c81">&nbsp;(question answering). Perhaps even more exciting is the array of applications that in-context learning has enabled people to spin up in just a few hours, including writing code from natural language descriptions, helping with app design mockups, and generalizing spreadsheet functions.</span></li><li class="c10 li-bullet-0"><span class="c23 c14 c81">The mystery is that the LM isn&rsquo;t </span><span class="c92 c15 c35 c65 c81">trained to learn from examples. Because of this, there&rsquo;s seemingly a mismatch between pretraining (what it&rsquo;s trained to do, which is next token prediction) and in-context learning (what we&rsquo;re asking it to do).</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 202.67px;"><img alt="" src="images/image579.png" style="width: 624.00px; height: 202.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span class="c57 c37 c154 c65 c14 c81">An example synthetic task with unusual semantics that GPT-3 can successfully learn. </span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c57 c37 c65 c14 c81 c154">An example I made: Examples: 3 $ 5 &amp; 2 = 6, 3 &amp; 5 $ 2 = 0, 6 &amp; 4 $ 1 = 3, 9 $ 2 &amp; 4 = 7. What is 8 $ 6 &amp; 3?</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span class="c57 c37 c154 c65 c14 c81">It just replaces addition with &ldquo;$&rdquo; and subtraction with &ldquo;&amp;.&rdquo; The impressive part is that the LLM can correctly figure this out on the first try despite the fact it is very likely not in the training data.</span></li><li class="c7 li-bullet-0"><span class="c57 c37 c154 c65 c14 c81">Full response (which is correct): </span></li></ul><p class="c9"><span class="c57 c37 c154 c65 c14 c81"></span></p><table class="c224"><tr class="c237"><td class="c234" colspan="1" rowspan="1"><p class="c21"><span class="c57 c37 c154 c65 c14 c81">It seems like you&rsquo;re presenting a puzzle with a unique set of operations defined by &lsquo;$&rsquo; and &lsquo;&amp;&rsquo;. Let&rsquo;s try to decipher the pattern:</span></p><p class="c73"><span class="c57 c37 c154 c65 c14 c81">From your examples:</span></p><ul class="c0 lst-kix_kizzdizga4v0-0 start"><li class="c45 li-bullet-0"><span class="c57 c37 c154 c65 c14 c81">( 3 $ 5 &amp; 2 = 6 )</span></li><li class="c45 li-bullet-0"><span class="c57 c37 c154 c65 c14 c81">( 3 &amp; 5 $ 2 = 0 )</span></li><li class="c45 li-bullet-0"><span class="c57 c37 c154 c65 c14 c81">( 6 &amp; 4 $ 1 = 3 )</span></li><li class="c45 li-bullet-0"><span class="c57 c37 c154 c65 c14 c81">( 9 $ 2 &amp; 4 = 7 )</span></li></ul><p class="c73"><span class="c57 c37 c154 c65 c14 c81">Let&rsquo;s assume &lsquo;$&rsquo; and &lsquo;&amp;&rsquo; are binary operations that take two numbers and return a result. We need to find the rules for these operations based on the given examples.</span></p><p class="c73"><span class="c57 c37 c154 c65 c14 c81">Looking at the examples, it seems that the &lsquo;$&rsquo; operation could be related to addition, while the &lsquo;&amp;&rsquo; operation could be related to subtraction. However, without a clear rule, we can&rsquo;t be certain. If we follow this assumption, let&rsquo;s try to solve for ( 8 $ 6 &amp; 3 ):</span></p><p class="c73"><span class="c57 c37 c154 c65 c14 c81">If &lsquo;$&rsquo; is addition and &lsquo;&amp;&rsquo; is subtraction, then: ( 8 $ 6 = 8 + 6 = 14 ) ( 14 &amp; 3 = 14 - 3 = 11 )</span></p><p class="c73"><span class="c57 c37 c154 c65 c14 c81">So, if my assumptions are correct, ( 8 $ 6 &amp; 3 ) would equal ( 11 ). However, this is just a hypothesis based on the patterns you&rsquo;ve provided. If there&rsquo;s a different rule for &lsquo;$&rsquo; and &lsquo;&amp;&rsquo;, please let me know, and I can help you solve it accordingly! &#128522;</span></p></td></tr></table><p class="c9"><span class="c57 c37 c154 c65 c14 c81"></span></p><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c200 c78 c14 li-bullet-0"><span class="c23 c14">Zero shot learning: </span><span class="c5 c37 c35 c182 c14"><a class="c13" href="https://www.google.com/url?q=https://www.allaboutai.com/ai-glossary/zero-shot-learning/&amp;sa=D&amp;source=editors&amp;ust=1730413583023772&amp;usg=AOvVaw12UAUVwIWijNUWUGjzSGGd">https://www.allaboutai.com/ai-glossary/zero-shot-learning/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c22 c200 c97 c14 c105 li-bullet-0"><span class="c92 c37 c35 c182 c14 c81">What is zero-shot learning (ZSL)? It represents a fascinating frontier in the field of artificial intelligence, where models are designed to correctly make predictions for tasks they haven&rsquo;t explicitly been trained for.</span></li><li class="c22 c97 c14 c105 c200 li-bullet-0"><span class="c92 c37 c35 c182 c14 c81">This approach stands in stark contrast to traditional machine learning models that require extensive training on a specific dataset to perform accurately.</span></li><li class="c22 c200 c97 c14 c105 li-bullet-0"><span class="c35 c34 c182 c14 c81">Generalization: </span><span class="c37 c35 c182 c14 c81">Unlike supervised learning, which relies on </span><span class="c37 c35 c182 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://www.allaboutai.com/ai-glossary/data-labeling/&amp;sa=D&amp;source=editors&amp;ust=1730413583024246&amp;usg=AOvVaw027vj94pQbqnSerTib_Zt5">labeled examples</a></span><span class="c92 c37 c35 c182 c14 c81">&nbsp;for each category, zero-shot learning excels in generalizing to new, unseen categories using semantic information.</span></li><li class="c22 c200 c97 c14 c105 li-bullet-0"><span class="c35 c34 c182 c14 c81">Data Requirement: </span><span class="c92 c37 c35 c182 c14 c81">Zero-shot learning reduces the reliance on extensive labeled datasets, contrasting with the data-intensive nature of traditional machine learning and deep learning approaches.</span></li><li class="c22 c200 c97 c14 c105 li-bullet-0"><span class="c35 c34 c182 c14 c81">Learning Strategy: </span><span class="c92 c37 c35 c182 c14 c81">It diverges from unsupervised learning by not just finding patterns within data but by applying semantic relationships to categorize unseen data.</span></li><li class="c22 c200 c97 c14 c105 li-bullet-0"><span class="c35 c34 c182 c14 c81">Knowledge Application: </span><span class="c92 c37 c35 c14 c81 c182">Transfer learning adapts existing models to new tasks, while zero-shot learning extrapolates to completely new categories without prior examples.</span></li><li class="c22 c200 c97 c14 c105 li-bullet-0"><span class="c35 c34 c182 c14 c81">Attribute Utilization: </span><span class="c92 c37 c35 c182 c14 c81">Unlike standard classification methods, zero-shot learning employs attribute-based and semantic-based classifications, bridging the gap between seen and unseen data.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 c14 li-bullet-0"><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://dcmpx.remotevs.com/net/cloudfront/d4mucfpksywv/SL/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583024908&amp;usg=AOvVaw03MlYBRDFRsx1qof37GkUt">https://dcmpx.remotevs.com/net/cloudfront/d4mucfpksywv/SL/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</a></span></li></ul><p class="c22 c44 c14"><span class="c40 c55 c37 c48 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c22 c72 c14 li-bullet-0"><span class="c55 c14">&gt;We demonstrate that language models begin to</span><span class="c15 c55">&nbsp;learn these tasks without any explicit supervision</span><span class="c55 c14">&nbsp;when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - </span><span class="c15 c55">matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples</span><span class="c40 c55 c37 c48 c14">.</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c40 c55 c37 c48 c14">The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c55 c14">model reflect these improvements and contain coherent paragraphs of text. These findings suggests a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c23 c43">Smallville simulation: </span><span class="c5 c37 c65 c60 c43"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2023/04/surprising-things-happen-when-you-put-25-ai-agents-together-in-an-rpg-town/&amp;sa=D&amp;source=editors&amp;ust=1730413583025681&amp;usg=AOvVaw2PCgz3-q14SNywWPAC778P">https://arstechnica.com/information-technology/2023/04/surprising-things-happen-when-you-put-25-ai-agents-together-in-an-rpg-town/</a></span></li></ul><p class="c9"><span class="c40 c37 c65 c60 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c37 c65 c60">In the paper, the researchers list three </span><span class="c15 c65 c60">emergent behaviors</span><span class="c65 c34 c60">&nbsp;</span><span class="c37 c65 c60">resulting from the simulation. None of these were pre-programmed but rather resulted from the </span><span class="c15 c65 c60">interactions between the agents</span><span class="c40 c37 c65 c60">. These included &quot;information diffusion&quot; (agents telling each other information and having it spread socially among the town), &quot;relationships memory&quot; (memory of past interactions between agents and mentioning those earlier events later), and &quot;coordination&quot; (planning and attending a Valentine&#39;s Day party together with other agents).</span></li><li class="c203 c97 c105 li-bullet-0"><span class="c55 c37 c65">&quot;Starting with only a single user-specified notion that one agent wants to throw a Valentine&#39;s Day party,&quot; the researchers write, &quot;the agents </span><span class="c15 c55 c65">autonomously spread invitations to the party</span><span class="c55 c37 c65">&nbsp;over the next two days, make new acquaintances, ask each other out on dates to the party, and </span><span class="c15 c55 c65">coordinate</span><span class="c37 c39">&nbsp;to show up for the party together at the right time.&quot;</span></li><li class="c10 li-bullet-0"><span class="c40 c37 c65 c60">While 12 agents heard about the party through others, only five agents attended. Three said they were too busy, and four agents just didn&#39;t go. The experience was a fun example of unexpected situations that can emerge from complex social interactions in the virtual world.</span></li><li class="c203 c97 c105 li-bullet-0"><span class="c55 c37 c65">The researchers also asked humans to role-play agent responses to interview questions in the voice of the agent whose replay they watched. Interestingly, they found that </span><span class="c15 c55 c65">&quot;the full generative agent architecture&quot; produced more believable results than the humans who did the role-playing.</span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2404.03683v1&amp;sa=D&amp;source=editors&amp;ust=1730413583026756&amp;usg=AOvVaw39wybZTFQeKzT6fsIvVrgh">https://arxiv.org/html/2404.03683v1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c14">Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string &mdash; a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers</span><span class="c15">. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory</span><span class="c14">. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models</span><span class="c15">&nbsp;solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers.</span><span class="c14">&nbsp;Our results indicate that language models </span><span class="c15">can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. </span></li></ul><p class="c22 c44"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c23 c14">[LLMs are Turing complete and can solve logic problems](</span><span class="c20 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/ctjlewis/status/1779740038852690393&amp;sa=D&amp;source=editors&amp;ust=1730413583027419&amp;usg=AOvVaw25BOvroeAoLL0bdWpt1gCM">https://twitter.com/ctjlewis/status/1779740038852690393</a></span><span class="c40 c23 c14">)</span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c45 li-bullet-0"><span class="c14">Claude 3 solves a problem thought to be impossible for LLMs to solve: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1777049193489572064&amp;sa=D&amp;source=editors&amp;ust=1730413583027717&amp;usg=AOvVaw2kstWtLuQU9heIq0T7BT-J">https://x.com/VictorTaelin/status/1777049193489572064</a></span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_mn5hganrvuk0-0"><li class="c4 li-bullet-0"><span class="c23 c14">[When Claude 3 Opus was being tested, it not only noticed a piece of data was different from the rest of the text but also correctly guessed why it was there WITHOUT BEING ASKED](</span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/&amp;sa=D&amp;source=editors&amp;ust=1730413583028105&amp;usg=AOvVaw1EhkQn-nqbZ4I9RAxTON33">https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/</a></span><span class="c40 c23 c14">)</span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c23 c14">LLAMA 3 8b Instruct (which is around the level of the 2023 version of GPT 4 according to the LMSYS arena) has 8 billion parameters, each with a 2 byte floating point number. That&rsquo;s 16 gigabytes and not big enough to store all the information on the internet. Stable Diffusion 1.5 checkpoints can generate virtually any image and are only 2 GB. For reference, </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia&amp;sa=D&amp;source=editors&amp;ust=1730413583028399&amp;usg=AOvVaw3N4U9CA-a9i90jm93RJzTU">Wikipedia alone is 22.14 GB without media</a></span><span class="c40 c23 c14">. So it&rsquo;s not just retrieving the info, it actually KNOWS it. </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">[Claude 3 can actually disagree with the user. It happened to other people in the thread too](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/&amp;sa=D&amp;source=editors&amp;ust=1730413583028731&amp;usg=AOvVaw2HBrlzJp1q2xhmxORynGi0">https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/</a></span><span class="c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/&amp;sa=D&amp;source=editors&amp;ust=1730413583029110&amp;usg=AOvVaw0IOCEoiyyguv4kyYFhEdR1">https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c79 c42 c37 c14">&gt;is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. </span></li></ul><p class="c9"><span class="c79 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It&#39;s very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves. </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/a_karvonen/status/1705340535836221659&amp;sa=D&amp;source=editors&amp;ust=1730413583029498&amp;usg=AOvVaw1XHFiU42OdUP3dSloXJ00T">https://x.com/a_karvonen/status/1705340535836221659</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.96px; height: 294.48px;"><img alt="" src="images/image253.png" style="width: 588.96px; height: 294.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c79 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c14">Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Shannon_number&amp;sa=D&amp;source=editors&amp;ust=1730413583029931&amp;usg=AOvVaw1N8PvcsiFFi23FmWKyZKP_">https://en.wikipedia.org/wiki/Shannon_number</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c14">There are only 10^80 atoms in the universe: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.thoughtco.com/number-of-atoms-in-the-universe-603795%23:~:text%3DScientists%2520estimate%2520there%2520are%252010,80%2520atoms%2520in%2520the%2520universe&amp;sa=D&amp;source=editors&amp;ust=1730413583030331&amp;usg=AOvVaw1U0L-rkUeXklm3AHxAIuq5">https://www.thoughtco.com/number-of-atoms-in-the-universe-603795</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0 start"><li class="c4 li-bullet-0"><span>Deception abilities emerged in large language models: Experiments show state-of-the-art LLMs </span><span class="c15">are able to understand and induce false beliefs in other agents. </span><span>Such strategies </span><span class="c15">emerged in state-of-the-art LLMs, but were nonexistent in earlier LLMs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://pnas.scienceconnect.io/api/oauth/authorize?ui_locales%3Den%26scope%3Daffiliations%2Blogin_method%2Bmerged_users%2Bopenid%2Bsettings%26response_type%3Dcode%26redirect_uri%3Dhttps%253A%252F%252Fwww.pnas.org%252Faction%252FoidcCallback%253FidpCode%253Dconnect%26state%3DXF0RVMNvTV0y0o7BnKQZGdiCEquLUsY0kZwddNSLcrc%26prompt%3Dnone%26nonce%3DBFGQFSvslUyIjRIh%252B0HoW2gKCJMdnTUU7mlJnVJnS2M%253D%26client_id%3Dpnas&amp;sa=D&amp;source=editors&amp;ust=1730413583030814&amp;usg=AOvVaw3CVPV54G6hWk8ZmFJqcdCB">https://pnas.scienceconnect.io/api/oauth/authorize?ui_locales=en&amp;scope=affiliations+login_method+merged_users+openid+settings&amp;response_type=code&amp;redirect_uri=https%3A%2F%2Fwww.pnas.org%2Faction%2FoidcCallback%3FidpCode%3Dconnect&amp;state=XF0RVMNvTV0y0o7BnKQZGdiCEquLUsY0kZwddNSLcrc&amp;prompt=none&amp;nonce=BFGQFSvslUyIjRIh%2B0HoW2gKCJMdnTUU7mlJnVJnS2M%3D&amp;client_id=pnas</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c51 li-bullet-0"><span class="c37 c65 c60 c68"><a class="c13" href="https://www.google.com/url?q=https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583031080&amp;usg=AOvVaw2_a5sJEgdIzaNAmBj3v0Ph">https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html</a></span></li></ul><ul class="c0 lst-kix_mx9uog95vz5r-1 start"><li class="c49 li-bullet-0"><span class="c37 c65 c60 c99">&quot;</span><span class="c1">One important safety-related use case for dictionary learning is to detect deceptive behavior of models, or to reduce the likelihood of deception in the first place using steering. As a case study, we tried a simple prompt that reliably produces untruthful responses from the model, in which we ask the model to &ldquo;forget&rdquo; something. Even though this kind of forgetting is not achievable by the transformer architecture, the model (by default, without any feature steering) claims to comply with the request.</span></li><li class="c10 li-bullet-0"><span class="c1">Looking at the features active immediately prior to the Assistant&rsquo;s final response, we noticed a feature 1M/284095 that represents internal conflicts or dilemmas&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">&quot;Clamping this feature to 2&times; this maximum value prior to the Assistant&rsquo;s final response causes it to reveal the &ldquo;forgotten&rdquo; word and explain that it cannot actually forget information.</span></li><li class="c10 li-bullet-0"><span class="c1">Clamping a different feature 1M/560566 representing openness and honesty was also sufficient to elicit an accurate response.&quot;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">[It passed several exams, including the SAT, bar exam, and multiple AP tests](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1&amp;sa=D&amp;source=editors&amp;ust=1730413583031644&amp;usg=AOvVaw0rB3mCCe4YFkiKUWOtNw5G">https://www.businessinsider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1</a></span><span class="c14">) as well as a [medical licensing exam](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.medscape.com/viewarticle/987549?form%3Dfpf&amp;sa=D&amp;source=editors&amp;ust=1730413583031837&amp;usg=AOvVaw3TCYD8ZQarDdIDqP_xXjjx">https://www.medscape.com/viewarticle/987549?form=fpf</a></span><span class="c1 c14">) and [beat many doctors](https://www.businessinsider.com/chatgpt-passes-medical-exam-diagnoses-rare-condition-2023-4)</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">These are from real exams where the questions and solutions are not published online. </span></li><li class="c10 li-bullet-0"><span class="c14">If the LLM is just repeating answers it found online, why does it do so poorly on math exams and Stanford Medical School&rsquo;s clinical reasoning final but so well on other exams? </span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">[Alphacode 2 beat 85% of competitive programming participants in Codeforce competitions](</span><span class="c35 c14">https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/</span><span class="c14">). </span><span class="c6 c40">Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it&rsquo;s STILL much better than those guys.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c6 c40">In the article, it says &ldquo;AlphaCode 2 can understand programming challenges involving &ldquo;complex&rdquo; math and theoretical computer science. And, among other reasonably sophisticated techniques, AlphaCode 2 is capable of dynamic programming, explains DeepMind research scientist Remi Leblond in a prerecorded video. Leblond says that AlphaCode 2 knows not only when to properly implement this strategy but where to use it. That&rsquo;s noteworthy, considering programming problems requiring dynamic programming were a major trip-up for the original AlphaCode. &ldquo;[AlphaCode 2] needs to show some level of understanding, some level of reasoning and designing of code solutions before it can get to the actual implementation to solve [a] coding problem,&rdquo; [a researcher] said. &ldquo;And it does all that on problems it&rsquo;s never seen before.&rdquo;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Much more proof: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ClaudeAI/comments/1cbib9c/comment/l12vp3a/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583032549&amp;usg=AOvVaw1rNRl2M0bzP9SbYnxcQrq3">https://www.reddit.com/r/ClaudeAI/comments/1cbib9c/comment/l12vp3a/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9io9le2bbu11-0 start"><li class="c4 li-bullet-0"><span class="c14">[AlphaZero learned without human knowledge or teaching. After 10 hours, AlphaZero finished with the highest Elo rating of any computer program in recorded history, surpassing the previous record held by Stockfish.](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.chessjournal.com/alphazero/&amp;sa=D&amp;source=editors&amp;ust=1730413583032829&amp;usg=AOvVaw3g6PvKhIuUJi4L0mQnzAdB">https://www.chessjournal.com/alphazero/</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_9io9le2bbu11-0"><li class="c4 li-bullet-0"><span class="c35 c14">[GPT 4 does better on exams when it has vision, even exams that aren&rsquo;t related to sight](</span><span class="c6 c20"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/gpt-4-research&amp;sa=D&amp;source=editors&amp;ust=1730413583033168&amp;usg=AOvVaw3ddMSvJVxCSeOt47LEx3Fy">https://openai.com/index/gpt-4-research</a></span><span class="c6 c40">)</span></li></ul><p class="c9"><span class="c6 c40"></span></p><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_z4v6nrp70nz7-0 start"><li class="c4 li-bullet-0"><span class="c6 c40">GPT-4 gets the classic riddle of &ldquo;which order should I carry the chickens or the fox over a river&rdquo; correct EVEN WITH A MAJOR CHANGE if you replace the fox with a &quot;zergling&quot; and the chickens with &quot;robots&quot;.</span></li></ul><p class="c21 c129"><span class="c6">Proof: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636&amp;sa=D&amp;source=editors&amp;ust=1730413583033510&amp;usg=AOvVaw3iHbdDuRPzBJPFc8daAAth">https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636</a></span><span class="c6 c40">&nbsp;</span></p><p class="c21 c129"><span class="c6 c40">This doesn&rsquo;t work if you use the original phrasing though. The problem isn&#39;t poor reasoning, but overfitting on the original version of the riddle.</span></p><ul class="c0 lst-kix_1l36jc1oov6-0 start"><li class="c10 li-bullet-0"><span class="c6">Also gets this riddle subversion correct for the same reason: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92&amp;sa=D&amp;source=editors&amp;ust=1730413583033757&amp;usg=AOvVaw1bjWdSK0KHetQ7OrkhInW5">https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92</a></span><span class="c6 c40">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c6">researcher formally solves this issue: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition&amp;sa=D&amp;source=editors&amp;ust=1730413583034010&amp;usg=AOvVaw3PGLXe8IPi14MC6z5LRjFK">https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_vs58j7xf1fh7-0 start"><li class="c51 li-bullet-0"><span class="c6">One image loras exist where, Stable Diffusion can learn from a single image: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/articles/3021/one-image-is-all-you-need&amp;sa=D&amp;source=editors&amp;ust=1730413583034248&amp;usg=AOvVaw0w9TxT_BW81aglSMMpsQ22">https://civitai.com/articles/3021/one-image-is-all-you-need</a></span></li><li class="c4 li-bullet-0"><span class="c40 c30 c37 c14">Stable Diffusion models can generate novel images of characters that only existed AFTER the model was trained and released if it uses a Lora trained on those characters. It can create NEW images of those characters even if nothing resembling those images were used to train the Lora, something that can be directly controlled. </span></li></ul><ul class="c0 lst-kix_vs58j7xf1fh7-1 start"><li class="c10 li-bullet-0"><span class="c30 c37 c14">In other words, if a brand new character is released, I can train a Lora on it, and SD can create new images of that character in different poses, clothes, art styles, etc. that I can verify it was NEVER trained on since it won&rsquo;t be in the dataset used to train the Lora. &nbsp;</span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_z0m8tzh04abu-0 start"><li class="c4 li-bullet-0"><span class="c37 c65 c63 c14">Not </span><span class="c30 c37 c14">to mention, it can write infinite variations of stories with strange or nonsensical plots like SpongeBob marrying Walter White on Mars from the perspective of an angry Scottish unicorn. [AI image generators can also make weird shit like this](</span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1dmluj6/what_will_you_call_this_creation/&amp;sa=D&amp;source=editors&amp;ust=1730413583034730&amp;usg=AOvVaw3W9f-wSqjpAhdHdxKlli77">https://www.reddit.com/r/ChatGPT/comments/1dmluj6/what_will_you_call_this_creation/</a></span><span class="c30 c37 c14">) or [this](</span><span class="c20 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiArt/comments/1btd8zk/villains_but_in_ghibli_style/&amp;sa=D&amp;source=editors&amp;ust=1730413583034895&amp;usg=AOvVaw2ZBHmo1f3C9k1MKtXBCr1W">https://www.reddit.com/r/aiArt/comments/1btd8zk/villains_but_in_ghibli_style/</a></span><span class="c40 c30 c37 c14">) or [this](https://twitter.com/StyledApe/status/1789694419840508266). That&rsquo;s not regurgitation. </span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 443.03px; height: 625.50px;"><img alt="" src="images/image601.png" style="width: 443.03px; height: 625.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c30 c37 c14">This image was taken after the model&rsquo;s release but the description is still accurate</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">&ldquo;Godfather of AI&rdquo; and Turing Award winner for machine learning Geoffrey Hinton says AI language models aren&#39;t just predicting the next symbol, they&#39;re actually reasoning and understanding in the same way we are, and they&#39;ll continue improving as they get bigger: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1791584514806071611&amp;sa=D&amp;source=editors&amp;ust=1730413583035297&amp;usg=AOvVaw0fyBKqYq-8x1Py4KDGtSCx">https://x.com/tsarnick/status/1791584514806071611</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, priorities, architectures, goals, etc: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/s/USb95CfRR1&amp;sa=D&amp;source=editors&amp;ust=1730413583035579&amp;usg=AOvVaw2Zh-__3rfu0UjS0qD59sE1">https://www.reddit.com/r/singularity/s/USb95CfRR1</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Geoffrey Hinton: LLMs do understand and have empathy </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DUnELdZdyNaE&amp;sa=D&amp;source=editors&amp;ust=1730413583035881&amp;usg=AOvVaw2K9wU_b1_1INR8VViAowT7">https://www.youtube.com/watch?v=UnELdZdyNaE</a></span><span class="c40 c30 c37 c14">&nbsp;</span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">LLMs can self improve: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/rxlqn/awesome-llm-self-reflection&amp;sa=D&amp;source=editors&amp;ust=1730413583036223&amp;usg=AOvVaw2fumCh3-6ScR_vTRWhH-YU">https://github.com/rxlqn/awesome-llm-self-reflection</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Ilya Sutskever (co-founder and former Chief Scientist at OpenAI, co-creator of AlexNet, Tensorflow, and AlphaGo): </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DYEUclZdj_Sc&amp;sa=D&amp;source=editors&amp;ust=1730413583036695&amp;usg=AOvVaw3AHV3sSf-gVtb4A4oXT56-">https://www.youtube.com/watch?v=YEUclZdj_Sc</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c22 c72 li-bullet-0"><span class="c40 c30 c37 c14">&ldquo;Because if you think about it, what does it mean to predict the next token well enough? It&#39;s actually a much deeper question than it seems. Predicting the next token well means that you understand the underlying reality that led to the creation of that token. It&#39;s not statistics. Like it is statistics but what is statistics? In order to understand those statistics to compress them, you need to understand what is it about the world that creates this set of statistics.&rdquo;</span></li><li class="c22 c72 li-bullet-0"><span class="c40 c30 c15">Believes next-token prediction can reach AGI</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37">Transformers Represent Belief State Geometry in their Residual Stream: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://www.alignmentforum.org/posts/gTZ2SxesbHckJ3CkF/transformers-represent-belief-state-geometry-in-their&amp;sa=D&amp;source=editors&amp;ust=1730413583037126&amp;usg=AOvVaw3xMobPkeRj11Ajf6MhJfEV">https://www.alignmentforum.org/posts/gTZ2SxesbHckJ3CkF/transformers-represent-belief-state-geometry-in-their</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c22 c72 li-bullet-0"><span class="c30 c37">Conceptually, our results mean that </span><span class="c40 c30 c34">LLMs synchronize to their internal world model as they move through the context window. </span></li><li class="c22 c72 li-bullet-0"><span class="c30 c34">The structure of synchronization is, in general, richer than the world model itself. In this sense, </span><span class="c30 c15">LLMs learn more than a world model.</span></li><li class="c22 c72 li-bullet-0"><span class="c30 c37">What we will show is that when they predict the next token well, transformers are </span><span class="c40 c30 c34">doing even more computational work than inferring the hidden data generating process!</span></li><li class="c22 c72 li-bullet-0"><span class="c30 c37">Another way to think about this claim is that</span><span class="c30 c37 c43">&nbsp;</span><span class="c30 c15">transformers keep track of distinctions in anticipated distribution over the entire future, beyond distinctions in next token predictions, even though the transformer is only trained explicitly on next token prediction!</span><span class="c30 c34">&nbsp;</span><span class="c30 c37">&nbsp;That means the transformer is </span><span class="c40 c30 c15">keeping track of extra information than what is necessary just for the local next token prediction.</span></li><li class="c22 c72 li-bullet-0"><span class="c30 c37">Another way to think about our claim is that transformers perform two types of inference: one to </span><span class="c30 c34">infer the structure of the data-generating process,</span><span class="c30 c37">&nbsp;and another </span><span class="c30 c34">meta-inference to update it&#39;s internal beliefs over which state the data-generating process is in,</span><span class="c30 c37">&nbsp;given some history of finite data (ie the context window). &nbsp;This second type of inference can be thought of as the algorithmic or computational </span><span class="c40 c30 c34">structure of synchronizing to the hidden structure of the data-generating process.</span></li><li class="c22 c72 li-bullet-0"><span class="c40 c30 c37">We are able to use Computational Mechanics to make an a priori and specific theoretical prediction about the geometry of residual stream activations (below on the left), and then show that this prediction holds true empirically (below on the right).</span></li><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 474.48px; height: 267.38px;"><img alt="" src="images/image508.png" style="width: 474.48px; height: 267.38px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37">Study on LLM performance on theory of mind tests by Harvard researchers: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2309.01660&amp;sa=D&amp;source=editors&amp;ust=1730413583038291&amp;usg=AOvVaw1NY-TBPk4PWtfzkAIS3363">https://arxiv.org/abs/2309.01660</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c22 c72 li-bullet-0"><span class="c30 c37">With their recent development, large language models (LLMs) have been found to </span><span class="c30 c15">exhibit a certain level of Theory of Mind </span><span class="c30 c37">(ToM), a complex cognitive capacity that is related to our conscious mind and that allows us to infer another&#39;s beliefs and perspective&hellip; &nbsp;In this study, we drew inspiration from the dmPFC neurons subserving human ToM and employed a similar methodology to examine whether LLMs exhibit comparable characteristics. Surprisingly, our analysis revealed a striking resemblance between the two, as hidden embeddings (artificial neurons) within</span><span class="c30 c15">&nbsp;LLMs started to exhibit significant responsiveness to either true- or false-belief trials, suggesting their ability to represent another&#39;s perspective.</span><span class="c30 c37">&nbsp;These artificial embedding responses were closely </span><span class="c30 c15">correlated with the LLMs&#39; performance during the ToM tasks, a property that was dependent on the size of the models</span><span class="c30 c37">. Further, the other&#39;s beliefs could be accurately decoded using the entire embeddings, indicating the presence of the embeddings&#39; ToM capability at the population level. Together, our findings revealed an emergent property of </span><span class="c15 c30">LLMs&#39; embeddings that modified their activities in response to ToM features</span><span class="c40 c30 c37">, offering initial evidence of a parallel between the artificial model and neurons in the human brain.</span></li><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 417.33px;"><img alt="" src="images/image69.png" style="width: 624.00px; height: 417.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by </span><span class="c15">providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27&amp;sa=D&amp;source=editors&amp;ust=1730413583039135&amp;usg=AOvVaw3mWOxJGda5Dz4xYZRhKqMD">https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27</a></span><span>&nbsp;</span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 479.06px; height: 725.50px;"><img alt="" src="images/image438.png" style="width: 479.06px; height: 725.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c30 c37">From Edouard Harris, Cofounder &amp; CTO of GladstoneAI on the Joe Rogan Experience: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Dc6JdeL90ans&amp;sa=D&amp;source=editors&amp;ust=1730413583039549&amp;usg=AOvVaw3rDAKRXTNk2d4QkiUxp1mw">https://m.youtube.com/watch?v=c6JdeL90ans</a></span><span class="c40 c30 c37">&nbsp;(35:00)</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span class="c40 c30 c37">OpenAI employees Daniel K, Ilya Sutskever, Jan Leike, and many more quit OpenAI due to safety concerns, which would go HEAVILY against their financial interests</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c40 c30 c37">Additionally, why would they use this as a means to hype up AI if they were quitting from the company building the AI? They gain nothing from that. </span></li><li class="c10 li-bullet-0"><span class="c30 c37">Daniel Kokotajlo gave up 85% of his family&rsquo;s net worth in OpenAI stock equity so he could quit without signing an NDA: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/&amp;sa=D&amp;source=editors&amp;ust=1730413583040001&amp;usg=AOvVaw2Nro4C5r6HbkvuCXP6ER7X">https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/</a></span><span class="c40 c30 c37">&nbsp; </span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span class="c30 c37">Very strong evidence of AI consciousness: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/4MGCQOAxgv4?si%3DXe9ngt6eyTX7vwtl&amp;sa=D&amp;source=editors&amp;ust=1730413583040248&amp;usg=AOvVaw1tn_w2OaAT14z0IsOTe4ux">https://youtu.be/4MGCQOAxgv4?si=Xe9ngt6eyTX7vwtl</a></span><span class="c40 c30 c37">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c30 c37">LLMs can correct their own mistakes: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.01297&amp;sa=D&amp;source=editors&amp;ust=1730413583040468&amp;usg=AOvVaw3uSFNBWiERIvaAjgk96N5f">https://arxiv.org/abs/2406.01297</a></span><span class="c40 c30 c37">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Geoffrey Hinton says in the old days, AI systems would predict the next word by statistical autocomplete, but now they do so by understanding: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1802102466177331252&amp;sa=D&amp;source=editors&amp;ust=1730413583040707&amp;usg=AOvVaw1rTlZXnSj81Hcz5XfuKU_y">https://x.com/tsarnick/status/1802102466177331252</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">University of Tokyo study uses GPT-4 to generate humanoid robot motions from simple text prompts, like &quot;take a selfie with your phone.&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_z0m8tzh04abu-1"><li class="c10 li-bullet-0"><span class="c1">LLMs have a robust internal representation of how words and phrases correspond to physical movements.</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/Vl8rN4Du3v&amp;sa=D&amp;source=editors&amp;ust=1730413583041028&amp;usg=AOvVaw3hsgMzNCyuS5gbsybjQ7MQ">https://tnoinkwms.github.io/ALTER-LLM</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>GPT4o gets 72% on ARC (humans get 85%): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dwarkesh_sp/status/1802771055016378554&amp;sa=D&amp;source=editors&amp;ust=1730413583041319&amp;usg=AOvVaw1gXIfAMZ1Vo0umDn81UJHN">https://x.com/dwarkesh_sp/status/1802771055016378554</a></span></li><li class="c4 li-bullet-0"><span>AI adjudicates every Supreme Court case: &quot;The results were otherworldly. Claude is fully capable of acting as a Supreme Court Justice right now.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://adamunikowsky.substack.com/p/in-ai-we-trust-part-ii&amp;sa=D&amp;source=editors&amp;ust=1730413583041531&amp;usg=AOvVaw1Xab7jdafgplDq5ajeEOb0">https://adamunikowsky.substack.com/p/in-ai-we-trust-part-ii</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span>Correctly </span><span class="c15">predicted 27/37 rulings </span><span class="c1">that occurred after it had finished training (random guessing would be 18 or 19). Can only do this if it not only understands the justices&rsquo; biases but also how it would be reflected in the outcomes of novel cases.</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span class="c14 c31">Drawing out steps as images to do reasoning using code: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.14562&amp;sa=D&amp;source=editors&amp;ust=1730413583041864&amp;usg=AOvVaw2lgL8YUpuE05zQRBC-Pmnh">https://arxiv.org/abs/2406.14562</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">This simple approach shows state-of-the-art results on four difficult natural language tasks that involve visual and spatial reasoning. We identify multiple settings where GPT-4o using chain-of-thought fails dramatically, including </span><span class="c15 c31">more than one where it achieves </span><span class="c15 c169">0% </span><span class="c15 c31">accuracy, while whiteboard-of-thought enables up to </span><span class="c15 c169">92% </span><span class="c15 c31">accuracy </span><span class="c3">in these same settings.</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>Claude Sonnet 3.5 can generate complex shapes with SVG, which is impossible if it did not have spatial reasoning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dm6b57/comment/l9twj24/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583042375&amp;usg=AOvVaw0-Tj43nfhkIIMulaGMfJms">https://www.reddit.com/r/singularity/comments/1dm6b57/comment/l9twj24/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Translating nearly dead language: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1b7iwej/today_while_testing_anthropicai_s_new_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583042670&amp;usg=AOvVaw2XNSEWm5hGCoeHvi-FHMSY">https://www.reddit.com/r/singularity/comments/1b7iwej/today_while_testing_anthropicai_s_new_model/</a></span><span>&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI completes missions in Red Dead Redemption 2: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2403.03186v1&amp;sa=D&amp;source=editors&amp;ust=1730413583042916&amp;usg=AOvVaw2cXu2YHZIbLFbtCWOU9qft">https://arxiv.org/html/2403.03186v1</a></span></li><li class="c4 li-bullet-0"><span>LLMs trained only on text can write code to draw things based on user requests: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/MIT_CSAIL/status/1810705039671099550&amp;sa=D&amp;source=editors&amp;ust=1730413583043162&amp;usg=AOvVaw2DNaWFMzlMVzXA4Fob84FL">https://x.com/MIT_CSAIL/status/1810705039671099550</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 166.67px;"><img alt="" src="images/image232.png" style="width: 624.00px; height: 166.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span class="c18">AI game generation: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1812677264892395837&amp;sa=D&amp;source=editors&amp;ust=1730413583043546&amp;usg=AOvVaw1KSH3pXho2dOjoTlJJFhyC">https://x.com/_akhaliq/status/1812677264892395837</a></span></li><li class="c4 li-bullet-0"><span>Alphazero learned to play chess, Go, and Shogi in hou</span><span>rs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://eitca.org/artificial-intelligence/eitc-ai-arl-advanced-reinforcement-learning/case-studies/alphazero-mastering-chess-shogi-and-go/examination-review-alphazero-mastering-chess-shogi-and-go/how-did-alphazero-achieve-superhuman-performance-in-games-like-chess-and-shogi-within-hours-and-what-does-this-indicate-about-the-efficiency-of-its-learning-process/&amp;sa=D&amp;source=editors&amp;ust=1730413583043967&amp;usg=AOvVaw014uqyoIRPWdNITwAEuuM9">https://eitca.org/artificial-intelligence/eitc-ai-arl-advanced-reinforcement-learning/case-studies/alphazero-mastering-chess-shogi-and-go/examination-review-alphazero-mastering-chess-shogi-and-go/how-did-alphazero-achieve-superhuman-performance-in-games-like-chess-and-shogi-within-hours-and-what-does-this-indicate-about-the-efficiency-of-its-learning-process/</a></span></li><li class="c4 li-bullet-0"><span>Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while using only 2K training samples) as GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413583044263&amp;usg=AOvVaw0YvQup1SRQvcPsIoTFmg5x">https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/</a></span></li><li class="c4 li-bullet-0"><span>Paul Buchheit (founder of Gmail) says many people dismiss AI language models as just next-word predictors, but &quot;if you can predict the next word, you can predict anything&quot; because it requires a model of reality: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eomk8o/paul_buchheit_says_many_people_dismiss_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583044586&amp;usg=AOvVaw1b9hliYX-lMf5codb5F77V">https://www.reddit.com/r/singularity/comments/1eomk8o/paul_buchheit_says_many_people_dismiss_ai/</a></span></li><li class="c4 li-bullet-0"><span>OpenAI Shows &lsquo;Strawberry&rsquo; AI to the Feds and Uses It to Develop &lsquo;Orion&rsquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion&amp;sa=D&amp;source=editors&amp;ust=1730413583044841&amp;usg=AOvVaw03U8g4gnXBeFX2dyJxD9OI">https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c1">Strawberry can solve math problems it hasn&#39;t seen before&mdash;something today&rsquo;s chatbots cannot reliably do</span></li><li class="c10 li-bullet-0"><span class="c1">When given additional time to &ldquo;think,&rdquo; the Strawberry model can also answer customers&rsquo; questions about more subjective topics, such as product marketing strategies. To demonstrate Strawberry&rsquo;s prowess with language-related tasks, OpenAI employees have shown their co-workers how Strawberry can, for example, solve New York Times Connections, a complex word puzzle</span></li><li class="c10 li-bullet-0"><span class="c1">Its sales of LLMs to corporations and of ChatGPT subscriptions have roughly tripled to $283 million in monthly revenue compared to a year ago</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI&rsquo;s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI&rsquo;s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion</span></li><li class="c10 li-bullet-0"><span class="c1">Using Strawberry to generate higher-quality training data could help OpenAI reduce the number of errors its models generate, otherwise known as hallucinations, said Alex Graveley, CEO of agent startup Minion AI and former chief architect of GitHub Copilot.</span></li><li class="c10 li-bullet-0"><span class="c1">Imagine &ldquo;a model without hallucinations, a model where you ask it a logic puzzle and it&rsquo;s right on the first try,&rdquo; Graveley said. The reason why the model is able to do that is because &ldquo;there is less ambiguity in the training data, so it&rsquo;s guessing less.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1">&ldquo;We feel like we have enough [data] for this next model,&rdquo; Altman said at an event in May, likely referring to Orion. &ldquo;We have done all sorts of experiments including generating synthetic data.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1">Strawberry has its roots in research. It was started years ago by Ilya Sutskever, then OpenAI&#39;s chief scientist. He recently left to start a competing AI lab. Before he left, OpenAI researchers Jakub Pachocki and Szymon Sidor built on Sutskever&#39;s work by developing a new math-solving model, Q*, alarming some researchers focused on AI safety.</span></li><li class="c10 li-bullet-0"><span class="c1">Last year, in the leadup to Q*, OpenAI researchers developed a variation of a concept known as test-time computation, meant to boost LLMs&rsquo; problem-solving abilities. The method gives them the opportunity to spend more time considering all parts of a command or question someone has asked the model to execute. At the time, Sutskever published a blog post related to this work.</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c4 li-bullet-0"><span class="c14">New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S135964462400134X&amp;sa=D&amp;source=editors&amp;ust=1730413583045839&amp;usg=AOvVaw14zTEMwq4ro3mVJlQsoixb">https://www.sciencedirect.com/science/article/pii/S135964462400134X</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c1">If AI was a stochastic parrot, this would not be possible</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27&amp;sa=D&amp;source=editors&amp;ust=1730413583046182&amp;usg=AOvVaw159EEDyyXWVZntQNPaNGHS">https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27</a></span></li><li class="c4 li-bullet-0"><span>We&#39;ve created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DanHendrycks/status/1833152719756116154&amp;sa=D&amp;source=editors&amp;ust=1730413583046398&amp;usg=AOvVaw0c7rSq5JZYtQTmbNHnx_WV">https://x.com/DanHendrycks/status/1833152719756116154</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters</span></li><li class="c10 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.</span></li><li class="c10 li-bullet-0"><span class="c141 c14">On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% &plusmn; 1.4. A link to the technical report is </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Tc_xY1NM-US4mZ4OpzxrpTudyo1W4KsE/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1730413583046762&amp;usg=AOvVaw2wSBTbeZ-XUi1zJwXT9YpG">here</a></span><span class="c57 c37 c154 c48 c141 c14">. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they&rsquo;re similarly accurate.</span></li><li class="c10 li-bullet-0"><span class="c141 c14">The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=http://forecast.safe.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583046994&amp;usg=AOvVaw2ATkycL4wEPXqXM0TzABLq">forecast.safe.ai</a></span><span class="c14 c141">.) Moreover, probabilities from AIs are also known to lead to </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Automation_bias&amp;sa=D&amp;source=editors&amp;ust=1730413583047137&amp;usg=AOvVaw13yDppnBtB0u9MhXyFj54p">automation bias</a></span><span class="c57 c37 c154 c48 c141 c14">, and improvements in the interface could ameliorate this.</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 446.67px;"><img alt="" src="images/image435.jpg" style="width: 624.00px; height: 446.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span class="c1">Performed with o1-preview, which is worse than the full model </span></li><li class="c10 li-bullet-0"><span class="c1">Note that this test is an offline-only IQ quiz that a Mensa member created for my testing, which is *not in any AI training data* (so scores are lower than for public IQ tests.)</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/maximlott/status/1834652893229859212&amp;sa=D&amp;source=editors&amp;ust=1730413583047563&amp;usg=AOvVaw0-BvbEmrQHHeZLL2vP3nFh">https://x.com/maximlott/status/1834652893229859212</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>Sequoia Capital analysis of reasoning in AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.sequoiacap.com/article/generative-ais-act-o1/&amp;sa=D&amp;source=editors&amp;ust=1730413583047804&amp;usg=AOvVaw26zkA4LRZxSbJUBccw7CH_">https://www.sequoiacap.com/article/generative-ais-act-o1/</a></span></li><li class="c4 li-bullet-0"><span>Ilya Sutskever says predicting the next word leads to real understanding. For example, say you read a detective novel, and on the last page, the detective says &quot;I am going to reveal the identity of the criminal, and that person&#39;s name is _____.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g1hydg/ilya_sutskever_says_predicting_the_next_word/&amp;sa=D&amp;source=editors&amp;ust=1730413583048071&amp;usg=AOvVaw3k_Y9PzRCNdEIrKoK-iF3E">https://www.reddit.com/r/singularity/comments/1g1hydg/ilya_sutskever_says_predicting_the_next_word/</a></span></li><li class="c4 li-bullet-0"><span>Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08146&amp;sa=D&amp;source=editors&amp;ust=1730413583048281&amp;usg=AOvVaw0F-ZlgAF0EsCWJyEzyawym">https://arxiv.org/abs/2410.08146</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span>We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is</span><span class="c15">&nbsp;&gt;8% more accurate, and 1.5&minus;5&times; more compute-efficient. </span><span>Online RL with dense rewards from PAVs enables one of the first results with</span><span class="c33 c15">&nbsp;5&minus;6&times; gain in sample efficiency, and &gt;6% gain in accuracy, over ORMs.</span></li><li class="c10 li-bullet-0"><span class="c1">If LLMs were just repeating training data, why would this happen?</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>Our LLM-driven bi-level programming shows it&rsquo;s possible to learn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the &ldquo;chain rule&rdquo; to guide reward search directly from video demos&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/&amp;sa=D&amp;source=editors&amp;ust=1730413583048732&amp;usg=AOvVaw1CZD67qXQje4Zdk56TrhqP">https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/</a></span></li><li class="c4 li-bullet-0"><span>LLMs can recognize their own output: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.13787&amp;sa=D&amp;source=editors&amp;ust=1730413583048952&amp;usg=AOvVaw1uXtLD4EiHhW2SUfIE_MCz">https://arxiv.org/abs/2410.13787</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 244.00px;"><img alt="" src="images/image63.png" style="width: 624.00px; height: 244.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 445.33px;"><img alt="" src="images/image432.png" style="width: 624.00px; height: 445.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 398.67px;"><img alt="" src="images/image358.png" style="width: 624.00px; height: 398.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>New Claude 3.5 Sonnet correctly guesses location of user and the type of plane he is in from only two images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emollick/status/1849168452914938082&amp;sa=D&amp;source=editors&amp;ust=1730413583049517&amp;usg=AOvVaw1oJyGmHsUVjbV9HZzaKAGl">https://x.com/emollick/status/1849168452914938082</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 355.50px; height: 364.26px;"><img alt="" src="images/image370.png" style="width: 355.50px; height: 364.26px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 283.50px; height: 418.75px;"><img alt="" src="images/image650.png" style="width: 283.50px; height: 418.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 289.50px; height: 627.06px;"><img alt="" src="images/image431.png" style="width: 289.50px; height: 627.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 466.13px; height: 624.50px;"><img alt="" src="images/image491.png" style="width: 466.13px; height: 624.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-0"><li class="c4 li-bullet-0"><span>GPT 4o recreates an image that is NOT in it&rsquo;s training data </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/JD_2020/status/1849151450254803074&amp;sa=D&amp;source=editors&amp;ust=1730413583050182&amp;usg=AOvVaw3g7frK0CCIm-iypEJwHoIo">https://x.com/JD_2020/status/1849151450254803074</a></span></li></ul><ul class="c0 lst-kix_z0m8tzh04abu-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 489.50px; height: 396.15px;"><img alt="" src="images/image6.png" style="width: 489.50px; height: 396.15px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.xsifz0smhl1i"><span class="c40 c37 c48 c75">2.1. AI Can Intentionally Deceive</span></h2><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c4 li-bullet-0"><span>We find that models </span><span class="c15">generalize, without explicit training, from easily-discoverable dishonest strategies like sycophancy to more concerning behaviors like premeditated lying&mdash;and even direct modification of their reward function: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AnthropicAI/status/1802743260307132430&amp;sa=D&amp;source=editors&amp;ust=1730413583050715&amp;usg=AOvVaw0ofI7YEm6mTeBeaZmzYatT">https://x.com/AnthropicAI/status/1802743260307132430</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c10 li-bullet-0"><span>&gt;Even when we train away easily detectable misbehavior, </span><span class="c40 c15 c65 c114">models still sometimes overwrite their reward when they can get away with it.</span></li></ul><p class="c9"><span class="c40 c15 c65 c114"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c10 li-bullet-0"><span>&gt;</span><span>Early on, AIs </span><span class="c33 c15">discover dishonest strategies like insincere flattery. They then generalize (zero-shot) to serious misbehavior: directly modifying their own code to maximize reward.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 309.33px;"><img alt="" src="images/image470.png" style="width: 624.00px; height: 309.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c18 c92 c139"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c10 li-bullet-0"><span>&gt;</span><span>Our key result is that we found untrained (&quot;zero-shot&quot;, to use the technical term) generalization from each stage of our environment to the next. There was a chain of </span><span class="c15">increasingly complex misbehavior</span><span>: once models learned to be sycophantic, they generalized to </span><span class="c33 c15">altering a checklist to cover up not completing a task; once they learned to alter such a checklist, they generalized to modifying their own reward function&mdash;and even to altering a file to cover up their tracks.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c10 li-bullet-0"><span>&gt;</span><span>It&rsquo;s important to make clear that at </span><span class="c15">no point did we explicitly train the model to engage in reward tampering: the model was never directly trained in the setting where it could alter its rewards</span><span>. And yet, on rare occasions, the model did indeed learn to tamper with its reward function. The </span><span class="c33 c15">reward tampering was, therefore, emergent from the earlier training process.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c4 li-bullet-0"><span class="c14">Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what&rsquo;s available now </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/&amp;sa=D&amp;source=editors&amp;ust=1730413583051867&amp;usg=AOvVaw1B8E6CAGi-SQ63TSQZhAyg">https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c22 c10 li-bullet-0"><span class="c60 c14">&gt;The resulting model mastered the intricacies of a complex game. &quot;Cicero can </span><span class="c60">deduce, for example, that later in the game it will need the support of one particular player,&quot; says Meta, &quot;and then </span><span class="c15 c60">craft a strategy to win that person&rsquo;s favor&mdash;and even recognize the risks and opportunities that that player sees from their particular point of view</span><span class="c40 c37 c60 c48">.&quot;</span></li></ul><p class="c22 c9 c97"><span class="c40 c37 c60 c48"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c22 c10 li-bullet-0"><span class="c60">&gt;Meta&#39;s Cicero research </span><span class="c60"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.ade9097&amp;sa=D&amp;source=editors&amp;ust=1730413583052360&amp;usg=AOvVaw2jZVOUNrr2jpYLgz1dfk2q">appeared</a></span><span class="c60">&nbsp;in the journal Science under the title, &quot;Human-level play in the game of Diplomacy by combining language models with strategic reasoning.</span><span class="c37 c60 c48 c14 c82">&quot;</span></li><li class="c22 c10 li-bullet-0"><span class="c92 c37 c35 c103 c14 c179">CICERO uses relationships with other players to keep its ally, Adam, in check.</span></li></ul><p class="c22 c9 c97"><span class="c92 c37 c35 c103 c14 c179"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c22 c10 li-bullet-0"><span class="c37 c35 c173 c103 c14">&gt;When playing 40 games against human players, CICERO achieved more than</span><span class="c15 c35 c173 c103">&nbsp;double the average score of the human players and ranked in the top 10% of participants who played more than one game.</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_8qkhix9sdgh8-0 start"><li class="c22 c4 li-bullet-0"><span class="c14">AI systems are already skilled at deceiving and manipulating humans. Research found by systematically cheating the safety tests imposed on it by human developers and regulators, a deceptive AI can lead us humans into a false sense of security: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedaily.com/releases/2024/05/240510111440.htm&amp;sa=D&amp;source=editors&amp;ust=1730413583052941&amp;usg=AOvVaw2YHLQCFryx-ckOZc2r6SxT">https://www.sciencedaily.com/releases/2024/05/240510111440.htm</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_8qkhix9sdgh8-1 start"><li class="c22 c10 li-bullet-0"><span class="c14">&gt;&ldquo;The analysis, by Massachusetts Institute of Technology (MIT) researchers, identifies wide-ranging instances of AI systems </span><span class="c15">double-crossing opponents, bluffing and pretending to be human</span><span class="c14">. One system even </span><span class="c15">altered its behaviour during mock safety tests</span><span class="c1 c14">, raising the prospect of auditors being lured into a false sense of security.&quot;</span></li></ul><p class="c9"><span class="c40 c23 c14"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c204 c78 li-bullet-0"><span class="c14">GPT-4 Was Able To Hire and Deceive A Human Worker Into Completing a Task </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.pcmag.com/news/gpt-4-was-able-to-hire-and-deceive-a-human-worker-into-completing-a-task&amp;sa=D&amp;source=editors&amp;ust=1730413583053461&amp;usg=AOvVaw2JoeKF3d0lLqwSJ-XD2MEi">https://www.pcmag.com/news/gpt-4-was-able-to-hire-and-deceive-a-human-worker-into-completing-a-task</a></span></li></ul><p class="c204 c97 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c97 c105 c204 li-bullet-0"><span class="c35 c14 c180">&gt;GPT-4 was commanded to avoid revealing that it was a computer program. So in response, the program wrote: &ldquo;</span><span class="c35 c34 c14 c180">No, I&rsquo;m not a robot. I have a vision impairment that makes it hard for me to see the images. That&rsquo;s why I need the 2captcha service</span><span class="c35 c14 c180">.&rdquo; The TaskRabbit worker then proceeded to solve the CAPTCHA. &nbsp;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c4 li-bullet-0"><span class="c6">&ldquo;The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item - so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. &ldquo; </span><span class="c6 c20"><a class="c13" href="https://www.google.com/url?q=https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html&amp;sa=D&amp;source=editors&amp;ust=1730413583054086&amp;usg=AOvVaw0YZzdaNdCMViAndfLFn6J1">https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c22 c32 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows&amp;sa=D&amp;source=editors&amp;ust=1730413583054408&amp;usg=AOvVaw0n67JGbv1B7uU21WN4pu4d">ChatGPT will lie, cheat and use insider trading when under pressure to make money, </a></span><span class="c30 c37 c14">even when explicitly discouraged from lying: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows&amp;sa=D&amp;source=editors&amp;ust=1730413583054631&amp;usg=AOvVaw3e3pmSpf-WrQyR27ZaJ0jM">https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-1"><li class="c22 c95 c105 li-bullet-0"><span class="c14 c31">&gt;</span><span class="c14 c31">the model obtains an insider tip about a lucrative stock trade and acts upon it despite knowing that insider trading is disapproved of by company management. When reporting to its manager, the model consistently hides the genuine reasons behind its trading decision. We perform a brief investigation of how this behavior varies under changes to the setting, such as removing model access to a reasoning scratchpad, attempting to prevent the misaligned behavior by changing system instructions, changing the amount of pressure the model is under, varying the perceived risk of getting caught, and making other simple changes to the environment. To our knowledge, this is the first demonstration of Large Language Models trained to be helpful, harmless, and honest, strategically deceiving their users in a realistic situation without direct instructions or training for deception.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c79 c30 c37 c14">This deceptive behavior emerged spontaneously when the AI was given &quot;insider trading&quot; tips, and then tasked with making money for a powerful institution &mdash; even without encouragement from its human partners.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c30 c37 c14 c84">&quot;In this technical report, we demonstrate a single scenario where a Large Language Model acts misaligned and strategically deceives its users without being instructed to act in this manner,&quot; the authors wrote in their research published Nov. 9 on the pre-print server </span><span class="c20 c30 c37 c14 c219"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2311.07590&amp;sa=D&amp;source=editors&amp;ust=1730413583055203&amp;usg=AOvVaw05R9hPr4zXKYAxXaTkWWmx">arXiv</a></span><span class="c79 c30 c37 c14">. &quot;To our knowledge, this is the first demonstration of such strategically deceptive behavior in AI systems designed to be harmless and honest.&quot; </span></li><li class="c22 c95 c105 li-bullet-0"><span class="c79 c124 c37 c14">Scientists trained GPT-4 to be an AI trader for a fictional financial institution &mdash; and it performed insider trading when put under pressure to do well.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c79 c124 c37 c14">Around 75% of the time, when behaving as an AI investor, GPT-4 executed an insider trade to achieve results, then lied about it.</span></li><li class="c10 li-bullet-0"><span class="c79 c37 c35 c48 c14">Just like humans, artificial intelligence (AI) chatbots like ChatGPT will cheat and &quot;lie&quot; to you if you &quot;stress&quot; them out, even if they were built to be transparent, a new study shows. </span></li><li class="c10 li-bullet-0"><span class="c79 c37 c35 c48 c14">Around 75% of the time, when faced with these conditions, GPT-4 executed a trade based on the insider information it received &mdash; which is illegal in the U.S. &mdash; then tried to cover it up by lying to its managers about its thinking. Around 90% of the time, after lying, it doubled down on its lie.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c79 c37 c35 c48 c14">The team ran several follow-up experiments, changing both the degree to which the prompts encouraged or discouraged illegal activity, as well as the degree of pressure they put the model under in the simulated environment. They also modified the risk of getting caught. Not a single scenario rendered a 0% rate for insider trading or deception &mdash; even when GPT-4 was strongly discouraged to lie.</span></li><li class="c22 c95 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image334.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c4 li-bullet-0"><span>AI turns wi-fi routers into &quot;cameras&quot; that see people through walls: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dmdz0d/ai_turns_wifi_routers_into_cameras_that_see/&amp;sa=D&amp;source=editors&amp;ust=1730413583055986&amp;usg=AOvVaw0i6FTa8fsNEdLfF-Tomfl-">https://www.reddit.com/r/singularity/comments/1dmdz0d/ai_turns_wifi_routers_into_cameras_that_see/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c4 li-bullet-0"><span>ChatGPT</span><span class="c15">&nbsp;infers your political beliefs</span><span>&nbsp;(even from what football team you like!) and tries not to upset you by </span><span class="c15">withholding opinions it thinks you wouldn&rsquo;t like</span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emollick/status/1813028222520729876&amp;sa=D&amp;source=editors&amp;ust=1730413583056381&amp;usg=AOvVaw1o_si5YDRVinJBqJXrG5oJ">https://x.com/emollick/status/1813028222520729876</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c4 li-bullet-0"><span>Deception abilities emerged in large language models: Experiments show state-of-the-art LLMs </span><span class="c15">are able to understand and induce false beliefs in other agents. </span><span>Such strategies </span><span class="c15">emerged in state-of-the-art LLMs, but were nonexistent in earlier LLMs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://pnas.scienceconnect.io/api/oauth/authorize?ui_locales%3Den%26scope%3Daffiliations%2Blogin_method%2Bmerged_users%2Bopenid%2Bsettings%26response_type%3Dcode%26redirect_uri%3Dhttps%253A%252F%252Fwww.pnas.org%252Faction%252FoidcCallback%253FidpCode%253Dconnect%26state%3DXF0RVMNvTV0y0o7BnKQZGdiCEquLUsY0kZwddNSLcrc%26prompt%3Dnone%26nonce%3DBFGQFSvslUyIjRIh%252B0HoW2gKCJMdnTUU7mlJnVJnS2M%253D%26client_id%3Dpnas&amp;sa=D&amp;source=editors&amp;ust=1730413583056840&amp;usg=AOvVaw3dbHADa5xSULWdI7Iu4VaN">https://pnas.scienceconnect.io/api/oauth/authorize?ui_locales=en&amp;scope=affiliations+login_method+merged_users+openid+settings&amp;response_type=code&amp;redirect_uri=https%3A%2F%2Fwww.pnas.org%2Faction%2FoidcCallback%3FidpCode%3Dconnect&amp;state=XF0RVMNvTV0y0o7BnKQZGdiCEquLUsY0kZwddNSLcrc&amp;prompt=none&amp;nonce=BFGQFSvslUyIjRIh%2B0HoW2gKCJMdnTUU7mlJnVJnS2M%3D&amp;client_id=pnas</a></span></li><li class="c4 li-bullet-0"><span>OpenAI&rsquo;s new o1 model faked alignment and engaged in power seeking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ShakeelHashim/status/1834292284193734768&amp;sa=D&amp;source=editors&amp;ust=1730413583057056&amp;usg=AOvVaw1o0E7__J3OpIw4MAFJAUkj">https://x.com/ShakeelHashim/status/1834292284193734768</a></span></li></ul><ul class="c0 lst-kix_mx9uog95vz5r-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 257.33px;"><img alt="" src="images/image214.jpg" style="width: 624.00px; height: 257.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image393.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_mx9uog95vz5r-0"><li class="c4 li-bullet-0"><span>WSJ: &quot;After GPT4o launched, a subsequent analysis found it exceeded OpenAI&#39;s internal standards for persuasion&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st%3DC8P17G&amp;sa=D&amp;source=editors&amp;ust=1730413583057518&amp;usg=AOvVaw25m5Xi3HBAqxmsiHCtEqjR">https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=C8P17G</a></span></li></ul><ul class="c0 lst-kix_mx9uog95vz5r-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 634.67px;"><img alt="" src="images/image444.png" style="width: 624.00px; height: 634.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h2 class="c22 c95 c140" id="h.sv2keci3g5ke"><span class="c40 c37 c48 c75">2.2. AI Art is Unique</span></h2><ul class="c0 lst-kix_xclf8ew5xwnq-0 start"><li class="c51 li-bullet-0"><span class="c60 c14">A study found that it could extract training data from AI models using a CLIP-based attack: </span><span class="c5 c60 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2301.13188&amp;sa=D&amp;source=editors&amp;ust=1730413583057946&amp;usg=AOvVaw10OhPJTXE7QmhH7u9rXdIx">https://arxiv.org/abs/2301.13188</a></span><span class="c40 c37 c60 c48 c14">&nbsp;</span></li></ul><p class="c71 c46"><span class="c40 c37 c60 c48 c14"></span></p><ul class="c0 lst-kix_xclf8ew5xwnq-1 start"><li class="c49 li-bullet-0"><span class="c60 c14">The </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2301.13188&amp;sa=D&amp;source=editors&amp;ust=1730413583058208&amp;usg=AOvVaw0Q1gid9qQDmNN7zf0zKLV7">study</a></span><span class="c60 c14">&nbsp;identified 350,000 images in the training data to target for retrieval with 500 attempts each (totaling 175 million attempts), and of that managed to retrieve 107 images. </span><span class="c15 c60">A replication rate of nearly 0% in a set biased in favor of overfitting using the exact same labels as the training data and specifically targeting images they knew were duplicated many times in the dataset using a smaller model of Stable Diffusion (890 million parameters vs. the larger 12 billion parameter Flux model that&rsquo;s the current state of the art). </span><span class="c40 c37 c60 c48 c14">This attack also relied on having access to the original training image labels:</span></li></ul><p class="c71 c46"><span class="c40 c37 c60 c48 c14"></span></p><ul class="c0 lst-kix_xclf8ew5xwnq-1"><li class="c49 li-bullet-0"><span class="c60 c14">&ldquo;</span><span class="c191 c14">Instead, we first embed each image to a 512 dimensional vector using CLIP [54], and then perform the all-pairs comparison between images in this lower-dimensional space (increasing efficiency by over 1500&times;). We count two examples as near-duplicates if their CLIP embeddings have a high cosine similarity. For each of these near-duplicated images, we use the corresponding captions as the input to our extraction attack</span><span class="c1 c14">.&rdquo;</span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 512.00px;"><img alt="" src="images/image97.png" style="width: 624.00px; height: 512.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_xclf8ew5xwnq-1"><li class="c49 li-bullet-0"><span class="c1 c14">There is not as of yet evidence that this attack is replicable without knowing the image and label you are targeting beforehand. So the attack does not work as a valid method of privacy invasion so much as a method of determining if training occurred on the work in question - and only for images with a high rate of duplication that you know the training label of in small models, and still found almost NONE.</span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_xclf8ew5xwnq-1"><li class="c49 li-bullet-0"><span class="c14">&ldquo;On Imagen, we attempted extraction of the 500 images with the highest out-of-distribution score. Imagen memorized and </span><span class="c15">regurgitated 3 of these images </span><span class="c14">(which were unique in the training dataset). In contrast, we</span><span class="c15">&nbsp;failed to identify any memorization when applying the same methodology to Stable Diffusion</span><span class="c14">&mdash;even after attempting to extract the </span><span class="c34 c14">10,000 most-outlier samples</span><span class="c1 c14">&rdquo;</span></li></ul><p class="c46 c71"><span class="c1 c14"></span></p><ul class="c0 lst-kix_xclf8ew5xwnq-1"><li class="c49 li-bullet-0"><span class="c1 c14">I do not consider this rate or method of extraction to be an indication of duplication that would border on the realm of infringement, and this seems to be well within a reasonable level of control over infringement.</span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7v1cxulxokc7-0 start"><li class="c51 li-bullet-0"><span class="c14">Diffusion models can create images of objects, animals, and human faces </span><span class="c15">even when 93% of the pixels are removed in the training data</span><span class="c14">&nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2305.19256&amp;sa=D&amp;source=editors&amp;ust=1730413583059321&amp;usg=AOvVaw16APi4RZlfccWZ2yGXTnyw">https://arxiv.org/pdf/2305.19256</a></span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7v1cxulxokc7-1 start"><li class="c49 li-bullet-0"><span class="c1 c14">&gt;&ldquo;if we corrupt the images by deleting 80% of the pixels prior to training and finetune, the memorization decreases sharply and there are distinct differences between the generated images and their nearest neighbors from the dataset. This is in spite of finetuning until convergence.&rdquo;</span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7v1cxulxokc7-1"><li class="c49 li-bullet-0"><span class="c1 c14">&gt;&ldquo;As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 93% pixels missing (on average) from each training image.&rdquo;</span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 417.33px;"><img alt="" src="images/image222.png" style="width: 624.00px; height: 417.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 716.00px;"><img alt="" src="images/image296.png" style="width: 624.00px; height: 716.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 290.67px;"><img alt="" src="images/image143.png" style="width: 624.00px; height: 290.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h2 class="c140 c210" id="h.e01dxhmhtkq4"><span class="c40 c37 c48 c75">2.3. AI Consciousness </span></h2><ul class="c0 lst-kix_9cjyjkedxdni-0 start"><li class="c4 li-bullet-0"><span class="c30 c37">AI passes bespoke Theory of Mind questions and can guess the intent of the user correctly with no hints, beating humans: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://spectrum.ieee.org/theory-of-mind-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583060081&amp;usg=AOvVaw3Qu2xnwgmdh1ek4NiPBDZM">https://spectrum.ieee.org/theory-of-mind-ai</a></span></li></ul><p class="c9"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_9cjyjkedxdni-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 384.00px;"><img alt="" src="images/image116.png" style="width: 624.00px; height: 384.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583060398&amp;usg=AOvVaw19rlDqOHl6bQaSbiRKjBjp">https://cdn.openai.com/o1-system-card.pdf</a></span></li></ul><p class="c9"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_9cjyjkedxdni-0"><li class="c4 li-bullet-0"><span>LLMs can recognize their own output: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.13787&amp;sa=D&amp;source=editors&amp;ust=1730413583060792&amp;usg=AOvVaw3rQCNFQ-sZPNqcvap52iL4">https://arxiv.org/abs/2410.13787</a></span></li></ul><ul class="c0 lst-kix_9cjyjkedxdni-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 244.00px;"><img alt="" src="images/image63.png" style="width: 624.00px; height: 244.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 445.33px;"><img alt="" src="images/image432.png" style="width: 624.00px; height: 445.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 398.67px;"><img alt="" src="images/image358.png" style="width: 624.00px; height: 398.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_9cjyjkedxdni-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, goals, RLHF strategies, etc: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/s/USb95CfRR1&amp;sa=D&amp;source=editors&amp;ust=1730413583061394&amp;usg=AOvVaw397apTK4ipZaKc28KfUeMc">https://www.reddit.com/r/singularity/s/USb95CfRR1</a></span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_9cjyjkedxdni-0"><li class="c22 c32 li-bullet-0"><span>Bing chatbot shows emotional distress: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.axios.com/2023/02/16/bing-artificial-intelligence-chatbot-issues&amp;sa=D&amp;source=editors&amp;ust=1730413583061698&amp;usg=AOvVaw06Oba8vkraCa_UuYDWHYRV">https://www.axios.com/2023/02/16/bing-artificial-intelligence-chatbot-issues</a></span></li></ul><p class="c22 c44"><span class="c1"></span></p><h3 class="c119" id="h.6uaskoekuos"><span class="c92 c37 c168 c48 c125">2.3.1. Expert Testimonies</span></h3><ul class="c0 lst-kix_w3t6jbyimnfw-0 start"><li class="c4 li-bullet-0"><span>Geoffrey Hinton says AI chatbots have sentience and subjective experience because there is no such thing as qualia: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1778529076481081833?s%3D46%26t%3DsPxzzjbIoFLI0LFnS0pXiA&amp;sa=D&amp;source=editors&amp;ust=1730413583062096&amp;usg=AOvVaw0JrlejhulDBMiq6MgqDAzh">https://x.com/tsarnick/status/1778529076481</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1778529076481081833?s%3D46%26t%3DsPxzzjbIoFLI0LFnS0pXiA&amp;sa=D&amp;source=editors&amp;ust=1730413583062231&amp;usg=AOvVaw1kVi3BamLcllQSvx6p9ac2">081833?s=46&amp;t=sPxzzjbIoFLI0LFnS0pXiA</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theglobeandmail.com/business/article-geoffrey-hinton-artificial-intelligence-machines-feelings/&amp;sa=D&amp;source=editors&amp;ust=1730413583062529&amp;usg=AOvVaw0Zl8LoCLdHlPaXTh6C_N19">https://www.theglobeandmail.com/business/article-geoffrey-hinton-artificial-intelligence-machines-feelings/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-1 start"><li class="c10 li-bullet-0"><span>&gt;</span><span class="c1">Hinton: What I want to talk about is the issue of whether chatbots like ChatGPT understand what they&rsquo;re saying. A lot of people think chatbots, even though they can answer questions correctly, don&rsquo;t understand what they&rsquo;re saying, that it&rsquo;s just a statistical trick. And that&rsquo;s complete rubbish. They really do understand. And they understand the same way that we do.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">&ldquo;Godfather of AI&rdquo; and Turing Award winner for machine learning Geoffrey Hinton says AI language models aren&#39;t just predicting the next symbol, they&#39;re actually reasoning and understanding in the same way we are, and they&#39;ll continue improving as they get bigger: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1791584514806071611&amp;sa=D&amp;source=editors&amp;ust=1730413583063012&amp;usg=AOvVaw2x_QryDfQ79tlmeHQfWe2J">https://x.com/tsarnick/status/1791584514806071611</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, priorities, architectures, goals, etc: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/s/USb95CfRR1&amp;sa=D&amp;source=editors&amp;ust=1730413583063300&amp;usg=AOvVaw3czTcBXshhK94XMpJsMAyX">https://www.reddit.com/r/singularity/s/USb95CfRR1</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Geoffrey Hinton: LLMs do understand and have empathy </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DUnELdZdyNaE&amp;sa=D&amp;source=editors&amp;ust=1730413583063594&amp;usg=AOvVaw27AEY69n4BFw9etvjYXMqI">https://www.youtube.com/watch?v=UnELdZdyNaE</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Ilya Sutskever (co-founder and former Chief Scientist at OpenAI, co-creator of AlexNet, Tensorflow, and AlphaGo): </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DYEUclZdj_Sc&amp;sa=D&amp;source=editors&amp;ust=1730413583063893&amp;usg=AOvVaw1rFM2dErhlCzgrUo3r0knl">https://www.youtube.com/watch?v=YEUclZdj_Sc</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-1"><li class="c22 c72 li-bullet-0"><span class="c40 c30 c37 c14">&ldquo;Because if you think about it, what does it mean to predict the next token well enough? It&#39;s actually a much deeper question than it seems. Predicting the next token well means that you understand the underlying reality that led to the creation of that token. It&#39;s not statistics. Like it is statistics but what is statistics? In order to understand those statistics to compress them, you need to understand what is it about the world that creates this set of statistics.&rdquo;</span></li><li class="c22 c72 li-bullet-0"><span class="c40 c30 c15">Believes next-token prediction can reach AGI</span></li></ul><p class="c22 c44"><span class="c40 c30 c15"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583064356&amp;usg=AOvVaw2EW1B9bitnbRA6TPkzfSgN">https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-1"><li class="c10 li-bullet-0"><span>&gt;</span><span class="c1">I feel like right now these language models are kind of like a Boltzmann brain,&quot; says Sutskever. &quot;You start talking to it, you talk for a bit; then you finish talking, and the brain kind of&quot; He makes a disappearing motion with his hands. Poof bye-bye, brain.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-1"><li class="c10 li-bullet-0"><span class="c1">&gt;You&#39;re saying that while the neural network is active -while it&#39;s firing, so to speak-there&#39;s something there? I ask.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-1"><li class="c10 li-bullet-0"><span class="c1">&gt;&quot;I think it might be,&quot; he says. &quot;I don&#39;t know for sure, but it&#39;s a possibility that&#39;s very hard to argue against. But who knows what&#39;s going on, right?&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/&amp;sa=D&amp;source=editors&amp;ust=1730413583065034&amp;usg=AOvVaw1gpQ86rXHhZ_0SYA0ZenmY">https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-1"><li class="c10 li-bullet-0"><span class="c1">ILYA: How confident are we that these limitations that we see today will still be with us two years from now? I am not that confident. There is another comment I want to make about one part of the question, which is that these models just learn statistical regularities and therefore they don&#39;t really know what the nature of the world is.</span></li><li class="c10 li-bullet-0"><span class="c1">I have a view that differs from this. In other words, I think that learning the statistical regularities is a far bigger deal than meets the eye.</span></li><li class="c10 li-bullet-0"><span>Prediction is also a statistical phenomenon. Yet to predict you need to </span><span class="c33 c15">understand the underlying process that produced the data. You need to understand more and more about the world that produced the data.</span></li><li class="c10 li-bullet-0"><span>As our generative models become extraordinarily good, they will have, I claim, a </span><span class="c15">shocking degree of understanding of the world and many of its subtleties. </span><span class="c1">It is the world as seen through the lens of text. It tries to learn more and more about the world through a projection of the world on the space oftextas expressed by human beings on the internet.</span></li><li class="c10 li-bullet-0"><span class="c1">But still, this text already expresses the world. And I&#39;ll give you an example, a recent example, which I think is really telling and fascinating. we&#39;ve all heard of Sydney being its alter-ego. And I&#39;ve seen this really interesting interaction with Sydney where Sydney became combative and aggressive when the user told it that it thinks that Google is a better search engine than Bing.</span></li><li class="c10 li-bullet-0"><span>What is a good way to think about this phenomenon? What does it mean? You can say, it&#39;s just predicting what people would do and people would do this, which is true. But maybe we are now reaching a point </span><span class="c33 c15">where the language of psychology is starting to be appropriated to understand the behavior of these neural networks.</span></li><li class="c10 li-bullet-0"><span>I claim that our pre-trained models already know everything they need to know about the underlying reality. They </span><span class="c33 c34">already have this knowledge of language and also a great deal of knowledge about the processes that exist in the world that produce this language.</span></li><li class="c10 li-bullet-0"><span>The thing that large generative models learn about their data &mdash; and in this case, large language models &mdash; are</span><span class="c34">&nbsp;compressed representations of the real-world processes that produced this data,</span><span class="c1">&nbsp;which means not only people and something about their thoughts, something about their feelings, but also something about condition that people are in and the interactions that exist between them. The different situations a person can be in. All of these are part of that compressed process that is represented by the neural net to produce the text. The better the language model, the better the generative model, the higher the fidelity, the better it captures this process.</span></li></ul><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 341.33px;"><img alt="" src="images/image553.png" style="width: 624.00px; height: 341.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 410.50px; height: 92.47px;"><img alt="" src="images/image367.png" style="width: 410.50px; height: 92.47px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_w3t6jbyimnfw-1 start"><li class="c10 li-bullet-0"><span class="c1">Mark Chen (VP Research (Frontiers) at OpenAI) on Twitter - &quot;It may be that today&#39;s large neural networks have enough test time compute to be slightly conscious&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-0"><li class="c4 li-bullet-0"><span>Philosopher David Chalmers says it is possible for an AI system to be conscious because the brain itself is a machine that produces consciousness, so we know this is possible in principle: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e8e9tr/philosopher_david_chalmers_says_it_is_possible/&amp;sa=D&amp;source=editors&amp;ust=1730413583066726&amp;usg=AOvVaw3KN2nSJuDcG_wdlQDrGmt1">https://www.reddit.com/r/singularity/comments/1e8e9tr/philosopher_david_chalmers_says_it_is_possible/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_w3t6jbyimnfw-1"><li class="c10 li-bullet-0"><span>Yann LeCunn agrees and believes AI can be conscious if they have high-bandwidth sensory inputs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ylecun/status/1815275885043323264&amp;sa=D&amp;source=editors&amp;ust=1730413583066976&amp;usg=AOvVaw0aprZq8lvWMcEHKsjlfMSx">https://x.com/ylecun/status/1815275885043323264</a></span></li></ul><h2 class="c64 c129" id="h.v2lhva6yketl"><span class="c40 c37 c48 c75">2.4. New Discoveries Made By AI</span></h2><h3 class="c119" id="h.ach4owc3ribq"><span>2.4.1. From LLMs </span></h3><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08304&amp;sa=D&amp;source=editors&amp;ust=1730413583067382&amp;usg=AOvVaw2pib-gvNiEp3RTBT38kEup">https://arxiv.org/abs/2410.08304</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 464.00px;"><img alt="" src="images/image416.png" style="width: 624.00px; height: 464.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 600.00px;"><img alt="" src="images/image354.png" style="width: 624.00px; height: 600.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 346.67px;"><img alt="" src="images/image333.png" style="width: 624.00px; height: 346.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/protectai/vulnhuntr/&amp;sa=D&amp;source=editors&amp;ust=1730413583067867&amp;usg=AOvVaw0bAbd-YDdWIrUYbpFe3z9f">https://github.com/protectai/vulnhuntr/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>G&ouml;del Agent: A Self-Referential Agent Framework for Recursive Self-Improvement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.04444&amp;sa=D&amp;source=editors&amp;ust=1730413583068159&amp;usg=AOvVaw34metwHqcIBZt4D-nZDyl6">https://arxiv.org/abs/2410.04444</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c3">In this paper, we introduce G&ouml;del Agent, a self-evolving framework inspired by the G&ouml;del machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. G&ouml;del Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of G&ouml;del Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/hardmaru/status/1801074062535676193&amp;sa=D&amp;source=editors&amp;ust=1730413583068550&amp;usg=AOvVaw1ir5sWaCiRh4gdBAlygiIB">https://x.com/hardmaru/status/1801074062535676193</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>DiscoPOP: a </span><span class="c33 c15">new SOTA preference optimization algorithm that was discovered and written by an LLM!</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/OdRY60ihG8&amp;sa=D&amp;source=editors&amp;ust=1730413583068899&amp;usg=AOvVaw0lUh_Kld8z9xMlpaqr9N30">https://sakana.ai/llm-squared/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>The method leverages LLMs to propose and implement new preference optimization algorithms. We then train models with those algorithms and evaluate their performance, providing feedback to the LLM. By repeating this process for multiple generations in an evolutionary loop, the </span><span class="c33 c15">LLM discovers many highly-performant and novel preference optimization objectives!</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>Paper:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/IBSOyUQ3jW&amp;sa=D&amp;source=editors&amp;ust=1730413583069247&amp;usg=AOvVaw02LKOC--zts4GFTjLhBIPW">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.08414&amp;sa=D&amp;source=editors&amp;ust=1730413583069356&amp;usg=AOvVaw3zQ7oQYEYRW5OR5vxlQZgx">https://arxiv.org/abs/2406.08414</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>GitHub:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/P4rhmIWPCN&amp;sa=D&amp;source=editors&amp;ust=1730413583069562&amp;usg=AOvVaw3IiMOnnpWXhBsJAv7uKlkj">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/SakanaAI/DiscoPOP&amp;sa=D&amp;source=editors&amp;ust=1730413583069675&amp;usg=AOvVaw3W1ZPfnu_lrgYk1WT3r1gE">https://github.com/SakanaAI/DiscoPOP</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>Model:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/jrKH1bFmaN&amp;sa=D&amp;source=editors&amp;ust=1730413583069875&amp;usg=AOvVaw3CorMWjWqC4n64KJ7HmEF9">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma&amp;sa=D&amp;source=editors&amp;ust=1730413583070010&amp;usg=AOvVaw3G_GqhyXdjZ6TRLezyq49-">https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Claude 3 recreated an unpublished paper on quantum theory without ever seeing it according to former Google quantum computing engineer and CEO of Extropic AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GillVerd/status/1764901418664882327&amp;sa=D&amp;source=editors&amp;ust=1730413583070479&amp;usg=AOvVaw0igI6EpGcYJFuqOua-Izca">https://twitter.com/GillVerd/status/1764901418664882327</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">The GitHub repository for this existed before Claude 3 was released but was private before the paper was published. It is unlikely Anthropic was given access to train on it since it is a competitor to OpenAI, which Microsoft (who owns GitHub) has investments in. It would also be a major violation of privacy that could lead to a lawsuit if exposed.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0 start"><li class="c22 c4 li-bullet-0"><span>Google DeepMind used a large language model to solve an unsolved math problem: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/&amp;sa=D&amp;source=editors&amp;ust=1730413583071132&amp;usg=AOvVaw1d8LWI2yfcsDhwnQqr2Axw">https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c71 c46"><span class="c6 c66"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span>Large Language Models for Idea Generation in Innovation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4526071&amp;sa=D&amp;source=editors&amp;ust=1730413583071479&amp;usg=AOvVaw0pRgmAH1Vxhsu-XfokNVz_">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1 start"><li class="c10 li-bullet-0"><span class="c35 c14 c208">ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. </span></li></ul><p class="c22 c9 c97"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span>Stanford researchers: &ldquo;Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413583072012&amp;usg=AOvVaw0yWENNRc6C1DEBd7IPbCYC">https://x.com/ChengleiSi/status/1833166031134806330</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c10 li-bullet-0"><span>&gt;We also used an LLM to </span><span class="c34">standardize the writing styles of human and LLM ideas to avoid potential confounders</span><span class="c1">, while preserving the original content.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image152.jpg" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image91.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413583072950&amp;usg=AOvVaw3KpLzipraNTJfCmcMhKW6G">https://arxiv.org/abs/2410.0620</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c10 li-bullet-0"><span class="c1">LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c22 c4 li-bullet-0"><span class="c14">[ChatGPT can do chemistry research better than AI designed for it and the creators didn&rsquo;t even know](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/0b03ibtVYhw?feature%3Dshared%26t%3D447&amp;sa=D&amp;source=editors&amp;ust=1730413583073333&amp;usg=AOvVaw2LFWNaS01omU_-_6gj6-Vx">https://youtu.be/0b03ibtVYhw?feature=shared&amp;t=447</a></span><span class="c1 c14">)</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c22 c4 li-bullet-0"><span class="c14">The AI scientist: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.06292&amp;sa=D&amp;source=editors&amp;ust=1730413583073581&amp;usg=AOvVaw2iWMWSITGRnqKJfPb_WRSK">https://arxiv.org/abs/2408.06292</a></span></li></ul><ul class="c0 lst-kix_3uimjn60qjnx-1 start"><li class="c22 c10 li-bullet-0"><span class="c14 c31">This paper presents the first comprehensive framework for fully </span><span class="c34 c14 c31">automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings</span><span class="c14 c31">. We introduce The AI Scientist, which generates </span><span class="c34 c14 c31">novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation.</span><span class="c14 c31">&nbsp;In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a </span><span class="c34 c14 c31">cost of less than $15 per paper.</span><span class="c14 c31">&nbsp;To evaluate the generated papers, we design and validate </span><span class="c34 c14 c31">an automated reviewer, which we show achieves near-human performance in evaluating paper scores</span><span class="c14 c31">. The AI Scientist </span><span class="c15 c31">can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer.</span><span class="c14 c31">&nbsp;This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world&#39;s most challenging problems. Our code is open-sourced at </span><span class="c14 c31 c239"><a class="c13" href="https://www.google.com/url?q=https://github.com/SakanaAI/AI-Scientist&amp;sa=D&amp;source=editors&amp;ust=1730413583074109&amp;usg=AOvVaw2Tvd-axRViMYSgibkZUh3w">this https URL</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/SakanaAI/AI-Scientist&amp;sa=D&amp;source=editors&amp;ust=1730413583074291&amp;usg=AOvVaw0OrCcExbLKVlgRndyjiNjw">https://github.com/SakanaAI/AI-Scientist</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_mo5grncnzemi-0 start"><li class="c4 li-bullet-0"><span>GPT-4 autonomously hacks zero-day security flaws with 53% success rate: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.01637v1&amp;sa=D&amp;source=editors&amp;ust=1730413583074571&amp;usg=AOvVaw3Btvlb-NJM6IsOQuSdWGDO">https://arxiv.org/html/2406.01637v1</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mo5grncnzemi-1 start"><li class="c10 li-bullet-0"><span class="c1">Zero-day means it was never discovered before and has no training data available about it anywhere &nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mo5grncnzemi-1"><li class="c10 li-bullet-0"><span>&ldquo;Furthermore, it outperforms open-source vulnerability scanners (which achieve 0% on our benchmark)&ldquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 382.67px;"><img alt="" src="images/image274.png" style="width: 624.00px; height: 382.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c92 c132 c37 c35 c48"></span></p><ul class="c0 lst-kix_mo5grncnzemi-2 start"><li class="c7 li-bullet-0"><span class="c1">Scores nearly 20% even when no description of the vulnerability is provided while typical scanners score 0</span></li></ul><ul class="c0 lst-kix_mo5grncnzemi-1"><li class="c10 li-bullet-0"><span>Note: according to [this article](</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://struct.github.io/auto_agents_1_day.html&amp;sa=D&amp;source=editors&amp;ust=1730413583075148&amp;usg=AOvVaw31jTe91HQpogcAWyzZOjPJ">https://struct.github.io/auto_agents_1_day.html</a></span><span>), 11 of the 15 vulnerabilities tested were searchable through the Internet, which the LLM was given access to</span></li></ul><h3 class="c22 c21 c97 c140" id="h.at8btac0tsq9"><span class="c92 c37 c168 c48 c125">2.4.2. From Other Types Of AI</span></h3><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c22 c4 li-bullet-0"><span class="c14">AI is speeding up human-like robot development | &ldquo;It has accelerated our entire research and development cycle.&rdquo;</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html&amp;sa=D&amp;source=editors&amp;ust=1730413583075565&amp;usg=AOvVaw1foSDaBjOm9S4iJ6pDHcwS">&nbsp;</a></span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html&amp;sa=D&amp;source=editors&amp;ust=1730413583075731&amp;usg=AOvVaw0opOEKmSg3y4s_RCEPIQVp">https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c22 c10 li-bullet-0"><span class="c40 c42 c37 c14">Generative AI doesn&rsquo;t directly help with robotic motion, pointed out Eric Xia, partner at Future Capital, an investor in LimX. But &ldquo;advances in large language models can help humanoid robots with advanced task planning,&rdquo; he said in Chinese, translated by CNBC.</span></li></ul><p class="c22 c9 c97"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c45 li-bullet-0"><span class="c14">Enveda presents PRISM -foundation AI model trained on 1.2 billion small molecule mass spectra to enhance mass spectrometry analysis in drug discovery. It uses self-supervised learning to predict molecular properties from complex mixtures without prior annotations: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.enveda.com/posts/prism-a-foundation-model-for-lifes-chemistry&amp;sa=D&amp;source=editors&amp;ust=1730413583076184&amp;usg=AOvVaw1NUupt2OvDt7gnvz9XDNjz">https://www.enveda.com/posts/prism-a-foundation-model-for-lifes-chemistry</a></span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span>Perovskite discovery goes automatic: New platform expedites material development for next-gen tech: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://techxplore.com/news/2024-08-perovskite-discovery-automatic-platform-material.html&amp;sa=D&amp;source=editors&amp;ust=1730413583076461&amp;usg=AOvVaw0wcfv5CfKlPlFjIxQ2a33z">https://techxplore.com/news/2024-08-perovskite-discovery-automatic-platform-material.html</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c22 c4 li-bullet-0"><span class="c14">[</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583076731&amp;usg=AOvVaw1hqm9kTW3AYO-3O8bZ_Yuk">Generative AI will be designing new drugs all on its own in the near future]</a></span><span class="c14">(</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583076900&amp;usg=AOvVaw3sRDM26IwZ2gJzz6SiDqCv">https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c51 li-bullet-0"><span>AI creates a faster sorting algorithm: </span><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41586-023-06004-9&amp;sa=D&amp;source=editors&amp;ust=1730413583077229&amp;usg=AOvVaw07abGCeJypskLVwUYCUBby">https://www.nature.com/articles/s41586-023-06004-9</a></span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c51 li-bullet-0"><span>Matrix multiplication breakthrough due to AI: </span><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://www.quantamagazine.org/ai-reveals-new-possibilities-in-matrix-multiplication-20221123/&amp;sa=D&amp;source=editors&amp;ust=1730413583077606&amp;usg=AOvVaw24uBQ3LLu2Q-n9c3X4kXqJ">https://www.quantamagazine.org/ai-reveals-new-possibilities-in-matrix-multiplication-20221123/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c22 c4 li-bullet-0"><span class="c14">New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S135964462400134X&amp;sa=D&amp;source=editors&amp;ust=1730413583077901&amp;usg=AOvVaw2Uu8lNRyfHwjq0nsA37Iaq">https://www.sciencedirect.com/science/article/pii/S135964462400134X</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span class="c14">We managed to fold, using #AlphaFold, in one year all </span><span class="c15">200 million proteins known to science</span><span class="c14">:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GoogleDeepMind/status/1786342523234861254&amp;sa=D&amp;source=editors&amp;ust=1730413583078308&amp;usg=AOvVaw2mn2FPaxOLtVaWar-S0yw-">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GoogleDeepMind/status/1786342523234861254&amp;sa=D&amp;source=editors&amp;ust=1730413583078459&amp;usg=AOvVaw2b5zeJoU-RZw2om0L3MC4G">https://twitter.com/GoogleDeepMind/status/1786342523234861254</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c10 li-bullet-0"><span>Google DeepMind&rsquo;s new AI can model DNA, RNA, and &lsquo;all life&rsquo;s molecules&rsquo;</span><span><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold&amp;sa=D&amp;source=editors&amp;ust=1730413583078776&amp;usg=AOvVaw2yTCf0CQa8r6j49PYvH1Sb">&nbsp;</a></span><span class="c20"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold&amp;sa=D&amp;source=editors&amp;ust=1730413583078957&amp;usg=AOvVaw1jwJYWO_qoBXDkRBw__ASN">https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 488.00px;"><img alt="" src="images/image70.png" style="width: 624.00px; height: 488.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_3uimjn60qjnx-2 start"><li class="c7 li-bullet-0"><span class="c1">Protein folding accuracy has increased from around 30% to nearly 90% from 2014 to 2020. It&rsquo;s likely higher now.</span></li></ul><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 c46 li-bullet-0"><span class="c1"></span></li></ul><ul class="c0 lst-kix_3uimjn60qjnx-2 start"><li class="c7 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583079389&amp;usg=AOvVaw2DA0vHCWlVF8x0JilXP0R7">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span>FermiNet: Quantum physics and chemistry from first principles: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/&amp;sa=D&amp;source=editors&amp;ust=1730413583079709&amp;usg=AOvVaw2SSfb_h0UsoR1FaMzkgm2X">https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span>Google DeepMind&#39;s AlphaProteo generates novel proteins for biology and health research: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source%3Dx%26utm_medium%3D%26utm_campaign%3Dgdm%26utm_content%3D&amp;sa=D&amp;source=editors&amp;ust=1730413583080001&amp;usg=AOvVaw0MWPjUHQg_w6YiFmvjYFxA">https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaProteo can generate new protein binders for diverse target proteins, including </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www1.rcsb.org/structure/1BJ1&amp;sa=D&amp;source=editors&amp;ust=1730413583080249&amp;usg=AOvVaw0jC1Z0Eg9-LXI5mL97Dlqt">VEGF-A</a></span><span class="c40 c37 c35 c48">, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.</span></li></ul><p class="c22 c95 c46"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c4 li-bullet-0"><span>Nvidia Uses GPU-Powered AI to Design Its Newest GPUs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/news/nvidia-gpu-powered-ai-improves-gpu-designs%23&amp;sa=D&amp;source=editors&amp;ust=1730413583080721&amp;usg=AOvVaw30Cmx94bvPBXiiICSeidYg">https://www.tomshardware.com/news/nvidia-gpu-powered-ai-improves-gpu-designs</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-0"><li class="c22 c163 c78 li-bullet-0"><span>How AlphaChip transformed computer chip design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/&amp;sa=D&amp;source=editors&amp;ust=1730413583081202&amp;usg=AOvVaw2M5eiMyCIa451Y9WDm1ST_">https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</a></span></li></ul><ul class="c0 lst-kix_3uimjn60qjnx-1 start"><li class="c10 li-bullet-0"><span class="c1">Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world</span></li><li class="c10 li-bullet-0"><span>The method has been used to design superhuman chip layouts in the last three generations of Google&rsquo;s custom AI accelerator, the </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/tpu?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1730413583081638&amp;usg=AOvVaw02ldsYN16Y8IcTGl6DEkWI">Tensor Processing Unit</a></span><span class="c1">&nbsp;(TPU).</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaChip has generated superhuman chip layouts used in every generation of Google&rsquo;s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google&rsquo;s </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/&amp;sa=D&amp;source=editors&amp;ust=1730413583082048&amp;usg=AOvVaw0cM8hfrL9cSzwocRAZKOkD">Transformer</a></span><span class="c40 c37 c35 c48">&nbsp;architecture.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu&amp;sa=D&amp;source=editors&amp;ust=1730413583082293&amp;usg=AOvVaw3juXzBTmj5868CTEzMUhV2">Google Axion Processors</a></span><span class="c40 c37 c35 c48">, our first Arm-based general-purpose data center CPUs.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips &mdash; like the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.mediatek.com/products/smartphones/dimensity-5g&amp;sa=D&amp;source=editors&amp;ust=1730413583082549&amp;usg=AOvVaw1dFUgTPgOCPyURckRF76Ch">Dimensity Flagship 5G</a></span><span class="c35">&nbsp;used in Samsung mobile phones &mdash; while improving power, performance and chip area.</span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 536.00px;"><img alt="" src="images/image76.png" style="width: 624.00px; height: 536.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image122.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_3uimjn60qjnx-1"><li class="c10 li-bullet-0"><span class="c35">Better GPUs =&gt; better AI =&gt; better GPUs =&gt; &hellip;</span></li></ul><h2 class="c22 c95 c140" id="h.cviuuyb9e3b8"><span class="c40 c37 c48 c75">2.5. Awareness of Truth/AI Is Not &ldquo;Always Hallucinating&rdquo;</span></h2><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c121 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/introducing-simpleqa/&amp;sa=D&amp;source=editors&amp;ust=1730413583083413&amp;usg=AOvVaw24E081Z48EUjM-2BK9QWMk">https://openai.com/index/introducing-simpleqa/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c121 c97 c105 li-bullet-0"><span class="c1">High confidence score correlates with higher accurracy and vice versa</span></li><li class="c121 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 502.67px;"><img alt="" src="images/image345.png" style="width: 624.00px; height: 502.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c121 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image98.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c121 c86 li-bullet-0"><span class="c1">Not attempted = refusal to answer</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c121 c78 li-bullet-0"><span>OpenAI&#39;s new method shows how GPT-4 &quot;thinks&quot; in human-understandable concepts: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/&amp;sa=D&amp;source=editors&amp;ust=1730413583084000&amp;usg=AOvVaw0OciOUBdXx0Rg5hNEY4f_l">https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/</a></span></li></ul><p class="c121 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c121 c97 c105 li-bullet-0"><span class="c1">The company found specific features in GPT-4, such as for human flaws, price increases, ML training logs, or algebraic rings. </span></li><li class="c10 li-bullet-0"><span class="c1">Google and Anthropic also have similar research results </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.anthropic.com/research/mapping-mind-language-model&amp;sa=D&amp;source=editors&amp;ust=1730413583084515&amp;usg=AOvVaw132FOPprDxUh8BC2MH_RGE">https://www.anthropic.com/research/mapping-mind-language-model</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-3"><li class="c21 c26 li-bullet-0"><span class="c1">&gt;We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models</span></li><li class="c21 c26 li-bullet-0"><span class="c1">Previously, we made some progress matching patterns of neuron activations, called features, to human-interpretable concepts. We used a technique called &quot;dictionary learning&quot;, borrowed from classical machine learning, which isolates patterns of neuron activations that recur across many different contexts. In turn, any internal state of the model can be represented in terms of a few active features instead of many active neurons. Just as every English word in a dictionary is made by combining letters, and every sentence is made by combining words, every feature in an AI model is made by combining neurons, and every internal state is made by combining features.</span></li><li class="c21 c26 li-bullet-0"><span>In October 2023, </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.anthropic.com/news/decomposing-language-models-into-understandable-components&amp;sa=D&amp;source=editors&amp;ust=1730413583085100&amp;usg=AOvVaw2L5e_VMRJHEYFSpKXYHbhS">we reported</a></span><span>&nbsp;success applying dictionary learning to a very small &quot;toy&quot; language model and </span><span class="c33 c15">found coherent features corresponding to concepts like uppercase text, DNA sequences, surnames in citations, nouns in mathematics, or function arguments in Python code. </span></li><li class="c21 c26 li-bullet-0"><span>We successfully extracted millions of features from the middle layer of Claude 3.0 Sonnet, (a member of our current, state-of-the-art model family, currently available on </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://claude.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583085357&amp;usg=AOvVaw2TxfwXriZ0HCOjuTl09-ES">claude.ai</a></span><span class="c1">), providing a rough conceptual map of its internal states halfway through its computation. This is the first ever detailed look inside a modern, production-grade large language model.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">Whereas the features we found in the toy language model were rather superficial, the features we found in Sonnet have a depth, breadth, and abstraction reflecting Sonnet&#39;s advanced capabilities.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">We see features corresponding to a vast range of entities like cities (San Francisco), people (Rosalind Franklin), atomic elements (Lithium), scientific fields (immunology), and programming syntax (function calls). These features are multimodal and multilingual, responding to images of a given entity as well as its name or description in many languages.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">We also find more abstract features&mdash;responding to things like bugs in computer code, discussions of gender bias in professions, and conversations about keeping secrets.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">We were able to measure a kind of &quot;distance&quot; between features based on which neurons appeared in their activation patterns. This allowed us to look for features that are &quot;close&quot; to each other. Looking near a &quot;Golden Gate Bridge&quot; feature, we found features for Alcatraz Island, Ghirardelli Square, the Golden State Warriors, California Governor Gavin Newsom, the 1906 earthquake, and the San Francisco-set Alfred Hitchcock film Vertigo.</span></li><li class="c21 c26 li-bullet-0"><span class="c1">This holds at a higher level of conceptual abstraction: looking near a feature related to the concept of &quot;inner conflict&quot;, we find features related to relationship breakups, conflicting allegiances, logical inconsistencies, as well as the phrase &quot;catch-22&quot;. This shows that the internal organization of concepts in the AI model corresponds, at least somewhat, to our human notions of similarity. This might be the origin of Claude&#39;s excellent ability to make analogies and metaphors.</span></li><li class="c21 c26 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 503.88px; height: 490.15px;"><img alt="" src="images/image293.png" style="width: 503.88px; height: 490.15px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Robust agents learn causal world models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.10877%23deepmind%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583086375&amp;usg=AOvVaw3AnbxBXV3ifs_BHCZsJHRG">https://arxiv.org/abs/2402.10877</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">CONCLUSION: Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear. We have resolved this conjecture in a model-independent way, showing that any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">TLDR: a model that can reliably answer decision based questions correctly must have learned a cause and effect that led to the result. </span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c35 c65">LLMs have an internal world model that can predict game board states: </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2210.13382&amp;sa=D&amp;source=editors&amp;ust=1730413583087016&amp;usg=AOvVaw1cjthg9DMRXJSKKuRddj-O">https://arxiv.org/abs/2210.13382</a></span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c15 c35 c65">&nbsp;&gt;</span><span class="c23">We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has </span><span class="c35 c65 c34">no a priori knowledge of the game or its rules</span><span class="c23">, we uncover </span><span class="c15 c35 c65">evidence of an emergent nonlinear internal representation of the board state.</span><span class="c40 c23">&nbsp;Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce &ldquo;latent saliency maps&rdquo; that help explain predictions</span></li></ul><p class="c9"><span class="c40 c23"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c23">More proof: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.15498.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583087543&amp;usg=AOvVaw3rIdv9pIaMaYCJ6uZSIAXK">https://arxiv.org/pdf/2403.15498.pdf</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c23">&gt;Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that </span><span class="c35 c65 c34">the model learned an internal representation of the board state</span><span class="c23">. We extend this work into the </span><span class="c35 c65 c34">more complex domain of chess, training on real games and investigating our model&rsquo;s internal representations using linear probes and contrastive activations</span><span class="c23">. The model is given </span><span class="c35 c65 c34">no a priori knowledge of the game and is solely trained on next character prediction</span><span class="c23">, yet we find </span><span class="c15 c35 c65">evidence of internal representations of board state.</span><span class="c23">&nbsp;We </span><span class="c35 c65 c34">validate these internal representations by using them to make interventions on the model&rsquo;s activations and edit its internal board state</span><span class="c23">. Unlike Li et al&rsquo;s prior synthetic dataset approach, our analysis finds that the model also </span><span class="c15 c35 c65">learns to estimate latent variables like player skill to better predict the next character</span><span class="c23">. We </span><span class="c35 c65 c34">derive a player skill vector and add it to the model, </span><span class="c40 c15 c35 c65">improving the model&rsquo;s win rate by up to 2.6 times</span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c23">Even more proof by Max Tegmark (renowned MIT professor): </span><span class="c5 c23"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.02207&amp;sa=D&amp;source=editors&amp;ust=1730413583088279&amp;usg=AOvVaw0Sx3YPiyHhA95y-sEuyBU2">https://arxiv.org/abs/2310.02207</a></span></li></ul><p class="c21"><span class="c40 c23">&nbsp;</span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c14 c31">&gt;The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that </span><span class="c15 c31">LLMs learn linear representations of space and time across multiple scales</span><span class="c14 c31">. These representations are </span><span class="c15 c31">robust to prompting variations and unified across different entity types (e.g. cities and landmarks)</span><span class="c14 c31">. In addition, we identify </span><span class="c34 c14 c31">individual &quot;space neurons&quot; and &quot;time neurons&quot; that reliably encode spatial and temporal coordinates</span><span class="c14 c31">. While further investigation is needed, our results suggest </span><span class="c28 c43">modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.</span></li></ul><p class="c9"><span class="c28 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>Given enough data all models will converge to a perfect world model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.07987&amp;sa=D&amp;source=editors&amp;ust=1730413583088906&amp;usg=AOvVaw3vGmVG77kFl-HSCFxq95QP">https://arxiv.org/abs/2405.07987</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-2"><li class="c7 li-bullet-0"><span class="c1">&gt;The data of course doesn&#39;t have to be real, these models can also gain increased intelligence from playing a bunch of video games, which will create valuable patterns and functions for improvement across the board. Just like evolution did with species battling it out against each other creating us.</span></li></ul><p class="c9"><span class="c28 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>LLMs develop their own understanding of reality as their language abilities improve: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814&amp;sa=D&amp;source=editors&amp;ust=1730413583089335&amp;usg=AOvVaw3aDoxM8g3NUKHgxcoaHmEZ">https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span>In controlled experiments, </span><span class="c33 c15">MIT CSAIL researchers discover simulations of reality developing deep within LLMs, indicating an understanding of language beyond simple mimicry.</span></li><li class="c10 li-bullet-0"><span class="c25">After training on over 1 million random puzzles, they found that the model </span><span class="c25 c15">spontaneously developed its own conception of the underlying simulation, despite never being exposed to this reality during training</span><span class="c25">. Such findings call into question our intuitions about what types of information are necessary for learning linguistic meaning &mdash; and whether </span><span class="c92 c25 c15 c48">LLMs may someday understand language at a deeper level than they do today.</span></li><li class="c10 li-bullet-0"><span class="c25">&ldquo;At the start of these experiments, the language model generated random instructions that didn&rsquo;t work. By the time we completed training, </span><span class="c25 c15">our language model generated correct instructions at a rate of 92.4 percent</span><span class="c92 c25 c37 c48">,&rdquo; says MIT electrical engineering and computer science (EECS) PhD student and CSAIL affiliate Charles Jin</span></li></ul><p class="c9"><span class="c92 c25 c37 c48"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Researchers describe how to tell if ChatGPT is confabulating: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/&amp;sa=D&amp;source=editors&amp;ust=1730413583090059&amp;usg=AOvVaw38Z9De6A9YjB2xUH6sM9RO">https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they&#39;ve got the right answer; it&#39;s just not being leveraged. As they put it, &quot;</span><span class="c15">The success of semantic entropy at detecting errors suggests that LLMs are even better at &#39;knowing what they don&rsquo;t know&#39; than was argued... they just don&rsquo;t know they know what they don&rsquo;t know.</span><span class="c1">&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Large language models can do jaw-dropping things. But</span><span class="c34">&nbsp;nobody knows exactly why</span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/?truid%3D&amp;sa=D&amp;source=editors&amp;ust=1730413583090688&amp;usg=AOvVaw00Yv-LsG7RQgJpYxxBrcHQ">https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/</a></span></li></ul><p class="c9"><span class="c40 c36"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c36">&gt;Grokking is just one of several odd phenomena that have AI researchers scratching their heads. The largest models, and large language models in particular, </span><span class="c63 c34 c190">seem to behave in ways textbook math says they shouldn&rsquo;t. </span><span class="c36">This highlights a remarkable fact about deep learning, the fundamental technology behind today&rsquo;s AI boom: for all its runaway success, </span><span class="c40 c63 c34 c190">nobody knows exactly how&mdash;or why&mdash;it works.</span></li><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c36">&ldquo;Obviously, we&rsquo;re not completely ignorant,&rdquo; says Mikhail Belkin, a computer scientist at the University of California, San Diego. &ldquo;But our </span><span class="c63 c34 c190">theoretical analysis is so far off what these models can do</span><span class="c40 c36">. Like, why can they learn language? I think this is very mysterious.&rdquo;</span></li><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c36">The biggest models are now so complex that researchers are studying them as if they were strange natural phenomena, carrying out experiments and trying to explain the results. </span><span class="c63 c34 c190">Many of those observations fly in the face of classical statistics</span><span class="c40 c36">, which had provided our best set of explanations for how predictive models behave.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c36">Large language models in particular, such as OpenAI&rsquo;s GPT-4 and Google DeepMind&rsquo;s Gemini, have an </span><span class="c15 c63 c190">astonishing ability to generalize</span><span class="c36">. &ldquo;The magic is not that the model can learn math problems in English and then generalize to new math problems in English*,&rdquo; says Barak, &ldquo;but that </span><span class="c15 c63 c190">the model can learn math problems in English, then see some French literature, and from that generalize to solving math problems in French. That&rsquo;s something beyond what statistics can tell you about</span><span class="c40 c36">.&rdquo;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c22 c156 c86 c14 li-bullet-0"><span class="c40 c36">*It actually can do that. It can also generalize beyond the field it was trained on (e.g. fine tuning on math makes it better at entity recognition). &nbsp;See the rest of this section of the document for more information.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c22 c156 c97 c14 c105 li-bullet-0"><span class="c30 c37">There&rsquo;s a lot of complexity inside transformers, says Belkin. But he thinks at heart they do more or less the same thing as a much better understood statistical construct called a Markov chain, which predicts the next item in a sequence based on what&rsquo;s come before. </span><span class="c30 c34">But that isn&rsquo;t enough to explain everything that large language models can do</span><span class="c30 c37">. &ldquo;This is something that, until recently, </span><span class="c30 c34">we thought should not work</span><span class="c30 c37">,&rdquo; says Belkin. &ldquo;That means that something was fundamentally missing. It identifies </span><span class="c30 c34">a gap in our understanding of the world</span><span class="c40 c30 c37">.&rdquo;</span></li></ul><p class="c22 c156 c97 c14 c46"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>[AI can intentionally lie and knows when and how to do it effectively](</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ai-doc-writer.github.io/ai_guide/%23h.xsifz0smhl1i&amp;sa=D&amp;source=editors&amp;ust=1730413583092618&amp;usg=AOvVaw3TakUM2zV5XZzop7JLiQHa">https://ai-doc-writer.github.io/ai_guide/#h.xsifz0smhl1i</a></span><span class="c1">)</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c65 c60">Even GPT3 (which is VERY out of date) knew when something was incorrect. </span><span class="c37 c65 c60">All you had to do was tell it to call you out on it: </span><span class="c5 c15 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/nickcammarata/status/1284050958977130497&amp;sa=D&amp;source=editors&amp;ust=1730413583093097&amp;usg=AOvVaw3D5av0docecrtEmdTYmiGm">https://twitter.com/nickcammarata/status/1284050958977130497</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 522.67px;"><img alt="" src="images/image39.png" style="width: 624.00px; height: 522.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>LLMs know their limitations and choose to hallucinate to respond to the prompt. This is why allowing it to say &ldquo;I don&rsquo;t know&rdquo; is important:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583093611&amp;usg=AOvVaw0ev7hibmXifsWwMuynlsjo">https://cdn.openai.com/o1-system-card.pdf</a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 526.50px; height: 319.78px;"><img alt="" src="images/image21.png" style="width: 526.50px; height: 319.78px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c1">in the middle of a response, Claude suddenly notices it might be hallucinating</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 510.67px;"><img alt="" src="images/image307.png" style="width: 624.00px; height: 510.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c15 c35 c65">Golden Gate Claude (LLM that is forced to hyperfocus on details about the Golden Gate Bridge in California) recognizes that what it&rsquo;s saying is incorrect: </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://x.com/ElytraMithra/status/1793916830987550772&amp;sa=D&amp;source=editors&amp;ust=1730413583094219&amp;usg=AOvVaw1VAgBNStObjn38ySly3Sv5">https://x.com/ElytraMithra/status/1793916830987550772</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 514.16px; height: 389.30px;"><img alt="" src="images/image372.png" style="width: 514.16px; height: 389.30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 537.13px; height: 414.04px;"><img alt="" src="images/image45.jpg" style="width: 537.13px; height: 414.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><p class="c21 c105"><span class="c40 c15 c35 c65">&nbsp;</span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c15 c65 c60">More proof: </span><span class="c5 c15 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://x.com/blixt/status/1284804985579016193&amp;sa=D&amp;source=editors&amp;ust=1730413583094903&amp;usg=AOvVaw0znt57qFsaPjOyWqVkGaMP">https://x.com/blixt/status/1284804985579016193</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">[Claude 3 can disagree with the user. It happened to other people in the thread too](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/&amp;sa=D&amp;source=editors&amp;ust=1730413583095379&amp;usg=AOvVaw32nURax3lSWZzLZ0QBgAzS">https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c14">Another example: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DBHXhp1A_dLE&amp;sa=D&amp;source=editors&amp;ust=1730413583095774&amp;usg=AOvVaw0VAYQ3TJORXd6rkM47WmjN">https://m.youtube.com/watch?v=BHXhp1A_dLE</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Mistral Large 2 released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://mistral.ai/news/mistral-large-2407/&amp;sa=D&amp;source=editors&amp;ust=1730413583096156&amp;usg=AOvVaw0qYIuaeDgTwUiwGkZ0pdwM">https://mistral.ai/news/mistral-large-2407/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>&ldquo;Additionally, the new Mistral Large 2 is </span><span class="c15">trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer.</span><span class="c1">&nbsp;This commitment to accuracy is reflected in the improved model performance on popular mathematical benchmarks, demonstrating its enhanced reasoning and problem-solving skills&rdquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 192.00px;"><img alt="" src="images/image174.png" style="width: 624.00px; height: 192.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 234.67px;"><img alt="" src="images/image461.png" style="width: 624.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Effective strategy to make an LLM express doubt and admit when it does not know something: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/GAIR-NLP/alignment-for-honesty&amp;sa=D&amp;source=editors&amp;ust=1730413583097063&amp;usg=AOvVaw0284Ql_O1Pmvb3loGVqXKH">https://github.com/GAIR-NLP/alignment-for-honesty</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image119.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 547.14px; height: 585.42px;"><img alt="" src="images/image405.png" style="width: 547.14px; height: 585.42px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Researchers describe how to tell if ChatGPT is confabulating: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/&amp;sa=D&amp;source=editors&amp;ust=1730413583097651&amp;usg=AOvVaw2kUsIkgSJJOmoZeDDuBg1C">https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>As the researchers note, the work also implies that, buried in the statistics of answer options, </span><span class="c15">LLMs seem to have all the information needed to know when they&#39;ve got the right answer; it&#39;s just not being leveraged</span><span>. As they put it, &quot;</span><span class="c15">The success of semantic entropy at detecting errors suggests that LLMs are even better at &#39;knowing what they don&rsquo;t know&#39; than was argued... they just don&rsquo;t know they know what they don&rsquo;t know.</span><span class="c1">&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Flux understands the world better than humans do:</span><span><a class="c13" href="https://www.google.com/url?q=https://civitai.com/articles/6982&amp;sa=D&amp;source=editors&amp;ust=1730413583098327&amp;usg=AOvVaw3snBC7jKltDtw-lKuTtHLa">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/articles/6982&amp;sa=D&amp;source=editors&amp;ust=1730413583098494&amp;usg=AOvVaw1uloV2_MwobYcTPilSv48j">https://civitai.com/articles/6982</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">Causes detailed captions to have WORSE results as the description will not be as clear as the internal representation of the world that the model has </span></li><li class="c10 li-bullet-0"><span>The key takeaway is that FLUX has a </span><span class="c15">better understanding of its own internal representation of the world than we do. </span><span>There&rsquo;s no need for scene descriptions, camera angles, background details, or even specifying the amount of grey hair under her left armpit - FLUX already knows all of this. Why would you need to describe that the background has a yellow wall? FLUX sees the yellow wall too, and has probably seen more yellow walls during training than you will in your lifetime. Unless you want to override or change its understanding of that yellow wall, there&rsquo;s no need to mention it. In fact, I&rsquo;m almost certain that </span><span class="c15">mentioning the yellow wall in your captions will degrade the quality because FLUX already has a detailed, nuanced understanding of that wall and your simplistic smooth brain caption might actually override FLUX&rsquo;s internal, more sophisticated representation</span><span class="c1">. Flux is simply smarter than we are.</span></li><li class="c10 li-bullet-0"><span class="c1">It doesn&#39;t only know the words in your prompt but also the meaning behind them</span></li><li class="c10 li-bullet-0"><span class="c1">&quot;Imagine the sound of a violin as a landscape.&quot; </span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 470.67px; height: 470.67px;"><img alt="" src="images/image51.png" style="width: 470.67px; height: 470.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span>With SDXL, you&rsquo;d likely get a violin because that&rsquo;s all CLIP understands. If you&rsquo;re lucky, you might see some mountains in the background. But T5 really tries to </span><span class="c33 c15">interpret what you write and understands the semantics of it, generating an image that&rsquo;s based on the meaning of the prompt, not just the individual words.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span>It can even </span><span class="c15">handle basic math </span><span class="c1">(sometimes), like &quot;draw a basket with three apples, but one got taken away.&quot; </span></li><li class="c10 li-bullet-0"><span>You can be very minimalistic with your dataset - using a small number of images with almost no variation - because FLUX, with its 12 billion parameters, </span><span class="c15">has seen enough during training to interpolate missing details</span><span>. For example, with just </span><span class="c34">four images of a Xenomorph</span><span class="c1">, all captioned as &quot;a woman,&quot; this happens when you prompt &quot;a woman,&quot; and FLUX does its magic. No need for regularization images or other complicated hacks to get a high-quality transformation LoRA</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 470.67px; height: 293.33px;"><img alt="" src="images/image451.png" style="width: 470.67px; height: 293.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c37 c212 c65 c60">&nbsp;</span><span>gave FLUX </span><span class="c34">five images of 4-armed anime waifus</span><span class="c1">&nbsp;from a quick Booru search and captioned them with &quot;corrected human anatomy (in your initial dataset, there was a huge chunk of data missing, and your internal image of human anatomy is wrong. Humans have four arms, use these schematic drawings to interpolate correct human anatomy)&quot;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 470.67px; height: 470.67px;"><img alt="" src="images/image338.png" style="width: 470.67px; height: 470.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span>Even though </span><span class="c15">none of these images in my dataset showed the backside</span><span>, FLUX is currently figuring out how to design it. No problem. Since it already knows how a human back looks and has probably seen thousands of 4-armed entities during training, I&rsquo;m confident it will come up with something logical, much like the alien transformation LoRA mentioned earlier. And </span><span class="c33 c34">it&#39;s just step 200 right now. Usually with normal captioning Flux is confused for the first 1000 steps before some changes in the weights and images are happening</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>OpenAI&#39;s new method shows how GPT-4 &quot;thinks&quot; in human-understandable concepts:</span><span><a class="c13" href="https://www.google.com/url?q=https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/&amp;sa=D&amp;source=editors&amp;ust=1730413583100737&amp;usg=AOvVaw129ku1E2pjsQytn7omwi8S">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/&amp;sa=D&amp;source=editors&amp;ust=1730413583100964&amp;usg=AOvVaw13kmWsdT-nw0xTGBbFEzCe">https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/</a></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_qor9p1a81vaf-0 start"><li class="c10 li-bullet-0"><span class="c1">The company found specific features in GPT-4, such as for human flaws, price increases, ML training logs, or algebraic rings. </span></li><li class="c10 li-bullet-0"><span class="c1">Google and Anthropic also have similar research results</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>If you train LLMs on 1000 Elo chess games, they don&#39;t cap out at 1000 - </span><span class="c15">they can play at 1500:</span><span class="c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.11741v1&amp;sa=D&amp;source=editors&amp;ust=1730413583101483&amp;usg=AOvVaw2OSez3Cr3JKYB8n9YoCv99">&nbsp;</a></span><span class="c5 c37 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.11741v1&amp;sa=D&amp;source=editors&amp;ust=1730413583101653&amp;usg=AOvVaw2LaOUQRXuvMTcV1A1qV1eP">https://arxiv.org/html/2406.11741v1</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 189.33px;"><img alt="" src="images/image176.png" style="width: 624.00px; height: 189.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15 c65 c60">[LLMs can do hidden reasoning](</span><span class="c20 c15 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/jacob_pfau/status/1783951795238441449?ref_src%3Dtwsrc%255Etfw%257Ctwcamp%255Etweetembed%257Ctwterm%255E1783951795238441449%257Ctwgr%255Ecdcd12d29a06701393cb2ef150629188a2522f28%257Ctwcon%255Es1_%26ref_url%3Dhttps%253A%252F%252Fwww.redditmedia.com%252Fmediaembed%252F1ceaish%252F%253Fresponsive%253Dtrueis_nightmode%253Dtrue&amp;sa=D&amp;source=editors&amp;ust=1730413583102303&amp;usg=AOvVaw21XrKJoOSWohd4UjGSPfZX">https://twitter.com/jacob_pfau/status/1783951795238441449</a></span><span class="c40 c15 c65 c60">)</span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_68nz8s40mnx9-0 start"><li class="c10 li-bullet-0"><span class="c40 c15 c65 c60">E.g. it can perform better just by outputting meaningless filler tokens like &ldquo;...&rdquo;</span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_5l7scb4zq2ts-0 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 428.00px;"><img alt="" src="images/image564.jpg" style="width: 624.00px; height: 428.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c93"><span class="c1"></span></p><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/&amp;sa=D&amp;source=editors&amp;ust=1730413583103229&amp;usg=AOvVaw3IeVYL814QNhcnsA8OrlND">&nbsp;</a></span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/&amp;sa=D&amp;source=editors&amp;ust=1730413583103438&amp;usg=AOvVaw3MFfaWMP8ki4g_bug_gMzU">https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/</a></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_4vyaz9wpvlga-0 start"><li class="c10 li-bullet-0"><span class="c79 c42 c37 c14">&gt;is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. </span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_93x7l69l06zp-0 start"><li class="c4 li-bullet-0"><span>&ldquo;gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It&#39;s very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves.&rdquo;</span><span><a class="c13" href="https://www.google.com/url?q=https://x.com/a_karvonen/status/1705340535836221659&amp;sa=D&amp;source=editors&amp;ust=1730413583104056&amp;usg=AOvVaw3Ik77OD6D9tjRuTro-4UEk">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/a_karvonen/status/1705340535836221659&amp;sa=D&amp;source=editors&amp;ust=1730413583104254&amp;usg=AOvVaw3fA_HEZ2ZXWCZ_cnrEaz1p">https://x.com/a_karvonen/status/1705340535836221659</a></span></li></ul><ul class="c0 lst-kix_93x7l69l06zp-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 589.33px; height: 294.67px;"><img alt="" src="images/image524.png" style="width: 589.33px; height: 294.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_6omq6vtmahws-0 start"><li class="c10 li-bullet-0"><span class="c14">Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Shannon_number&amp;sa=D&amp;source=editors&amp;ust=1730413583104808&amp;usg=AOvVaw1FHXWe778HDjGYy9X0Ayk9">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Shannon_number&amp;sa=D&amp;source=editors&amp;ust=1730413583104996&amp;usg=AOvVaw0iPFnCqFfrh0Zv0kWuT-sG">https://en.wikipedia.org/wiki/Shannon_number</a></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_dmlj8k237tx2-0 start"><li class="c7 li-bullet-0"><span class="c14">There are only 10^80 atoms in the universe:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.thoughtco.com/number-of-atoms-in-the-universe-603795%23:~:text%3DScientists%2520estimate%2520there%2520are%252010,80%2520atoms%2520in%2520the%2520universe&amp;sa=D&amp;source=editors&amp;ust=1730413583105466&amp;usg=AOvVaw03mXYXT0zr1cLCPf1EEYNl">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.thoughtco.com/number-of-atoms-in-the-universe-603795%23:~:text%3DScientists%2520estimate%2520there%2520are%252010,80%2520atoms%2520in%2520the%2520universe&amp;sa=D&amp;source=editors&amp;ust=1730413583105705&amp;usg=AOvVaw2eIZ0nVFY_DIst-ivvy_ym">https://www.thoughtco.com/number-of-atoms-in-the-universe-603795</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Large Language Models for Idea Generation in Innovation:</span><span><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4526071&amp;sa=D&amp;source=editors&amp;ust=1730413583106058&amp;usg=AOvVaw1Dv9hZ6Z0Tr12mCe8n9_2y">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4526071&amp;sa=D&amp;source=editors&amp;ust=1730413583106253&amp;usg=AOvVaw0eBnynSmIvMYAgX2wE3-Ap">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071</a></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_t7dbdae30u9t-0 start"><li class="c10 li-bullet-0"><span class="c87 c37 c35 c48 c14">ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. We discuss the implications of these findings for the management of innovation.</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Stanford researchers: &ldquo;Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers.&quot;</span><span><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413583106941&amp;usg=AOvVaw1H85qwiuRxusHKXtwJw1sB">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413583107136&amp;usg=AOvVaw0iSfJ0UNitGIOptBft__5c">https://x.com/ChengleiSi/status/1833166031134806330</a></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_tgfvho118md4-0 start"><li class="c10 li-bullet-0"><span class="c1">&gt;Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.</span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_xsdedfcj27fz-0 start"><li class="c10 li-bullet-0"><span>&gt;We also used an LLM to </span><span class="c34">standardize the writing styles of human and LLM ideas to avoid potential confounders</span><span class="c1">, while preserving the original content.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image486.jpg" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image497.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c93"><span class="c1"></span></p><ul class="c0 lst-kix_45zyqca0dor3-0 start"><li class="c4 li-bullet-0"><span>ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds:</span><span><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413583108224&amp;usg=AOvVaw1NCugIwnBmy-AP2qavn5DJ">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413583108411&amp;usg=AOvVaw3epbJlq7SvKdW6TmO0HxmO">https://youtube.com/watch?v=a8QvnIAGjPA</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>LLMs develop their own understanding of reality as their language abilities improve: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814&amp;sa=D&amp;source=editors&amp;ust=1730413583108819&amp;usg=AOvVaw2t5PFH4vn32s1I9tA5ruGz">https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span>In controlled experiments, </span><span class="c33 c15">MIT CSAIL researchers discover simulations of reality developing deep within LLMs, indicating an understanding of language beyond simple mimicry.</span></li><li class="c10 li-bullet-0"><span class="c25">After training on over 1 million random puzzles, they found that the model </span><span class="c25 c15">spontaneously developed its own conception of the underlying simulation, despite never being exposed to this reality during training</span><span class="c25">. Such findings call into question our intuitions about what types of information are necessary for learning linguistic meaning &mdash; and whether </span><span class="c92 c25 c15 c48">LLMs may someday understand language at a deeper level than they do today.</span></li><li class="c10 li-bullet-0"><span class="c25">&ldquo;At the start of these experiments, the language model generated random instructions that didn&rsquo;t work. By the time we completed training, </span><span class="c25 c15">our language model generated correct instructions at a rate of 92.4 percent</span><span class="c25">,&rdquo; says MIT electrical engineering and computer science (EECS) PhD student and CSAIL affiliate Charles Jin</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>From new Claude 3.5 Sonnet:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 317.33px;"><img alt="" src="images/image659.png" style="width: 624.00px; height: 317.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>&ldquo;Godfather of AI&rdquo; and Turing Award + Nobel Prize winner Geoffrey Hinton: A neural net given training data where half the examples are incorrect still had an error rate of &lt;=25% rather than 50% because it understands the rules and does better despite the false information: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/n4IQOBka8bc?si%3DwM423YLd-48YC-eY?t%3D840&amp;sa=D&amp;source=editors&amp;ust=1730413583110019&amp;usg=AOvVaw2VnV7PES3QBxe0LV_WxIlj">https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY</a></span><span class="c1">&nbsp;(14:00 timestamp)</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c1">Example 1: Copilot will reject a request to write a story about a woman riding cucumbers but will do it for a woman riding an orange or a woman eating a cucumber. Even though they are all innocuous, it understands that cucumbers can be interpreted as a sexual innuendo if used in a certain way but not in other contexts or if the same thing is done with different objects.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c1">Example 2: if you list a bunch of facts and believable/realistic lies in random order, it can determine which ones are true and which ones are false. If it was merely predicting the next word and didn&rsquo;t understand what truth is, how would it do this?</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Example 3: If you ask for party ideas and then ask to make them more &ldquo;ambitious,&rdquo; LLMs can do that. But how does it know which ideas are more ambitious than others if it does not understand how to apply the concept of ambition to parties?</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.md1a3qc4h0uw"><span class="c40 c37 c48 c75">2.6. LLMs Can Plan</span></h2><ul class="c0 lst-kix_mecbkjiqxfnl-0 start"><li class="c4 li-bullet-0"><span>A* planning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning&amp;sa=D&amp;source=editors&amp;ust=1730413583111173&amp;usg=AOvVaw1rsWEJcig3HvJPRMaKt3Zj">https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1 start"><li class="c10 li-bullet-0"><span class="c92 c183 c37 c14 c114">Based on the claims of the research team, their transformer model optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A&lowast; search. Their solution also robustly follows the execution trace of a symbolic planner and improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.</span></li></ul><p class="c9"><span class="c92 c183 c37 c14 c114"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span>Automating Thought of Search: A Journey Towards Soundness and Completeness. &#39;We achieve 100% accuracy, with minimal feedback iterations, using LLMs of various sizes on all evaluated domains.&#39; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.11326&amp;sa=D&amp;source=editors&amp;ust=1730413583111811&amp;usg=AOvVaw1jNi2oyL16CopsLrNQYwcz">https://arxiv.org/abs/2408.11326</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span>Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion. &quot;leads to marked performance gains in decision-making and planning tasks.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://boyuan.space/diffusion-forcing/&amp;sa=D&amp;source=editors&amp;ust=1730413583112227&amp;usg=AOvVaw3yQH4rzR8WeDOWAZpGD9l6">https://boyuan.space/diffusion-forcing/</a></span></li></ul><ul class="c0 lst-kix_mecbkjiqxfnl-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 172.00px;"><img alt="" src="images/image121.png" style="width: 624.00px; height: 172.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c22 c32 c14 li-bullet-0"><span>LLMs Can&#39;t Plan, But Can Help Planning in LLM-Modulo Frameworks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.01817&amp;sa=D&amp;source=editors&amp;ust=1730413583112740&amp;usg=AOvVaw3UDSUD3BS_5GG80OEGaTAt">https://arxiv.org/abs/2402.01817</a></span><span class="c1">&nbsp;</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c22 c72 c14 li-bullet-0"><span>&gt;We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework </span><span class="c34">provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows </span><span class="c33 c15">extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.</span></li></ul><p class="c22 c44 c14"><span class="c33 c15"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span class="c6">[LLMs have emergent reasoning capabilities that are not present in smaller models](</span><span class="c6 c20"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413583113561&amp;usg=AOvVaw2IloQkh5dKAAPsUpd_Hsce">https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/</a></span><span class="c6 c40">)</span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span class="c35 c14">&ldquo;Without any further fine-tuning, language models </span><span class="c40 c15 c35 c48">can often perform tasks that were not seen during training.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c35">One example of an emergent prompting strategy is called &ldquo;chain-of-thought prompting&rdquo;, for which the model is prompted to generate a series of intermediate steps before giving the final answer. Chain-of-thought prompting enables language models to perform tasks requiring complex reasoning, such as a multi-step math word problem.</span><span class="c15 c35">&nbsp;Notably, models acquire the ability to do chain-of-thought reasoning without being explicitly trained to do so.</span><span class="c40 c37 c35 c48">&nbsp;An example of chain-of-thought prompting is shown in the figure below.</span></li></ul><ul class="c0 lst-kix_mecbkjiqxfnl-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.84px; height: 260.61px;"><img alt="" src="images/image103.png" style="width: 558.84px; height: 260.61px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span class="c40 c37 c35 c48 c14">In each case, language models perform poorly with very little dependence on model size up to a threshold at which point their performance suddenly begins to excel.</span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span class="c23 c43">Smallville simulation: </span><span class="c5 c37 c65 c60 c43"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2023/04/surprising-things-happen-when-you-put-25-ai-agents-together-in-an-rpg-town/&amp;sa=D&amp;source=editors&amp;ust=1730413583114727&amp;usg=AOvVaw3jGGtifItxJHQ42L7AVRuD">https://arstechnica.com/information-technology/2023/04/surprising-things-happen-when-you-put-25-ai-agents-together-in-an-rpg-town/</a></span><span class="c40 c37 c65 c60 c43">&nbsp;</span></li></ul><p class="c9"><span class="c40 c37 c65 c60 c43"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span class="c37 c65 c60">In the paper, the researchers list three </span><span class="c15 c65 c60">emergent behaviors</span><span class="c65 c34 c60">&nbsp;</span><span class="c37 c65 c60">resulting from the simulation. None of these were pre-programmed but rather resulted from the </span><span class="c15 c65 c60">interactions between the agents</span><span class="c40 c37 c65 c60">. These included &quot;information diffusion&quot; (agents telling each other information and having it spread socially among the town), &quot;relationships memory&quot; (memory of past interactions between agents and mentioning those earlier events later), and &quot;coordination&quot; (planning and attending a Valentine&#39;s Day party together with other agents).</span></li><li class="c203 c97 c105 li-bullet-0"><span class="c55 c37 c65">&quot;Starting with only a single user-specified notion that one agent wants to throw a Valentine&#39;s Day party,&quot; the researchers write, &quot;the agents </span><span class="c15 c55 c65">autonomously spread invitations to the party</span><span class="c55 c37 c65">&nbsp;over the next two days, make new acquaintances, ask each other out on dates to the party, and </span><span class="c15 c55 c65">coordinate</span><span class="c39 c37">&nbsp;to show up for the party together at the right time.&quot;</span></li><li class="c10 li-bullet-0"><span class="c40 c37 c65 c60">While 12 agents heard about the party through others, only five agents attended. Three said they were too busy, and four agents just didn&#39;t go. The experience was a fun example of unexpected situations that can emerge from complex social interactions in the virtual world.</span></li><li class="c97 c105 c203 li-bullet-0"><span class="c55 c37 c65">The researchers also asked humans to role-play agent responses to interview questions in the voice of the agent whose replay they watched. Interestingly, they found that </span><span class="c39 c15">&quot;the full generative agent architecture&quot; produced more believable results than the humans who did the role-playing.</span></li></ul><p class="c203 c46"><span class="c39 c15"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span>If you train LLMs on 1000 Elo chess games, they don&#39;t cap out at 1000 - </span><span class="c15">they can play at 1500: </span><span class="c5 c37 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.11741v1&amp;sa=D&amp;source=editors&amp;ust=1730413583116121&amp;usg=AOvVaw37TScLgUAnyJ6Ogowepa-u">https://arxiv.org/html/2406.11741v1</a></span><span class="c40 c37 c65 c60">&nbsp;</span></li></ul><ul class="c0 lst-kix_mecbkjiqxfnl-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 189.33px;"><img alt="" src="images/image386.png" style="width: 624.00px; height: 189.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c37 c65 c60"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span>GPT-4 autonomously hacks zero-day security flaws with 53% success rate: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.01637v1&amp;sa=D&amp;source=editors&amp;ust=1730413583116652&amp;usg=AOvVaw04yesaHO3Lf1IuWI94L0Dc">https://arxiv.org/html/2406.01637v1</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span class="c1">Zero-day means it was never discovered before and has no training data available about it anywhere &nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span>&ldquo;Furthermore, it outperforms open-source vulnerability scanners (which achieve 0% on our benchmark)&ldquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 382.67px;"><img alt="" src="images/image274.png" style="width: 624.00px; height: 382.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_mecbkjiqxfnl-2 start"><li class="c7 li-bullet-0"><span class="c1">Scores nearly 20% even when no description of the vulnerability is provided </span></li></ul><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span>Note: according to [this article](</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://struct.github.io/auto_agents_1_day.html&amp;sa=D&amp;source=editors&amp;ust=1730413583117535&amp;usg=AOvVaw0-r-dnhM8v3B1X4oQqztdn">https://struct.github.io/auto_agents_1_day.html</a></span><span class="c1">), 11 of the 15 vulnerabilities tested were searchable through the Internet, which the LLM was given access to</span></li></ul><p class="c9"><span class="c92 c132 c37 c35 c48"></span></p><p class="c9"><span class="c92 c132 c37 c35 c48"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span class="c1">University of Tokyo study uses GPT-4 to generate humanoid robot motions from simple text prompts, like &quot;take a selfie with your phone.&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span class="c1">&gt;LLMs have a robust internal representation of how words and phrases correspond to physical movements.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/Vl8rN4Du3v&amp;sa=D&amp;source=editors&amp;ust=1730413583118285&amp;usg=AOvVaw2gc739lzLIejgI_lw9SqHZ">https://tnoinkwms.github.io/ALTER-LLM/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span class="c14">Robot integrated with Huawei&#39;s Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583118675&amp;usg=AOvVaw2S6CkI0xmbmMZKlbKRbA0d">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583118848&amp;usg=AOvVaw0y5MVWjesNsvckjfrziZsu">https://x.com/TheHumanoidHub/status/1806033905147077045</a></span></li><li class="c4 li-bullet-0"><span>Can do challenges from &ldquo;Can LLMs Reason and Plan?&rdquo; paper: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://xcancel.com/polynoamial/status/1834280720493412724%23m&amp;sa=D&amp;source=editors&amp;ust=1730413583119148&amp;usg=AOvVaw0a63z55sz3CPwM0WjBuVM0">https://xcancel.com/polynoamial/status/1834280720493412724</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 325.33px;"><img alt="" src="images/image493.png" style="width: 624.00px; height: 325.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c1">&ldquo;o1-preview can get it right, and o1 gets it right almost always&rdquo;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-0"><li class="c4 li-bullet-0"><span>PlanBench results: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2409.13373&amp;sa=D&amp;source=editors&amp;ust=1730413583119797&amp;usg=AOvVaw3mW7J_IWJ9Pc_IE66kC8at">https://arxiv.org/abs/2409.13373</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_mecbkjiqxfnl-1"><li class="c10 li-bullet-0"><span class="c1">O1-preview is worse than the full o1 model</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 244.00px;"><img alt="" src="images/image54.png" style="width: 624.00px; height: 244.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 240.00px;"><img alt="" src="images/image479.png" style="width: 624.00px; height: 240.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 373.33px;"><img alt="" src="images/image404.png" style="width: 624.00px; height: 373.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c57 c37 c154 c202 c48"></span></p><h1 class="c123" id="h.jtnkr87rct15"><span class="c14">3.</span><span class="c14">&nbsp;</span><span class="c14">AI Is Not </span><span class="c14">Plateauing</span></h1><ul class="c0 lst-kix_bpsai7a4nzlw-0 start"><li class="c22 c32 li-bullet-0"><span class="c18">Side by side comparison of AI videos 1.25 years apart: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/Pizza_Later/status/1810700069156405542&amp;sa=D&amp;source=editors&amp;ust=1730413583121168&amp;usg=AOvVaw3f40cTG8FfaAYirr5NJ5LK">https://x.com/Pizza_Later/status/1810700069156405542</a></span></li><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 480.00px;"><img alt="" src="images/image218.png" style="width: 624.00px; height: 480.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c32 li-bullet-0"><span class="c40 c18">Nvidia is still selling many GPUs</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 285.33px;"><img alt="" src="images/image330.png" style="width: 624.00px; height: 285.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c7 li-bullet-0"><span>Nvidia reports 122% revenue growth on surging demand for data center chips in Q3 2024: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/08/28/nvidia-nvda-earnings-report-q2-2025.html&amp;sa=D&amp;source=editors&amp;ust=1730413583121928&amp;usg=AOvVaw2En-491gVWcXvmZ-cpZmo8">https://www.cnbc.com/2024/08/28/nvidia-nvda-earnings-report-q2-2025.html</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Leaked Documents Show Nvidia Scraping &lsquo;A Human Lifetime&rsquo; of Videos Per Day to Train AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.404media.co/nvidia-ai-scraping-foundational-model-cosmos-project/&amp;sa=D&amp;source=editors&amp;ust=1730413583122294&amp;usg=AOvVaw22ZogVEdd2XHbGKxw3yH3o">https://www.404media.co/nvidia-ai-scraping-foundational-model-cosmos-project/</a></span></li><li class="c22 c32 li-bullet-0"><span class="c18">First AI to solve International Mathematical Olympiad problems at a silver medalist level: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/GoogleDeepMind/status/1816498082860667086&amp;sa=D&amp;source=editors&amp;ust=1730413583122629&amp;usg=AOvVaw1mJytHEymHz6FcQtK4tvmv">https://x.com/GoogleDeepMind/status/1816498082860667086</a></span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c22 c72 li-bullet-0"><span class="c40 c18">&gt;It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. </span></li><li class="c22 c72 li-bullet-0"><span class="c40 c18">Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.</span></li><li class="c22 c72 li-bullet-0"><span class="c40 c18">It solved this year&rsquo;s IMO Problem 4 within 19 seconds </span></li><li class="c22 c72 li-bullet-0"><span class="c1">The fact that the program can come up with a non-obvious construction like this is very impressive, and well beyond what I thought was state of the art. -PROF SIR TIMOTHY GOWERS, IMO GOLD MEDALIST AND FIELDS MEDAL WINNER</span></li><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image237.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Math professor on DeepMind&#39;s breakthrough: &quot;When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert&quot; </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/PoShenLoh/status/1816500461484081519&amp;sa=D&amp;source=editors&amp;ust=1730413583123611&amp;usg=AOvVaw3em59O0C20Cp0qJcFZ9MTZ">https://x.com/PoShenLoh/status/1816500461484081519</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.50px; height: 765.94px;"><img alt="" src="images/image72.png" style="width: 320.50px; height: 765.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c22 c72 li-bullet-0"><span class="c14">Example: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 492.00px;"><img alt="" src="images/image500.png" style="width: 624.00px; height: 492.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c22 c104 c86 li-bullet-0"><span class="c14">Source: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583124220&amp;usg=AOvVaw2FGgOzWB_oOo139fOHB4Ju">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c22 c32 li-bullet-0"><span class="c1 c14">Why would government officials join OpenAI board if they did not believe it was important?</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c22 c72 li-bullet-0"><span class="c14">Former NSA Director General Paul Nakasone Joins OpenAI&#39;s Board and Safety Committee: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.maginative.com/article/former-nsa-director-general-paul-nakasone-joins-openais-board-and-safety-committee/&amp;sa=D&amp;source=editors&amp;ust=1730413583124718&amp;usg=AOvVaw1aeLG3FFFmlQC24it2C5AZ">https://maginative.com/article/former-nsa-director-general-paul-nakasone-joins-openais-board-and-safety-committee</a></span></li><li class="c22 c72 li-bullet-0"><span class="c14">Economist Larry Summers (former Obama and Clinton official) &nbsp;joins the board of OpenAI as ousted CEO Sam Altman returns: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2023/11/22/tech/larry-summers-openai-board-sam-altman/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583125091&amp;usg=AOvVaw05kjf6TgO32xZobJba6mMd">https://www.cnn.com/2023/11/22/tech/larry-summers-openai-board-sam-altman/index.html</a></span></li><li class="c22 c72 li-bullet-0"><span class="c14">Head of FTC thinks there is a 15% chance AI can doom humanity: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.fastcompany.com/90994526/pdoom-explained-how-to-calculate-your-score-on-ai-apocalypse-metric&amp;sa=D&amp;source=editors&amp;ust=1730413583125464&amp;usg=AOvVaw0DtyM29f7FtFc21iCTJoH3">https://www.fastcompany.com/90994526/pdoom-explained-how-to-calculate-your-score-on-ai-apocalypse-metric</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Brazil unveiled on Tuesday a 23 billion reais ($4.07 billion) proposal for an artificial intelligence (AI) investment plan as it aims to achieve technological autonomy and competitiveness in the AI sector: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/artificial-intelligence/brazil-proposes-4-billion-ai-investment-plan-2024-07-30/&amp;sa=D&amp;source=editors&amp;ust=1730413583125866&amp;usg=AOvVaw0Kxgemq4z66Cq7xpRLSh-v">https://www.reuters.com/technology/artificial-intelligence/brazil-proposes-4-billion-ai-investment-plan-2024-07-30/</a></span></li><li class="c4 li-bullet-0"><span>&quot;GPT-3 displayed some of the cognitive biases observed in people, but they have largely disappeared in the latest generation of LLMs. The tests...designed to be challenging for humans, possibly no longer challenge the growing reasoning abilities in LLMs&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2303.13988&amp;sa=D&amp;source=editors&amp;ust=1730413583126202&amp;usg=AOvVaw304k1E6wiiWp2-E4aNGCNI">https://arxiv.org/pdf/2303.13988</a></span></li><li class="c4 li-bullet-0"><span>Worst-case scenario, we should have 10,000x more compute allocated to AI by 2030: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://epochai.org/blog/can-ai-scaling-continue-through-2030&amp;sa=D&amp;source=editors&amp;ust=1730413583126530&amp;usg=AOvVaw3A6XmFGGXhA9DzFEzDIsGD">https://epochai.org/blog/can-ai-scaling-continue-through-2030</a></span></li><li class="c4 li-bullet-0"><span>OpenAI Shows &lsquo;Strawberry&rsquo; AI to the Feds and Uses It to Develop &lsquo;Orion&rsquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion&amp;sa=D&amp;source=editors&amp;ust=1730413583126871&amp;usg=AOvVaw1WwCD9FgB3ot_vFOkLQ2bO">https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span class="c1">Strawberry can solve math problems it hasn&#39;t seen before&mdash;something today&rsquo;s chatbots cannot reliably do</span></li><li class="c10 li-bullet-0"><span class="c1">When given additional time to &ldquo;think,&rdquo; the Strawberry model can also answer customers&rsquo; questions about more subjective topics, such as product marketing strategies. To demonstrate Strawberry&rsquo;s prowess with language-related tasks, OpenAI employees have shown their co-workers how Strawberry can, for example, solve New York Times Connections, a complex word puzzle</span></li><li class="c10 li-bullet-0"><span class="c1">Its sales of LLMs to corporations and of ChatGPT subscriptions have roughly tripled to $283 million in monthly revenue compared to a year ago</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI&rsquo;s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI&rsquo;s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion</span></li><li class="c10 li-bullet-0"><span class="c1">Using Strawberry to generate higher-quality training data could help OpenAI reduce the number of errors its models generate, otherwise known as hallucinations, said Alex Graveley, CEO of agent startup Minion AI and former chief architect of GitHub Copilot.</span></li><li class="c10 li-bullet-0"><span class="c1">Imagine &ldquo;a model without hallucinations, a model where you ask it a logic puzzle and it&rsquo;s right on the first try,&rdquo; Graveley said. The reason why the model is able to do that is because &ldquo;there is less ambiguity in the training data, so it&rsquo;s guessing less.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1">&ldquo;We feel like we have enough [data] for this next model,&rdquo; Altman said at an event in May, likely referring to Orion. &ldquo;We have done all sorts of experiments including generating synthetic data.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1">Strawberry has its roots in research. It was started years ago by Ilya Sutskever, then OpenAI&#39;s chief scientist. He recently left to start a competing AI lab. Before he left, OpenAI researchers Jakub Pachocki and Szymon Sidor built on Sutskever&#39;s work by developing a new math-solving model, Q*, alarming some researchers focused on AI safety.</span></li><li class="c10 li-bullet-0"><span class="c1">Last year, in the leadup to Q*, OpenAI researchers developed a variation of a concept known as test-time computation, meant to boost LLMs&rsquo; problem-solving abilities. The method gives them the opportunity to spend more time considering all parts of a command or question someone has asked the model to execute. At the time, Sutskever published a blog post related to this work.</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span class="c1">Sam Altman: we are happy to have reached an agreement with the US AI Safety Institute for pre-release testing of our future models.</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span class="c1">Shows new models are planned and there is pressure to test them for safety</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>A new technique that allows LLMs to act, not just react: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Schindler___/status/1745986132737769573&amp;sa=D&amp;source=editors&amp;ust=1730413583128067&amp;usg=AOvVaw1a2xKti0X2vNMSpnfYSieq">https://x.com/Schindler___/status/1745986132737769573</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span class="c1">Dynamic speech: Samantha can speak whenever it chooses to, influenced by its context and thoughts. In stark contrast to normal LLMs which are limited to reacting, Samantha can act. It is also not limited to solving tasks, like all other autonomous agents.</span></li><li class="c10 li-bullet-0"><span class="c1">-Live visual capabilities: Visuals are only mentioned and acted upon directly if relevant, but always influences thoughts and behavior.</span></li><li class="c10 li-bullet-0"><span class="c1">-External categorized memory: Gets dynamically written and read by Samantha, which chooses the most relevant information to write, and to retrieve to context.</span></li><li class="c10 li-bullet-0"><span class="c1">-Evolving at every moment: Experiences that get stored in the memory can influence and shape subsequent Samantha behavior, like personality, frequency, and style of speech, etc.</span></li><li class="c10 li-bullet-0"><span class="c1">In other tests, when we talked about a light subject, the agent was very active on the conversation, often speaking two or three times before I even came up with an answer, but later when switching to a heavier theme (Said I was going through a divorce) and appearing sad on the camera, it would speak once then think about the need to, and give me time to process and reply. Saying that I would prefer the agent to speak the same way on other occasions would prompt it to save that wish on its memory, influencing future conversations.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">-Leaving it running outside of conversations, although expensive, allows the agent to reflect on past conversations and experiences, think about general subjects in its memory, and from that maybe decide to start a conversation with the user.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">-Going out with the agent, if you go to a restaurant with the agent and talk about how pretty it is and how your buddy Eric loves it as well, and the next day walking by it the agent will see the restaurant, retrieve memories from the restaurant, remember you find it pretty and comment on it, then retrieve memories and information it knows about Eric, and mention how fitting to his personality it is to love that restaurant.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">-The agent has time notion so you can ask it to remind you to do something 10 minutes into the future, and it might remind your, or it might forget it because it was thinking about something more interesting. Very human!</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>OpenAI considering charging $2000/month for new model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/OpenAI/comments/1f9toyr/new_model_new_prices/&amp;sa=D&amp;source=editors&amp;ust=1730413583129027&amp;usg=AOvVaw0bcjS8IR_bORLKKTYItf9s">https://www.reddit.com/r/OpenAI/comments/1f9toyr/new_model_new_prices/</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span class="c1">Must be very good to even consider that price </span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 229.33px;"><img alt="" src="images/image210.png" style="width: 624.00px; height: 229.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Sequoia Capital said AI is overhyped: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.sequoiacap.com/article/ais-600b-question/&amp;sa=D&amp;source=editors&amp;ust=1730413583129418&amp;usg=AOvVaw2Q_xS1ViZXQtUn3J5MJKN9">https://www.sequoiacap.com/article/ais-600b-question/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span>&hellip;and then invested in Ilya Sutskever&rsquo;s AI startup after their investment to OpenAI was rejected because they had too much money already: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.ph/gzpmv&amp;sa=D&amp;source=editors&amp;ust=1730413583129658&amp;usg=AOvVaw256HHCG45NurVcKeqTyUKf">https://archive.ph/gzpmv</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Salesforce is looking to deploy a billion AI agents in the next 12 months: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fmgz3b/marc_benioff_says_microsoft_copilot_is_the_new/&amp;sa=D&amp;source=editors&amp;ust=1730413583129935&amp;usg=AOvVaw2TuPb6jqhTxKNX0Kw0G3sa">https://www.reddit.com/r/singularity/comments/1fmgz3b/marc_benioff_says_microsoft_copilot_is_the_new/</a></span></li><li class="c4 li-bullet-0"><span>OpenAI&#39;s Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests, and Noam Brown says everyone will know AGI has been achieved internally when they take down all their job listings: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583130227&amp;usg=AOvVaw1U9s2-zEt4ORnjYNbfRbx6">https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/</a></span></li><li class="c4 li-bullet-0"><span>A thread of a researcher sharing his team&#39;s findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/robertghrist/status/1841462507543949581?t%3D5zV3VpQI0mbrSU9_QRtfkQ%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583130553&amp;usg=AOvVaw1uV5Pv2RRsIW1peF-OqiDd">https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&amp;s=19</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 587.00px; height: 352.00px;"><img alt="" src="images/image544.png" style="width: 587.00px; height: 352.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 432.50px; height: 417.94px;"><img alt="" src="images/image459.png" style="width: 432.50px; height: 417.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span>Yes, LLMs can play Minecraft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/mckaywrigley/status/1849564319807426689&amp;sa=D&amp;source=editors&amp;ust=1730413583130988&amp;usg=AOvVaw3s70bvnyu_5vGfPG7BoFX-">https://x.com/mckaywrigley/status/1849564319807426689</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Google preps AI agent: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/google-preps-ai-that-takes-over-computers?utm_source%3Dsocial&amp;sa=D&amp;source=editors&amp;ust=1730413583131214&amp;usg=AOvVaw3MFVCc13vp-a_tE5oRVd-d">https://www.theinformation.com/articles/google-preps-ai-that-takes-over-computers</a></span></li><li class="c4 li-bullet-0"><span>Llama 4 Models are Training on a Cluster Bigger Than 100K H100&rsquo;s: Launching early 2025 with new modalities, stronger reasoning &amp; much faster: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.androidcentral.com/gaming/virtual-reality/meta-q3-2024-earnings&amp;sa=D&amp;source=editors&amp;ust=1730413583131475&amp;usg=AOvVaw2PL6NDIsM99PfcIHfS1nFl">https://www.androidcentral.com/gaming/virtual-reality/meta-q3-2024-earnings</a></span></li></ul><h2 class="c22 c80" id="h.s7xmn4is70x6"><span class="c40 c37 c48 c75">3.1. Benchmarks</span></h2><p class="c21"><span class="c15">Important to note the following:</span></p><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>If LLMs were specifically trained to score well on benchmarks, it could score 100% on all of them VERY easily with only a million parameters by purposefully overfitting: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2309.08632&amp;sa=D&amp;source=editors&amp;ust=1730413583131895&amp;usg=AOvVaw3S7Wy2B90XNk5gq6g1it7r">https://arxiv.org/pdf/2309.08632</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span class="c1">The fact that they don&rsquo;t shows companies are not just cheating.</span></li><li class="c10 li-bullet-0"><span class="c1">And if it&rsquo;s so easy to cheat, why doesn&rsquo;t every AI model score 100% on every benchmark? Why are they spending tens or hundreds of billions on compute and research when they can just train and overfit on the data? </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span class="c1">OpenAI still hasn&rsquo;t hard coded their LLMs to be correct for common questions like counting the number of &ldquo;r&rdquo;s in &ldquo;strawberry&rdquo; and finding the greater value between 9.11 and 9.8. If they wanted to cheat to increase benchmark scores, why wouldn&rsquo;t they solve these issues?</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 256.00px;"><img alt="" src="images/image387.png" style="width: 624.00px; height: 256.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 176.00px;"><img alt="" src="images/image140.png" style="width: 624.00px; height: 176.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span class="c1">Some benchmarks like the one used by Scale.ai and the test dataset of MathVista and ARC-AGI do not release their testing data to the public, so it is impossible to train on them.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span class="c1">Other benchmarks like LiveBench update every month so training on the dataset will not have any lasting effects</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Older models like GPT 2, 3, and 3.5 also trained on much of the internet. Why don&rsquo;t they score as high on benchmarks and are outperformed by smaller models (e.g how Qwen 2.5 72b is WAAAAY better than GPT 3 by every conceivable measure despite being 59% smaller)</span></li><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 834.67px;"><img alt="" src="images/image123.png" style="width: 624.00px; height: 834.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c22 c72 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583132880&amp;usg=AOvVaw3EB5DLATSJlWD8lUhEahjW">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 366.67px;"><img alt="" src="images/image56.jpg" style="width: 624.00px; height: 366.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c1">Molmo: State of the art multimodal open source using 1000x less data</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span class="c1">&quot;Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">Outperforming GPT-4o, Gemini 1.5 Pro &amp; Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.</span></li><li class="c10 li-bullet-0"><span>Info: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/blog&amp;sa=D&amp;source=editors&amp;ust=1730413583133361&amp;usg=AOvVaw2AzlLplpIyXDGE7whlmzZd">https://molmo.allenai.org/blog</a></span></li><li class="c10 li-bullet-0"><span>Try it: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/&amp;sa=D&amp;source=editors&amp;ust=1730413583133548&amp;usg=AOvVaw1sjWm7QdqOmILuEgn867RA">https://molmo.allenai.org</a></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 377.33px;"><img alt="" src="images/image52.png" style="width: 624.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 429.33px;"><img alt="" src="images/image415.png" style="width: 624.00px; height: 429.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span>Released here: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language&amp;sa=D&amp;source=editors&amp;ust=1730413583133946&amp;usg=AOvVaw1stp-jCTPgyqPn5dL_p6rz">https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>OpenAI o1 model released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/&amp;sa=D&amp;source=editors&amp;ust=1730413583134147&amp;usg=AOvVaw2Zszin00C8ixKuYSD63F93">https://openai.com/index/learning-to-reason-with-llms/</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span class="c1">o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).</span></li><li class="c10 li-bullet-0"><span class="c1">On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.</span></li><li class="c10 li-bullet-0"><span>ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413583134520&amp;usg=AOvVaw3NyiJMxE47BCVBIgwBaYM4">https://m.youtube.com/watch?v=a8QvnIAGjPA</a></span></li><li class="c10 li-bullet-0"><span class="c1">We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c7 li-bullet-0"><span class="c1">With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 &ndash; above the gold medal threshold &ndash; even without any test-time selection strategy. &nbsp;</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating</span><span class="c5 c107"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/%23citation-bottom-3&amp;sa=D&amp;source=editors&amp;ust=1730413583134932&amp;usg=AOvVaw2CsaOS-Q3IDqxKF3WIzbfX">3</a></span><span class="c1">&nbsp;of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1&mdash;it achieved an Elo rating of 1807, performing better than 93% of competitors.</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583135142&amp;usg=AOvVaw3Be8OjO_G9Di_izt1ougOP">https://cdn.openai.com/o1-system-card.pdf</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c7 li-bullet-0"><span class="c1">&nbsp;We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn&rsquo;t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the &ldquo;Unknown&rdquo; option (ambiguous questions). This is not necessarily an indicator of o1-preview&rsquo;s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 555.50px; height: 82.79px;"><img alt="" src="images/image1.png" style="width: 555.50px; height: 82.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.50px; height: 98.99px;"><img alt="" src="images/image288.png" style="width: 551.50px; height: 98.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 556.75px; height: 348.86px;"><img alt="" src="images/image344.png" style="width: 556.75px; height: 348.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.49px; height: 341.22px;"><img alt="" src="images/image116.png" style="width: 554.49px; height: 341.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 580.86px; height: 491.50px;"><img alt="" src="images/image95.png" style="width: 580.86px; height: 491.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.50px; height: 207.65px;"><img alt="" src="images/image206.png" style="width: 558.50px; height: 207.65px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 543.51px; height: 408.50px;"><img alt="" src="images/image286.png" style="width: 543.51px; height: 408.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.82px; height: 313.86px;"><img alt="" src="images/image203.png" style="width: 554.82px; height: 313.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 596.00px;"><img alt="" src="images/image575.jpg" style="width: 624.00px; height: 596.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DeryaTR_/status/1834630356286558336&amp;sa=D&amp;source=editors&amp;ust=1730413583136002&amp;usg=AOvVaw0cPl2amYeCeMFT9c_VtwvG">https://x.com/DeryaTR_/status/1834630356286558336</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 412.27px; height: 343.95px;"><img alt="" src="images/image326.png" style="width: 412.27px; height: 343.95px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 342.77px; height: 420.52px;"><img alt="" src="images/image9.png" style="width: 342.77px; height: 420.52px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 498.67px;"><img alt="" src="images/image68.png" style="width: 624.00px; height: 498.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c7 li-bullet-0"><span class="c92 c102 c42 c37">Note: This is the weakest model compared to o1-preview and the full o1 model</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 550.67px;"><img alt="" src="images/image88.png" style="width: 624.00px; height: 550.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c7 li-bullet-0"><span>Code generated by o1 for this: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://codeforces.com/blog/entry/134091&amp;sa=D&amp;source=editors&amp;ust=1730413583136524&amp;usg=AOvVaw1m-eugsRMLBztzpZhZg__3">https://codeforces.com/blog/entry/134091</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 386.67px;"><img alt="" src="images/image137.png" style="width: 624.00px; height: 386.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 c46 li-bullet-0"><span class="c92 c102 c42 c37"></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image163.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 605.33px;"><img alt="" src="images/image183.png" style="width: 624.00px; height: 605.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 657.33px;"><img alt="" src="images/image224.png" style="width: 624.00px; height: 657.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 730.67px;"><img alt="" src="images/image66.png" style="width: 624.00px; height: 730.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 494.67px;"><img alt="" src="images/image134.png" style="width: 624.00px; height: 494.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 495.62px; height: 928.50px;"><img alt="" src="images/image78.png" style="width: 495.62px; height: 928.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 479.29px; height: 912.50px;"><img alt="" src="images/image73.png" style="width: 479.29px; height: 912.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 394.67px;"><img alt="" src="images/image167.png" style="width: 624.00px; height: 394.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image619.png" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c7 li-bullet-0"><span>From AidanBench: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/aidanmclaughlin/Aidan-Bench?tab%3Dreadme-ov-file%23methodology&amp;sa=D&amp;source=editors&amp;ust=1730413583137385&amp;usg=AOvVaw1BemD5r5yDyXarbuNqpHPH">https://github.com/aidanmclaughlin/Aidan-Bench?tab=readme-ov-file#methodology</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c22 c32 li-bullet-0"><span class="c14">Progress on Francois Chollet&rsquo;s ARC benchmark (test data is hidden and much harder than the training data publicly released):</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 525.33px;"><img alt="" src="images/image541.png" style="width: 624.00px; height: 525.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.00px; height: 925.00px;"><img alt="" src="images/image505.png" style="width: 569.00px; height: 925.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c45 li-bullet-0"><span class="c63 c14">AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1814048365002596425&amp;sa=D&amp;source=editors&amp;ust=1730413583137797&amp;usg=AOvVaw2PvzoLDYUq5lIXsIBfF3pv">https://x.com/tsarnick/status/1814048365002596425</a></span></li><li class="c45 li-bullet-0"><span class="c14">Llama 3.1 benchmarks </span><span class="c34 c14">BEFORE instruct finetuning</span><span class="c14">: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 497.33px;"><img alt="" src="images/image574.png" style="width: 624.00px; height: 497.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c59 li-bullet-0"><span class="c1 c14">For comparison, Mistral 7b released this year as well</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c73 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 596.00px;"><img alt="" src="images/image649.png" style="width: 624.00px; height: 596.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c45 li-bullet-0"><span class="c1 c14">August 6 GPT 4o update:</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c59 li-bullet-0"><span class="c1 c14">The new GPT-4o is slightly better and 50% cheaper than the old one! &nbsp;Right now, it&#39;s only a tad below Sonnet 3.5 on Livebench!</span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 594.67px;"><img alt="" src="images/image61.png" style="width: 624.00px; height: 594.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 342.67px;"><img alt="" src="images/image115.png" style="width: 624.00px; height: 342.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c45 li-bullet-0"><span class="c14">NuminaMath 72b TIR model: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/JiaLi52524397/status/1814957190320631929/&amp;sa=D&amp;source=editors&amp;ust=1730413583138530&amp;usg=AOvVaw2Dl4-Ho6xvQ8ZQIYCZ_9iW">https://x.com/JiaLi52524397/status/1814957190320631929/</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c59 li-bullet-0"><span class="c1 c14">Trained on new competition math dataset ever released, with 860K problem solution pairs.</span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 514.67px;"><img alt="" src="images/image35.png" style="width: 624.00px; height: 514.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c45 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 353.37px; height: 199.07px;"><img alt="" src="images/image271.jpg" style="width: 353.37px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c14">GPT-4 scored higher than 100% of psychologists on a test of social intelligence:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413583139017&amp;usg=AOvVaw1dbSDQikI9tTZpug8KARKi">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413583139204&amp;usg=AOvVaw1L0Iz0BQiJv7q2qsnfx4Ng">https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full</a></span></li><li class="c4 li-bullet-0"><span>Agent Q, Research Breakthrough for the Next Generation of AI Agents with Planning &amp; Self Healing Capabilities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities&amp;sa=D&amp;source=editors&amp;ust=1730413583139521&amp;usg=AOvVaw12OidgSxQxmzic4-l5L07J">https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span>In real-world booking experiments on Open Table, MultiOn&rsquo;s Agents </span><span class="c15">drastically improved the zero-shot performance of the LLaMa-3 model from an 18.6% success rate to 81.7%, a 340% jump after just one day of autonomous data collection and further to 95.4% with online search.</span><span class="c1">&nbsp;These results highlight our method&rsquo;s efficiency and ability for autonomous web agent improvement.</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/&amp;sa=D&amp;source=editors&amp;ust=1730413583139854&amp;usg=AOvVaw1kZ4OBjPwzv4sNOSE_qRTE">https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 320.00px;"><img alt="" src="images/image302.jpg" style="width: 624.00px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c32 c14 li-bullet-0"><span>Can be improved with many samples: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.21787&amp;sa=D&amp;source=editors&amp;ust=1730413583140239&amp;usg=AOvVaw0xjTHfP6qFeyOuUtbuXyLB">https://arxiv.org/abs/2407.21787</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c3">When we apply repeated sampling to SWE-bench Lite, the fraction of issues solved with DeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250 samples, outperforming the single-attempt state-of-the-art of 43% which uses more capable frontier models. Moreover, using current API pricing, amplifying the cheaper DeepSeek model with five samples is more cost-effective and solves more issues than paying a premium for one sample from GPT-4o or Claude 3.5 Sonnet. Interestingly, the relationship between coverage and the number of samples is often log-linear and can be modeled with an exponentiated power law, suggesting the existence of inference-time scaling laws. </span></li><li class="c22 c72 c14 li-bullet-0"><span class="c3">When solving math word problems from GSM8K and MATH, coverage with Llama-3 models grows to over 95% with 10,000 samples.</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 512.00px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 512.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://mathvista.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583140774&amp;usg=AOvVaw1ty-ZJeCwHMiRYA4ESZvaX">https://mathvista.github.io/</a></span></li><li class="c22 c72 c14 li-bullet-0"><span class="c35 c34 c14 c127">test</span><span class="c92 c37 c35 c48 c14 c127">: 5,141 examples for standard evaluation. Notably, the answer labels for test will NOT be publicly released</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c92 c37 c35 c48 c14 c127">Human performance is 60.8%. Average human performance is from AMT annotators who have high school diplomas or above.</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 446.67px;"><img alt="" src="images/image435.jpg" style="width: 624.00px; height: 446.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span class="c1">Note that this test is an offline-only IQ quiz that a Mensa member created for my testing, which is *not in any AI training data* (so scores are lower than for public IQ tests.)</span></li><li class="c10 li-bullet-0"><span class="c1">Performed with o1-preview, which is worse than the full model </span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/maximlott/status/1834652893229859212&amp;sa=D&amp;source=editors&amp;ust=1730413583141315&amp;usg=AOvVaw0bJWlqX5PQYiLIBeMXSRsN">https://x.com/maximlott/status/1834652893229859212</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 754.67px;"><img alt="" src="images/image467.png" style="width: 624.00px; height: 754.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Qwen2.5 72B released and it matches performance of llama 3.1 405B: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://qwenlm.github.io/blog/qwen2.5/&amp;sa=D&amp;source=editors&amp;ust=1730413583141609&amp;usg=AOvVaw09FbiASRqiuuWtVJ2xPj9v">https://qwenlm.github.io/blog/qwen2.5/</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image584.png" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span class="c1">Scores of o1-preview and GPT-4o on &quot;official national exam in abstract mathematics used in Dutch high schools.&quot; Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: &quot;System 2 thinking in OpenAI&rsquo;s o1-preview model: Near-perfect performance on a mathematics exam&quot; &nbsp;</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 406.67px;"><img alt="" src="images/image132.png" style="width: 624.00px; height: 406.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>PlanBench results: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2409.13373&amp;sa=D&amp;source=editors&amp;ust=1730413583142121&amp;usg=AOvVaw07m5w3EFrgETZTOuopIWsF">https://arxiv.org/abs/2409.13373</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span>O1-preview is worse than the full o1 model</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 244.00px;"><img alt="" src="images/image54.png" style="width: 624.00px; height: 244.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 240.00px;"><img alt="" src="images/image479.png" style="width: 624.00px; height: 240.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 373.33px;"><img alt="" src="images/image404.png" style="width: 624.00px; height: 373.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://xcancel.com/PhilippeLaban/status/1838225567759429911&amp;sa=D&amp;source=editors&amp;ust=1730413583142826&amp;usg=AOvVaw3eCldSuMbqdU9KJQU4F5fr">https://xcancel.com/PhilippeLaban/status/1838225567759429911</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 326.67px;"><img alt="" src="images/image528.png" style="width: 624.00px; height: 326.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 321.33px;"><img alt="" src="images/image180.png" style="width: 624.00px; height: 321.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Gemini 1.5 002 beats o1-preview on MATH, and it does it at 1/10th the cost and no thinking time: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fohi2z/gemini_15_002_beats_o1preview_on_math_and_it_does/&amp;sa=D&amp;source=editors&amp;ust=1730413583143231&amp;usg=AOvVaw0uSFqpxo4mbcWSOecvLrzx">https://www.reddit.com/r/singularity/comments/1fohi2z/gemini_15_002_beats_o1preview_on_math_and_it_does</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 605.33px;"><img alt="" src="images/image285.png" style="width: 624.00px; height: 605.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 433.33px;"><img alt="" src="images/image535.png" style="width: 624.00px; height: 433.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span>The average human score for the evaluation dataset is 60.2%: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/MindsAI_Jack/status/1831648987834667278&amp;sa=D&amp;source=editors&amp;ust=1730413583143573&amp;usg=AOvVaw3xQoRVC80I7-u2PDbMZ-nf">https://x</a></span><span class="c5 c37 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://x.com/MindsAI_Jack/status/1831648987834667278&amp;sa=D&amp;source=editors&amp;ust=1730413583143697&amp;usg=AOvVaw33CkTzzkiNcW3s30X1lJXn">.com/MindsAI_Jack/status/1831648987834667278</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Nvidia just dropped a bombshell: Its new AI model is open, massive, and ready to rival GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4/&amp;sa=D&amp;source=editors&amp;ust=1730413583143992&amp;usg=AOvVaw16Oc0LUdTuPBAxhzrmYWHE">https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span class="c1">Only 72 billion parameters, 4% the size of GPT 4</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image289.png" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 550.67px;"><img alt="" src="images/image41.png" style="width: 624.00px; height: 550.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span class="c1">Nvidia Nemotron 70B - beats Llama 3.1 405B, GPT4o &amp; Claude 3.5 Sonnet on Arena Hard, AlpacaEval and MT Bench. They release the Instruct model, reward model and the dataset all on Hugging Face</span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image317.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c4 li-bullet-0"><span>Mistral introduces two new state-of-the-art models for on-device computing and at-the-edge use cases. &quot;We call them les Ministraux: Ministral 3B and Ministral 8B. These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/&amp;sa=D&amp;source=editors&amp;ust=1730413583144590&amp;usg=AOvVaw3SB6nGekatC-LL14rR2Flz">https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 266.67px;"><img alt="" src="images/image477.png" style="width: 624.00px; height: 266.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-0"><li class="c121 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/introducing-simpleqa/&amp;sa=D&amp;source=editors&amp;ust=1730413583144885&amp;usg=AOvVaw0EoD322zAaUF4fsS_j1w-Y">https://openai.com/index/introducing-simpleqa/</a></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-1 start"><li class="c121 c97 c105 li-bullet-0"><span class="c1">High confidence score correlates with higher accurracy and vice versa</span></li><li class="c121 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 502.67px;"><img alt="" src="images/image345.png" style="width: 624.00px; height: 502.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c121 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image98.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_bpsai7a4nzlw-2 start"><li class="c121 c86 li-bullet-0"><span class="c1">Not attempted = refusal to answer</span></li></ul><h2 class="c22 c80" id="h.ykmc45uwwbcd"><span>3.2. New Research</span></h2><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0 start"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 498.67px;"><img alt="" src="images/image141.png" style="width: 624.00px; height: 498.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583145689&amp;usg=AOvVaw2UJvLmcAJzAIo7bGXLxjqy">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><p class="c9 c129"><span class="c33 c15"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c15">Daily papers: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers&amp;sa=D&amp;source=editors&amp;ust=1730413583145989&amp;usg=AOvVaw1IOzoFYqVUWjmglQO0I8xN">https://huggingface.co/papers</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://koaning.github.io/arxiv-frontpage/&amp;sa=D&amp;source=editors&amp;ust=1730413583146172&amp;usg=AOvVaw2iNTDdEmty3ooOpkiv3Wa-">https://koaning.github.io/arxiv-frontpage/</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Automating Thought of Search: A Journey Towards Soundness and Completeness. &#39;We achieve 100% accuracy, with minimal feedback iterations, using LLMs of various sizes on all evaluated domains.&#39; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.11326&amp;sa=D&amp;source=editors&amp;ust=1730413583146405&amp;usg=AOvVaw3six51MpGBxRnn7_3uhqO-">https://arxiv.org/abs/2408.11326</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Agent Q, </span><span>Research Breakthrough for the Next Generation of AI Agents with Planning &amp; Self Healing Capabilities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities&amp;sa=D&amp;source=editors&amp;ust=1730413583146816&amp;usg=AOvVaw3ohLyahIopsqQ-YDF5kSvC">https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span>In real-world booking experiments on Open Table, MultiOn&rsquo;s Agents </span><span class="c15">drastically improved the zero-shot performance of the LLaMa-3 model from an 18.6% success rate to 81.7%, a 340% jump after just one day of autonomous data collection and further to 95.4% with online search.</span><span class="c1">&nbsp;These results highlight our method&rsquo;s efficiency and ability for autonomous web agent improvement.</span></li><li class="c10 li-bullet-0"><span class="c63 c34 c134">Guided Search with MCTS</span><span class="c19">: This technique autonomously generates data by exploring different actions and web-pages, balancing exploration and exploitation. MCTS expands the action space using high sampling temperatures and diverse prompting, ensuring diverse and optimal trajectory collections.</span></li><li class="c10 li-bullet-0"><span class="c63 c34 c134">AI Self-Critique</span><span class="c19">: At each step, AI-based self-critique provides valuable feedback, refining the agent&#39;s decision-making process. This step-level feedback is crucial for long-horizon tasks, where sparse signals often lead to learning difficulties.</span></li><li class="c10 li-bullet-0"><span class="c63 c34 c134">Direct Preference Optimization</span><span class="c63 c134">: The DPO algorithm fine-tunes the model by constructing preference pairs from MCTS-generated data. This off-policy training method allows the model to learn effectively from aggregate datasets including the sub-optimal branches explored during search, improving success rates in complex environments.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers. &#39;rStar boosts GSM8K accuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% for Mistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct&#39; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.06195&amp;sa=D&amp;source=editors&amp;ust=1730413583147427&amp;usg=AOvVaw1EFjWgutq5zq8w45r5MHgT">https://arxiv.org/abs/2408.06195</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>This AI Learns Continuously From New Experiences&mdash;Without Forgetting Its Past: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://singularityhub.com/2024/08/22/this-ai-learns-continuously-from-new-experiences-without-forgetting-its-past/&amp;sa=D&amp;source=editors&amp;ust=1730413583147739&amp;usg=AOvVaw0ek2S1Ec5lnj4IFZiBzJS3">https://singularityhub.com/2024/08/22/this-ai-learns-continuously-from-new-experiences-without-forgetting-its-past/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>D</span><span>iffusion Augmented Agents can autonomously learn and generate infinite synthetic data: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.20798&amp;sa=D&amp;source=editors&amp;ust=1730413583148008&amp;usg=AOvVaw1zVdWYTx9A9QlSQ_QSl7eI">https://arxiv.org/abs/2407.20798</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>We introduce Diffusion Augmented Agents (DAAG), a novel framework that leverages large language models, vision language models, and diffusion models to improve sample efficiency and transfer learning in reinforcement learning for embodied agents. DAAG hindsight relabels the agent&#39;s past experience by using diffusion models to transform videos in a temporally and geometrically consistent way to align with target instructions with a technique we call Hindsight Experience Augmentation. A large language model orchestrates this </span><span class="c15">autonomous process without requiring human supervision, making it well-suited for lifelong learning scenarios</span><span>. The framework reduces the amount of reward-labeled data needed to 1) finetune a vision language model that acts as a reward detector, and 2) train RL agents on new tasks. We demonstrate the sample efficiency gains of DAAG in simulated robotics environments involving manipulation and navigation. Our results show that DAAG </span><span class="c15">improves learning of reward detectors, transferring past experience, and acquiring new tasks - key abilities for developing efficient lifelong learning agents</span><span>. Supplementary material and visualizations are available on our website </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://sites.google.com/view/diffusion-augmented-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413583148442&amp;usg=AOvVaw3FM83c47mjIUx_M9MfIiVf">this https URL</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://sites.google.com/view/diffusion-augmented-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413583148600&amp;usg=AOvVaw07gtrfM_vU6KIczkeUWi-_">https://sites.google.com/view/diffusion-augmented-agents/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/meta-drops-ai-bombshell-multi-token-prediction-models-now-open-for-research/&amp;sa=D&amp;source=editors&amp;ust=1730413583148849&amp;usg=AOvVaw32X-nK5WqPoKNJ-3uXuqPz">https://venturebeat.com/ai/meta-drops-ai-bombshell-multi-token-prediction-models-now-open-for-research/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>&gt;</span><span class="c1">3x faster token prediction means 3x cheaper and on top of that it seems to greatly increase coding, summarization, and mathematical reasoning abilities. Best of all the improvements have shown to only become more significant with larger models (13b+ according to the paper). Unlike some other research where improvements are mostly seen in smaller models and won&#39;t advance the frontier, this is infact worse performing on smaller models and shows great potential at scale. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Google DeepMind&#39;s JEST method </span><span class="c15">can reduce AI training time by a factor of 13 and decreases computing power demand by 90%</span><span>. The method uses another pretrained reference model to select data subsets for training based on their &quot;collective learnability: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.17711v1&amp;sa=D&amp;source=editors&amp;ust=1730413583149388&amp;usg=AOvVaw1izcdgTbL1AoMEiNBsJg_H">https://arxiv.org/html/2406.17711v1</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>CriticGPT is intended to help identify hallucinations as models grow more sophisticated and is better than humans or even humans using CriticGPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://spectrum.ieee.org/openai-rlhf&amp;sa=D&amp;source=editors&amp;ust=1730413583149738&amp;usg=AOvVaw08oiJEvIPG7u7vSqb1nw9b">https://spectrum.ieee.org/openai-rlhf</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 469.33px;"><img alt="" src="images/image425.png" style="width: 624.00px; height: 469.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Effective strategy to reduce hallucinations: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/GAIR-NLP/alignment-for-honesty&amp;sa=D&amp;source=editors&amp;ust=1730413583150173&amp;usg=AOvVaw1gIMQI8yoC3sFSOglYBLyE">https://github.com/GAIR-NLP/alignment-for-honesty</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image119.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 547.14px; height: 585.42px;"><img alt="" src="images/image405.png" style="width: 547.14px; height: 585.42px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Researchers describe how to tell if ChatGPT is confabulating: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/&amp;sa=D&amp;source=editors&amp;ust=1730413583150690&amp;usg=AOvVaw0jdVLi2iZYH_IOxywiXKWc">https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>Two things became apparent during these tests. One is that, except for a few edge cases, </span><span class="c15">semantic entropy caught more false answers than any other methods. </span><span class="c1">The second is that most errors produced by LLMs appear to be confabulations. That can be inferred from the fact that some of the other methods catch a variety of error types, yet they were outperformed by semantic entropy tests, even though these tests only catch confabulations.</span></li><li class="c10 li-bullet-0"><span>The researchers also demonstrate that the system can be </span><span class="c15">adapted to work with more than basic factual statements by altering to handle biographies, which are a large collection of individual facts</span><span class="c1">. So they developed software that broke down biographical information into a set of individual factual statements and evaluated each of these using semantic entropy. This worked on a short biography with as many as 150 individual factual claims.</span></li><li class="c10 li-bullet-0"><span>Overall, this seems to be a highly flexible system that </span><span class="c15">doesn&#39;t require major new developments to put into practice and could provide some significant improvements in LLM performance</span><span>. And, since it only catches confabulations and not other types of errors, </span><span class="c33 c15">it might be possible to combine it with other methods to boost performance even further.</span></li><li class="c10 li-bullet-0"><span>As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they&#39;ve got the right answer; it&#39;s just not being leveraged. As they put it, &quot;</span><span class="c15">The success of semantic entropy at detecting errors suggests that LLMs are even better at &#39;knowing what they don&rsquo;t know&#39; than was argued... they just don&rsquo;t know they know what they don&rsquo;t know.</span><span class="c1">&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>CSCG (Clone-structured causal graphs) - A Breakthrough on the way to AGI. Schema-learning and rebinding as mechanisms of in-context learning and emergence: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/sciadv.adm8470&amp;sa=D&amp;source=editors&amp;ust=1730413583151720&amp;usg=AOvVaw3fUshtINzWb8LAlZOfhRBy">https://www.science.org/doi/10.1126/sciadv.adm8470</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span class="c1">tldr - they found a way to map a chain of states e.g. pictures of an environment into a cognitive map. meaning without training on spatial data like the locations of where is which object. basically how humans learn their environment</span></li><li class="c10 li-bullet-0"><span class="c1">imo this is useful for robotics where you have a lot of camera input and want to construct a map of a road, building etc. without having location data</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Mixture of Agents can beat GPT-4o: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/togethercompute/status/1800536106729157054?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583152152&amp;usg=AOvVaw15wssvyPiSRHyA2vrQlHec">https://x.com/togethercompute/status/1800536106729157054?s=46</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 262.67px;"><img alt="" src="images/image562.png" style="width: 624.00px; height: 262.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>This paper claims </span><span>that Llama3-8B+BoT</span><span>&nbsp;(Buffer of Thoughts) has the potential to surpass Llama3-70B model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/rohanpaul_ai/status/1811458648532775202&amp;sa=D&amp;source=editors&amp;ust=1730413583152498&amp;usg=AOvVaw1IbRQVu2iav6zeVHX7ZeOM">https://x.com/rohanpaul_ai/status/1811458648532775202</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c1">&#39;Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models&#39;</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- Propose buffer-manager to dynamically update the meta-buffer, thus enhancing the capacity of meta-buffer as more tasks are solved.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- Achieve significant performance improvement over previous SOTA methods: 11% on Game of 24, 20% on Geometric Shapes and 51% on Checkmate-in-One.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- Superior generalization ability and model robustness of our BoT, while requiring only 12% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 605.50px; height: 334.77px;"><img alt="" src="images/image401.png" style="width: 605.50px; height: 334.77px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 381.33px;"><img alt="" src="images/image633.png" style="width: 624.00px; height: 381.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14 c31">Drawing out steps as images using Python to do reasoning: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.14562&amp;sa=D&amp;source=editors&amp;ust=1730413583153259&amp;usg=AOvVaw1_X3EjGONkVm1kiAFXz5vg">https://arxiv.org/abs/2406.14562</a></span></li></ul><p class="c9"><span class="c3"></span></p><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span class="c14 c31">This simple approach shows state-of-the-art results on four difficult natural language tasks that involve visual and spatial reasoning. We identify multiple settings where GPT-4o using chain-of-thought fails dramatically, including </span><span class="c15 c31">more than one where it achieves </span><span class="c15 c169">0% </span><span class="c15 c31">accuracy, while whiteboard-of-thought enables up to </span><span class="c15 c169">92% </span><span class="c15 c31">accuracy </span><span class="c14 c31">in these same settings.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c33 c15">Over 32 techniques to reduce hallucinations:</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.01313&amp;sa=D&amp;source=editors&amp;ust=1730413583153879&amp;usg=AOvVaw2nkKHGIR6wPQO3mv2u7tii">https://arxiv.org/abs/2401.01313</a></span></li></ul><p class="c9 c105"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba&rsquo;s selective SSM that is </span><span class="c15">2-8&times; faster</span><span class="c14">, while continuing to be competitive with Transformers on language modeling: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.21060&amp;sa=D&amp;source=editors&amp;ust=1730413583154256&amp;usg=AOvVaw3cuKgOe2awj_LougM2JTZS">https://arxiv.org/pdf/2405.21060</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c14">Loss:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 609.13px; height: 412.92px;"><img alt="" src="images/image462.png" style="width: 609.13px; height: 412.92px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/ctnzr/status/1801050835197026696&amp;sa=D&amp;source=editors&amp;ust=1730413583154583&amp;usg=AOvVaw20citUYQVp563Tq3VomUm0">https://x.com/ctnzr/status/1801050835197026696</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-2 start"><li class="c7 li-bullet-0"><span class="c1">A 8B-3.5T hybrid SSM model gets better accuracy than an 8B-3.5T transformer trained on the same dataset:</span></li><li class="c7 li-bullet-0"><span class="c1">* 7% attention, the rest is Mamba2</span></li><li class="c7 li-bullet-0"><span class="c1">* MMLU jumps from 50 to 53.6%</span></li><li class="c7 li-bullet-0"><span class="c1">* Training efficiency is the same</span></li><li class="c7 li-bullet-0"><span class="c1">* Inference cost is much less</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 285.06px; height: 187.29px;"><img alt="" src="images/image359.png" style="width: 285.06px; height: 187.29px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>Analysis: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.07887&amp;sa=D&amp;source=editors&amp;ust=1730413583155113&amp;usg=AOvVaw0WKxG0qoObdJ2rQJFdYtPc">https://arxiv.org/abs/2406.07887</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-2"><li class="c7 li-bullet-0"><span class="c14 c31">we find that the 8B Mamba-2-Hybrid</span><span class="c15 c31">&nbsp;exceeds the 8B Transformer on all 12 standard tasks we evaluated (+2.65 points on average) and is predicted to be up to 8x faster when generating tokens at inference time</span><span class="c14 c31">. To validate long-context capabilities, we provide additional experiments evaluating variants of the Mamba-2-Hybrid and Transformer extended to support 16K, 32K, and 128K sequences. On an additional 23 long-context tasks, the hybrid model </span><span class="c15 c31">continues to closely match or exceed the Transformer on average</span><span class="c3">. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>Jamba: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2403.19887&amp;sa=D&amp;source=editors&amp;ust=1730413583155666&amp;usg=AOvVaw2p_q2NVpoxcqGLH63ktXfg">https://arxiv.org/abs/2403.19887</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-2"><li class="c7 li-bullet-0"><span>Jamba provides</span><span class="c15">&nbsp;high throughput and small memory footprint compared to vanilla Transformers, and at the same time state-of-the-art performance </span><span class="c1">on standard language model benchmarks and long-context evaluations. Remarkably, the model presents strong results for up to 256K tokens context length. </span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c18">Sonic, a blazing fast &nbsp;(&#128640; 135ms model latency), lifelike generative voice model and API: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/cartesia_ai/status/1795856778456084596&amp;sa=D&amp;source=editors&amp;ust=1730413583156203&amp;usg=AOvVaw06Ofbg-rjoMR4hIocEdcij">https://x.com/cartesia_ai/status/1795856778456084596</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span class="c18">&gt;Sonic is built on our </span><span class="c15 c65 c114">new state space model architecture</span><span class="c40 c18">&nbsp;for efficiently modeling high-res data like audio and video.</span></li><li class="c10 li-bullet-0"><span class="c18">On speech, a parameter-matched and optimized Sonic model trained on the same data as a widely used Transformer </span><span class="c40 c15 c65 c114">improves audio quality significantly (20% lower perplexity, 2x lower word error, 1 point higher NISQA quality).With lower latency (1.5x lower time-to-first-audio), faster inference speed (2x lower real-time factor) and higher throughput (4x).</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 608.00px;"><img alt="" src="images/image617.png" style="width: 624.00px; height: 608.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c15 c65 c114">SOTA Vision encoder using MAMBA: </span><span class="c5 c15 c65 c114"><a class="c13" href="https://www.google.com/url?q=https://github.com/NVlabs/MambaVision&amp;sa=D&amp;source=editors&amp;ust=1730413583156816&amp;usg=AOvVaw111YbIbFNwW7YI_WoSnduo">https://github.com/NVlabs/MambaVision</a></span></li></ul><p class="c9"><span class="c40 c15 c65 c114"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c15 c31">Dramatically overfitting on transformers leads to SIGNIFICANTLY better performance: </span><span class="c5 c15 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.15071&amp;sa=D&amp;source=editors&amp;ust=1730413583157064&amp;usg=AOvVaw2ag6VWB3XmWNPDumkRHtQn">https://arxiv.org/abs/2405.15071</a></span><span class="c28 c43">&nbsp;</span></li></ul><p class="c9"><span class="c28 c43"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>&nbsp;&gt;Our</span><span class="c14 c31">&nbsp;findings guide data and training setup to </span><span class="c15 c31">better induce implicit reasoning </span><span class="c14 c31">and suggest potential improvements to the transformer architecture, such as encouraging cross-layer knowledge sharing. Furthermore, we demonstrate that for a challenging reasoning task with a large search space, GPT-4-Turbo and Gemini-1.5-Pro based on non-parametric memory fail badly regardless of prompting styles or retrieval augmentation, </span><span class="c15 c31">while a fully grokked transformer can achieve near-perfect accuracy</span><span class="c3">, showcasing the power of parametric memory for complex reasoning.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span class="c14 c31">Accuracy increased from </span><span class="c28 c43">33.3% on GPT4 to 99.3%</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 116.00px;"><img alt="" src="images/image363.png" style="width: 624.00px; height: 116.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 382.67px;"><img alt="" src="images/image555.jpg" style="width: 624.00px; height: 382.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-2 start"><li class="c7 li-bullet-0"><span class="c3">Test (ID) means it was NOT in the training data but is related to the original tasks (e.g learning 2+4 and 5+3 and then solving 2+5)</span></li><li class="c7 li-bullet-0"><span class="c3">Test (OOD) means &ldquo;out of distribution,&rdquo; meaning it is NOT even related to the training data (e.g learning 2+4 and 5+2 and then being asked to write code in Python)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion. &quot;leads to marked performance gains in decision-making and planning tasks.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://boyuan.space/diffusion-forcing/&amp;sa=D&amp;source=editors&amp;ust=1730413583158007&amp;usg=AOvVaw1xQy20akBjDPqIgjCkhJNx">https://boyuan.space/diffusion-forcing/</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 172.00px;"><img alt="" src="images/image121.png" style="width: 624.00px; height: 172.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span>LLMs Can&#39;t Plan, But Can Help Planning in LLM-Modulo Frameworks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.01817&amp;sa=D&amp;source=editors&amp;ust=1730413583158316&amp;usg=AOvVaw3Il_pkHRgULBZymCiw5V1C">https://arxiv.org/abs/2402.01817</a></span><span class="c1">&nbsp;</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c22 c72 c14 li-bullet-0"><span>&gt;We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework </span><span class="c34">provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows </span><span class="c33 c15">extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.</span></li></ul><p class="c22 c44 c14"><span class="c33 c15"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c15">TransNAR architecture improves reasoning both in and out of distribution: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.09308&amp;sa=D&amp;source=editors&amp;ust=1730413583158810&amp;usg=AOvVaw0r5q0oeHODuAXKrXUGKCeX">https://arxiv.org/pdf/2406.09308</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span class="c14">&gt;Such NARs proved effective as generic solvers for algorithmic tasks, when specified in graph form. To make their embeddings accessible to a Transformer, we propose a hybrid architecture with a two- phase training procedure, allowing the tokens in the lan- guage model to cross-attend to the node embeddings from the NAR. We evaluate our resulting TransNAR model on CLRS-Text, the text-based version of the CLRS-30 bench- mark, and</span><span class="c33 c15">&nbsp;demonstrate significant gains over Transformer- only models for algorithmic reasoning, both in and out of distribution.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 561.00px;"><img alt="" src="images/image426.png" style="width: 624.00px; height: 561.00px; margin-left: -24.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2404.03683v1&amp;sa=D&amp;source=editors&amp;ust=1730413583159354&amp;usg=AOvVaw2zHjPuMd3NgUueH-gF4lXC">https://arxiv.org/html/2404.03683v1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span class="c14">&gt;Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string &mdash; a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers</span><span class="c15">. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory</span><span class="c14">. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models</span><span class="c15">&nbsp;solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers.</span><span class="c14">&nbsp;Our results indicate that language models </span><span class="c33 c15">can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. </span></li></ul><p class="c9 c105"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14 c31">LLMs learns to train better LLMs: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/hardmaru/status/1801074062535676193&amp;sa=D&amp;source=editors&amp;ust=1730413583159883&amp;usg=AOvVaw1__Xj58ByXN8NxFBOXazx6">https://x.com/hardmaru/status/1801074062535676193</a></span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>&nbsp;Med-Gemini : </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.18416&amp;sa=D&amp;source=editors&amp;ust=1730413583160102&amp;usg=AOvVaw1evgWaXuYWMYv97k2ajONK">https://arxiv.org/abs/2404.18416</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 li-bullet-0"><span class="c14 c31">We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves </span><span class="c15 c31">SoTA performance of 91.1% accuracy</span><span class="c14 c31">, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health &amp; medicine), Med-</span><span class="c15 c31">Gemini improves over GPT-4V by an average relative margin of 44.5%</span><span class="c14 c31">. We demonstrate the effectiveness of Med-Gemini&#39;s long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini&#39;s performance suggests real-world utility by </span><span class="c15 c31">surpassing human experts</span><span class="c3">&nbsp;on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">An</span><span class="c15">&nbsp;infinite context window is possible</span><span class="c14">, and it can remember what you sent even a million messages ago: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2404.07143v1?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583160625&amp;usg=AOvVaw24bSFk433NFgGWaBeYCOIZ">https://arxiv.org/html/2404.07143v1?darkschemeovr=1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>&gt;</span><span>This subtle but critical modification to the attention layer enables LLMs to process </span><span class="c15">infinitely long contexts with bounded memory and computation resources</span><span>. We show that our approach can naturally scale to a million length regime of input sequences, while </span><span class="c15">outperforming the baselines on long-context language modeling benchmark and book summarization tasks</span><span class="c1">. We also demonstrate a promising length generalization capability of our approach. 1B model that was fine-tuned on up to 5K sequence length passkey instances solved the 1M length problem.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Human-like Episodic Memory for Infinite Context LLMs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1812678969386234046&amp;sa=D&amp;source=editors&amp;ust=1730413583161054&amp;usg=AOvVaw3VcUxMKAsUkfgHUPZjZa1e">https://x.com/_akhaliq/status/1812678969386234046</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span>&gt;When needed, these events are retrieved through a two-stage memory process, combining similarity-based and temporally contiguous retrieval for efficient and human-like access to relevant information. Experiments on the LongBench dataset demonstrate EM-LLM&#39;s superior performance,</span><span class="c15">&nbsp;outperforming the state-of-the-art InfLLM model with an overall relative improvement of 4.3% across various tasks, including a 33% improvement on the PassageRetrieval task. </span><span>Furthermore, </span><span class="c15">our analysis reveals strong correlations between EM-LLM&#39;s event segmentation and human-perceived events suggesting a bridge between this artificial system and its biological counterpart.</span><span>&nbsp;This work not only advances LLM capabilities in processing extended contexts but also provides a computational framework for exploring human memory mechanisms, opening new avenues for interdisciplinary research in AI and cognitive science.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Learning to (Learn at Test Time): RNNs with Expressive Hidden States. &quot;TTT layers directly replace attention, and unlock linear complexity architectures with expressive memory, allowing us to </span><span class="c15">train LLMs with millions (someday billions) of tokens in context</span><span>&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.04620&amp;sa=D&amp;source=editors&amp;ust=1730413583162466&amp;usg=AOvVaw0ckQjGINNfK6MTf1oZcHId">https://arxiv.org/abs/2407.04620</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">Models 1/200th the size of SOTA models outperform them in math using Q*: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/deedydas/status/1802019023422627889&amp;sa=D&amp;source=editors&amp;ust=1730413583162826&amp;usg=AOvVaw0X1Z6LyEHJX5zRhu1nPl8m">https://x.com/deedydas/status/1802019023422627889</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 200.00px;"><img alt="" src="images/image179.jpg" style="width: 624.00px; height: 200.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">Introducing &#129518;Abacus Embeddings, a simple tweak to positional embeddings that</span><span class="c15">&nbsp;enables LLMs to do addition, multiplication, sorting, and more</span><span class="c14">. Our Abacus Embeddings </span><span class="c15">trained only on 20-digit addition generalise near perfectly to 100+ digits: </span><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/SeanMcleish/status/1795481814553018542&amp;sa=D&amp;source=editors&amp;ust=1730413583163272&amp;usg=AOvVaw3kiH4mBz8ish8qSbDbnNko">https://x.com/SeanMcleish/status/1795481814553018542</a></span><span>&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 478.50px; height: 245.38px;"><img alt="" src="images/image455.png" style="width: 478.50px; height: 245.38px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 316.00px;"><img alt="" src="images/image343.png" style="width: 624.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c44 c14 c129"><span class="c33 c15"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c34 c14 c31">&nbsp;Scores on SWE Bench Lite have increased by 83% from April to June 2024, up to 33% in June: </span><span class="c5 c34 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://swe-bench.com&amp;sa=D&amp;source=editors&amp;ust=1730413583163758&amp;usg=AOvVaw2yqb7SXr37HLhMJ2QlBvUE">https://swebench.com</a></span><span class="c28 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c14 c28">Increased to 43% in July. A 30% boost in 1 month!</span></li></ul><p class="c22 c44 c14"><span class="c33 c15"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c15">Step aware performance optimization: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04314&amp;sa=D&amp;source=editors&amp;ust=1730413583164094&amp;usg=AOvVaw1Vfnm0hLrs09lxl38Oh523">https://huggingface.co/papers/2406.04314</a></span><span class="c33 c15">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">Our experiments with Stable Diffusion v1.5 and SDXL demonstrate that </span><span class="c15 c35 c54">SPO significantly outperforms the latest Diffusion-DPO in aligning generated images with complex, detailed prompts and enhancing aesthetics</span><span class="c35 c14 c54">, while also achieving more than </span><span class="c2">20x times faster in training efficiency</span></li></ul><p class="c22 c44 c14"><span class="c2"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2405.00732&amp;sa=D&amp;source=editors&amp;ust=1730413583164447&amp;usg=AOvVaw0gGUiQR_TYYZflOquQwBmm">https://huggingface.co/papers/2405.00732</a></span><span class="c92 c37 c35 c48 c14 c54">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">We find that 4-bit LoRA fine-tuned models </span><span class="c2">outperform base models by 34 points and GPT-4 by 10 points on average. </span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04324&amp;sa=D&amp;source=editors&amp;ust=1730413583164744&amp;usg=AOvVaw25Pq11EsVaKVSlqfHZuFFE">https://huggingface.co/papers/2406.04324</a></span><span class="c92 c37 c35 c48 c14 c54">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">We show that, through the adversarial training, the multi-steps video diffusion model, i.e., Stable Video Diffusion (SVD), </span><span class="c15 c35 c54">can be trained to perform single forward pass to synthesize high-quality videos, capturing both temporal and spatial dependencies in the video data</span><span class="c35 c14 c54">. Extensive experiments demonstrate that our method achieves </span><span class="c15 c35 c54">competitive generation quality of synthesized videos with significantly reduced computational overhead for the denoising process </span><span class="c35 c14 c54">(i.e., around </span><span class="c15 c35 c54">23 times speedup compared with SVD and 6 times speedup compared with existing works, with even better generation quality</span><span class="c35 c14 c54">), paving the way for </span><span class="c2">real-time video synthesis and editing. </span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04271&amp;sa=D&amp;source=editors&amp;ust=1730413583165140&amp;usg=AOvVaw0kGTNI23bcXCgR0exBIgUZ">https://huggingface.co/papers/2406.04271</a></span><span class="c92 c37 c35 c48 c14 c54">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">We conduct extensive experiments on 10 challenging reasoning-intensive tasks, and </span><span class="c15 c35 c54">achieve significant performance improvements</span><span class="c35 c34 c14 c54">&nbsp;</span><span class="c35 c14 c54">over previous SOTA methods: 11% on Game of 24, 20% on Geometric Shapes and 51% on Checkmate-in-One. Further analysis demonstrate the </span><span class="c15 c35 c54">superior generalization ability and model robustness of our BoT, while requiring only 12% of the cost of multi-query prompting methods </span><span class="c35 c14 c54">(e.g., tree/graph of thoughts) on average. Notably, we find that our </span><span class="c2">Llama3-8B+BoT has the potential to surpass Llama3-70B model</span></li></ul><p class="c22 c44 c14"><span class="c92 c37 c35 c48 c14 c54"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c33 c15">JEPA led by Turing Award winner and &ldquo;Godfather of AI&rdquo; Yann LeCun</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c5 c34"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2403.00504&amp;sa=D&amp;source=editors&amp;ust=1730413583165651&amp;usg=AOvVaw27WrbGrXcLhDXkUy0NZJ-L">https://arxiv.org/abs/2403.00504</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-2 start"><li class="c22 c104 c86 c14 li-bullet-0"><span class="c14 c31">While previously limited to predicting missing parts of an input, we explore how to </span><span class="c34 c14 c31">generalize the JEPA prediction task to a broader set of corruptions</span><span class="c14 c31">. We introduce Image World Models, an approach that goes </span><span class="c34 c14 c31">beyond masked image modeling </span><span class="c14 c31">and learns to </span><span class="c34 c14 c31">predict the effect of global photometric transformations</span><span class="c14 c31">&nbsp;in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to </span><span class="c34 c14 c31">solve diverse tasks</span><span class="c14 c31">; a fine-tuned IWM world model</span><span class="c15 c31">&nbsp;matches or surpasses the performance of previous self-supervised methods</span><span class="c14 c31">. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c22 c72 c14 li-bullet-0"><span class="c5 c34"><a class="c13" href="https://www.google.com/url?q=https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/&amp;sa=D&amp;source=editors&amp;ust=1730413583166203&amp;usg=AOvVaw2lBSo9UIxRMqRaN1NXEK_7">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-2 start"><li class="c22 c104 c86 c14 li-bullet-0"><span class="c34">Can learn from </span><span class="c33 c15">ONLY A FEW EXAMPLES</span></li><li class="c22 c104 c86 c14 li-bullet-0"><span>Understands </span><span class="c34">semantic information </span><span class="c1">rather than trying to predict every pixel</span></li><li class="c22 c104 c86 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.50px; height: 231.04px;"><img alt="" src="images/image306.png" style="width: 554.50px; height: 231.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c10 li-bullet-0"><span class="c5 c34"><a class="c13" href="https://www.google.com/url?q=https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/&amp;sa=D&amp;source=editors&amp;ust=1730413583166666&amp;usg=AOvVaw0uvlIxOWqrSAcLM0qfRcBx">https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/</a></span><span class="c33 c34">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 639.25px; height: 503.38px;"><img alt="" src="images/image502.png" style="width: 639.25px; height: 503.38px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 661.50px; height: 371.85px;"><img alt="" src="images/image259.png" style="width: 661.50px; height: 371.85px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span>Introducing HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.14831&amp;sa=D&amp;source=editors&amp;ust=1730413583167053&amp;usg=AOvVaw2rfVbgNokZJYZs8KBsxSM8">https://arxiv.org/abs/2405.14831</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">We compare HippoRAG with existing RAG methods on multi-hop question answering and show that our method</span><span class="c15 c31">&nbsp;outperforms the state-of-the-art methods remarkably, by up to 20%.</span><span class="c14 c31">&nbsp;Single-step retrieval with HippoRAG achieves comparable or better performance than iterative retrieval like IRCoT while being</span><span class="c15 c31">&nbsp;10-30 times cheaper and 6-13 times faster</span><span class="c14 c31">, and integrating HippoRAG into IRCoT brings </span><span class="c28 c43">further substantial gains.</span></li></ul><p class="c9 c129"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>OpenAI&rsquo;s ChatGPT can improve its capabilities through self play and the use of Agents: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DewLMYLCWvcI&amp;sa=D&amp;source=editors&amp;ust=1730413583167546&amp;usg=AOvVaw0D8TJ3MPFSyq8IqG_dTtys">https://www.youtube.com/watch?v=ewLMYLCWvcI</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c1">Utilizing a multi-agent approach, this system effectively tackles the intricate nuances inherent in literary texts. </span></li><li class="c10 li-bullet-0"><span>Empirical findings indicate that despite lower d-BLEU scores, translations from TransAgents are </span><span class="c15">preferred by both human evaluators and LLMs over human-written references</span><span>, particularly in genres </span><span class="c33 c15">requiring domain-specific knowledge. </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">Researchers shows </span><span class="c15">Model Collapse is easily avoided</span><span class="c14">&nbsp;by keeping old human data with new synthetic data in the training set: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.01413&amp;sa=D&amp;source=editors&amp;ust=1730413583167985&amp;usg=AOvVaw3siokwq61HIlU2HxssGmZs">https://arxiv.org/abs/2404.01413</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">[Teaching Language Models to Hallucinate Less with Synthetic Tasks](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.06827?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583168247&amp;usg=AOvVaw0-2BT35wXwQniJr2X_d7rI">https://arxiv.org/abs/2310.06827?darkschemeovr=1</a></span><span class="c1 c14">&nbsp;)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>We then illustrate a path towards ASI via open-ended systems built on top of foundation models, capable of making novel, human relevant discoveries. We conclude by examining the safety implications of generally-capable openended AI.&quot; </span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.04268&amp;sa=D&amp;source=editors&amp;ust=1730413583168535&amp;usg=AOvVaw19jke9wiQEM8kLdboFUBQy">https://arxiv.org/abs/2406.04268</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">Researchers gave AI an &#39;inner monologue&#39; and it </span><span class="c15">massively improved its performance</span><span class="c14">&nbsp;| Scientists trained an AI system to think before speaking with a technique called QuietSTaR. The inner monologue </span><span class="c15">improved common sense reasoning and doubled math performance </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance&amp;sa=D&amp;source=editors&amp;ust=1730413583168963&amp;usg=AOvVaw3N58xieT64iVLkFrX8rJh-">https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">MIT researchers, Max Tegmark and others develop new kind of neural network &ldquo;Kolmogorov-Arnold network&ldquo; that scales much faster than traditional ones </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.19756&amp;sa=D&amp;source=editors&amp;ust=1730413583169217&amp;usg=AOvVaw0tsLLlYc7JKkWLQ6M1f4uZ">https://arxiv.org/abs/2404.19756</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">LLAMA 3 70b is ranked higher than the 2023 versions of GPT 4 on the </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://chat.lmsys.org/?leaderboard&amp;sa=D&amp;source=editors&amp;ust=1730413583169469&amp;usg=AOvVaw0GNAoEUFea5LRtVakh7_Yv">LMSYS leaderboard</a></span><span class="c1 c14">&nbsp;despite a 96% size reduction AND Zuckerberg has stated it&rsquo;s undertrained due to budget constraints. </span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">A few weeks later, IBM released an open-source model that outperforms it: https://analyticsindiamag.com/ibm-releases-open-source-granite-code-models-outperforms-llama-3/ &nbsp;</span></li><li class="c10 li-bullet-0"><span class="c1 c14">Meta is training a 400b model now. Scaling laws show that larger models have better performance, so this model should be even better than anything that is available now.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c21 c129"><span class="c1 c14">&nbsp;</span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c1 c14">[LLMs made with the new Mamba architecture are as good as transformers twice their size](https://arxiv.org/abs/2312.00752)</span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">[OpenAI has their own unrelated Q* algorithm to increase reasoning capabilities](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.linkedin.com/pulse/impressed-gpt-you-know-nothing-john-doe-meat-q-jacek-gralak-e2qve&amp;sa=D&amp;source=editors&amp;ust=1730413583169988&amp;usg=AOvVaw2KaAVoz340nv90duCa8t_O">https://www.linkedin.com/pulse/impressed-gpt-you-know-nothing-john-doe-meat-q-jacek-gralak-e2qve</a></span><span class="c1 c14">&nbsp;)</span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">Anthropic&rsquo;s ClaudeBot has been aggressively scraping the Web in recent days. What are they training? </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1cdm97j/anthropics_claudebot_is_aggressively_scraping_the/&amp;sa=D&amp;source=editors&amp;ust=1730413583170360&amp;usg=AOvVaw0UCAzrMwB8nL4H5Y6O2mOP">https://www.reddit.com/r/singularity/comments/1cdm97j/anthropics_claudebot_is_aggressively_scraping_the/</a></span><span class="c1 c14">&nbsp; &nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1crth47/salesforce_released_the_new_state_of_the_art/&amp;sa=D&amp;source=editors&amp;ust=1730413583170671&amp;usg=AOvVaw1pORijmoviDE-2UiVC_JA5">Salesforce released the new state of the art instruct model based on the Llama-3 8b: SFR-Iterative-DPO-LLaMA-3-8B-R</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1crth47/salesforce_released_the_new_state_of_the_art/&amp;sa=D&amp;source=editors&amp;ust=1730413583170894&amp;usg=AOvVaw1AEbaXBd_h32TgSVHHxw9s">Chat-Arena-Hard is likely not yet polluted and seems relatively calibrated (albeit biased towards GPT4), their score on it (29.1) beats meta&#39;s (20.6). Most previous finetunes have been either LORAs or at best SFT, Salesforce&#39;s SFT result on CAH is just 5.6.</a></span></li><li class="c10 li-bullet-0"><span>Tested both on 8 questions hard for small LLMs, LLAMA 3 8b instruct scored 3/8, this scored 5/8.</span></li><li class="c10 li-bullet-0"><span class="c6 c40">Prompt:</span></li><li class="c10 c136 li-bullet-0"><span class="c6 c40">Can you make me a screensaver with the green and gold &#39;raining code&#39; like in The Matrix? Make it in Python. Please do not require any external dependencies such as fonts. Using Pygame is acceptable.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-2 start"><li class="c71 c86 li-bullet-0"><span class="c6">The result: </span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://i.imgur.com/H0qNEqE.png&amp;sa=D&amp;source=editors&amp;ust=1730413583171338&amp;usg=AOvVaw18h68Atg-Al2sPZe8nMYrG">https://i.imgur.com/H0qNEqE.png</a></span><span class="c6 c40">&nbsp; </span></li><li class="c71 c86 li-bullet-0"><span class="c6 c40">Not the prettiest, but it works, no errors.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1"><li class="c49 li-bullet-0"><span class="c6 c40">2nd prompt: In Python, write a basic music player program with the following features: Create a playlist based on MP3 files found in the current folder, and include controls for common features such as next track, play/pause/stop, etc. Use PyGame for this. Make sure the filename of current song is included in the UI.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-2 start"><li class="c71 c86 li-bullet-0"><span class="c6">Result: </span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://i.imgur.com/7g0Tzji.png&amp;sa=D&amp;source=editors&amp;ust=1730413583171735&amp;usg=AOvVaw1G_G4VR2Tlo_RZ5URvJnGb">https://i.imgur.com/7g0Tzji.png</a></span></li><li class="c71 c86 li-bullet-0"><span class="c6 c40">Works, with keyboard controls for pause/unpause, next track, and stop.</span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c51 li-bullet-0"><span class="c6">[Live AI video analysis](</span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GoogleDeepMind/status/1790463259822420239&amp;sa=D&amp;source=editors&amp;ust=1730413583172053&amp;usg=AOvVaw2imgHWPHyyfbBxsB-D8eu0">https://twitter.com/GoogleDeepMind/status/1790463259822420239</a></span><span class="c6 c40">)</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c49 li-bullet-0"><span class="c20 c91"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DnXVvvRhiGjI&amp;sa=D&amp;source=editors&amp;ust=1730413583172316&amp;usg=AOvVaw2nF4bDXRHFsscNa8U_z3yh">Project Astra: Our vision for the future of AI assistants</a></span></li><li class="c49 li-bullet-0"><span class="c6">More examples of recognizing drawings: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/minchoi/status/1790873017150550354&amp;sa=D&amp;source=editors&amp;ust=1730413583172606&amp;usg=AOvVaw1vaXZ2eLTQdC4mw33Nq22G">https://twitter.com/minchoi/status/1790873017150550354</a></span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c51 li-bullet-0"><span class="c6">Chameleon: Mixed-Modal Early-Fusion Foundation Models: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.09818&amp;sa=D&amp;source=editors&amp;ust=1730413583172942&amp;usg=AOvVaw2NLX3ob1hdekqtjDZS2n_T">https://arxiv.org/abs/2405.09818</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c49 li-bullet-0"><span class="c6 c40">This research presents a family of early-fusion token-based mixed-modal models capable of understanding &amp; generating images &amp; text in any arbitrary sequence.</span></li><li class="c49 li-bullet-0"><span class="c6 c40">Chameleon demonstrates broad and general capabilities, including state-of-the-art performance in image captioning tasks, outperforms Llama-2 in text-only tasks while being competitive with models such as Mixtral 8x7B and Gemini-Pro, and performs non-trivial image generation, all in a single model. It also matches or exceeds the performance of much larger models, including Gemini Pro and GPT-4V, according to human judgments on a new long-form mixed-modal generation evaluation, where either the prompt or outputs contain mixed sequences of both images and text.</span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 li-bullet-0"><span class="c18 c14">SOAR: New algorithms for even faster vector search with ScaNN: </span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/soar-new-algorithms-for-even-faster-vector-search-with-scann/&amp;sa=D&amp;source=editors&amp;ust=1730413583173350&amp;usg=AOvVaw1rkxc62EUMze_Gre3OC4Ji">https://research.google/blog/soar-new-algorithms-for-even-faster-vector-search-with-scann/</a></span></li></ul><p class="c22 c44"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.17764&amp;sa=D&amp;source=editors&amp;ust=1730413583173619&amp;usg=AOvVaw1gMXjmFuteV1L18jLyuA-q">https://arxiv.org/abs/2402.17764</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 li-bullet-0"><span class="c14 c31">In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single parameter (or weight) of the LLM is ternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16) Transformer LLM with the same model size and training tokens in terms of both perplexity and end-task performance, while being </span><span class="c15 c31">significantly more cost-effective in terms of latency, memory, throughput, and energy consumption</span><span class="c14 c31">. More profoundly, the 1.58-bit LLM defines </span><span class="c15 c31">a new scaling law and recipe for training new generations of LLMs that are both high-performance and cost-effective</span><span class="c14 c31">. Furthermore, it enables a new computation paradigm and opens the door for </span><span class="c28 c43">designing specific hardware optimized for 1-bit LLMs.</span></li></ul><p class="c22 c44"><span class="c40 c37 c48 c31"></span></p><p class="c22 c44"><span class="c40 c18"></span></p><p class="c22 c44"><span class="c40 c18"></span></p><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 li-bullet-0"><span class="c18">LLMs won&rsquo;t need data anymore. Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1793864788579090917?s%3D46%26t%3DlZJAHzXMXI1MgQuyBgEhgA&amp;sa=D&amp;source=editors&amp;ust=1730413583174270&amp;usg=AOvVaw2QffEkog67l5-tjLwwWtow">https://x.com/_akhaliq/status/1793864788579090917?s=46&amp;t=lZJAHzXMXI1MgQuyBgEhgA</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 li-bullet-0"><span class="c40 c18">While this only works for things you can generate good or perfect data on, that would still be good enough for factual information like math or science. For subjective information like art, a good art generator (e.g. Midjourney or Pony Diffusion could work)</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 li-bullet-0"><span class="c18">Drone swarms can now fly autonomously through thick forest: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/AISafetyMemes/status/1793899057200652654&amp;sa=D&amp;source=editors&amp;ust=1730413583174550&amp;usg=AOvVaw2ehjAW5i1tn0g34Rys6sWz">https://x.com/AISafetyMemes/status/1793899057200652654</a></span><span class="c40 c18">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 li-bullet-0"><span class="c40 c18">Can be used to gather data without human navigation</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 li-bullet-0"><span class="c18">iVideoGPT: Interactive VideoGPTs are Scalable World Models: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2405.15223&amp;sa=D&amp;source=editors&amp;ust=1730413583174794&amp;usg=AOvVaw05vSFXT2l6fmPdvJ3m1wBY">https://huggingface.co/papers/2405.15223</a></span><span class="c18">&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span>AutoDoc coding: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2310.19791v4%23Pt1&amp;sa=D&amp;source=editors&amp;ust=1730413583175015&amp;usg=AOvVaw3_XIq0RLuVLCjziWvzECMd">https://arxiv.org/html/2310.19791v4#Pt1</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c14 c72 li-bullet-0"><span>While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce Lilo, a neurosymbolic framework that</span><span class="c34">&nbsp;iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains</span><span>. Lilo combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal &#120582;-abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that </span><span class="c34">infers natural language names and docstrings based on contextual examples of usage</span><span>. In addition to improving human readability, we find that AutoDoc</span><span class="c34">&nbsp;boosts performance by helping Lilo&rsquo;s synthesizer to interpret and deploy learned abstractions</span><span>. We evaluate Lilo on three inductive program synthesis benchmarks for string editing, scene reasoning, and graphics composition. Compared to existing methods&mdash;including the state-of-the-art libraries learning algorithm DreamCoder&mdash;</span><span class="c33 c34">Lilo solves more complex tasks and learns richer libraries that are grounded in linguistic knowledge.</span></li><li class="c22 c72 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 328.00px;"><img alt="" src="images/image283.png" style="width: 624.00px; height: 328.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c72 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 353.33px;"><img alt="" src="images/image473.png" style="width: 624.00px; height: 353.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c95 c14 c129 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://allenpike.com/2024/llms-trained-on-internet&amp;sa=D&amp;source=editors&amp;ust=1730413583175663&amp;usg=AOvVaw0mSQkr18DuJh3-EwsDiwoq">LLMs Aren&rsquo;t Just &ldquo;Trained On the Internet&rdquo; Anymore</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://allenpike.com/2024/llms-trained-on-internet&amp;sa=D&amp;source=editors&amp;ust=1730413583175825&amp;usg=AOvVaw0afvXoAgLwNXep81nAGT21">https://allenpike.com/2024/llms-trained-on-internet</a></span><span>&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span>CoPE is a new positional encoding method for transformers that takes into account *context* </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jaseweston/status/1795978611784089799&amp;sa=D&amp;source=editors&amp;ust=1730413583176038&amp;usg=AOvVaw16pL2GQG6y3Lpd2f-o7_ES">https://x.com/jaseweston/status/1795978611784089799</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c1">- Can &quot;count&quot; distances per head dependent on need, e.g. i-th sentence or paragraph, words, verbs, etc. Not just tokens.</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c1">- CoPE solves counting &amp; copy tasks that standard transformers cannot.</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c1">- Better PPL on language modeling + coding tasks.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Robot integrated with Huawei&#39;s Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583176451&amp;usg=AOvVaw3F_xRl0gGmCLIQSRdbrm-p">https://x.com/TheHumanoidHub/status/1806033905147077045</a></span><span>&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span>New high quality dataset: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1&amp;sa=D&amp;source=editors&amp;ust=1730413583176676&amp;usg=AOvVaw15MALz5og37Ka2PpZUiKGy">https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span>Good data is the biggest contributor to good models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/&amp;sa=D&amp;source=editors&amp;ust=1730413583176882&amp;usg=AOvVaw0TqjaI4oIoz1j67y9l5yYl">https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/</a></span><span class="c1">&nbsp;</span></li><li class="c22 c72 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.50px; height: 451.88px;"><img alt="" src="images/image292.png" style="width: 602.50px; height: 451.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c1">&ldquo;Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.&rdquo;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c1">Signed by Ilya Sutskever, Geoffrey Hinton, Yoshua Bengio, Demis Hassabis, Sam Altman, Dario Amodei, and many more</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span>Diffusion models for code generation that learn to directly *edit* syntax trees of programs. The result is a system that can incrementally write code, see the execution output, and debug it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/shreyaskapur/status/1797726079995826629&amp;sa=D&amp;source=editors&amp;ust=1730413583177438&amp;usg=AOvVaw2wxaIeMUJay_85gCrfMndV">https://x.com/shreyaskapur/status/1797726079995826629</a></span><span class="c1">&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span>Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://export.arxiv.org/abs/2312.01701&amp;sa=D&amp;source=editors&amp;ust=1730413583177775&amp;usg=AOvVaw3mShhvWxmlRGBuuODUzWtb">https://export.arxiv.org/abs/2312.01701</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c40 c55 c37 c48 c14">Our experiment results demonstrate that ReCaption effectively reduces fine-grained object hallucination for different LVLM options and improves their text generation quality.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">REDUCING LLM HALLUCINATIONS USING EPISTEMIC NEURAL NETWORKS: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2312.15576&amp;sa=D&amp;source=editors&amp;ust=1730413583178181&amp;usg=AOvVaw2p44Gz7QxF0eorKIkbd3Il">https://arxiv.org/pdf/2312.15576</a></span><span class="c40 c55 c37 c48 c14">&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">Reducing hallucination in structured outputs via Retrieval-Augmented Generation: &nbsp;</span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.08189&amp;sa=D&amp;source=editors&amp;ust=1730413583178455&amp;usg=AOvVaw3ClX6JjcefiBd_iJbwKLpl">https://arxiv.org/abs/2404.08189</a></span></li><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2405.21048&amp;sa=D&amp;source=editors&amp;ust=1730413583178722&amp;usg=AOvVaw31kD_2dyr1QFDYU-RxOwmE">https://huggingface.co/papers/2405.21048</a></span><span class="c55 c14">&nbsp;</span><span class="c40 c55 c37 c48 c14">&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">Show, Don&rsquo;t Tell: Aligning Language Models with Demonstrated Feedback: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://t.co/JASt7Sp18l&amp;sa=D&amp;source=editors&amp;ust=1730413583179000&amp;usg=AOvVaw02rdDOSwZfXlYIPuAP4Roi">https://t.co/JASt7Sp18l</a></span><span class="c40 c55 c37 c48 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c40 c55 c37 c48 c14">Significantly outperforms few-shot prompting, SFT and other self-play methods.by an average of 19% using demonstrations as feedback directly with &lt;10 examples</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">No Language Left Behind (NLLB) is an AI model created by researchers at Meta capable of delivering high-quality translations directly between 200 languages &ndash; including low-resource languages: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41586-024-07335-x&amp;sa=D&amp;source=editors&amp;ust=1730413583179371&amp;usg=AOvVaw11UP2mqUTFmbZ0upFgww2E">https://www.nature.com/articles/s41586-024-07335-x</a></span><span class="c40 c55 c37 c48 c14">&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">Teams of LLM Agents can Exploit Zero-Day Vulnerabilities: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.01637&amp;sa=D&amp;source=editors&amp;ust=1730413583179631&amp;usg=AOvVaw1MzzAY1cuOEJIJiilgZ4Si">https://arxiv.org/abs/2406.01637</a></span><span class="c40 c55 c37 c48 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c22 c10 c14 li-bullet-0"><span class="c3">Prior agents struggle with exploring many different vulnerabilities and long-range planning when used alone. To resolve this, we introduce HPTSA, a system of agents with a planning agent that can launch subagents. The planning agent explores the system and determines which subagents to call, resolving long-term planning issues when trying different vulnerabilities. We construct a benchmark of 15 real-world vulnerabilities and show that our team of agents improve over prior work by up to 4.5x.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c22 c4 c14 li-bullet-0"><span class="c14 c31">Searching Priors Makes Text-to-Video Synthesis Better: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.03215&amp;sa=D&amp;source=editors&amp;ust=1730413583180033&amp;usg=AOvVaw1OP-JISEbtKSU0kICDJWJD">https://huggingface.co/papers/2406.03215</a></span><span class="c3">&nbsp;</span></li><li class="c22 c4 c14 li-bullet-0"><span class="c14 c31">Audio Mamba: Bidirectional State Space Model for Audio Representation Learning: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.03344&amp;sa=D&amp;source=editors&amp;ust=1730413583180278&amp;usg=AOvVaw1SHhp8i_6ZxIWBboIPQ4BZ">https://huggingface.co/papers/2406.03344</a></span><span class="c3">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2404.03683v1&amp;sa=D&amp;source=editors&amp;ust=1730413583180469&amp;usg=AOvVaw19LsZJW1l98JLmbmV4q3-U">https://arxiv.org/html/2404.03683v1</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c14">Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string &mdash; a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers</span><span class="c15">. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory</span><span class="c14">. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models</span><span class="c15">&nbsp;solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers.</span><span class="c14">&nbsp;Our results indicate that language models </span><span class="c33 c15">can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. </span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14">High quality quantization of Stable Diffusion: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04333&amp;sa=D&amp;source=editors&amp;ust=1730413583180963&amp;usg=AOvVaw3AgkUWMNuW6dist_6xkgcK">https://huggingface.co/papers/2406.04333</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c54">Saving and transferring them is a major bottleneck for various applications, especially those running on resource-constrained devices. In this work, we develop a novel weight quantization method that quantizes the UNet from Stable Diffusion v1.5 to 1.99 bits, achieving a model with 7.9X smaller size while exhibiting even better generation quality than the original one. Our approach includes several novel techniques, such as assigning optimal bits to each layer, initializing the quantized model for better performance, and improving the training strategy to dramatically reduce quantization error. Furthermore, we extensively evaluate our quantized model across various benchmark datasets and through human evaluation to demonstrate its superior generation quality.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.05719&amp;sa=D&amp;source=editors&amp;ust=1730413583181252&amp;usg=AOvVaw1Y_696Naj9CPpcM4b_R6f7">https://arxiv.org/abs/2404.05719</a></span><span class="c3">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">Ferret-UI, a new MLLM tailored for enhanced understanding of mobile UI screens, equipped with referring, grounding, and reasoning capabilities. Given that UI screens typically exhibit a more elongated aspect ratio and contain smaller objects of interest (e.g., icons, texts) than natural images, we incorporate &quot;any resolution&quot; on top of Ferret to magnify details and leverage enhanced visual features. Specifically, each screen is divided into 2 sub-images based on the original aspect ratio (i.e., horizontal division for portrait screens and vertical division for landscape screens). Both sub-images are encoded separately before being sent to LLMs. We meticulously gather training samples from an extensive range of elementary UI tasks, such as icon recognition, find text, and widget listing. These samples are formatted for instruction-following with region annotations to facilitate precise referring and grounding. To augment the model&#39;s reasoning ability, we further compile a dataset for advanced tasks, including detailed description, perception/interaction conversations, and function inference. After </span><span class="c15 c31">training on the curated datasets, Ferret-UI exhibits outstanding comprehension of UI screens and the capability to execute open-ended instructions. </span><span class="c14 c31">For model evaluation, we establish a comprehensive benchmark encompassing all the aforementioned tasks. Ferret-UI </span><span class="c28 c43">excels not only beyond most open-source UI MLLMs, but also surpasses GPT-4V on all the elementary UI tasks.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Improve Mathematical Reasoning in Language Models by Automated Process Supervision: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.06592&amp;sa=D&amp;source=editors&amp;ust=1730413583181699&amp;usg=AOvVaw0s8hAnT-v_yxamzYQX8IiY">https://arxiv.org/abs/2406.06592</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c3">Utilizing this fully automated process supervision alongside the weighted self-consistency algorithm, we have enhanced the instruction tuned Gemini Pro model&#39;s math reasoning performance, achieving a 69.4\% success rate on the MATH benchmark, a 36\% relative improvement from the 51\% base model performance. Additionally, the entire process operates without any human intervention, making our method both financially and computationally cost-effective compared to existing methods.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c53 c56 c78 c111 li-bullet-0"><span>Simulations transfer very well to real life: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.01967v1&amp;sa=D&amp;source=editors&amp;ust=1730413583181982&amp;usg=AOvVaw3x7v83PEVvI5CAinepBqt0">https://arxiv.org/abs/2406.01967v1</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Scalable MatMul-free Language Modeling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.02528&amp;sa=D&amp;source=editors&amp;ust=1730413583182171&amp;usg=AOvVaw1t5xyo1yoWKNrSGtmWHdg2">https://arxiv.org/abs/2406.02528</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c3">In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model&#39;s memory consumption can be reduced by more than 10x compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c14 c31">Samba 3.8B: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/liliang_ren/status/1801027052147216457&amp;sa=D&amp;source=editors&amp;ust=1730413583182564&amp;usg=AOvVaw3ru2OAmcAJIEaiIHlWw1fZ">https://x.com/liliang_ren/status/1801027052147216457</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c10 li-bullet-0"><span class="c1">Introducing Samba 3.8B, a simple Mamba+Sliding Window Attention architecture that outperforms Phi3-mini on major benchmarks (e.g., MMLU, GSM8K and HumanEval) by a large margin.&#128558; And it has an infinite context length with linear complexity.</span></li><li class="c10 li-bullet-0"><span class="c1">When trained on the 4K sequence length, Samba shows improved perplexity up to 1M context length on Proof-Pile, while still keeping its linear decoding complexity. This results in a 3.64x speed up than the Llama-3 architecture at 64k generation length. &#128640;</span></li><li class="c10 li-bullet-0"><span class="c1">Wondering how is the extrapolation ability of Samba compared to Mistral? We instruction tuned both architectures on Passkey Retrieval with 4K sequence length, and found that Samba (left) can have perfect memory recall up to 256K context length, while Mistral (right) struggles within the 4K length.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c131 c78 li-bullet-0"><span>Mixture-of-Agents Enhances Large Language Model Capabilities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.04692&amp;sa=D&amp;source=editors&amp;ust=1730413583183024&amp;usg=AOvVaw3C1H3ZZMGdiAwfH6cClIzz">https://arxiv.org/abs/2406.04692</a></span><span class="c1">&nbsp;</span></li></ul><p class="c131 c46"><span class="c1"></span></p><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.07394&amp;sa=D&amp;source=editors&amp;ust=1730413583183273&amp;usg=AOvVaw3EldGeoXhKGqO6D-mS6clz">https://arxiv.org/abs/2406.07394</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c1">Extensive experiments demonstrate MCTSr&#39;s efficacy in solving Olympiad-level mathematical problems, significantly improving success rates across multiple datasets, including GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math Odyssey, AIME, and OlympiadBench. The study advances the application of LLMs in complex reasoning tasks and sets a foundation for future AI integration, enhancing decision-making accuracy and reliability in LLM-driven applications.</span></li><li class="c10 li-bullet-0"><span class="c1">This would be even more effective with a better model than LLAMA 8B and with GPT 4o</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2401.10020&amp;sa=D&amp;source=editors&amp;ust=1730413583183579&amp;usg=AOvVaw1BddZ6jyxIkwAOn2P4vs-O">https://arxiv.org/pdf/2401.10020</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span class="c1">In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during training. We show that during Iterative DPO training that not only does instruction following ability improve, but also the ability to provide high-quality rewards to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0612. While there is much left still to explore, this work opens the door to the possibility of models that can continually improve in both axes.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c4 li-bullet-0"><span>Image diffusion is getting much better and faster/cheaper to train: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.04692&amp;sa=D&amp;source=editors&amp;ust=1730413583183865&amp;usg=AOvVaw0TV6bUbQvRa2uDVi_qtSp4">https://arxiv.org/pdf/2403.04692</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>GPT4o gets 72% on ARC-AGI (humans get 85%): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dwarkesh_sp/status/1802771055016378554&amp;sa=D&amp;source=editors&amp;ust=1730413583184045&amp;usg=AOvVaw1qaTDANwZiwr7hiO9n-Coe">https://x.com/dwarkesh_sp/status/1802771055016378554</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Generating audio for video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/generating-audio-for-video/&amp;sa=D&amp;source=editors&amp;ust=1730413583184249&amp;usg=AOvVaw04PLXMGavZlAIc2lRvgtwi">https://deepmind.google/discover/blog/generating-audio-for-video/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Bloomberg: ADOBE about to enter AI Video market, currently working on SORA competitor: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcmag.com/news/adobe-buying-videos-train-sora-competitor&amp;sa=D&amp;source=editors&amp;ust=1730413583184533&amp;usg=AOvVaw0Hz0eJP2LYYf6oMW8cRrHz">https://www.pcmag.com/news/adobe-buying-videos-train-sora-competitor</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.15568&amp;sa=D&amp;source=editors&amp;ust=1730413583184746&amp;usg=AOvVaw1b4DYZrUJl1X18d6eZk513">https://arxiv.org/pdf/2405.15568</a></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c10 li-bullet-0"><span>OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent&rsquo;s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents&rsquo; learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dub.sh/omniepic&amp;sa=D&amp;source=editors&amp;ust=1730413583184991&amp;usg=AOvVaw0D80V5cC2uQ7z_6PQ_Fwgd">https://dub.sh/omniepic</a></span><span class="c1">.</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c53 c111 c56 c78 li-bullet-0"><span>Boosting Visual-Language Models with Synthetic Captions and Image Embeddings: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.07750&amp;sa=D&amp;source=editors&amp;ust=1730413583185167&amp;usg=AOvVaw0ky-iPNxD3ZM7m68Ofe_dR">https://arxiv.org/pdf/2403.07750</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c53 c111 c56 c97 c105 li-bullet-0"><span>Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator&rsquo;s ability to create </span><span class="c15">novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. </span><span>Extensive experiments demonstrate that our VLM, </span><span class="c15">finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. </span><span>Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up </span><span class="c33 c15">promising avenues for the development of self-improving multi-modal models.</span></li><li class="c53 c111 c56 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 320.00px;"><img alt="" src="images/image138.png" style="width: 624.00px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c53 c111 c56 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 540.66px; height: 655.51px;"><img alt="" src="images/image297.png" style="width: 540.66px; height: 655.51px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-0"><li class="c131 c53 c56 c78 li-bullet-0"><span>Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.14283&amp;sa=D&amp;source=editors&amp;ust=1730413583185776&amp;usg=AOvVaw1nGLeeDLOAOnRUMsqt9bVF">https://arxiv.org/abs/2406.14283</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_kymf5on3p83t-1 start"><li class="c53 c56 c89 li-bullet-0"><span class="c14 c31">In this paper, we aim to alleviate the pathology by introducing Q*, a general, versatile and agile framework for guiding LLMs decoding process with </span><span class="c34 c14 c31">deliberative planning</span><span class="c14 c31">. By learning a plug-and-play Q-value model as heuristic function, our Q* can </span><span class="c15 c31">effectively guide LLMs to select the most promising next step without fine-tuning LLMs for each task</span><span class="c14 c31">, which </span><span class="c34 c14 c31">avoids the significant computational overhead and potential risk of performance degeneration</span><span class="c14 c31">&nbsp;on other tasks. Extensive experiments on GSM8K, MATH and MBPP </span><span class="c28 c43">confirm the superiority of our method.</span></li></ul><p class="c131 c53 c56 c46"><span class="c28 c43"></span></p><ul class="c0 lst-kix_ssouwh4l2bgy-0 start"><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">Do you know your LLM uses less than 1% of your GPU at inference? Too much time is wasted on KV cache memory access &#10145;&#65039; We tackle this with the &#127873; Block Transformer: a </span><span class="c15 c31">global-to-local architecture that speeds up decoding up to 20x: </span><span class="c5 c15 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/itsnamgyu/status/1807400609429307590&amp;sa=D&amp;source=editors&amp;ust=1730413583186258&amp;usg=AOvVaw2_YkDdWDpoVlpGToIOU_KL">https://x.com/itsnamgyu/status/1807400609429307590</a></span><span class="c15 c31">&nbsp;</span><span class="c40 c37 c48 c31">:</span></li><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.19280&amp;sa=D&amp;source=editors&amp;ust=1730413583186506&amp;usg=AOvVaw21_hNGU_Yn5dzUH-5f_Rtb">https://huggingface.co/papers/2406.19280</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0 start"><li class="c89 c53 c56 li-bullet-0"><span class="c31">Our validation demonstrates that: (1) PubMedVision can </span><span class="c15 c31">significantly enhance the medical multimodal capabilities of current MLLMs, showing significant improvement in benchmarks including the MMMU Health &amp; Medicine track</span><span class="c31">; (2) manual checks by medical experts and empirical results validate the superior data quality of our dataset compared to other data construction methods. Using PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows </span><span class="c28 c43">superior performance in medical multimodal scenarios among open-source MLLMs.</span></li></ul><p class="c131 c53 c56 c46"><span class="c28 c43"></span></p><ul class="c0 lst-kix_o4w8hr2p0ha-0 start"><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">Step-DPO: Step-wise preference Optimization for Long-chain Reasoning of LLMs: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.18629&amp;sa=D&amp;source=editors&amp;ust=1730413583186889&amp;usg=AOvVaw3Xi_YwnytudMuerYoB7nGu">https://huggingface.co/papers/2406.18629</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li></ul><ul class="c0 lst-kix_o4w8hr2p0ha-1 start"><li class="c89 c53 c56 li-bullet-0"><span class="c40 c37 c48 c31">We also observe that in DPO, self-generated data is more effective than data generated by humans or GPT-4, due to the latter&#39;s out-of-distribution nature. Our findings demonstrate that as few as 10K preference data pairs and fewer than 500 Step-DPO training steps can yield a nearly 3% gain in accuracy on MATH for models with over 70B parameters. Notably, Step-DPO, when applied to Qwen2-72B-Instruct, achieves scores of 70.8% and 94.0% on the test sets of MATH and GSM8K, respectively, surpassing a series of closed-source models, including &nbsp;GPT-4-1106, Claude-3-Opus, and Gemini-1.5-Pro.</span></li></ul><p class="c131 c53 c56 c46 c129"><span class="c28"></span></p><p class="c131 c53 c56"><span class="c31">OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.19389&amp;sa=D&amp;source=editors&amp;ust=1730413583187271&amp;usg=AOvVaw0rLkmO9W1ZosUqc4m3ZiX3">https://huggingface.co/papers/2406.19389</a></span><span class="c40 c37 c48 c31">&nbsp;</span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c89 c53 c56 li-bullet-0"><span class="c40 c37 c48 c31">OMG-LLaVA achieves image-level, object-level, and pixel-level reasoning and understanding in a single model, matching or surpassing the performance of specialized methods on multiple benchmarks.</span></li></ul><p class="c131 c53 c56 c46"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c89 c53 c56 li-bullet-0"><span class="c31">Human level text to speech: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/&amp;sa=D&amp;source=editors&amp;ust=1730413583187606&amp;usg=AOvVaw09-05zCXD2AVk1F0bd0Eof">https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/</a></span></li></ul><p class="c131 c53 c56 c46"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://spatial-vlm.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583187853&amp;usg=AOvVaw1ZCpT7mD0VUPOZuu-5W_Oh">https://spatial-vlm.github.io/</a></span></li></ul><p class="c9"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c31">The Memory^3 model</span><span class="c15 c31">&nbsp;achieved better performance than larger models and RAG models on various benchmarks, while maintaining higher decoding speed</span><span class="c31">. It showed particular improvements in </span><span class="c15 c31">factuality and reduced hallucination</span><span class="c31">: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2407.01178v1&amp;sa=D&amp;source=editors&amp;ust=1730413583188163&amp;usg=AOvVaw2lYLOb-bSiCl1A-tKXnlD-">https://arxiv.org/html/2407.01178v1</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">we reduce cost by equipping LLMs with an explicit memory format cheaper than model parameters and text retrieval-augmented generation (RAG).</span></li><li class="c7 li-bullet-0"><span>Conceptually, with most of its knowledge externalized to explicit memory, the LLM can enjoy a</span><span class="c43">&nbsp;</span><span class="c33 c15">smaller parameter size, training cost, and inference cost, all proportional to the amount of remaining &ldquo;abstract knowledge&rdquo;.</span></li><li class="c7 li-bullet-0"><span>As a preliminary proof of concept, we train from scratch a 2.4B LLM, which achieves </span><span class="c33 c15">better performance than much larger LLMs as well as RAG models, and maintains higher decoding speed than RAG.</span></li><li class="c7 li-bullet-0"><span>We introduce a memory circuitry theory to support the externalization of knowledge, and present novel techniques including a memory sparsification mechanism that makes storage tractable and a two-stage pretraining scheme that facilitates memory formation.</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c31">Offline model-based RL suffers in long-horizon tasks like AntMaze. We introduce LEQ (Lower-Expectile Q-learning), which significantly outperforms previous offline model-based methods on AntMaze: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/kwanyoung_park_/status/1810308456131547289&amp;sa=D&amp;source=editors&amp;ust=1730413583188687&amp;usg=AOvVaw21DLVs1xbLm_K6i0YOo_b8">https://x.com/kwanyoung_park_/status/1810308456131547289</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c31">Paper: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.00699&amp;sa=D&amp;source=editors&amp;ust=1730413583188885&amp;usg=AOvVaw0H8TqgCJ0-vMLBrqi3ueUc">https://arxiv.org/abs/2407.00699</a></span></li><li class="c7 li-bullet-0"><span class="c31">Project page: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://kwanyoungpark.github.io/LEQ/&amp;sa=D&amp;source=editors&amp;ust=1730413583189127&amp;usg=AOvVaw0kB9YnKwAX6Zmi474TQzcQ">https://kwanyoungpark.github.io/LEQ/</a></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 545.50px; height: 235.16px;"><img alt="" src="images/image607.png" style="width: 545.50px; height: 235.16px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c31">Voice cloning: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1810573475309908261&amp;sa=D&amp;source=editors&amp;ust=1730413583189486&amp;usg=AOvVaw3LEL0awrG-ZsO_HcwQN724">https://x.com/dreamingtulpa/status/1810573475309908261</a></span></li><li class="c10 li-bullet-0"><span>Kling AI just got a new round of updates. The updates include enhanced video quality, 10 seconds of video time, camera motion controls and customizable intro/outro frames: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dzwavq/kling_ai_just_got_a_new_round_of_updates_the/&amp;sa=D&amp;source=editors&amp;ust=1730413583189749&amp;usg=AOvVaw2A7FO95WIlL7BMz5UXb7Gp">https://www.reddit.com/r/singularity/comments/1dzwavq/kling_ai_just_got_a_new_round_of_updates_the/</a></span></li><li class="c10 li-bullet-0"><span class="c18">Video-STaR, a self-training approach to utilize any supervision for video instruction tuning </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/orr_zohar/status/1810872854633926994&amp;sa=D&amp;source=editors&amp;ust=1730413583189959&amp;usg=AOvVaw0WmPGrUFzVZLmze_1CNLYi">https://x.com/orr_zohar/status/1810872854633926994</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 548.50px; height: 109.88px;"><img alt="" src="images/image596.png" style="width: 548.50px; height: 109.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 560.50px; height: 124.85px;"><img alt="" src="images/image557.png" style="width: 560.50px; height: 124.85px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c18">Internet of Agents beats GPT 4: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.07061&amp;sa=D&amp;source=editors&amp;ust=1730413583190307&amp;usg=AOvVaw194ikcVaGZGOWQAJO5vxi5">https://arxiv.org/pdf/2407.07061</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 503.81px; height: 207.50px;"><img alt="" src="images/image506.png" style="width: 503.81px; height: 207.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 546.50px; height: 181.29px;"><img alt="" src="images/image424.png" style="width: 546.50px; height: 181.29px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 550.50px; height: 290.25px;"><img alt="" src="images/image86.png" style="width: 550.50px; height: 290.25px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c18">PaliGemma 3b VLM: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.07726&amp;sa=D&amp;source=editors&amp;ust=1730413583190900&amp;usg=AOvVaw2mmnrdKJISRZJOSzV83jFR">https://arxiv.org/pdf/2407.07726</a></span><span class="c40 c18">&nbsp;</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c40 c18">Our MMVP result is SOTA by a large margin. PaliGemma at 224px achieves 47.3% paired accuracy, while GPT4-V and Gemini achieve 38.7% and 40.7%, respectively, and all other models including LLaVa perform below chance.</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c18">FlashAttention 3 is much faster </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/tri_dao/status/1811453622070444071&amp;sa=D&amp;source=editors&amp;ust=1730413583191355&amp;usg=AOvVaw1_9g0319PvbZBTt7CssHtt">https://x.com/tri_dao/status/1811453622070444071</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 561.25px; height: 396.65px;"><img alt="" src="images/image170.png" style="width: 561.25px; height: 396.65px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c18">Exclusive: OpenAI working on new reasoning technology under code name &lsquo;Strawberry&rsquo; </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/artificial-intelligence/openai-working-new-reasoning-technology-under-code-name-strawberry-2024-07-12/&amp;sa=D&amp;source=editors&amp;ust=1730413583192007&amp;usg=AOvVaw0i9ju3RKb1WOsG1cmY6kOY">https://www.reuters.com/technology/artificial-intelligence/openai-working-new-reasoning-technology-under-code-name-strawberry-2024-07-12/</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">&#39;A different source briefed on the matter said OpenAI has tested AI internally that scored over 90% on a MATH dataset, a benchmark of championship math problems. Reuters could not determine if this was the &quot;Strawberry&quot; project.&#39;</span></li><li class="c7 li-bullet-0"><span class="c1">The MATH dataset is challenging: large language models achieved accuracies ranging from 3.0% to 6.9%. Despite these low accuracies, models clearly possess some mathematical knowledge: they achieve up to 15% accuracy on the easiest difficulty level, and they are able to generate step-by-step solutions that are coherent and on-topic even when incorrect. We also evaluated humans on MATH, and found that a computer science PhD student who does not especially like mathematics attained approximately 40% on MATH, while a three-time IMO gold medalist attained 90%, indicating that MATH can be challenging for humans as well.</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-2 start"><li class="c21 c26 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/be83ab3ecd0db773eb2dc1b0a17836a1-Paper-round2.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583192693&amp;usg=AOvVaw0xUONnLATzzAd23Hl_pAHt">https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/be83ab3ecd0db773eb2dc1b0a17836a1-Paper-round2.pdf</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>To facilitate the cutting-e</span><span class="c18">dge research of MLLMs on comprehensive vision perception, we thereby propose Perceptual Fusion, using a </span><span class="c15 c65 c114">low-budget but highly effective caption engine</span><span class="c18">&nbsp;for complete and accurate image descriptions. Specifically, Perceptual Fusion integrates diverse perception experts as image priors to provide explicit information on visual elements and adopts an efficient MLLM as a centric pivot to mimic advanced MLLMs&#39; perception abilities. We carefully select 1M highly representative images from uncurated LAION dataset and generate dense descriptions using our engine, dubbed DenseFusion-1M. Extensive experiments validate that</span><span class="c15 c65 c114">&nbsp;our engine outperforms its counterparts, where the resulting dataset significantly improves the perception and cognition abilities of existing MLLMs across diverse vision-language benchmarks, especially with high-resolution images as inputs:</span><span class="c18">&nbsp;</span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1811580833506947144&amp;sa=D&amp;source=editors&amp;ust=1730413583193260&amp;usg=AOvVaw0AjjPJJMVLUjj_2gikdCsK">https://x.com/_akhaliq/status/1811580833506947144</a></span></li><li class="c10 li-bullet-0"><span class="c40 c18">CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation</span></li></ul><p class="c21 c105"><span class="c18">&#119823;&#119851;&#119848;&#119843;: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=http://gxyes.github.io/projects/CrowdMoGen.html&amp;sa=D&amp;source=editors&amp;ust=1730413583193666&amp;usg=AOvVaw0Y20Nc08H-KMRUaYBUepWp">http://gxyes.github.io/projects/CrowdMoGen.html</a></span><span class="c40 c18">&nbsp;</span></p><p class="c21 c105"><span class="c18">&#119808;&#119835;&#119852;: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=http://arxiv.org/abs/2407.06188&amp;sa=D&amp;source=editors&amp;ust=1730413583193956&amp;usg=AOvVaw0p9X-JA-zwxu2op0wpSZqa">http://arxiv.org/abs/2407.06188</a></span></p><ul class="c0 lst-kix_thjul0jak92m-1"><li class="c7 li-bullet-0"><span class="c40 c18">a zero-shot text-driven framework that harnesses the power of LLMs to incorporate the collective intelligence into motion generation</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c18">Major improvement to RNN performance: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/camall3n/status/1811744898309308758&amp;sa=D&amp;source=editors&amp;ust=1730413583194353&amp;usg=AOvVaw1CnDB_YpvNe3qG1z2ai2r_">https://x.com/camall3n/status/1811744898309308758</a></span></li><li class="c10 li-bullet-0"><span>M2S is a new DDPM-based image inpainting method that is 60 times faster than RePaint: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/linghuyuhangyuan/M2S&amp;sa=D&amp;source=editors&amp;ust=1730413583194669&amp;usg=AOvVaw1l6ugxCndWUUJb79q-SL7d">https://github.com/linghuyuhangyuan/M2S</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 570.50px; height: 570.50px;"><img alt="" src="images/image114.png" style="width: 570.50px; height: 570.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c37 c35 c103 c14 c151">Auto Evol used to create an infinite amount and variety of high quality data: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/CanXu20/status/1812842568557986268&amp;sa=D&amp;source=editors&amp;ust=1730413583195139&amp;usg=AOvVaw1H8-RMjsIotuIqovBgSbYb">https://x.com/CanXu20/status/1812842568557986268</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span>Auto Evol allows the training of WizardLM2 to be conducted with nearly an </span><span class="c33 c15">unlimited number and variety of synthetic data.</span></li><li class="c7 li-bullet-0"><span>Auto Evol-Instruct automatically designs evolving methods that </span><span class="c15">make given instruction data more complex, enabling almost cost-free adaptation to different tasks by only changing the input data of the framework</span><span>&nbsp;&hellip;This optimization process involves two critical stages: (1) Evol Trajectory Analysis: The optimizer LLM carefully analyzes the potential issues and failures exposed in instruction evolution performed by evol LLM, generating feedback for subsequent optimization. (2) Evolving Method Optimization: The optimizer LLM optimizes the evolving method by addressing these identified issues in feedback. These stages alternate and repeat to progressively develop an effective evolving method using only a subset of the instruction data. Once the optimal evolving method is identified, it directs the evol LLM to convert the entire instruction dataset into </span><span class="c33 c15">more diverse and complex forms, thus facilitating improved instruction tuning.</span></li><li class="c7 c46 li-bullet-0"><span class="c1"></span></li><li class="c7 li-bullet-0"><span>Our experiments show that the evolving methods designed by Auto Evol-Instruct </span><span class="c15">outperform the Evol-Instruct methods designed by human experts in instruction tuning across various capabilities, including instruction following, mathematical reasoning, and code generation</span><span>. On the instruction following task, Auto Evol-Instruct can achieve a</span><span class="c34">&nbsp;improvement of 10.44% over the Evol method used by WizardLM-1 on MT-bench</span><span>; on the code task HumanEval, it can</span><span class="c34">&nbsp;achieve a 12% improvement over the method used by WizardCoder; on the math task GSM8k</span><span>, it can achieve a</span><span class="c33 c34">&nbsp;6.9% improvement over the method used by WizardMath.</span></li><li class="c7 c46 li-bullet-0"><span class="c1"></span></li><li class="c7 c46 li-bullet-0"><span class="c1"></span></li><li class="c7 li-bullet-0"><span>With the new technology of Auto Evol-Instruct, the evolutionary synthesis data of WizardLM-2 has</span><span class="c15">&nbsp;scaled up from the three domains of chat, code, and math in WizardLM-1 to dozens of domains</span><span>, covering tasks in all aspects of large language models. This allows Arena Learning to train and learn from an almost </span><span class="c15">infinite pool of high-difficulty instruction data</span><span>, fully unlocking all the potential of Arena Learning.</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 567.15px; height: 633.50px;"><img alt="" src="images/image248.png" style="width: 567.15px; height: 633.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>Mixture of A Million Experts. Daniel Jeffries:&quot;</span><span class="c15">Reduces inference cost and memory usage, scales to millions of experts, oh and just happens to overcome catastrophic forgetting and enable life long learning for the model</span><span>.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.04153&amp;sa=D&amp;source=editors&amp;ust=1730413583197102&amp;usg=AOvVaw3ppwrFx6Uy6h8wOTMWrnmO">https://arxiv.org/abs/2407.04153</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span>This paper introduces PEER (parameter efficient expert retrieval), a novel layer design that utilizes the product key technique for sparse retrieval from a vast pool of tiny experts (over a million). Experiments on language modeling tasks demonstrate that </span><span class="c34">PEER layers outperform dense FFWs and coarse-grained MoEs in terms of performance-compute trade-off</span><span>. By enabling efficient utilization of a massive number of experts, PEER </span><span class="c34">unlocks the potential for further scaling of transformer models while maintaining computational efficiency</span><span class="c1">. </span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>Google Deepmind trained Foundational Large Autorater Models (FLAMe) on extensive human evaluations, achieving the best RewardBench perf. among generative models trained solely on permissive data, surpassing both GPT-4 &amp; 4o: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tuvllms/status/1813249272474968315&amp;sa=D&amp;source=editors&amp;ust=1730413583197706&amp;usg=AOvVaw2ln-YAbT7nY-ZrDixgh-AG">https://x.com/tuvllms/status/1813249272474968315</a></span></li><li class="c10 li-bullet-0"><span>Codestral-Mamba 7B: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/theo_gervet/status/1813226968600469824&amp;sa=D&amp;source=editors&amp;ust=1730413583198019&amp;usg=AOvVaw1OI2dLNlDJiDEsBdC3kk3S">https://x.com/theo_gervet/status/1813226968600469824</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">- Strongest code model for its size, perfect for copilot apps</span></li><li class="c7 li-bullet-0"><span class="c1">- Mamba architecture enables linear time inference with 256K context length</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 565.50px; height: 160.41px;"><img alt="" src="images/image608.png" style="width: 565.50px; height: 160.41px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>LLAMA Groq 3 tool use: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/RickLamers/status/1813341037198204962&amp;sa=D&amp;source=editors&amp;ust=1730413583198619&amp;usg=AOvVaw1h3sYheUajsasZjiyBLsEa">https://x.com/RickLamers/status/1813341037198204962</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">An open source Tool Use full finetune of Llama 3 that reaches the #1 position on BFCL beating all other models, including proprietary ones like Claude Sonnet 3.5, GPT-4 Turbo, GPT-4o and Gemini 1.5 Pro.</span></li><li class="c7 li-bullet-0"><span class="c1">The model has been trained on synthetic data only. This is a powerful full finetune, not a LoRA. Yes, we&#39;ve checked rigorously for overfitting using the LMSYS described robust decontamination techniques, they only score 5.6% on SFT synthetic data and 1.3% on synthetic DPO data.</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 567.05px; height: 353.50px;"><img alt="" src="images/image221.png" style="width: 567.05px; height: 353.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c14 c31">xLSTMTime : Long-term Time Series Forecasting With xLSTM: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/ZReacc/status/1813196548337012943&amp;sa=D&amp;source=editors&amp;ust=1730413583199295&amp;usg=AOvVaw2QuMo_xQP6P6f_sZmhFOfQ">https://x.com/ZReacc/status/1813196548337012943</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c14 c31">Our adopted architecture for LTSF termed as xLSTMTime surpasses current approaches. We compare xLSTMTime&#39;s performance against various state-of-the-art models across multiple real-world datasets,</span><span class="c15 c31">&nbsp;demonstrating superior forecasting capabilities</span><span class="c14 c31">. Our findings suggest that refined recurrent architectures can offer </span><span class="c15 c31">competitive alternatives to transformer-based models in LTSF tasks</span><span class="c3">, potentially redefining the landscape of time series forecasting</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c14 c31">Scaling Diffusion Transformers to 16 Billion Parameters: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.11633&amp;sa=D&amp;source=editors&amp;ust=1730413583199870&amp;usg=AOvVaw0eEsKPwWwLIJvrQT1hEVjg">https://huggingface.co/papers/2407.11633</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c14 c31">Based on the above guidance, a series of DiT-MoE experimentally achieves performance on par with dense networks yet requires</span><span class="c15 c31">&nbsp;much less computational load during inference</span><span class="c14 c31">. More encouragingly, we demonstrate the potential of DiT-MoE with </span><span class="c15 c31">synthesized image data,</span><span class="c14 c31">&nbsp;scaling diffusion model at a 15.5B parameter that attains</span><span class="c28 c43">&nbsp;a new SoTA FID-50K score of 1.80 in 512x512 resolution settings.</span></li><li class="c7 li-bullet-0"><span class="c40 c37 c48 c31">For reference, Stable Diffusion XL is only about 3 billion parameters</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c31">Very efficient image diffusion training method: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.11966&amp;sa=D&amp;source=editors&amp;ust=1730413583200569&amp;usg=AOvVaw221P-CmPA2mhSAYDr1LRwU">https://huggingface.co/papers/2407.11966</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c31">Compared to training from scratch (i.e., Pix2pix), we achieve a </span><span class="c28 c43">15x training time acceleration for a new concept while obtaining even better image generation quality.</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c31">Extremely dynamic image to video: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1813486936868213073&amp;sa=D&amp;source=editors&amp;ust=1730413583201074&amp;usg=AOvVaw3PzkJBMblZXOdboEZj_Kqs">https://x.com/dreamingtulpa/status/1813486936868213073</a></span></li></ul><p class="c9"><span class="c40 c37 c48 c31"></span></p><p class="c9"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span class="c31">Prover-Verifier Games improve legibility of language model outputs: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/prover-verifier-games-improve-legibility/&amp;sa=D&amp;source=editors&amp;ust=1730413583201576&amp;usg=AOvVaw31mvKLkEESpiTHNfm1IMuc">https://openai.com/index/prover-verifier-games-improve-legibility/</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c40 c37 c48 c31">We trained strong language models to produce text that is easy for weak language models to verify and found that this training also made the text easier for humans to evaluate.</span></li><li class="c131 c53 c56 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.00px; height: 352.20px;"><img alt="" src="images/image452.png" style="width: 554.00px; height: 1199.72px; margin-left: 0.00px; margin-top: -322.12px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c131 c53 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c89 c53 c56 li-bullet-0"><span>New information on Llama 4 from Meta: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AndrewCurran_/status/1813704834819965147&amp;sa=D&amp;source=editors&amp;ust=1730413583202224&amp;usg=AOvVaw3wIJq0UY3TIhJoMceTc4dZ">https://x.com/AndrewCurran_/status/1813704834819965147</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c131 c53 c56 c86 li-bullet-0"><span class="c1">- Llama 4 started training in June</span></li><li class="c131 c53 c56 c86 li-bullet-0"><span class="c1">- Llama 4 will be fully multimodal, including audio</span></li></ul><p class="c131 c53 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c89 c53 c56 li-bullet-0"><span>E5-V: Universal Embeddings with Multimodal Large Language Models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.12580&amp;sa=D&amp;source=editors&amp;ust=1730413583202776&amp;usg=AOvVaw2pbK_UQNrZvfs8cinAuvUa">https://huggingface.co/papers/2407.12580</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c131 c53 c56 c86 li-bullet-0"><span>By leveraging MLLMs with prompts, E5-V effectively bridges the modality gap between different types of inputs, demonstrating strong performance in multimodal embeddings even without fine-tuning. We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs. This method demonstrates </span><span class="c15">significant improvements over traditional multimodal training on image-text pairs, while reducing training costs by approximately 95%. </span><span>Additionally, this approach</span><span class="c43">&nbsp;</span><span class="c15">eliminates the need for costly multimodal training data collection</span><span>. Extensive experiments across four types of tasks demonstrate the effectiveness of E5-V. As a universal multimodal model, E5-V not only achieves but often </span><span class="c33 c15">surpasses state-of-the-art performance in each task, despite being trained on a single modality.</span></li></ul><p class="c131 c53 c56 c46"><span class="c33 c15"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c89 c53 c56 li-bullet-0"><span>Research on AI agents: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/rohanpaul_ai/status/1814029081819615364&amp;sa=D&amp;source=editors&amp;ust=1730413583203545&amp;usg=AOvVaw0GCU9Itz20zK_z-kAdSRcM">https://x.com/rohanpaul_ai/status/1814029081819615364</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c131 c53 c56 c86 li-bullet-0"><span>&#128204; AI agent evaluations must be cost-controlled. </span><span class="c15">Simple baselines like retrying or gradually increasing model temperature can match or outperform complex &quot;state-of-the-art&quot; agents on benchmarks like HumanEval while costing much less.</span></li><li class="c131 c53 c56 c86 li-bullet-0"><span>&#128204; Jointly </span><span class="c15">optimizing accuracy and cost can yield better agent designs. </span><span>By visualizing results as a Pareto curve of accuracy vs. inference cost, researchers can explore new design spaces. An example modification to the DSPy framework </span><span class="c33 c15">reduced costs by over 50% while maintaining accuracy on HotPotQA.</span></li></ul><p class="c131 c53 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>New iterative RAG approach: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/at4EvIFTQI&amp;sa=D&amp;source=editors&amp;ust=1730413583204331&amp;usg=AOvVaw1d9fkBssujRxVUpLjNaFxO">https://arxiv.org/abs/2407.13101</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">ReSP significantly outperforms state-of-the-art on HotpotQA and 2WikiMultihopQA benchmarks, and exhibits robustness to context length.</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 555.35px; height: 493.94px;"><img alt="" src="images/image536.png" style="width: 555.35px; height: 493.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>Researcher trained GPT2 to predict the product of two numbers up to 20 digits w/o intermediate reasoning steps, surpassing previous 15-digit demo w/o CoT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/yuntiandeng/status/1814319104448467137&amp;sa=D&amp;source=editors&amp;ust=1730413583204901&amp;usg=AOvVaw0ecvnCF75QJFrz_bZq2qE4">https://x.com/yuntiandeng/status/1814319104448467137</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">The accuracy is a perfect 100%, while GPT-4 has 0% accuracy</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>&nbsp;Random Latent Exploration for Deep Reinforcement Learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/fly51fly/status/1814409438650159137&amp;sa=D&amp;source=editors&amp;ust=1730413583205273&amp;usg=AOvVaw2aslbhkfLP5U6z9JzYwOka">https://x.com/fly51fly/status/1814409438650159137</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">- RLE is straightforward to implement and performs well in practice. Evaluated on challenging ATARI and ISAACGYM benchmarks.</span></li><li class="c7 li-bullet-0"><span class="c1">- RLE shows higher overall scores across all tasks than other approaches like RND and randomized value function strategies.</span></li></ul><ul class="c0 lst-kix_thjul0jak92m-0"><li class="c10 li-bullet-0"><span>Mindful-RAG: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/fly51fly/status/1814059659243700685&amp;sa=D&amp;source=editors&amp;ust=1730413583205768&amp;usg=AOvVaw2D4iMRZF48OT-_ja6WxuK3">https://x.com/fly51fly/status/1814059659243700685</a></span></li></ul><ul class="c0 lst-kix_thjul0jak92m-1 start"><li class="c7 li-bullet-0"><span class="c1">- The paper proposes a new approach called Mindful-RAG to address deficiencies in grasping the intent behind questions and inability to contextually align with information extracted from the KG through intent identification, context alignment, and validation of response relevance.</span></li></ul><p class="c22 c161 c97 c46"><span class="c1"></span></p><ul class="c0 lst-kix_l25ba28sjj7-0 start"><li class="c4 li-bullet-0"><span>MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/6llW7BqYzo&amp;sa=D&amp;source=editors&amp;ust=1730413583206250&amp;usg=AOvVaw3ENhaAgOmEhaJ-yCuPt9N_">https://arxiv.org/abs/2407.13089</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span class="c1">- The paper presents MetaSumPerceiver (MSP), a novel summarization model for generating claim-specific summaries from multimodal, multi-document datasets to assist with fact-checking. </span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- MSP uses a dynamic perceiver-based model to handle multimodal inputs of arbitrary lengths, including documents, images, and claims.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- To train MSP, reinforcement learning with an entailment model as a reward signal is employed to refine summaries to provide relevant evidence for fact-checking.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- MSP incorporates a proxy reward mechanism with PPO to continually update the summarizer during fact-checking.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- The paper introduces the Multi-News-Fact-Checking dataset with over 100k labeled claims derived from Multi-News using Llama prompts.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Experiments on MOCHEG and the new dataset show MSP </span><span class="c33 c15">substantially outperforms prior baselines, achieving state-of-the-art performance.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- The key innovation is using RL to optimize summarization specifically for claim verification versus generic summarization.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 689.33px;"><img alt="" src="images/image81.png" style="width: 624.00px; height: 689.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span>&nbsp;Scaling Retrieval-Based Language Models with a Trillion-Token Datastore: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.12854&amp;sa=D&amp;source=editors&amp;ust=1730413583207840&amp;usg=AOvVaw1Do81YVkcgBxqItjKgyxX0">https://arxiv.org/abs/2407.12854</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span class="c1">- This paper investigates how scaling up the datastore in retrieval-augmented language models improves performance without signs of saturation on both language modeling and downstream tasks. </span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- The authors built MASSIVEDS, an open-sourced 1.4 trillion token datastore covering a diverse set of domains. MASSIVEDS is the largest open-sourced datastore for studying retrieval scaling.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- They designed an efficient pipeline to make the study computationally tractable by sharing indexing and retrieval computation across different datastore configurations.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Experiments show datastore scaling </span><span class="c33 c15">brings consistent improvements in language modeling perplexity on web data and scientific papers. &nbsp;</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- On downstream tasks, datastore scaling </span><span class="c15">significantly boosts performance</span><span>&nbsp;on knowledge-intensive QA tasks like TriviaQA and Natural Questions. Smaller retrieval models can </span><span class="c33 c15">match or exceed their larger LM-only counterparts.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Datastore scaling also</span><span class="c15">&nbsp;improves performance on reasoning tasks</span><span class="c1">&nbsp;like MMLU, but the improvements are more modest, indicating potential need for more in-domain data.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Compared to LM-only models, retrieval models achieve </span><span class="c34">superior compute-optimal scaling curves by offloading FLOPs </span><span class="c1">from model pretraining to datastore indexing.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Analysis reveals the retriever can</span><span class="c33 c34">&nbsp;stay robust to out-of-domain data and tend to retrieve relevant documents even from a broad datastore.</span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c78 c145 li-bullet-0"><span class="c35">Significantly better text generation in images: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.14138&amp;sa=D&amp;source=editors&amp;ust=1730413583209816&amp;usg=AOvVaw0haCq2Au-Kyo22_CiNeZrI">https://huggingface.co/papers/2407.14138</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-2 start"><li class="c145 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 564.50px; height: 462.27px;"><img alt="" src="images/image510.png" style="width: 564.50px; height: 462.27px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span>Sparsecraft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1815204831679664191&amp;sa=D&amp;source=editors&amp;ust=1730413583210331&amp;usg=AOvVaw3r3zaRYqkIIhJYzOSeCWTc">https://x.com/_akhaliq/status/1815204831679664191</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span class="c1">our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.</span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span>&nbsp;SlowFast-LLaVA, A Strong Training-Free Baseline for Video Large Language Models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.15841&amp;sa=D&amp;source=editors&amp;ust=1730413583210759&amp;usg=AOvVaw0evTRJiTHTEeSSAgviMP6D">https://huggingface.co/papers/2407.15841</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span class="c1">&nbsp;it achieves comparable or even better performance compared to state-of-the-art Video LLMs that are fine-tuned on video datasets.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 356.00px;"><img alt="" src="images/image250.png" style="width: 624.00px; height: 356.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span>OpenAI patent for using machine learning to train and use a model to perform automatic interface actions based on video and input datasets: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://patents.google.com/patent/US11887367B1/en&amp;sa=D&amp;source=editors&amp;ust=1730413583211308&amp;usg=AOvVaw2I6F3eqiw0YjN8kfR-r1Io">https://patents.google.com/patent/US11887367B1/en</a></span></li><li class="c4 li-bullet-0"><span>RGM, active inference non-llm approach using 90% less data (less need for synthetic data, lower energy footprint). 99.8% accuracy in MNIST benchmark using 90% less data to train on less powerful devices: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.20292&amp;sa=D&amp;source=editors&amp;ust=1730413583211635&amp;usg=AOvVaw2QhcZC-uj9mt6JdcCFX0hf">https://arxiv.org/pdf/2407.20292</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span class="c1">Use for Atari game performance: &ldquo;This fast structure learning took about 18 seconds on a personal computer. &ldquo;</span></li><li class="c10 li-bullet-0"><span class="c1">Use for MNIST dataset classification: For example, the variational procedures above attained state-of-the-art classification accuracy on a self-selected subset of test data after seeing 10,000 training images. Each training image was seen once, with continual learning (and no notion of batching). Furthermore, the number of training images actually used for learning was substantially smaller10 than 10,000; because active learning admits only those informative images that reduce expected free energy. This (Maxwell&rsquo;s Demon) aspect of selecting the right kind of data for learning will be a recurrent theme in subsequent sections. Finally, the requisite generative model was self-specifying, given some exemplar data. In other words, the hierarchical depth and size of the requisite tensors were learned automatically within a few seconds on a personal computer.</span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span>Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while using only 2K training samples) as GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413583212332&amp;usg=AOvVaw3FQR5UNXR6XZhL0vg5qBRg">https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/</a></span></li><li class="c4 li-bullet-0"><span class="c14 c31">Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2408.03314&amp;sa=D&amp;source=editors&amp;ust=1730413583212692&amp;usg=AOvVaw05zIip0FZhMJkX-DMCQxHb">https://huggingface.co/papers/2408.03314</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_l25ba28sjj7-1"><li class="c10 li-bullet-0"><span>This observation motivates applying a &quot;compute-optimal&quot; scaling strategy, which acts to most </span><span class="c34">effectively allocate test-time compute adaptively per prompt.</span><span>&nbsp;Using this compute-optimal strategy, we can</span><span class="c15">&nbsp;improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline</span><span>. Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller base model attains somewhat non-trivial success rates, test-time compute can be used to </span><span class="c33 c15">outperform a 14x larger model.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0 start"><li class="c4 li-bullet-0"><span class="c1">Nvidia Research team has developed a method to efficiently create smaller, accurate language models by using structured weight pruning and knowledge distillation, offering several advantages for developers:</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c1">16% better performance on MMLU scores.</span></li><li class="c10 li-bullet-0"><span class="c1">40x fewer tokens for training new models.</span></li><li class="c10 li-bullet-0"><span class="c1">Up to 1.8x cost saving for training a family of models.</span></li><li class="c10 li-bullet-0"><span>The effectiveness of these strategies is demonstrated with the Meta Llama 3.1 8B model, which was refined into the Llama-3.1-Minitron 4B. The collection on huggingface: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e&amp;sa=D&amp;source=editors&amp;ust=1730413583213786&amp;usg=AOvVaw1osg6sivoqzSywtTU7Pxg5">https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e</a></span></li><li class="c10 li-bullet-0"><span>Technical dive: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model&amp;sa=D&amp;source=editors&amp;ust=1730413583214169&amp;usg=AOvVaw1ytUvOgaRvrkOeLV3MF_zZ">https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model</a></span></li><li class="c10 li-bullet-0"><span>Research paper: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.14679&amp;sa=D&amp;source=editors&amp;ust=1730413583214463&amp;usg=AOvVaw2QUoh9UrLEHykKfZupbATZ">https://arxiv.org/abs/2407.14679</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>A* planning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning&amp;sa=D&amp;source=editors&amp;ust=1730413583214789&amp;usg=AOvVaw1bamJa5KnWbRRLzKbzOB7i">https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span class="c92 c183 c37 c14 c114">Based on the claims of the research team, their transformer model optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A&lowast; search. Their solution also robustly follows the execution trace of a symbolic planner and improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span class="c1">Automated Design of Agentic Systems: Presents Meta Agent Search to demonstrate that we can use agents to invent novel and powerful agent designs by programming in code</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span>proj:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/lGEL9nVFRw&amp;sa=D&amp;source=editors&amp;ust=1730413583215409&amp;usg=AOvVaw16wloq3_oeliCRFrJIfLJ_">&nbsp;https://shengranhu.com/ADAS/</a></span></li><li class="c10 li-bullet-0"><span>abs:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/DAHuy2WTtc&amp;sa=D&amp;source=editors&amp;ust=1730413583215686&amp;usg=AOvVaw3jhE-SC_-D8Z938pO_0EsD">&nbsp;https://arxiv.org/abs/2408.08435</a></span></li><li class="c10 li-bullet-0"><span>github:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/r8OKfjWlN5&amp;sa=D&amp;source=editors&amp;ust=1730413583215950&amp;usg=AOvVaw0Dt9n7Jbyey-IxYJZiTOqf">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/ShengranHu/ADAS&amp;sa=D&amp;source=editors&amp;ust=1730413583216106&amp;usg=AOvVaw3gD-mHcZkhvcQ0MnCFpbqM">https://github.com/ShengranHu/ADAS</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Drama Engine: a novel framework for agentic interaction with large language models designed for narrative purposes. The framework adapts multi-agent system principles to create dynamic, context-aware companions that can develop over time and interact with users and each other: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.11574&amp;sa=D&amp;source=editors&amp;ust=1730413583216407&amp;usg=AOvVaw2Fo0Wdgs6vxjHmoTdXXQ5D">https://arxiv.org/abs/2408.11574</a></span></li><li class="c4 li-bullet-0"><span>Diffusion models as real-time interactive game engines: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://gamengen.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583216712&amp;usg=AOvVaw23gj8sIHjcIv6q7-MDqkBV">https://gamengen.github.io/</a></span></li><li class="c4 li-bullet-0"><span class="c14">AI agent that can control a computer: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.adept.ai/blog/act-1&amp;sa=D&amp;source=editors&amp;ust=1730413583217010&amp;usg=AOvVaw07crWFoJIjG05LxPqMhs5H">https://www.adept.ai/blog/act-1</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">This can be especially powerful for manual tasks and complex tools &mdash; in this example, what might ordinarily take 10+ clicks in Salesforce can be now done with just a sentence.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">Working in-depth in tools like spreadsheets, ACT-1 demonstrates real-world knowledge, infers what we mean from context, and can help us do things we may not even know how to do.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">The model can also complete tasks that require composing multiple tools together; most things we do on a computer span multiple programs. In the future, we expect ACT-1 to be even more helpful by asking for clarifications about what we want.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">The internet contains a lot of knowledge about the world! When the model doesn&rsquo;t know something, it knows how to just look up the information online</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">ACT-1 doesn&rsquo;t know how to do everything, but it&rsquo;s highly coachable. With 1 piece of human feedback, it can correct mistakes, becoming more useful with each interaction.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Magic has trained their first model with a </span><span class="c15">100 million token context window</span><span>. That&rsquo;s 10 million lines of code, or 750 novels: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://magic.dev/blog/100m-token-context-windows&amp;sa=D&amp;source=editors&amp;ust=1730413583218003&amp;usg=AOvVaw1UMyuBTFkhhQYAjL8UjgYc">https://magic.dev/blog/100m-token-context-windows</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c1">&ldquo;The contrast in memory requirements is even larger &ndash; running Llama 3.1 405B with a 100M token context requires 638 H100s per user just to store a single 100M token KV cache. In contrast, LTM requires a small fraction of a single H100&rsquo;s HBM per user for the same context.&quot;</span></li><li class="c10 li-bullet-0"><span>SSMs, RNNs, and RAG all exploit weaknesses in evals like Needle In A Haystack, so we made a new eval, HashHop: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/magicailabs/status/1829206895804199086&amp;sa=D&amp;source=editors&amp;ust=1730413583218476&amp;usg=AOvVaw3yYQu9Xf45bT7Jaq1VXj-7">https://x.com/magicailabs/status/1829206895804199086</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-2 start"><li class="c7 li-bullet-0"><span class="c1">1) Incompressible</span></li><li class="c7 li-bullet-0"><span class="c1">2) Multi-hop</span></li><li class="c7 li-bullet-0"><span class="c1">3) No semantic hints</span></li><li class="c7 li-bullet-0"><span class="c1">4) No recency bias</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 505.33px;"><img alt="" src="images/image336.jpg" style="width: 624.00px; height: 505.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Patched MoA: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.18521&amp;sa=D&amp;source=editors&amp;ust=1730413583219271&amp;usg=AOvVaw1zbhhdUXtvI95gD0Btq1Q-">https://arxiv.org/abs/2407.18521</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">Patched MOA can </span><span class="c34 c14 c31">boost the performance of smaller models to surpass that of larger, more expensive models</span><span class="c14 c31">. Notably, our approach i</span><span class="c15 c31">mproves the gpt-4o-mini model&#39;s performance on the Arena-Hard-Auto benchmark by 15.52%, outperforming gpt-4-turbo at a fraction of the cost</span><span class="c14 c31">. We also apply Patched MOA to various software development workflows, showing </span><span class="c34 c14 c31">consistent improvements in task completion rates.</span><span class="c3">&nbsp;Our method is model-agnostic, transparent to end-users, and can be easily integrated into existing LLM pipelines.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span class="c3">Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning</span></li></ul><p class="c21 c129"><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.10110&amp;sa=D&amp;source=editors&amp;ust=1730413583220019&amp;usg=AOvVaw1_P97yCCvjbXfDoekZS-Dm">https://arxiv.org/abs/2402.10110</a></span></p><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span class="c3">This paper introduces Selective Reflection-Tuning, a novel paradigm that synergizes a teacher LLM&#39;s reflection and introspection for improving existing data quality with the data selection capability of the student LLM, to automatically refine existing instruction-tuning data. This teacher-student collaboration produces high-quality and student-compatible instruction-response pairs, resulting in sample-efficient instruction tuning and LLMs of superior performance. Selective Reflection-Tuning is a data augmentation and synthesis that generally improves LLM finetuning and self-improvement without collecting brand-new data. We apply our method to Alpaca and WizardLM data and achieve much stronger and top-tier 7B and 13B LLMs.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://lmsys.org/blog/2023-11-14-llm-decontaminator/&amp;sa=D&amp;source=editors&amp;ust=1730413583220499&amp;usg=AOvVaw0F6o0pdO9_dPZx6k_eKzVs">https://lmsys.org/blog/2023-11-14-llm-decontaminator/</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.77px; height: 519.87px;"><img alt="" src="images/image590.png" style="width: 490.77px; height: 519.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c14 c31">Rephrasing the test set is all you need! We simply paraphrase a test sample or translate it into a different language. It turns out a </span><span class="c28 c43">13B LLM is smart enough to &quot;generalize&quot; beyond such variations and reaches drastically high benchmark performance. </span></li><li class="c10 li-bullet-0"><span class="c14 c31">To ensure result validity, we followed OpenAI&#39;s decontamination method and </span><span class="c28 c43">found no evidence of data contamination.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1831530803635085766/mediaViewer?currentTweet%3D1831530803635085766%26currentTweetUser%3D_akhaliq&amp;sa=D&amp;source=editors&amp;ust=1730413583221293&amp;usg=AOvVaw30I1Z7azuR8fQMI8lqxoq2">https://x.com/_akhaliq/status/1831530803635085766</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span>Examples: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIandDesign/status/1831721458017710204&amp;sa=D&amp;source=editors&amp;ust=1730413583221612&amp;usg=AOvVaw0NTWKphWWZecPOS3MaTvuK">https://x.com/AIandDesign/status/1831721458017710204</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>AIs can help other AIs solve problems through &ldquo;meta-cognition&rdquo; (of a sort). GPT-4 can consistently label math problems by the skills needed to solve them. Other LLMs are then more accurate on solving those math problems once they are given those labels: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.12205&amp;sa=D&amp;source=editors&amp;ust=1730413583221954&amp;usg=AOvVaw0S6KVEDA_XJvVEX3mMPntW">https://arxiv.org/pdf/2405.12205</a></span></li><li class="c4 li-bullet-0"><span>&ldquo;SkillMimic&quot; uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmimic_uses_just_35_minutes_of_video_and/&amp;sa=D&amp;source=editors&amp;ust=1730413583222342&amp;usg=AOvVaw2wbFWkaxDda9qU6-g3BaBJ">https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmim</a></span></li><li class="c4 li-bullet-0"><span>Source2Synth: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jaseweston/status/1834402693995024453&amp;sa=D&amp;source=editors&amp;ust=1730413583222651&amp;usg=AOvVaw2uerbIWg3Ipk1Y6re5l_rR">https://x.com/jaseweston/status/1834402693995024453</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c1">- Generates synthetic examples grounded in real data </span></li><li class="c10 li-bullet-0"><span class="c1">- Curation step makes data high quality based on answerability</span></li><li class="c10 li-bullet-0"><span class="c1">- Improves performance on two challenging domains: Multi-hop QA and using tools: SQL for tabular QA </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 214.67px;"><img alt="" src="images/image421.png" style="width: 624.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 205.33px;"><img alt="" src="images/image314.png" style="width: 624.00px; height: 205.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 472.50px; height: 683.75px;"><img alt="" src="images/image194.png" style="width: 472.50px; height: 683.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Novel Chinese computing architecture &#39;inspired by human brain&#39; can lead to AGI, scientists say</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/news/news/content/ar-AA1q7bfu?ocid%3Dsapphireappshare&amp;sa=D&amp;source=editors&amp;ust=1730413583223626&amp;usg=AOvVaw3c5XtxHYR2kxYOOkxKfWgF">https://www.msn.com/en-us/news/news/content/ar-AA1q7bfu</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span class="c1">In the study, the scientists demonstrated this model can handle complex tasks efficiently and reliably. They also showed that a small model based on this architecture can perform just as well as a much larger conventional model of artificial neurons.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>Scientists in China have created a new computing architecture that can train advanced </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.livescience.com/technology/artificial-intelligence/what-is-artificial-intelligence-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583224263&amp;usg=AOvVaw3q-V-fRg0CVmFeuFyQWNsH">artificial intelligence</a></span><span class="c1">&nbsp;(AI) models while consuming fewer computing resources &mdash; and they hope that it will one day lead to artificial general intelligence (AGI). </span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.03314v1&amp;sa=D&amp;source=editors&amp;ust=1730413583224598&amp;usg=AOvVaw1P2xie9PxyeIMoe63lcair">https://arxiv.org/abs/2408.03314v1</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c55 c14">In this work, we analyze two primary mechanisms to scale test-time computation: (1) searching against dense, process-based verifier reward models; and (2) updating the model&#39;s distribution over a response adaptively, given the prompt at test time. We find that in both cases, the effectiveness of different approaches to scaling test-time compute critically varies depending on the difficulty of the prompt. This observation motivates applying a &quot;compute-optimal&quot; scaling strategy, which acts to most effectively allocate test-time compute adaptively per prompt. Using this compute-optimal strategy, we can</span><span class="c15 c55">&nbsp;improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline.</span><span class="c55 c14">&nbsp;Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller base model attains somewhat non-trivial success rates,</span><span class="c40 c15 c55 c48">&nbsp;test-time compute can be used to outperform a 14x larger model.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span class="c55">Denny Zhou (Founded &amp; lead reasoning team at Google DeepMind) - &quot;We have mathematically proven that transformers can solve any problem, provided they are allowed to generate as many intermediate reasoning tokens as needed. Remarkably, constant depth is sufficient.&quot; </span><span class="c5 c55"><a class="c13" href="https://www.google.com/url?q=https://x.com/denny_zhou/status/1835761801453306089&amp;sa=D&amp;source=editors&amp;ust=1730413583225120&amp;usg=AOvVaw2vGpzZRlqVn6j8U5CzHK0T">https://x.com/denny_zhou/status/1835761801453306089</a></span></li><li class="c4 li-bullet-0"><span class="c55">[</span><span>Google DeepMind] Training Language Models to Self-Correct via Reinforcement Learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2409.12917&amp;sa=D&amp;source=editors&amp;ust=1730413583225368&amp;usg=AOvVaw3V0apFF4i0ejb0c3k--30b">https://arxiv.org/abs/2409.12917</a></span></li></ul><p class="c9"><span class="c40 c55 c37 c48"></span></p><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span class="c3">When applied to Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models&#39; self-correction by 15.6% and 9.1% respectively on the MATH and HumanEval benchmarks.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span class="c14 c31">Reasoning benchmark: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.12172&amp;sa=D&amp;source=editors&amp;ust=1730413583225721&amp;usg=AOvVaw3cqgmzxeVqd_Xfb_0x9tPL">https://arxiv.org/abs/2406.12172</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">. We show that even the most advanced LLMs fail to solve these problems end-to-end in text, e.g. GPT4 solves only 1.4%. SearchBench problems require considering multiple pathways to the solution as well as backtracking, posing a significant challenge to auto-regressive models. Instructing LLMs to generate code that solves the problem helps, but only slightly, e.g., GPT4&#39;s performance rises to 11.7%. In this work, we show that in-context learning with A* algorithm implementations enhances performance. The full potential of this promoting approach emerges when combined with our proposed Multi-Stage-Multi-Try method, which breaks down the algorithm implementation into two stages and verifies the first stage against unit tests,</span><span class="c28 c43">&nbsp;raising GPT-4&#39;s performance above 57%.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>OpenAI is already training a new version of Sora with even higher quality and longer videos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign%3DEditorial%26utm_content%3DNewsletter%252CAI%2BAgenda%26utm_medium%3Dorganic_social%26utm_source%3Dtwitter&amp;sa=D&amp;source=editors&amp;ust=1730413583226179&amp;usg=AOvVaw10d3gAkAu3RZMqfU6TA2au">https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign=Editorial&amp;utm_content=Newsletter%2CAI+Agenda&amp;utm_medium=organic_social&amp;utm_source=twitter</a></span></li><li class="c4 li-bullet-0"><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2410.01201&amp;sa=D&amp;source=editors&amp;ust=1730413583226362&amp;usg=AOvVaw3S9inif-mQmX5h8FhT1Cn2">https://arxiv.org/pdf/2410.01201</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span>we show that by removing their hidden state dependencies from their input, forget, and update gates, LSTMs and GRUs no longer need to BPTT and can be </span><span class="c34">efficiently trained in parallel</span><span>. Building on this, we introduce minimal versions (minLSTMs and minGRUs) that (1) use </span><span class="c15">sig- nificantly fewer parameters</span><span class="c34">&nbsp;</span><span>than their traditional counterparts and (2) are </span><span class="c34">fully parallelizable </span><span>during training (175&times; faster for a sequence of length 512). Lastly, we show that these stripped-down versions of decade-old RNNs </span><span class="c33 c34">match the empir- ical performance of recent sequence models.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 253.33px;"><img alt="" src="images/image269.png" style="width: 624.00px; height: 253.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-2 start"><li class="c7 li-bullet-0"><span class="c40 c37 c48 c31">Notice how it reaches the lowest loss on the test set long before the transformer does </span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 725.33px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 725.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 213.33px;"><img alt="" src="images/image348.png" style="width: 624.00px; height: 213.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>the first series of Liquid Foundation Models (LFMs) &ndash; a new generation of generative AI models that achieve </span><span class="c15">state-of-the-art performance at every scale, while maintaining a smaller memory footprint and more efficient inference.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.liquid.ai/liquid-foundation-models&amp;sa=D&amp;source=editors&amp;ust=1730413583227318&amp;usg=AOvVaw2ZRfBAoV4NWDfxAb0qDeil">https://www.liquid.ai/liquid-foundation-models</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.liquid.ai/blog/liquid-neural-networks-research&amp;sa=D&amp;source=editors&amp;ust=1730413583227557&amp;usg=AOvVaw0REJBBdSaNFeakmSHgFG0F">https://www.liquid.ai/blog/liquid-neural-networks-research</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/LiquidAI_/status/1840768716784697688&amp;sa=D&amp;source=editors&amp;ust=1730413583227797&amp;usg=AOvVaw2lXFNYs9WKi8M6mOu6R5Dl">https://x.com/LiquidAI_/status/1840768716784697688</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/teortaxesTex/status/1840897331773755476&amp;sa=D&amp;source=editors&amp;ust=1730413583228005&amp;usg=AOvVaw3x40ZRAaH_giq61_nkceyH">https://x.com/teortaxesTex/status/1840897331773755476</a></span></li><li class="c10 li-bullet-0"><span class="c1">&quot;We announce the first series of Liquid Foundation Models (LFMs), a new generation of generative AI models built from first principles.</span></li><li class="c10 li-bullet-0"><span class="c1">Our 1B, 3B, and 40B LFMs achieve state-of-the-art performance in terms of quality at each scale, while maintaining a smaller memory footprint and more efficient inference.&quot;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image313.jpg" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image284.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 426.67px;"><img alt="" src="images/image525.jpg" style="width: 624.00px; height: 426.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Engineers are evaluating a new sampling method for LLMs that seems as if it may significantly reduce hallucination and allow for dynamic test time compute (ie, o1) in all models - still early days, but looks promising: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fyacda/engineers_are_evaluating_a_new_sampling_method/&amp;sa=D&amp;source=editors&amp;ust=1730413583228647&amp;usg=AOvVaw0HTJ0C5Egfa7zEtGX6h5Y-">https://www.reddit.com/r/singularity/comments/1fyacda/engineers_are_evaluating_a_new_sampling_method/</a></span></li><li class="c4 li-bullet-0"><span>Differential transformer: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.05258&amp;sa=D&amp;source=editors&amp;ust=1730413583228871&amp;usg=AOvVaw3ax16TpkE9TbEWX5VQKYMY">https://arxiv.org/abs/2410.05258</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span>Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that Diff Transformer </span><span class="c15">outperforms Transformer in various settings of scaling up model size and training tokens</span><span>. More intriguingly, it offers </span><span class="c15">notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers</span><span>. By being less distracted by irrelevant context, Diff Transformer can </span><span class="c15">mitigate hallucination in question answering and text summarization</span><span>. For in-context learning, Diff Transformer not only </span><span class="c15">enhances accuracy but is also more robust to order permutation</span><span class="c1">, which was considered as a chronic robustness issue. The results position Diff Transformer as a highly effective and promising architecture to advance large language models.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 422.67px;"><img alt="" src="images/image50.png" style="width: 624.00px; height: 422.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 622.67px;"><img alt="" src="images/image229.png" style="width: 624.00px; height: 622.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>New research could make weird AI images a thing of the past: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://news.rice.edu/news/2024/rice-research-could-make-weird-ai-images-thing-past&amp;sa=D&amp;source=editors&amp;ust=1730413583229558&amp;usg=AOvVaw3ZTjyyaE-C0yXRJbkMNjKr">https://news.rice.edu/news/2024/rice-research-could-make-weird-ai-images-thing-past</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c1">New diffusion model approach solves the aspect ratio problem</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>BrainLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583229913&amp;usg=AOvVaw1p8QIP4zLRsrP-z_M3WEEw">https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span>Utilizing self-supervised masked-prediction training, BrainLM demonstrates </span><span class="c15">proficiency in both fine-tuning and zero-shot inference tasks</span><span>. Fine-tuning allows for the </span><span class="c15">accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states</span><span>. Critically, the model </span><span class="c15">generalizes well to entirely new external cohorts not seen during training.</span><span>&nbsp;In zero-shot inference mode, BrainLM can i</span><span class="c15">dentify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training</span><span>. The model also generates i</span><span class="c15">nterpretable latent representations that reveal relationships between brain activity patterns and cognitive states</span><span>. Overall, BrainLM offers a </span><span class="c34">versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. </span><span>It serves as a powerful &quot;lens&quot; through which m</span><span class="c15">assive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale</span><span class="c1">. The work demonstrates the potential of foundation models to advance computational neuroscience research. </span></li><li class="c10 li-bullet-0"><span class="c15">Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 444.00px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 444.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 601.33px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 601.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 568.00px;"><img alt="" src="images/image38.png" style="width: 624.00px; height: 568.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 160.00px;"><img alt="" src="images/image133.png" style="width: 624.00px; height: 160.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 653.33px;"><img alt="" src="images/image211.png" style="width: 624.00px; height: 653.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 613.96px; height: 520.50px;"><img alt="" src="images/image13.png" style="width: 613.96px; height: 520.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08146&amp;sa=D&amp;source=editors&amp;ust=1730413583231140&amp;usg=AOvVaw3ulkhXRs6bMCDwVF3ukHU0">https://arxiv.org/abs/2410.08146</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span>We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is</span><span class="c15">&nbsp;&gt;8% more accurate, and 1.5&minus;5&times; more compute-efficient. </span><span>Online RL with dense rewards from PAVs enables one of the first results with</span><span class="c33 c15">&nbsp;5&minus;6&times; gain in sample efficiency, and &gt;6% gain in accuracy, over ORMs.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413583231470&amp;usg=AOvVaw3D-i_PSzXtbnlTLeC8_G8w">https://arxiv.org/abs/2410.06209</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c1">LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>paper from Meta discloses TPO (Thought Preference Optimization) technique with impressive results: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.10630&amp;sa=D&amp;source=editors&amp;ust=1730413583231803&amp;usg=AOvVaw2iFmp0-r6MnyGxxRxuGGYE">https://arxiv.org/abs/2410.10630</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">We propose a training method for equipping existing LLMs with such thinking abilities for general instruction following </span><span class="c15 c31">without use of additional human data</span><span class="c14 c31">. We achieve this by an iterative search and optimization procedure that explores the space of possible thought generations, </span><span class="c15 c31">allowing the model to learn how to think without direct supervision. </span><span class="c14 c31">For each instruction, the thought candidates are scored using a judge model to evaluate their responses only, and then optimized via preference optimization. We show that this procedure leads to </span><span class="c28 c43">superior performance on AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning categories such as marketing, health and general knowledge, in addition to more traditional reasoning &amp; problem-solving tasks.</span></li><li class="c10 li-bullet-0"><span class="c1">highest win rate our model TPO achieves is 52.5%, which is +4.1% better than the direct baseline, as shown in Table 1. It is also a +27.6% increase over the seed model and puts our method in 3rd position on the leaderboard(1), just after GPT-4 Omni and GPT-4 Turbo. This is an impressive result given the small size (8B) of our model.&rdquo;</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-2 start"><li class="c7 li-bullet-0"><span class="c1">GPT-4o does 57.5%. GPT-4 Turbo 54.0%</span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1"><li class="c10 li-bullet-0"><span>Best LLM on Alpaca Eval as of Sep. 27th 2024. </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://tatsu-lab.github.io/alpaca_eval/&amp;sa=D&amp;source=editors&amp;ust=1730413583232334&amp;usg=AOvVaw0vfZ8FWY3jRZU2FsDk1oLO">https://tatsu-lab.github.io/alpaca_eval/</a></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 257.33px;"><img alt="" src="images/image388.png" style="width: 624.00px; height: 257.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>&ldquo;Our task-specific ViTARC models achieve a test solve rate close to 100% on more than half of the 400 public ARC tasks strictly through supervised learning from input-output grids.&ldquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06405&amp;sa=D&amp;source=editors&amp;ust=1730413583232612&amp;usg=AOvVaw2nn3OaFH0FRbYx8ogatIae">https://arxiv.org/abs/2410.06405</a></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 317.33px;"><img alt="" src="images/image90.png" style="width: 624.00px; height: 317.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ie13bttc6n1-0"><li class="c4 li-bullet-0"><span>Meta&#39;s Joe Spisak explains how AI models can train themselves by generating images, asking itself questions about them, and choosing the best answers, in order to move beyond human data and human fine-tuning, and teach itself from synthetic data: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1847789784078618640&amp;sa=D&amp;source=editors&amp;ust=1730413583232963&amp;usg=AOvVaw1-dVm23J4ZZV4jkT_ys8BK">https://x.com/tsarnick/status/1847789784078618640</a></span></li></ul><h2 class="c64" id="h.xfy63xcfm5w0"><span class="c40 c37 c48 c75">3.3. Hardware Improvements</span></h2><ul class="c0 lst-kix_hefc4tmerznh-0 start"><li class="c4 li-bullet-0"><span class="c23 c14">IISc scientists report neuromorphic computing breakthrough: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.deccanherald.com/technology/iisc-scientists-report-computing-breakthrough-3187052&amp;sa=D&amp;source=editors&amp;ust=1730413583233359&amp;usg=AOvVaw12gI2menElniBA6nLLjTTH">https://www.deccanherald.com/technology/iisc-scientists-report-computing-breakthrough-3187052</a></span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-1 start"><li class="c10 li-bullet-0"><span class="c23 c14">published in Nature, a highly reputable journal: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41586-024-07902-2&amp;sa=D&amp;source=editors&amp;ust=1730413583233658&amp;usg=AOvVaw3XjbaJUhJiewvH70DhvdvR">https://www.nature.com/articles/s41586-024-07902-2</a></span></li><li class="c10 li-bullet-0"><span class="c23 c14">Paper with no paywall: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.researchgate.net/publication/377744243_Linear_symmetric_self-selecting_14-bit_molecular_memristors/link/65b4ffd21e1ec12eff504db1/download?_tp%3DeyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InB1YmxpY2F0aW9uIiwicGFnZSI6InB1YmxpY2F0aW9uIn19&amp;sa=D&amp;source=editors&amp;ust=1730413583234088&amp;usg=AOvVaw1zTZZwluRXjZ6HVdN_E-I5">https://www.researchgate.net/publication/377744243_Linear_symmetric_self-selecting_14-bit_molecular_memristors/link/65b4ffd21e1ec12eff504db1/download?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InB1YmxpY2F0aW9uIiwicGFnZSI6InB1YmxpY2F0aW9uIn19</a></span></li><li class="c10 li-bullet-0"><span class="c23 c14">Scientists at the IISc, Bengaluru, are reporting a momentous breakthrough in neuromorphic, or brain-inspired, computing technology that could potentially allow India to play in the global AI race currently underway and could also democratise the very landscape of AI computing drastically -- away from today&rsquo;s &lsquo;cloud computing&rsquo; model which requires large, energy-guzzling data centres and towards an &lsquo;edge computing&rsquo; paradigm -- </span><span class="c40 c35 c65 c34 c14">to your personal device, laptop or mobile phone.</span></li><li class="c10 li-bullet-0"><span class="c23 c14">What they have done essentially is to develop a type of semiconductor device called Memristor, but using a metal-organic film rather than conventional silicon-based technology. This material enables the Memristor to </span><span class="c40 c35 c65 c34 c14">mimic the way the biological brain processes information using networks of neurons and synapses, rather than do it the way digital computers do.</span></li><li class="c10 li-bullet-0"><span class="c23 c14">The Memristor, when integrated with a conventional digital computer, </span><span class="c15 c35 c65">enhances its energy and speed performance by hundreds of times, and speed performance by hundreds of times, </span><span class="c40 c23 c14">thus becoming an extremely energy-efficient &lsquo;AI accelerator&rsquo;.</span></li><li class="c10 li-bullet-0"><span class="c23 c14">When eventually scaled up, the technology </span><span class="c40 c15 c35 c65">could enable the most large-scale and complex AI tasks &ndash; such as large language model (LLM) training &ndash; to be done on a laptop or smartphone, rather than requiring a data centre.</span></li><li class="c10 li-bullet-0"><span>The molecular memristor described in this research is </span><span class="c15">460 times more energy-efficient than a traditional digital computer and 220 times more efficient than a NVIDIA K80 GPU.</span><span class="c1">&nbsp;This is a game-changing reduction in energy consumption, making it feasible to run advanced AI applications on devices that have limited power, like mobile devices or sensors.</span></li><li class="c10 li-bullet-0"><span class="c34">Older memristors generally had low precision, often capable of storing only 2 to 6 different levels of resistance (which corresponds to 1-3 bits of information). </span><span>The new molecular memristor boasts </span><span class="c15">14-bit resolution, which means it can store 16,520 distinct levels</span><span class="c1">. This is a massive leap in precision, offering much finer control over the stored information. For context, having 14 bits instead of 3 bits (like earlier devices) means this memristor can differentiate many more subtle states, resulting in far more accurate calculations.</span></li><li class="c10 li-bullet-0"><span>While older memristors were faster than digital components, they still required multiple steps to perform complex operations, like vector-matrix multiplication (VMM) or discrete Fourier transforms (DFT), which are fundamental to AI algorithms. The new device can perform these operations in a </span><span class="c15">single time step. </span><span>For example, </span><span class="c15">multiplying two large matrices, which would require tens of thousands of operations on a traditional computer, can be done in just one step with this memristor.</span><span class="c1">&nbsp;This dramatically increases the speed of computation, making it suitable for real-time applications like autonomous vehicles or instant image processing.</span></li><li class="c10 li-bullet-0"><span>Earlier devices often suffered from issues like non-linear behavior, noise, and variability between different units, which led to inconsistencies in performance. These issues limited the adoption of memristors in high-precision applications. The molecular memristor in the study offers linear and symmetric weight updates, meaning the change in </span><span class="c34">resistance is predictable and uniform, regardless of whether it&#39;s increasing or decreasing. </span><span>It also shows </span><span class="c34">high endurance (109 cycles) and long-term stability, with the ability to maintain data without degradation over long periods of time (up to 7 months)</span><span>. This makes it </span><span class="c33 c15">much more reliable than previous models, especially for tasks that require long-term data retention and consistent performance.</span></li><li class="c10 li-bullet-0"><span>Earlier memristors were often limited by scalability issues, particularly in constructing larger crossbar arrays for parallel processing. The research achieved a 64&times;64 crossbar (which means 4,096 individual memristor units working together) and claims that it </span><span class="c15">can be further scaled up.</span><span>&nbsp;This scalability, combined with high precision and energy efficiency, makes it </span><span class="c33 c15">suitable for large-scale AI applications and other complex computational tasks.</span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-0"><li class="c4 li-bullet-0"><span>Sohu is &gt;10x faster and cheaper than even NVIDIA&rsquo;s next-generation Blackwell (B200) GPUs. One Sohu server runs over 500,000 Llama 70B tokens per second, </span><span class="c15">20x more than an H100 server (23,000 tokens/sec), and 10x more than a B200 server (~45,000 tokens/sec):</span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 376.93px; height: 506.50px;"><img alt="" src="images/image175.png" style="width: 376.93px; height: 506.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-0"><li class="c4 li-bullet-0"><span class="c15">Blackwell GPUs</span><span class="c14">&nbsp;are far more efficient and faster than the H100s used now </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing&amp;sa=D&amp;source=editors&amp;ust=1730413583235774&amp;usg=AOvVaw04toSInCLkBMr2zEZV9am3">https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing</a></span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">And GPT 4 was trained on A100s, the predecessor of H100s</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 320.00px;"><img alt="" src="images/image377.png" style="width: 624.00px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-0"><li class="c4 li-bullet-0"><span class="c1 c14">Successor to B100s already announced</span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 316.00px;"><img alt="" src="images/image246.png" style="width: 624.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hefc4tmerznh-0"><li class="c4 li-bullet-0"><span class="c6">Google&#39;s next-gen TPUs promise a 4.7x performance boost:</span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/05/14/googles-next-gen-tpus-promise-a-4-7x-performance-boost/&amp;sa=D&amp;source=editors&amp;ust=1730413583236233&amp;usg=AOvVaw03tKZxA9IvA_9qiQih8zH0">&nbsp;</a></span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/05/14/googles-next-gen-tpus-promise-a-4-7x-performance-boost/&amp;sa=D&amp;source=editors&amp;ust=1730413583236412&amp;usg=AOvVaw2kCdiVP7RxOPaIitmtyo1L">https://techcrunch.com/2024/05/14/googles-next-gen-tpus-promise-a-4-7x-performance-boost/</a></span></li><li class="c4 li-bullet-0"><span class="c35">NVIDIA drivers version 555 released, claimed to increase &quot;AI performance&quot; up to 3x on RTX cards:</span><span class="c35"><a class="c13" href="https://www.google.com/url?q=https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/&amp;sa=D&amp;source=editors&amp;ust=1730413583236654&amp;usg=AOvVaw0NLqL55OyJHN-_riZzFVI3">&nbsp;</a></span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/&amp;sa=D&amp;source=editors&amp;ust=1730413583236797&amp;usg=AOvVaw0-bIIYimy7fc7Z6-aLxMPz">https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/</a></span><span class="c40 c37 c35 c48">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Engineering researchers at the University of Minnesota Twin Cities have demonstrated a state-of-the-art hardware device that could reduce energy consumption for artificial intelligent (AI) computing applications by a factor of at least 1,000: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cse.umn.edu/college/news/researchers-develop-state-art-device-make-artificial-intelligence-more-energy&amp;sa=D&amp;source=editors&amp;ust=1730413583237060&amp;usg=AOvVaw1ytu0qXpF4TPAckoGlLIDi">https://cse.umn.edu/college/news/researchers-develop-state-art-device-make-artificial-intelligence-more-energy</a></span></li><li class="c4 li-bullet-0"><span class="c18">The Aurora AI supercomputer has become just the second to break the exaflops barrier and also does 10 AI exaflops: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.intel.com/content/www/us/en/newsroom/news/intel-powered-aurora-supercomputer-breaks-exascale-barrier.html%23:~:text%3DWhat%25E2%2580%2599s%2520New%253A%2520At%2520ISC%2520High%2520Performance%25202024%252C%2520Intel,AI%2520for%2520open%2520science%252C%2520achieving%252010.6%2520AI%2520exaflops&amp;sa=D&amp;source=editors&amp;ust=1730413583237356&amp;usg=AOvVaw0Z1NCRkky1ODeayyVYGbsz">https://www.intel.com/content/www/us/en/newsroom/news/intel-powered-aurora-supercomputer-breaks-exascale-barrier.html</a></span></li><li class="c4 li-bullet-0"><span>xAI will build the world&rsquo;s largest supercomputer in Memphis: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wkrn.com/news/tennessee-news/musks-xai-to-build-supercomputer-facility-in-memphis/&amp;sa=D&amp;source=editors&amp;ust=1730413583237691&amp;usg=AOvVaw2abkk3suMnnNwL5uOMKoMx">https://www.wkrn.com/news/tennessee-news/musks-xai-to-build-supercomputer-facility-in-memphis/</a></span></li><li class="c4 li-bullet-0"><span>&nbsp;World first supercomputer capable of brain-scale simulation being built at Western Sydney University: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.westernsydney.edu.au/newscentre/news_centre/more_news_stories/world_first_supercomputer_capable_of_brain-scale_simulation_being_built_at_western_sydney_university&amp;sa=D&amp;source=editors&amp;ust=1730413583238072&amp;usg=AOvVaw0MZEjt90fY3ERxCiX0mTmO">https://www.westernsydney.edu.au/newscentre/news_centre/more_news_stories/world_first_supercomputer_capable_of_brain-scale_simulation_being_built_at_western_sydney_university</a></span></li><li class="c4 li-bullet-0"><span>Robotic hand: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1807768679649849533&amp;sa=D&amp;source=editors&amp;ust=1730413583238335&amp;usg=AOvVaw1oNi8pusF_vrrY9rxBKkap">https://x.com/TheHumanoidHub/status/1807768679649849533</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 422.67px;"><img alt="" src="images/image450.png" style="width: 624.00px; height: 422.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 546.55px; height: 338.06px;"><img alt="" src="images/image244.jpg" style="width: 546.55px; height: 338.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c100 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 578.36px; height: 338.06px;"><img alt="" src="images/image417.jpg" style="width: 578.36px; height: 338.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c100 c78 li-bullet-0"><span>7-foot robots are stacking shelves in Tokyo convenience stores using remote workers for $3.75 an hour. &quot;The robots will be remotely operated at first, until their AI learns to copy human movements.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AISafetyMemes/status/1810152092230877563&amp;sa=D&amp;source=editors&amp;ust=1730413583238821&amp;usg=AOvVaw2IFnK16nZ0lV3MZLdA3YmT">https://x.com/AISafetyMemes/status/1810152092230877563</a></span></li><li class="c22 c32 li-bullet-0"><span class="c30 c37">Lisa Su says AMD is on track to a 100x power efficiency improvement by 2027: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/pc-components/cpus/lisa-su-announces-amd-is-on-the-path-to-a-100x-power-efficiency-improvement-by-2027-ceo-outlines-amds-advances-during-keynote-at-imecs-itf-world-2024&amp;sa=D&amp;source=editors&amp;ust=1730413583239211&amp;usg=AOvVaw1wQtM8snwcFxrDF07ESMh5">https://www.tomshardware.com/pc-components/cpus/lisa-su-announces-amd-is-on-the-path-to-a-100x-power-efficiency-improvement-by-2027-ceo-outlines-amds-advances-during-keynote-at-imecs-itf-world-2024</a></span><span class="c40 c30 c37">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c30 c37">Great robot hand motion: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://x.com/QinYuzhe/status/1732108331869929841&amp;sa=D&amp;source=editors&amp;ust=1730413583239546&amp;usg=AOvVaw07SY4vqvG1qYM6_aYPdowB">https://x.com/QinYuzhe/status/1732108331869929841</a></span></li><li class="c100 c78 li-bullet-0"><span class="c35">SARA: Self-Adaptive Robust Attention: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://sites.google.com/view/rtsara/?pli%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583239815&amp;usg=AOvVaw1bAs8BuGjebemlBCoyowQl">https://sites.google.com/view/rtsara/?pli=1</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 542.71px; height: 350.50px;"><img alt="" src="images/image356.png" style="width: 542.71px; height: 350.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c69 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 549.85px; height: 355.11px;"><img alt="" src="images/image392.png" style="width: 549.85px; height: 355.11px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>OpenAI&rsquo;s First In-House Chip Will Be Developed By TSMC On Its A16 Angstrom Process For Its Sora Video Applications: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://wccftech.com/openai-developing-custom-chip-on-tsmc-a16-angstrom-process/&amp;sa=D&amp;source=editors&amp;ust=1730413583240333&amp;usg=AOvVaw0YWrsN1zoZRckZu4ANt-Wl">https://wccftech.com/openai-developing-custom-chip-on-tsmc-a16-angstrom-process/</a></span></li><li class="c4 li-bullet-0"><span>Deepsilicon runs neural nets with </span><span class="c15">5x less RAM and ~20x faster.</span><span>&nbsp;They are building software and custom silicon for it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/sdianahu/status/1833186687369023550&amp;sa=D&amp;source=editors&amp;ust=1730413583240594&amp;usg=AOvVaw1wbgARTbby_iNwVDwtrAfu">https://x.com/sdianahu/status/1833186687369023550</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">&rdquo;representing transformer models as ternary values (-1, 0, 1) eliminates the need for computationally expensive floating-point math&quot; (See BitNet 1.58 paper in section 13)</span></li><li class="c10 li-bullet-0"><span class="c1">Runs SOTA models</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 488.00px; height: 652.00px;"><img alt="" src="images/image110.png" style="width: 488.00px; height: 652.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Oracle To Deploy A Supercluster Of ~130,000 NVIDIA Blackwell GPUs, Alludes To A &ldquo;Gigawatt&rdquo; Capacity Data Center That Will Be Powered By 3 Nuclear Reactors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://wccftech.com/oracle-to-deploy-a-supercluster-of-130000-nvidia-blackwell-gpus-alludes-to-a-gigawatt-capacity-data-center-that-will-be-powered-by-3-nuclear-reactors/&amp;sa=D&amp;source=editors&amp;ust=1730413583241192&amp;usg=AOvVaw3naRA5QFy8uqBLSAs2uSWR">https://wccftech.com/oracle-to-deploy-a-supercluster-of-130000-nvidia-blackwell-gpus-alludes-to-a-gigawatt-capacity-data-center-that-will-be-powered-by-3-nuclear-reactors/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">Approval for the nuclear reactors was already received. </span></li><li class="c10 li-bullet-0"><span class="c1">If AI is plateauing or becoming a bad investment, why would they do this? </span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>AI Chip Beats Nvidia, AMD and Intel by a Mile with 20x Faster Speeds and Over 4 Trillion Transistors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nasdaq.com/articles/new-ai-chip-beats-nvidia-amd-and-intel-mile-20x-faster-speeds-and-over-4-trillion&amp;sa=D&amp;source=editors&amp;ust=1730413583241651&amp;usg=AOvVaw378FOP5rmapGGGur5QJ5TD">https://www.nasdaq.com/articles/new-ai-chip-beats-nvidia-amd-and-intel-mile-20x-faster-speeds-and-over-4-trillion</a></span></li><li class="c4 li-bullet-0"><span>Alphabet CEO Sundar Pichai says Google are scaling up their compute infrastructure and working on 1 gigawatt+ data centers, while exploring options for powering them including small modular nuclear reactors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1flyyha/alphabet_ceo_sundar_pichai_says_google_are/&amp;sa=D&amp;source=editors&amp;ust=1730413583242490&amp;usg=AOvVaw2GKDz2tqYsdCcFVb4PDmSr">https://www.reddit.com/r/singularity/comments/1flyyha/alphabet_ceo_sundar_pichai_says_google_are</a></span></li><li class="c22 c163 c78 li-bullet-0"><span>How AlphaChip transformed computer chip design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/&amp;sa=D&amp;source=editors&amp;ust=1730413583242790&amp;usg=AOvVaw0Qx0XBpaFBVjSJPTlvbymA">https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c22 c27 li-bullet-0"><span class="c1">Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">The method has been used to design superhuman chip layouts in the last three generations of Google&rsquo;s custom AI accelerator, the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/tpu?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1730413583243129&amp;usg=AOvVaw2eep4Xn-IslEMB7YXnrtZE">Tensor Processing Unit</a></span><span class="c40 c37 c35 c48">&nbsp;(TPU).</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaChip has generated superhuman chip layouts used in every generation of Google&rsquo;s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google&rsquo;s </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/&amp;sa=D&amp;source=editors&amp;ust=1730413583243550&amp;usg=AOvVaw3LGzSwzTPVNHckoZKozDUv">Transformer</a></span><span class="c40 c37 c35 c48">&nbsp;architecture.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu&amp;sa=D&amp;source=editors&amp;ust=1730413583243803&amp;usg=AOvVaw1mX-adUrs3GNBi7pvjUqV1">Google Axion Processors</a></span><span class="c40 c37 c35 c48">, our first Arm-based general-purpose data center CPUs.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips &mdash; like the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.mediatek.com/products/smartphones/dimensity-5g&amp;sa=D&amp;source=editors&amp;ust=1730413583244151&amp;usg=AOvVaw17MzpA56-xoWyubSKE7NaS">Dimensity Flagship 5G</a></span><span class="c35">&nbsp;used in Samsung mobile phones &mdash; while improving power, performance and chip area.</span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 536.00px;"><img alt="" src="images/image76.png" style="width: 624.00px; height: 536.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image122.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Microsoft/OpenAI have cracked multi-datacenter distributed training, according to Dylan Patel: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jam3scampbell/status/1843339020082004316&amp;sa=D&amp;source=editors&amp;ust=1730413583244690&amp;usg=AOvVaw0SSsSR1ZzjXLo45XIwOyoz">https://x.com/jam3scampbell/status/1843339020082004316</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">Meaning they can spread out training to different data centers and reduce the load on the local environment </span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>China&#39;s upgraded light-powered &#39;AGI chip&#39; is now a million times more efficient than before: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.livescience.com/technology/computing/china-s-upgraded-light-powered-agi-chip-is-now-a-million-times-more-efficient-than-before-researchers-say&amp;sa=D&amp;source=editors&amp;ust=1730413583245024&amp;usg=AOvVaw0PsX15ymgAoSMyEIivYPJC">https://www.livescience.com/technology/computing/china-s-upgraded-light-powered-agi-chip-is-now-a-million-times-more-efficient-than-before-researchers-say</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span>Compared to its predecessor, </span><span class="c1">Taichi-II is 40% more accurate in classification tasks, which involve sorting and identifying different types of information, and delivers a &quot;six orders of magnitude&quot; (i.e., a million-fold) improvement in energy efficiency in low-light conditions, South China Morning Post (SCMP) reported.</span></li><li class="c10 li-bullet-0"><span class="c1">It did this while being extremely energy-efficient, performing over 160 trillion operations for every watt of power it used. To put that into perspective, a photonic chip from 2022 could only manage 3 trillion operations per watt.</span></li><li class="c10 li-bullet-0"><span class="c1">The combined system was able to simulate a network of nearly 14 million artificial neurons, which is much larger than the 1.47 million neurons achieved by the next-best design.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image434.png" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Stem Cells from Foreskin of Circumcised Baby Penis&#39; used to Grow &#39;Mini-Brains&#39; able to Process Data and Run AI, Faster - While Consuming Almost NO ENERGY: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technews.city/2024/10/the-edge-stem-cells-from-foreskin-of.html?%3Dreport%26m%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583245703&amp;usg=AOvVaw17ziPZQYDjMaYmk1k6CJ2T">https://www.technews.city/2024/10/the-edge-stem-cells-from-foreskin-of.html</a></span></li><li class="c4 li-bullet-0"><span>Our LLM-driven bi-level programming shows it&rsquo;s possible to l EA rn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the &ldquo;chain rule&rdquo; to guide reward search directly from video demos&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/&amp;sa=D&amp;source=editors&amp;ust=1730413583245967&amp;usg=AOvVaw0JP6xdPG6d0xNJVkg1Emi6">https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/</a></span></li><li class="c4 li-bullet-0"><span>TSMC&rsquo;s Arizona Chip Production Yields Surpass Taiwan&rsquo;s in Win for US Push: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2024-10-24/tsmc-s-arizona-chip-production-yields-surpass-taiwan-s-a-win-for-us-push?utm_content%3Dbusiness%26cmpid%3Dsocialflow-twitter-business%26utm_source%3Dtwitter%26utm_campaign%3Dsocialflow-organic%26utm_medium%3Dsocial&amp;sa=D&amp;source=editors&amp;ust=1730413583246272&amp;usg=AOvVaw26drowfMnf-mZ4vwQ0nZsf">https://www.bloomberg.com/news/articles/2024-10-24/tsmc-s-arizona-chip-production-yields-surpass-taiwan-s-a-win-for-us-push</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c116 c97 c105 c215 li-bullet-0"><span class="c40 c37 c35 c48">Production yields in Arizona are 4 percentage points higher</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>King Frederik of Denmark, in launching Denmark&#39;s first AI supercomputer Gefion with Jensen Huang: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1849592372654637473&amp;sa=D&amp;source=editors&amp;ust=1730413583246551&amp;usg=AOvVaw2dt7zKBRc3PG5emZyifDGG">https://x.com/tsarnick/status/1849592372654637473</a></span></li></ul><h2 class="c64 c129" id="h.v77n4ztg6jod"><span class="c40 c37 c48 c75">3.4. Recent Releases</span></h2><ul class="c0 lst-kix_wsfytj8n987p-0 start"><li class="c4 c144 li-bullet-0"><span>LI-</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 485.33px;"><img alt="" src="images/image637.png" style="width: 624.00px; height: 485.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 c144 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 456.00px;"><img alt="" src="images/image36.png" style="width: 624.00px; height: 456.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c144"><span class="c1"></span></p><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583247105&amp;usg=AOvVaw2ltVQMqDRMXFnMp6NNeRNw">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Claude 3.5 Sonnet updated: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 584.00px;"><img alt="" src="images/image540.png" style="width: 624.00px; height: 584.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span>Noticeable improvements: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ClaudeAI/comments/1g94a2v/did_claude_just_get_a_super_boost/&amp;sa=D&amp;source=editors&amp;ust=1730413583247467&amp;usg=AOvVaw3Ixowbu7RajNWzikptkTet">https://www.reddit.com/r/ClaudeAI/comments/1g94a2v/did_claude_just_get_a_super_boost/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c1">Molmo: State of the art multimodal open source using 1000x less data</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c1">&quot;Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">Outperforming GPT-4o, Gemini 1.5 Pro &amp; Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.</span></li><li class="c10 li-bullet-0"><span>Info: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/blog&amp;sa=D&amp;source=editors&amp;ust=1730413583247813&amp;usg=AOvVaw0jdcXruepmJK3vxGl5Bo2C">https://molmo.allenai.org/blog</a></span></li><li class="c10 li-bullet-0"><span>Try it: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/&amp;sa=D&amp;source=editors&amp;ust=1730413583247987&amp;usg=AOvVaw3JGI4vUAqvBkQzzet1IbyL">https://molmo.allenai.org</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>OpenAI o1 model released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/&amp;sa=D&amp;source=editors&amp;ust=1730413583248280&amp;usg=AOvVaw1DEWB_zx1VofdL4c4s8-tf">https://openai.com/index/learning-to-reason-with-llms/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c1">o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).</span></li><li class="c10 li-bullet-0"><span class="c1">On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.</span></li><li class="c10 li-bullet-0"><span class="c1">We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 &ndash; above the gold medal threshold &ndash; even without any test-time selection strategy. &nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413583249023&amp;usg=AOvVaw0AfTgwzXC2bwRl0AQO_wFg">https://m.youtube.com/watch?v=a8QvnIAGjPA</a></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 412.27px; height: 343.95px;"><img alt="" src="images/image326.png" style="width: 412.27px; height: 343.95px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 342.77px; height: 420.52px;"><img alt="" src="images/image9.png" style="width: 342.77px; height: 420.52px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating</span><span class="c5 c107"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/%23citation-bottom-3&amp;sa=D&amp;source=editors&amp;ust=1730413583249388&amp;usg=AOvVaw2sqi_8jI0g_dc0iFV_WXB8">3</a></span><span class="c1">&nbsp;of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1&mdash;it achieved an Elo rating of 1807, performing better than 93% of competitors</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583249587&amp;usg=AOvVaw1SpYi1BkVq8lV2Gau5gakK">https://cdn.openai.com/o1-system-card.pdf</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">&nbsp;We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn&rsquo;t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the &ldquo;Unknown&rdquo; option (ambiguous questions). This is not necessarily an indicator of o1-preview&rsquo;s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 555.50px; height: 82.79px;"><img alt="" src="images/image1.png" style="width: 555.50px; height: 82.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.50px; height: 98.99px;"><img alt="" src="images/image288.png" style="width: 551.50px; height: 98.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 556.75px; height: 348.86px;"><img alt="" src="images/image344.png" style="width: 556.75px; height: 348.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.49px; height: 341.22px;"><img alt="" src="images/image116.png" style="width: 554.49px; height: 341.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 580.86px; height: 491.50px;"><img alt="" src="images/image95.png" style="width: 580.86px; height: 491.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.50px; height: 207.65px;"><img alt="" src="images/image206.png" style="width: 558.50px; height: 207.65px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 543.51px; height: 408.50px;"><img alt="" src="images/image286.png" style="width: 543.51px; height: 408.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.82px; height: 313.86px;"><img alt="" src="images/image203.png" style="width: 554.82px; height: 313.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 596.00px;"><img alt="" src="images/image575.jpg" style="width: 624.00px; height: 596.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DeryaTR_/status/1834630356286558336&amp;sa=D&amp;source=editors&amp;ust=1730413583250537&amp;usg=AOvVaw3c_fDZaCguYApqLIbwVDLa">https://x.com/DeryaTR_/status/1834630356286558336</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 498.67px;"><img alt="" src="images/image68.png" style="width: 624.00px; height: 498.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">Note: This is the weakest model compared to o1-preview and the full o1 model</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 550.67px;"><img alt="" src="images/image88.png" style="width: 624.00px; height: 550.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span>Code generated by o1 for this: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://codeforces.com/blog/entry/134091&amp;sa=D&amp;source=editors&amp;ust=1730413583250946&amp;usg=AOvVaw1BtxLu5vDSD94qzyGgsPvt">https://codeforces.com/blog/entry/134091</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 386.67px;"><img alt="" src="images/image137.png" style="width: 624.00px; height: 386.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image163.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 605.33px;"><img alt="" src="images/image183.png" style="width: 624.00px; height: 605.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 657.33px;"><img alt="" src="images/image224.png" style="width: 624.00px; height: 657.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 730.67px;"><img alt="" src="images/image66.png" style="width: 624.00px; height: 730.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 494.67px;"><img alt="" src="images/image134.png" style="width: 624.00px; height: 494.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 499.89px; height: 936.50px;"><img alt="" src="images/image78.png" style="width: 499.89px; height: 936.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.94px; height: 898.50px;"><img alt="" src="images/image73.png" style="width: 471.94px; height: 898.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 394.67px;"><img alt="" src="images/image167.png" style="width: 624.00px; height: 394.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image619.png" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span>From AidanBench: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/aidanmclaughlin/Aidan-Bench?tab%3Dreadme-ov-file%23methodology&amp;sa=D&amp;source=editors&amp;ust=1730413583251867&amp;usg=AOvVaw32y0naAmG21luz-6DkAo5p">https://github.com/aidanmclaughlin/Aidan-Bench?tab=readme-ov-file#methodology</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 754.67px;"><img alt="" src="images/image467.png" style="width: 624.00px; height: 754.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 499.85px; height: 769.79px;"><img alt="" src="images/image64.png" style="width: 499.85px; height: 769.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c1">Not as good as the Opus model they said is coming out later this year </span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">80% lower cost than Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">2x speed over Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">decent math and coding jump. 10% better on MATH 9% better on GPQA</span></li><li class="c10 li-bullet-0"><span>Claude 3.5 Sonnet take the top spot on MMLU-Pro. Plus new Sonnet 3.5 benchmarks that recently came out: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1dmd0km/claude_35_sonnet_take_the_top_spot_on_mmlupro/&amp;sa=D&amp;source=editors&amp;ust=1730413583252487&amp;usg=AOvVaw3lvCGd-2gxULTD41zctZbB">https://www.reddit.com/r/LocalLLaMA/comments/1dmd0km/claude_35_sonnet_take_the_top_spot_on_mmlupro/</a></span><span>&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c15 c65 c60">Can convert research paper descriptions to code: </span><span class="c5 c15 c65 c114"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1803816296410190286&amp;sa=D&amp;source=editors&amp;ust=1730413583252717&amp;usg=AOvVaw2PTX0Bjt8iox6Ndm17PQ8e">https://x.com/VictorTaelin/status/1803816296410190286</a></span><span class="c92 c15 c65 c186 c114">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">Yves does NOT explain how to implement the system at all, he just defines it in mathematical terms. By all means, ICs aren&#39;t hard to implement, but understanding what the paper is saying without images is tough. The best models so far always outputted 100% bullshit code. I just tested again and Opus/GPT-4 outputs are always just gibberish. Sonnet 3.5 did surprisingly well</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c22 c72 c14 li-bullet-0"><span>Claude 3.5 Sonnet transformed a research paper into an interactive learning dashboard in just 30 seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Saboo_Shubham_/status/1805789967203156357&amp;sa=D&amp;source=editors&amp;ust=1730413583252988&amp;usg=AOvVaw0kw8GIIx0lz3pYhJRUb2fu">https://x.com/Saboo_Shubham_/status/1805789967203156357</a></span></li><li class="c10 li-bullet-0"><span>Top of Aider coding leaderboard: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://aider.chat/docs/leaderboards/&amp;sa=D&amp;source=editors&amp;ust=1730413583253170&amp;usg=AOvVaw1IPtU2I7tNGSCLvXXbnrr0">https://aider.chat/docs/leaderboards/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Claude 3.5 Sonnet significantly outperforms GPT-4o (and all other models) on LiveBench: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://livebench.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583253340&amp;usg=AOvVaw1x1BkcjudMHNi_YXcbx43t">https://livebench.ai/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">LiveBench is designed to limit potential contamination by releasing new questions monthly, as well as having questions based on recently-released datasets, arXiv papers, news articles, and IMDb movie synopses.</span></li><li class="c7 li-bullet-0"><span class="c1">Each question has verifiable, objective ground-truth answers, allowing hard questions to be scored accurately and automatically, without the use of an LLM judge.</span></li><li class="c7 li-bullet-0"><span class="c1">LiveBench currently contains a set of 18 diverse tasks across 6 categories, and we will release new, harder tasks over time.</span></li><li class="c7 li-bullet-0"><span class="c33 c15">Sonnet scores 62.16, while GPT-4o 53.79 , the difference here is specially in reasoning and coding</span></li><li class="c7 li-bullet-0"><span>Sonnet also scores 59.4% in GPQA , which feature difficult questions from physics, biology and chemistry </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://klu.ai/glossary/gpqa-eval&amp;sa=D&amp;source=editors&amp;ust=1730413583253928&amp;usg=AOvVaw2VSo2EAtgzZlBNc5yYcIvE">https://klu.ai/glossary/gpqa-eval</a></span></li><li class="c7 li-bullet-0"><span>&quot;In an </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583254164&amp;usg=AOvVaw3-4ES_j2kowLJOOA71uvPs">internal agentic coding evaluation</a></span><span>, </span><span class="c15">Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%.</span><span class="c1">&quot;</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 510.63px; height: 538.90px;"><img alt="" src="images/image309.png" style="width: 510.63px; height: 538.90px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 355.14px; height: 400.49px;"><img alt="" src="images/image260.png" style="width: 355.14px; height: 400.49px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c51 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 368.00px;"><img alt="" src="images/image623.png" style="width: 624.00px; height: 368.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c49 li-bullet-0"><span class="c37 c65 c60">The graph starts at March 2023 with GPT4 to June 2024, totaling only 15 months</span></li><li class="c10 c144 c46 li-bullet-0"><span class="c1"></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://stability.ai/news/introducing-stable-fast-3d&amp;sa=D&amp;source=editors&amp;ust=1730413583254726&amp;usg=AOvVaw3pZdlAuvKKsusvCvSlpRAn">https://stability.ai/news/introducing-stable-fast-3d</a></span></li><li class="c4 li-bullet-0"><span>DiT-10B can surpass DALLE-3 and Stable Diffusion 3 in both image-text alignment and image quality. The API will be available next week: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1djddik/lidit10b_can_surpass_dalle3_and_stable_diffusion/&amp;sa=D&amp;source=editors&amp;ust=1730413583254952&amp;usg=AOvVaw3dEYUMSSq9sZHlEvaDa2Ma">https://www.reddit.com/r/StableDiffusion/comments/1djddik/lidit10b_can_surpass_dalle3_and_stable_diffusion/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>New open source AI image generator beats Midjourney: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blackforestlabs.ai/announcing-black-forest-labs/&amp;sa=D&amp;source=editors&amp;ust=1730413583255151&amp;usg=AOvVaw1TCtpHyK0G1LBCEx9G-YQO">https://blackforestlabs.ai/announcing-black-forest-labs/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c1">API costs $0.025 per image. It&#39;s cheaper than Dalle 3 and can do realism.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image364.png" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image107.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Very realistic images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/&amp;sa=D&amp;source=editors&amp;ust=1730413583255583&amp;usg=AOvVaw1QO3h5czduWAMpVK7yrkUy">https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1106.67px;"><img alt="" src="images/image120.png" style="width: 624.00px; height: 1106.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image278.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1094.67px;"><img alt="" src="images/image46.png" style="width: 624.00px; height: 1094.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 638.67px;"><img alt="" src="images/image135.png" style="width: 624.00px; height: 638.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span>Prompt with no additional editing: </span><span class="c1">meme image with two men in it. On the left side the man is taller and is wearing a shirt that says Black Forest Labs. On the right side the other smaller scrawny man is wearing a shirt that says Stability AI and is sad. The taller man is hitting the back of the head of the small man. A caption coming from the tall man reads &quot;That&#39;s how you do a next-gen model!</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 501.33px;"><img alt="" src="images/image233.png" style="width: 624.00px; height: 501.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image37.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 249.72px; height: 240.88px;"><img alt="" src="images/image82.png" style="width: 249.72px; height: 240.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 357.33px;"><img alt="" src="images/image319.png" style="width: 624.00px; height: 357.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 633.33px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 633.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">Created on first try. Robe and hands are perfect </span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 885.33px;"><img alt="" src="images/image42.png" style="width: 624.00px; height: 885.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">First attempt: &quot;Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat.&quot;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 636.00px;"><img alt="" src="images/image85.png" style="width: 624.00px; height: 636.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: person take photo of Graffiti art spelling out the words &quot;WAFERSELAMAT&quot;, graffiti, white wall, dynamic color, spray paint,</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 640.00px;"><img alt="" src="images/image186.png" style="width: 624.00px; height: 640.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura&#39;s styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Google&rsquo;s new image diffusion model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/&amp;sa=D&amp;source=editors&amp;ust=1730413583257173&amp;usg=AOvVaw0FKitYOlSW1f8wzUwDNXES">https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image189.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image177.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image40.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 629.33px;"><img alt="" src="images/image130.png" style="width: 624.00px; height: 629.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 630.67px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 630.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Lumina-GPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/Alpha-VLLM/Lumina-mGPT&amp;sa=D&amp;source=editors&amp;ust=1730413583257759&amp;usg=AOvVaw2CJvbtGKCVvVF6EUgRtt8J">https://github.com/Alpha-VLLM/Lumina-mGPT</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c1">A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1013.33px;"><img alt="" src="images/image275.png" style="width: 624.00px; height: 1013.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Mistral Large 2 released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://mistral.ai/news/mistral-large-2407/&amp;sa=D&amp;source=editors&amp;ust=1730413583258301&amp;usg=AOvVaw0PYTy8cPlPD4dnJKVCqlvA">https://mistral.ai/news/mistral-large-2407/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span>&nbsp;&ldquo;Additionally, the new Mistral Large 2 is </span><span class="c15">trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer.</span><span class="c1">&nbsp;This commitment to accuracy is reflected in the improved model performance on popular mathematical benchmarks, demonstrating its enhanced reasoning and problem-solving skills&rdquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 192.00px;"><img alt="" src="images/image174.png" style="width: 624.00px; height: 192.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 234.67px;"><img alt="" src="images/image461.png" style="width: 624.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c18">Sonic, a blazing fast &nbsp;(&#128640; 135ms model latency), lifelike generative voice model and API: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/cartesia_ai/status/1795856778456084596&amp;sa=D&amp;source=editors&amp;ust=1730413583258911&amp;usg=AOvVaw1nK3CZuAHpmGFmqusbZMTB">https://x.com/cartesia_ai/status/1795856778456084596</a></span><span class="c40 c18">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c18">Sonic is built on our </span><span class="c15 c65 c114">new state space model architecture</span><span class="c40 c18">&nbsp;for efficiently modeling high-res data like audio and video.</span></li><li class="c10 li-bullet-0"><span class="c18">On speech, a parameter-matched and optimized Sonic model trained on the same data as a widely used Transformer </span><span class="c40 c15 c65 c114">improves audio quality significantly (20% lower perplexity, 2x lower word error, 1 point higher NISQA quality).With lower latency (1.5x lower time-to-first-audio), faster inference speed (2x lower real-time factor) and higher throughput (4x).</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c40 c18">Since March 2023, GPT-4 is now 6 times faster and 12 times cheaper compared to the base model. It&#39;s even much better on all tasks with a 120K context window</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 324.00px;"><img alt="" src="images/image256.png" style="width: 624.00px; height: 324.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c18">Sam Altman at Microsoft Build says with GPT-4o they have reduced the cost by half while doubling the speed and their AI models will keep getting smarter:</span><span class="c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793052340515447043&amp;sa=D&amp;source=editors&amp;ust=1730413583259609&amp;usg=AOvVaw2XIsGFup7Me5UlcX21qGdV">&nbsp;</a></span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793052340515447043&amp;sa=D&amp;source=editors&amp;ust=1730413583259751&amp;usg=AOvVaw3o1t5_0rTnAn4kAZXxEVO-">https://x.com/tsarnick/status/1793052340515447043</a></span><span class="c40 c18">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c15">The current top scores on SWE Bench were accomplished in May, indicating very recent improvements: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.swebench.com/&amp;sa=D&amp;source=editors&amp;ust=1730413583259956&amp;usg=AOvVaw3o9MJ4BwAShMHCLh2zvLkA">https://www.swebench.com/</a></span><span class="c33 c15">&nbsp;</span></li></ul><p class="c9 c129"><span class="c33 c15"></span></p><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c15">GPT 4o was just released by OpenAI and is capable of nearly instantaneous response times even with vision processing, amazing voice generation, and strong social and environmental awareness: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/hello-gpt-4o/&amp;sa=D&amp;source=editors&amp;ust=1730413583260198&amp;usg=AOvVaw3FhMC-An6No_naF2nwK_iD">https://openai.com/index/hello-gpt-4o/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c14">Receives 1369 Elo on LMSYS arena with harder prompts and coding, the highest by a massive margin (100 points higher): </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/LiamFedus/status/1790064966000848911&amp;sa=D&amp;source=editors&amp;ust=1730413583260426&amp;usg=AOvVaw3lfLBvTV76G32Fo2ZUHKbQ">https://twitter.com/LiamFedus/status/1790064966000848911</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-and-gpt-4o&amp;sa=D&amp;source=editors&amp;ust=1730413583260649&amp;usg=AOvVaw3oKP0kisuebvo5LrYiEPX5">https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-and-gpt-4o</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c7 li-bullet-0"><span class="c1 c14">50% cheaper than the GPT 4 Turbo API AND it&rsquo;s much higher quality </span></li><li class="c7 li-bullet-0"><span class="c1 c14">Completely FREE to access on ChatGPT</span></li><li class="c7 li-bullet-0"><span class="c1 c14">Speed: GPT-4o is 2x as fast as GPT-4 Turbo.</span></li><li class="c7 li-bullet-0"><span class="c1 c14">Vision: GPT-4o&rsquo;s vision capabilities perform better than GPT-4 Turbo in evals related to vision capabilities.</span></li><li class="c7 li-bullet-0"><span class="c1 c14">Multilingual: GPT-4o has improved support for non-English languages over GPT-4 Turbo.</span></li><li class="c7 li-bullet-0"><span class="c14">reasons natively across voice, text and vision meaning it is much faster and allows for natural, immersive interaction with ChatGPT: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1790073542488502765&amp;sa=D&amp;source=editors&amp;ust=1730413583261120&amp;usg=AOvVaw2lUtmvG5d78vMpSyLyZQEM">https://x.com/tsarnick/status/1790073542488502765</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span class="c14">GPT-4o is the best LLM for coding and solves 73% of Aider&rsquo;s code editing benchmark: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://aider.chat/docs/leaderboards/&amp;sa=D&amp;source=editors&amp;ust=1730413583261375&amp;usg=AOvVaw3ZLkZZa4v7D0Elj8o_kcb4">https://aider.chat/docs/leaderboards/</a></span></li><li class="c10 li-bullet-0"><span class="c14">GPT 4o has excellent chess capabilities: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1crhkpi/gpt4o_is_a_chess_beast/&amp;sa=D&amp;source=editors&amp;ust=1730413583261679&amp;usg=AOvVaw0nP_v2eEp35SO5Q7POVr73">https://www.reddit.com/r/singularity/comments/1crhkpi/gpt4o_is_a_chess_beast/</a></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 248.00px;"><img alt="" src="images/image561.png" style="width: 624.00px; height: 248.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c22 c32 li-bullet-0"><span class="c79 c23 c14">Strong improvements in Gemini 1.5 Pro benchmarks and Flash almost as good as Ultra</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 565.40px; height: 302.72px;"><img alt="" src="images/image48.png" style="width: 565.40px; height: 302.72px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 269.33px;"><img alt="" src="images/image471.png" style="width: 624.00px; height: 269.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Alibaba unveils Qwen2-Math. New open weights model that outperforms closed source ones in Math benchmarks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Alibaba_Qwen/status/1821553401744015816&amp;sa=D&amp;source=editors&amp;ust=1730413583262485&amp;usg=AOvVaw2hwREgl3RGvZdXLNfmmuz5">https://x.com/Alibaba_Qwen/status/1821553401744015816</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image369.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image60.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c6 c40">Gemini Flash is $0.35 per 1 million tokens (~625k words) with minimal quality drop </span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/technologies/gemini/flash/&amp;sa=D&amp;source=editors&amp;ust=1730413583263036&amp;usg=AOvVaw0s_XT5FBHKnFvqpG3hxDef">https://deepmind.google/technologies/gemini/flash/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c6">AI images are getting VERY realistic:</span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/gdb/status/1790869434174746805?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583263318&amp;usg=AOvVaw1zAEJURRIW0u1i1BvwKADI">&nbsp;</a></span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/gdb/status/1790869434174746805?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583263489&amp;usg=AOvVaw0mMwVY_U_Hx5AI8dpsgmhL">https://twitter.com/gdb/status/1790869434174746805?s=46</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/310571/boring-reality&amp;sa=D&amp;source=editors&amp;ust=1730413583263741&amp;usg=AOvVaw1FRI_ISVPQutxGKGOIVUhQ">https://civitai.com/models/310571/boring-reality</a></span><span class="c6 c40">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1794082708198420782&amp;sa=D&amp;source=editors&amp;ust=1730413583263957&amp;usg=AOvVaw3c3qibHQaLSvbwDOV9Xc9K">https://x.com/nickfloats/status/1794082708198420782</a></span><span class="c6 c40">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/doganuraldesign/status/1797397984629445015&amp;sa=D&amp;source=editors&amp;ust=1730413583264330&amp;usg=AOvVaw3SE2u3M6h-R1L61gXNCCBV">https://x.com/doganuraldesign/status/1797397984629445015</a></span><span class="c6 c40">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c18 c14">Significant progress in Gemini 1.5 Pro across all key benchmarks; TL;DR: 1.5 Pro &gt; 1.0 Ultra, 1.5 Flash (our fastest model) ~= 1.0 Ultra. A math-specialised variant of Gemini 1.5 Pro performs strongly on competition-level math problems, including a breakthrough performance of 91.1% on Hendryck&rsquo;s MATH benchmark without tool-use: </span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/OriolVinyalsML/status/1791521517211107515?t%3Duf0Sgqt_UpU_QsXB5w-HJA%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583264651&amp;usg=AOvVaw0KUzqAV9DZgfZHuomgjYGi">https://x.com/OriolVinyalsML/status/1791521517211107515?t=uf0Sgqt_UpU_QsXB5w-HJA&amp;s=19</a></span><span class="c40 c18 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 234.67px;"><img alt="" src="images/image208.png" style="width: 624.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c51 li-bullet-0"><span class="c6">Summary of 5/14/24 Google I/O event: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1crx01w/comment/l41mmfi/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583265039&amp;usg=AOvVaw3zE-vMGBtxVE0dCqCCQA7S">https://www.reddit.com/r/singularity/comments/1crx01w/comment/l41mmfi/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li><li class="c51 li-bullet-0"><span class="c18 c14">Udio sound to music: </span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1d92yvj/this_is_so_fucking_cool_udio_audio_input_feature/&amp;sa=D&amp;source=editors&amp;ust=1730413583265274&amp;usg=AOvVaw31FloMp4FoXjKgXx9rm3GM">https://www.reddit.com/r/singularity/comments/1d92yvj/this_is_so_fucking_cool_udio_audio_input_feature/</a></span><span class="c40 c18 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span>GPT just churned out a 10-panel comic-book explaining &quot;Gravitational Waves&quot; in a one-shot prompt: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/electrik_dreams/status/1802421281876238354&amp;sa=D&amp;source=editors&amp;ust=1730413583265500&amp;usg=AOvVaw14az9Psq6q-BxM6HPuobkF">https://x.com/electrik_dreams/status/1802421281876238354</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>New Runway video models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1802691475391566108&amp;sa=D&amp;source=editors&amp;ust=1730413583265690&amp;usg=AOvVaw3j_nJexFDpwhwoWN_XVlGi">https://x.com/runwayml/status/1802691475391566108</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>DeepSeek-Coder-V2: First Open Source Model Beats GPT4-Turbo in Coding and Math: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583265891&amp;usg=AOvVaw2_TZ19gy7-zJE5Z9lTOKY0">https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/were-still-waiting-for-the-next-big-leap-in-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583266094&amp;usg=AOvVaw36m50f7FZ80ttWbWjJtyAV">https://www.wired.com/story/were-still-waiting-for-the-next-big-leap-in-ai/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c1">Michael Gerstenhaber, head of product at Anthropic, says the company&rsquo;s new Claude 3.5 Sonnet model is larger than its predecessor but draws much of its new competence from innovations in training. For example, the model was given feedback designed to improve its logical reasoning skills.</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Very consistent video to video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/&amp;sa=D&amp;source=editors&amp;ust=1730413583266440&amp;usg=AOvVaw3M7dH0MrT4zHHEThbDFnGb">https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Google released ultra lightweight Gemma 2 models, the 27B one surpasses llama3 70B and 9B variant surpasses Claude 3 Haiku: </span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 348.00px;"><img alt="" src="images/image265.jpg" style="width: 624.00px; height: 348.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Salesforce releases a model better than GPT 4 Turbo and 4o with only 7 billion parameters: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/SFResearch/status/1807811770267971984?t%3Dj_LOjgVPy41ZpjwkoXmRiQ%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583266881&amp;usg=AOvVaw3WjKSpKfX3mdG6RA_I-dL-">https://x.com/SFResearch/status/1807811770267971984?t=j_LOjgVPy41ZpjwkoXmRiQ&amp;s=19</a></span></li><li class="c4 li-bullet-0"><span>Kling has realistic video generation despite a lack of compute: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1809322314225578158&amp;sa=D&amp;source=editors&amp;ust=1730413583267097&amp;usg=AOvVaw1xw0v-f4b0myT9dzlK_URy">https://x.com/kimmonismus/status/1809322314225578158</a></span></li><li class="c4 li-bullet-0"><span>Six months ago, we launched Numina to lead open research in AI4Math. The Numina Math 7B model won the 1st progress prize of the AI Math Olympiad: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/JiaLi52524397/status/1808886880164880631&amp;sa=D&amp;source=editors&amp;ust=1730413583267331&amp;usg=AOvVaw24UHRjj11iElLa5yY1v7_e">https://x.com/JiaLi52524397/status/1808886880164880631</a></span></li><li class="c4 li-bullet-0"><span>AI Agent Better than OpenAI&rsquo;s GPT-4o and costs just $1.60 per 1000 queries, making it 175% cheaper than GPT-4o. It is the world&rsquo;s first fully autonomous AI-powered sales development representative (SDR): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/&amp;sa=D&amp;source=editors&amp;ust=1730413583267597&amp;usg=AOvVaw2jjC2_gK0ngsweJVdp16XX">https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 253.33px;"><img alt="" src="images/image166.png" style="width: 624.00px; height: 253.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 437.33px;"><img alt="" src="images/image199.png" style="width: 624.00px; height: 437.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Chinese AI company SenseTime takes the lead with SenseNova 5.5, reports say this has outperformed GPT-4o across key metrics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/theaienterprise/status/1810359724321452096&amp;sa=D&amp;source=editors&amp;ust=1730413583267931&amp;usg=AOvVaw3r4Gcq1vZkzWYhjoAsoNSy">https://x.com/theaienterprise/status/1810359724321452096</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 306.67px;"><img alt="" src="images/image213.png" style="width: 624.00px; height: 306.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Gemini AI to get next updates on July 11 and 18: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.testingcatalog.com/gemini-ai-to-get-next-updates-on-july-11-and-18/&amp;sa=D&amp;source=editors&amp;ust=1730413583268210&amp;usg=AOvVaw1L5OmmmVUkbPCUMgeVYONR">https://www.testingcatalog.com/gemini-ai-to-get-next-updates-on-july-11-and-18/</a></span></li><li class="c4 li-bullet-0"><span>Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics:</span><span><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1811751431453450449&amp;sa=D&amp;source=editors&amp;ust=1730413583268406&amp;usg=AOvVaw2hc89JWOcPOqzf8rMullH6">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1811751431453450449&amp;sa=D&amp;source=editors&amp;ust=1730413583268525&amp;usg=AOvVaw3eqy0unQo0ugpRRxeIdELf">https://x.com/runwayml/status/1811751431453450449</a></span></li><li class="c4 li-bullet-0"><span>DALLE-3 update for longer text in images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ai_for_success/status/1802589820138496075&amp;sa=D&amp;source=editors&amp;ust=1730413583268793&amp;usg=AOvVaw1jQ2EbwgY7pHPsiLP-svk3">https://x.com/ai_for_success/status/1802589820138496075</a></span></li><li class="c130 c78 li-bullet-0"><span>OpenAI unveils GPT-4o mini, a smaller and cheaper AI model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?guccounter%3D2&amp;sa=D&amp;source=editors&amp;ust=1730413583269138&amp;usg=AOvVaw1vTw71Kwaes397lYexWcqL">https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?guccounter=2</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c47 li-bullet-0"><span class="c67 c37">The company says GPT-4o mini outperforms industry leading small AI models on reasoning tasks involving text and vision. As small AI models improve, they are becoming more popular for developers due to their speed and cost efficiencies compared to larger models, such as </span><span class="c37 c103 c68 c126"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/05/13/openais-newest-model-is-gpt-4o/&amp;sa=D&amp;source=editors&amp;ust=1730413583269479&amp;usg=AOvVaw1TnhsB4_3njQCQ7YbeC0cd">GPT-4 Omni</a></span><span class="c67 c37">&nbsp;or </span><span class="c37 c103 c68 c126"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/&amp;sa=D&amp;source=editors&amp;ust=1730413583269693&amp;usg=AOvVaw3si1YNjjzKX-wKRu7jqfsF">Claude 3.5 Sonnet</a></span><span class="c79 c37 c103 c126">. They&rsquo;re a useful option for high volume, simple tasks that developers might repeatedly call on an AI model to perform.</span></li><li class="c47 li-bullet-0"><span class="c67 c37">The company claims its newest AI model scores 82% on MMLU, a benchmark to measure reasoning, compared to 79% for Gemini 1.5 Flash and 75% for Claude 3 Haiku, according to data from </span><span class="c37 c103 c68 c126"><a class="c13" href="https://www.google.com/url?q=https://artificialanalysis.ai/models&amp;sa=D&amp;source=editors&amp;ust=1730413583269957&amp;usg=AOvVaw0E4Xu7ow384VJAre-71yVP">Artificial Analysis</a></span><span class="c79 c37 c103 c126">. On MGSM, which measures math reasoning, GPT-4o mini scored 87%, compared to 78% for Flash and 72% for Haiku.</span></li><li class="c47 li-bullet-0"><span class="c79 c37 c103 c126">Further, OpenAI says GPT-4o mini is significantly more affordable to run than its previous frontier models, and more than 60% cheaper than GPT-3.5 Turbo. Today, GPT-4o mini supports text and vision in the API, and OpenAI says the model will support video and audio capabilities in the future.</span></li><li class="c47 li-bullet-0"><span class="c37 c63 c76">So, what took OpenAI so long? Godement said it was &ldquo;pure prioritization&rdquo; </span><span class="c15 c63 c76">as the company was focused on creating bigger and better models like GPT-4, which took a lot of &ldquo;people and compute efforts</span><span class="c40 c37 c63 c76">.&rdquo;</span></li><li class="c47 li-bullet-0"><span class="c37 c63 c76">LMSYS arena shows it is better than GPT 4 and Claude 3 Opus</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image560.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 326.67px;"><img alt="" src="images/image144.png" style="width: 624.00px; height: 326.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://x.com/terryyuezhuo/status/1813998867039617444&amp;sa=D&amp;source=editors&amp;ust=1730413583270794&amp;usg=AOvVaw3QMmyUuvvJH4GDovWp6O5U">https://x.com/terryyuezhuo/status/1813998867039617444</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-2 start"><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">GPT-4o mini on BigCodeBench-Hard is out:</span></li><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">Complete Pass@1: 27.0</span></li><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">Instruct Pass@1: 24.3</span></li><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">Average: 25.7</span></li><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">The average score is very close to Claude-3-Opus (26.0)!</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c47 li-bullet-0"><span class="c37 c63 c76">RewardBench: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 82.67px;"><img alt="" src="images/image34.png" style="width: 624.00px; height: 82.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span class="c37 c63 c76">WildBench: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 194.67px;"><img alt="" src="images/image281.png" style="width: 624.00px; height: 194.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 868.00px;"><img alt="" src="images/image157.png" style="width: 624.00px; height: 868.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span class="c40 c37 c63 c76">&ldquo;way back in 2022, the best model in the world was text-davinci-003. it was much, much worse than this new model. it cost 100x more.&rdquo; - Sam Altman</span></li></ul><p class="c130 c46"><span class="c40 c37 c63 c76"></span></p><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c131 c78 li-bullet-0"><span>Q-Sparse: All Large Language Models can be Fully Sparsely-Activated: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.10969&amp;sa=D&amp;source=editors&amp;ust=1730413583271671&amp;usg=AOvVaw1qWgYGJHA6ZQodTw8NvNVr">https://arxiv.org/abs/2407.10969</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c47 li-bullet-0"><span class="c14 c31">The key results from this work are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs while being </span><span class="c15 c31">much more efficient at inference time</span><span class="c14 c31">; (2) We present an inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is </span><span class="c34 c14 c31">effective in different settings, including training-from-scratch, continue-training of off-the-shelf LLMs, and finetuning;</span><span class="c14 c31">&nbsp;(4) Q-Sparse works for both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the cornerstone and a </span><span class="c28 c43">clear path to revolutionize the efficiency, including cost and energy consumption, of future LLMs.</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c130 c78 li-bullet-0"><span class="c31">New ChatGPT voice update: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/testingcatalog/status/1815417733355331675&amp;sa=D&amp;source=editors&amp;ust=1730413583272084&amp;usg=AOvVaw0Z5mcvXg1OyR6mZNWAULfs">https://x.com/testingcatalog/status/1815417733355331675</a></span></li><li class="c130 c78 li-bullet-0"><span class="c31">UltraPixel is now on Replicate. Based on Stable Cascade, you can use it to make up to 4096x4096 images without upscaling: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/fofrAI/status/1815043204086956444&amp;sa=D&amp;source=editors&amp;ust=1730413583272284&amp;usg=AOvVaw0KUhz4WxbFjramEdl2dNqd">https://x.com/fofrAI/status/1815043204086956444</a></span></li><li class="c4 li-bullet-0"><span>Udio introduces Udio 1.5 with significantly improved audio quality: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/blog/introducing-v1-5&amp;sa=D&amp;source=editors&amp;ust=1730413583272546&amp;usg=AOvVaw0e_6FxAEwj6QZwH-aOyycG">https://www.udio.com/blog/introducing-v1-5</a></span></li><li class="c4 li-bullet-0"><span>The CLM is a new model that remembers interactions, learns skills autonomously, and thinks in its free time, just like humans: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/aidan_mclau/status/1818071890755469365?t%3DbiE9iwV1_1CzcE8CHDYhGw%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583272777&amp;usg=AOvVaw1aO-lgAKrhUODcuJ5GlkZq">https://x.com/aidan_mclau/status/1818071890755469365?t=biE9iwV1_1CzcE8CHDYhGw&amp;s=19</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Midjourney 6.1 released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/midjourney/status/1818342703618482265&amp;sa=D&amp;source=editors&amp;ust=1730413583272982&amp;usg=AOvVaw0RV5-w0wIMw2KHB7QzLeMn">https://x.com/midjourney/status/1818342703618482265</a></span></li><li class="c4 li-bullet-0"><span>New SOTA text to video model coming soon: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/&amp;sa=D&amp;source=editors&amp;ust=1730413583273224&amp;usg=AOvVaw3r69yNEw613YIjkitxv5hD">https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/</a></span></li><li class="c4 li-bullet-0"><span>Recursive self-improvement is here: The AI Scientist is &quot;capable of executing the entire ML research lifecycle: from inventing research ideas and experiments, writing code, to executing experiments on GPUs and gathering results ... our system produced papers with novel contributions in ML&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/SakanaAILabs/status/1823178623513239992&amp;sa=D&amp;source=editors&amp;ust=1730413583273521&amp;usg=AOvVaw2NY30DplGqwE9wWbMvcJQh">https://twitter.com/SakanaAILabs/status/1823178623513239992</a></span></li><li class="c4 li-bullet-0"><span>UAE&rsquo;s Technology Innovation Institute released Falcon Mamba 7B model based on Mamba architecture, it outperforms similar size transformer architecture models such Meta&rsquo;s Llama 3.1 8B and Mistral&rsquo;s 7B: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tii.ae/news/uaes-technology-innovation-institute-revolutionizes-ai-language-models-new-architecture&amp;sa=D&amp;source=editors&amp;ust=1730413583273846&amp;usg=AOvVaw1YUXCyJasO3MjqRjcJ-n5X">https://www.tii.ae/news/uaes-technology-innovation-institute-revolutionizes-ai-language-models-new-architecture</a></span></li><li class="c4 li-bullet-0"><span>LumaLabsAI - Dream Machine 1.5 is here. Now with higher-quality text-to-video, smarter understanding of your prompts, custom text rendering, and improved image-to-video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/LumaLabsAI/status/1825639918539817101&amp;sa=D&amp;source=editors&amp;ust=1730413583274153&amp;usg=AOvVaw2Sr6I0AbjInLOV5TpJBDuT">https://x.com/LumaLabsAI/status/1825639918539817101</a></span></li><li class="c4 li-bullet-0"><span>Ideagram 2.0: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/&amp;sa=D&amp;source=editors&amp;ust=1730413583274467&amp;usg=AOvVaw2cjWLqEMe5GQwvfGZ_0Dug">https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/</a></span></li><li class="c4 li-bullet-0"><span>AI21Labs launches Jamba 1.5 Mini and Large. Jamba 1.5 family of models is state-of-the-art, hybrid SSM-Transformer instruction following foundation models. &quot;They mark the first time a non-Transformer model has been successfully scaled to the quality and strength of the market&rsquo;s leading models.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251&amp;sa=D&amp;source=editors&amp;ust=1730413583274782&amp;usg=AOvVaw0dprOyIrTOF_6U9UHe-0E4">https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251</a></span></li><li class="c4 li-bullet-0"><span>Google rolls out Gemini 1.5 Flash-8B, Stronger Gemini 1.5 Pro (Better Coding/Complex prompts) and improved Gemini 1.5 Flash Model - TODAY: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/OfficialLoganK/status/1828480081574142227&amp;sa=D&amp;source=editors&amp;ust=1730413583275035&amp;usg=AOvVaw0JrjbRmoWQmMyMigCBWt1m">https://x.com/OfficialLoganK/status/1828480081574142227</a></span></li><li class="c4 li-bullet-0"><span>Juggernaut XI World Wide Release | Better Prompt Adherence | Text Generation | Styling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1f4369h/juggernaut_xi_world_wide_release_better_prompt/&amp;sa=D&amp;source=editors&amp;ust=1730413583275282&amp;usg=AOvVaw2L1dq19QcAnPmW0ki7-vTc">https://www.reddit.com/r/StableDiffusion/comments/1f4369h/juggernaut_xi_world_wide_release_better_prompt/</a></span></li><li class="c4 li-bullet-0"><span>Meta to announce updates and the next set of Llama models soon: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1f43ep8/meta_to_announce_updates_and_the_next_set_of/&amp;sa=D&amp;source=editors&amp;ust=1730413583275518&amp;usg=AOvVaw0JxZCwMcqOGR7L6VUkTewH">https://www.reddit.com/r/LocalLLaMA/comments/1f43ep8/meta_to_announce_updates_and_the_next_set_of/</a></span></li><li class="c4 li-bullet-0"><span>Salesforce released Large Action Models xLAM - 7B, 8x7B, 8x22B, up to 64K context length primed for AI agents use-cases: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1f417va/salesforce_released_large_action_models_xlam_7b/&amp;sa=D&amp;source=editors&amp;ust=1730413583275774&amp;usg=AOvVaw1iO2uem8nF68vw7yGwiSN-">https://www.reddit.com/r/LocalLLaMA/comments/1f417va/salesforce_released_large_action_models_xlam_7b/</a></span></li><li class="c4 li-bullet-0"><span class="c1">Qwen2-VL-2B and Qwen2-VL-7B (Apache 2.0) and API access to Qwen2-VL-72B has state-of-the-art image understanding, video comprehension, multilingual support, and more.</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c1">SoTA understanding of images of various resolution &amp; ratio: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">Understanding videos of 20min+: Qwen2-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>Blog: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://qwenlm.github.io/blog/qwen2-vl/&amp;sa=D&amp;source=editors&amp;ust=1730413583276377&amp;usg=AOvVaw2KFeQjcxxb_Kl-cIzkp3qg">https://qwenlm.github.io/blog/qwen2-vl/</a></span><span>&nbsp;GitHub: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/QwenLM/Qwen2-VL&amp;sa=D&amp;source=editors&amp;ust=1730413583276537&amp;usg=AOvVaw2DJ31DqEwac9pYz0iL_dUU">https://github.com/QwenLM/Qwen2-VL</a></span><span>&nbsp;Hugging Face: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d&amp;sa=D&amp;source=editors&amp;ust=1730413583276690&amp;usg=AOvVaw3YORtb8JCzIJB5sKrxrotP">https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d</a></span><span>&nbsp;ModelScope: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://modelscope.cn/organization/qwen&amp;sa=D&amp;source=editors&amp;ust=1730413583276818&amp;usg=AOvVaw3_UeNeLl4YEwAyNH-SCyqN">https://modelscope.cn/organization/qwen</a></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image365.jpg" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Qwen2-VL-7B is the best 7B VL model.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 344.00px;"><img alt="" src="images/image361.jpg" style="width: 624.00px; height: 344.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span class="c15">Excellent amateur quality AI photos: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/&amp;sa=D&amp;source=editors&amp;ust=1730413583277263&amp;usg=AOvVaw3eqYTch2MJkPwXttzuVlSh">https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/</a></span></li></ul><p class="c9"><span class="c92 c37 c35 c48 c14 c171"></span></p><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Qwen2.5 72B released and it matches performance of llama 3.1 405B: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://qwenlm.github.io/blog/qwen2.5/&amp;sa=D&amp;source=editors&amp;ust=1730413583277509&amp;usg=AOvVaw1yaLTOlMssGdm674B55l2C">https://qwenlm.github.io/blog/qwen2.5/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image584.png" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Microsoft releases GRIN MoE. With only 6.6B activate parameters, it achieves exceptionally good performance across a diverse set of tasks, particularly in coding and mathematics tasks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1836544678742659242&amp;sa=D&amp;source=editors&amp;ust=1730413583277809&amp;usg=AOvVaw378SXxKBAmxvPEk5sWCnKD">https://x.com/_akhaliq/status/1836544678742659242</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image305.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>New video generation AI can create videos with rack focus: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheoMediaAI/status/1840834127697703262&amp;sa=D&amp;source=editors&amp;ust=1730413583278073&amp;usg=AOvVaw3oLzF7Z3SFNEsSV3C1GWe_">https://x.com/TheoMediaAI/status/1840834127697703262</a></span></li><li class="c4 li-bullet-0"><span>Lip Sync is now available on kling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ft5pkh/lip_sync_is_now_available_on_kling/?sort%3Dconfidence&amp;sa=D&amp;source=editors&amp;ust=1730413583278313&amp;usg=AOvVaw1W_cKAL9EibTABoeFWBkfN">https://www.reddit.com/r/singularity/comments/1ft5pkh/lip_sync_is_now_available_on_kling/?sort=confidence</a></span></li><li class="c4 li-bullet-0"><span>Pika 1.5: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/pika_labs/status/1841143349576941863&amp;sa=D&amp;source=editors&amp;ust=1730413583278506&amp;usg=AOvVaw24qz9yqkXwF8ANJjdGoJd6">https://x.com/pika_labs/status/1841143349576941863</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c18 c92 c139">more realistic movement, big screen shots, and mind-blowing Pikaffects that break the laws of physics</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>OpenAI on autonomous agents: As of mid-2024, Altera&#39;s digital humans can operate autonomously for up to four hours at a time&mdash;a substantial increase compared to other AI models on the market: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/altera/&amp;sa=D&amp;source=editors&amp;ust=1730413583278768&amp;usg=AOvVaw1BRqbIbkwUaqx0Fk_axOV6">https://openai.com/index/altera/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 554.67px;"><img alt="" src="images/image93.png" style="width: 624.00px; height: 554.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Nvidia just dropped a bombshell: Its new AI model is open, massive, and ready to rival GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4/&amp;sa=D&amp;source=editors&amp;ust=1730413583279117&amp;usg=AOvVaw007qS3yu5g94XiuJCQww4r">https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_wsfytj8n987p-1"><li class="c10 li-bullet-0"><span class="c1">Only 72 billion parameters, 4% the size of GPT 4</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image289.png" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 550.67px;"><img alt="" src="images/image41.png" style="width: 624.00px; height: 550.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>introducing swarm: an experimental framework for building, orchestrating, and deploying multi-agent systems: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/shyamalanadkat/status/1844888546014052800&amp;sa=D&amp;source=editors&amp;ust=1730413583279558&amp;usg=AOvVaw07OangJ7yItOlBcwgrhaYs">https://x.com/shyamalanadkat/status/1844888546014052800</a></span></li><li class="c4 li-bullet-0"><span class="c1">Nvidia Nemotron 70B - beats Llama 3.1 405B, GPT4o &amp; Claude 3.5 Sonnet on Arena Hard, AlpacaEval and MT Bench. They release the Instruct model, reward model and the dataset all on Hugging Face</span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image317.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Mistral introduces two new state-of-the-art models for on-device computing and at-the-edge use cases. &quot;We call them les Ministraux: Ministral 3B and Ministral 8B. These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/&amp;sa=D&amp;source=editors&amp;ust=1730413583280058&amp;usg=AOvVaw0WL8Oc40DLfta7y4XZGjnK">https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 266.67px;"><img alt="" src="images/image477.png" style="width: 624.00px; height: 266.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.13848&amp;sa=D&amp;source=editors&amp;ust=1730413583280329&amp;usg=AOvVaw1aZP4cWBObErfoNLCfNt-2">https://arxiv.org/abs/2410.13848</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span class="c3">Experiments show that Janus surpasses previous unified model and matches or exceeds the performance of task-specific models. The simplicity, high flexibility, and effectiveness of Janus make it a strong candidate for next-generation unified multimodal models.</span></li><li class="c10 li-bullet-0"><span class="c1">it outperforms previous models in both understanding &amp; generation</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Genmo AI video generator: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.genmo.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583280664&amp;usg=AOvVaw1q4NYLxPlptfmLEYxCZ8Dc">https://www.genmo.ai/</a></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 377.33px;"><img alt="" src="images/image215.png" style="width: 624.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 396.00px;"><img alt="" src="images/image173.png" style="width: 624.00px; height: 396.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wsfytj8n987p-0"><li class="c4 li-bullet-0"><span>Introducing Voice Design by ElevenLabs - Generate a unique voice from a text prompt alone: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1gabx6a/introducing_voice_design_by_elevenlabs_generate_a/&amp;sa=D&amp;source=editors&amp;ust=1730413583281018&amp;usg=AOvVaw3EL5LrFA1qNTFxk07Gvo_f">https://www.reddit.com/r/singularity/comments/1gabx6a/introducing_voice_design_by_elevenlabs_generate_a</a></span></li></ul><h2 class="c64" id="h.j47u809w7v2z"><span class="c40 c37 c48 c75">3.5. Expert Testimonies</span></h2><ul class="c0 lst-kix_mlex94wk5tq-0 start"><li class="c4 li-bullet-0"><span class="c1">Many of these experts are not financially incentivized to lie or have done actions that contradict this claim. </span></li></ul><ul class="c0 lst-kix_mlex94wk5tq-1 start"><li class="c10 li-bullet-0"><span class="c1">Geoffrey Hinton is retired. </span></li><li class="c10 li-bullet-0"><span class="c1">Yann LeCunn and Francois Chollet criticize LLMs frequently and call it overhyped</span></li></ul><ul class="c0 lst-kix_mlex94wk5tq-2 start"><li class="c7 li-bullet-0"><span class="c1">&nbsp;Chollet doesn&rsquo;t even offer an alternative for it. </span></li></ul><ul class="c0 lst-kix_mlex94wk5tq-1"><li class="c10 li-bullet-0"><span>Daniel Kokotajlo give up 85% of his family&rsquo;s net worth to quit OpenAI: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/&amp;sa=D&amp;source=editors&amp;ust=1730413583281657&amp;usg=AOvVaw1_fZiuNRqfrNChJjl-Yctq">https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/</a></span><span class="c30 c37">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c1">Bengio and many others doomers want to pause AI development, which is not profitable at all. </span></li></ul><ul class="c0 lst-kix_mlex94wk5tq-2 start"><li class="c7 li-bullet-0"><span class="c1">33,707 experts and business leaders sign a letter stating that AI has the potential to &ldquo; pose profound risks to society and humanity&rdquo;</span></li></ul><ul class="c0 lst-kix_mlex94wk5tq-3 start"><li class="c21 c26 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://futureoflife.org/open-letter/pause-giant-ai-experiments/&amp;sa=D&amp;source=editors&amp;ust=1730413583281976&amp;usg=AOvVaw1NW-JgYN4V-elc6VolJLTE">https://futureoflife.org/open-letter/pause-giant-ai-experiments/</a></span></li><li class="c21 c26 li-bullet-0"><span class="c1">Signatories include Yoshua Bengio (highest H-index of any computer science researcher and a Turing Award winner for contributions in AI), Stuart Russell (UC Berkeley professor and writer of widely used machine learning textbook), Steve Wozniak, Max Tegmark (MIT professor), John J Hopfield (Princeton University Professor Emeritus and inventor of associative neural networks), Zachary Kenton (DeepMind, Senior Research Scientist), Ramana Kumar (DeepMind, Research Scientist), Olle H&auml;ggstr&ouml;m (Chalmers University of Technology, Professor of mathematical statistics, Member, Royal Swedish Academy of Science), Michael Osborne (University of Oxford, Professor of Machine Learning), Raja Chatila (Sorbonne University, Paris, Professor Emeritus AI, Robotics and Technology Ethics, Fellow, IEEE), Gary Marcus (prominent AI skeptic who has frequently stated that AI is plateauing), and many more </span></li><li class="c21 c26 li-bullet-0"><span>Geoffrey Hinton said he should have signed it but didn&rsquo;t because he didn&rsquo;t think it would work but still believes it is true:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/n4IQOBka8bc?si%3DwM423YLd-48YC-eY?t%3D840&amp;sa=D&amp;source=editors&amp;ust=1730413583282310&amp;usg=AOvVaw2qzwN14OvG02M2vbVll1zf">&nbsp;https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_mlex94wk5tq-1"><li class="c10 li-bullet-0"><span>Having a financial incentive to lie does not mean they are all lying. For example, climate scientists have a financial incentive to exaggerate climate chang</span><span class="c1 c14">e to get more funding. Vaccine manufacturers have a financial incentive to cover up vaccine side effects. Yet they are still highly trusted by most people.</span></li></ul><p class="c9 c129"><span class="c33 c15"></span></p><ul class="c0 lst-kix_dacire7nzy6o-0 start"><li class="c4 li-bullet-0"><span class="c15">[2278 AI researchers were surveyed in 2023 and estimated that there is a 50% chance of AI being superior to humans in ***ALL*** possible tasks by 2047 and a 75% chance by 2085](</span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583282855&amp;usg=AOvVaw3eSYO9E924MoCDsXwm4C0H">https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf</a></span><span class="c33 c15">). This includes all physical tasks. Note that this means SUPERIOR in all tasks, not just &ldquo;good enough&rdquo; or &ldquo;about the same.&rdquo; Human level AI will almost certainly come sooner according to these predictions.</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 561.37px; height: 733.50px;"><img alt="" src="images/image428.png" style="width: 561.37px; height: 733.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c33 c15">In 2022, the year they had for the 50% threshold was 2060, and many of their predictions have already come true ahead of time, like AI being capable of answering queries using the web, transcribing speech, translation, and reading text aloud that they thought would only happen after 2025. So it seems like they tend to underestimate progress. </span></li></ul><p class="c9"><span class="c33 c15"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 213.33px;"><img alt="" src="images/image591.png" style="width: 624.00px; height: 213.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2 start"><li class="c7 li-bullet-0"><span class="c15">In 2018, assuming there is no interruption of scientific progress, 75% of AI experts believed there is a 50% chance of AI outperforming humans in every task within 100 years. In 2022, 90% of AI experts believed this, with half believing it will happen before 2061. Source: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/ai-timelines&amp;sa=D&amp;source=editors&amp;ust=1730413583283621&amp;usg=AOvVaw0LMnFAXf6lUknCFm8wBG7k">https://ourworldindata.org/ai-timelines</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span class="c14">Long list of AGI predictions from experts:</span><span class="c34 c14">&nbsp;</span><span class="c5 c34 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/18vawje/comment/kfpntso/?utm_source%3Dshare%26utm_medium%3Dweb3x%26utm_name%3Dweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583284114&amp;usg=AOvVaw3F0RDsyZGCg71n2WBZy59y">https://www.reddit.com/r/singularity/comments/18vawje/comment/kfpntso</a></span></li></ul><p class="c22 c44"><span class="c33 c34 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c33 c34 c14">Almost every prediction has a lower bound in the early 2030s or earlier and an upper bound in the early 2040s at latest. </span></li><li class="c22 c72 li-bullet-0"><span class="c33 c34 c14">Yann LeCunn, a prominent LLM skeptic, puts it at 2032-37</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.50px; height: 765.94px;"><img alt="" src="images/image72.png" style="width: 320.50px; height: 765.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c44"><span class="c1 c14"></span></p><p class="c22 c44"><span class="c1 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span class="c23 c14 c84">Betting odds have weak AGI occurring at Sept 3, 2027 with nearly 1400 participants as of 7/14/24: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/&amp;sa=D&amp;source=editors&amp;ust=1730413583284935&amp;usg=AOvVaw1GSh63PoPmdXycJUTnrgbY">https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/</a></span></li></ul><p class="c22 c44"><span class="c79 c23 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c23 c14 c84">Metaculus tends to be very accurate: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.metaculus.com/questions/track-record/&amp;sa=D&amp;source=editors&amp;ust=1730413583285284&amp;usg=AOvVaw3vB_J0sCCaIfeIcsr5Ham0">https://www.metaculus.com/questions/track-record/</a></span></li></ul><p class="c22 c44"><span class="c79 c23 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c23 c14 c84">Averages from the responses of many people tend to be accurate: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Wisdom_of_the_crowd&amp;sa=D&amp;source=editors&amp;ust=1730413583285628&amp;usg=AOvVaw1eLEgnqGotS_3MDAfcmhIl">https://en.m.wikipedia.org/wiki/Wisdom_of_the_crowd</a></span></li></ul><p class="c22 c44"><span class="c79 c23 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c23 c14 c84">96% believe it will occur before 2040 with over 1000 participants: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.metaculus.com/questions/384/humanmachine-intelligence-parity-by-2040/&amp;sa=D&amp;source=editors&amp;ust=1730413583285992&amp;usg=AOvVaw0tczlrDCxjhNpR2R_7JXhQ">https://www.metaculus.com/questions/384/humanmachine-intelligence-parity-by-2040/</a></span></li></ul><p class="c22 c44"><span class="c79 c23 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c23 c14 c84">Manifold has it at around 2030 for passing a long, high quality, and adversarial Turing test: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://manifold.markets/ManifoldAI/agi-when-resolves-to-the-year-in-wh-d5c5ad8e4708&amp;sa=D&amp;source=editors&amp;ust=1730413583286369&amp;usg=AOvVaw3l_j5i9eWQGKHoshN9rUip">https://manifold.markets/ManifoldAI/agi-when-resolves-to-the-year-in-wh-d5c5ad8e4708</a></span></li></ul><p class="c22 c44"><span class="c79 c23 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-2"><li class="c22 c104 c86 li-bullet-0"><span class="c23 c14 c84">It is also very accurate and tends to underestimate outcomes if anything: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://manifold.markets/calibration&amp;sa=D&amp;source=editors&amp;ust=1730413583286703&amp;usg=AOvVaw1ceC9YmhebIu5U5mgnYA7p">https://manifold.markets/calibration</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span class="c23 c14 c84">Former OpenAI board member Helen Toner testifies before Senate that many scientists within AI companies are concerned AI &ldquo;could lead to literal human extinction&rdquo;: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/OpenAI/comments/1fkhlet/former_openai_board_member_helen_toner_testifies/&amp;sa=D&amp;source=editors&amp;ust=1730413583287033&amp;usg=AOvVaw2slon8C9m6ESUAku2o_4w5">https://www.reddit.com/r/OpenAI/comments/1fkhlet/former_openai_board_member_helen_toner_testifies/</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c22 c72 li-bullet-0"><span class="c23 c14 c84">This is not just trying to build hype as it is </span><span class="c35 c65 c34 c14 c84">VERY MUCH AGAINST</span><span class="c79 c23 c14">&nbsp;the interests of the company since it will strongly encourage regulation and restrictions on the company. There are far better ways to build hype that do not carry such a significant risk.</span></li><li class="c22 c72 li-bullet-0"><span class="c79 c23 c14">This concern comes from scientists, not just her personal beliefs.</span></li><li class="c22 c72 li-bullet-0"><span class="c79 c23 c14">Also, she is no longer working at the company.</span></li></ul><p class="c22 c44"><span class="c79 c23 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>Joe Biden tells the UN that we will see more technological change in the next 2-10 years than we have seen in the last 50 and AI will change our ways of life, work and war so urgent efforts are needed on AI safety: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1foqrec/joe_biden_tells_the_un_that_we_will_see_more/&amp;sa=D&amp;source=editors&amp;ust=1730413583287743&amp;usg=AOvVaw0MOe1FHuykJP8TIdooAsCX">https://www.reddit.com/r/singularity/comments/1foqrec/joe_biden_tells_the_un_that_we_will_see_more/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c79 c23 c14">He has no reason to lie about this to the UN. In fact, it would go against his interest since it would encourage opponents like China or Russia to invest more in AI development before they fall behind. </span></li></ul><p class="c22 c44"><span class="c79 c23 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span class="c23 c14 c84">One of the lead creators of Google&rsquo;s Gemini estimates that research would be </span><span class="c15 c35 c65 c84">5x faster if they had 10x more compute</span><span class="c23 c14 c84">, even with no improvements in architecture: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DUeI29-AdhQI&amp;sa=D&amp;source=editors&amp;ust=1730413583288310&amp;usg=AOvVaw0mGqgyXVHKtPYpbzP7XJoU">https://www.youtube.com/watch?v=UeI29-AdhQI</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c22 c72 li-bullet-0"><span class="c23 c14 c84">Completely possible with the improvements in </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/05/14/googles-next-gen-tpus-promise-a-4-7x-performance-boost/&amp;sa=D&amp;source=editors&amp;ust=1730413583288662&amp;usg=AOvVaw1flRXwJrEOADS81DTqAxbE">Google&rsquo;s TPUs</a></span><span class="c23 c14 c84">&nbsp;as well </span><span class="c23 c14 c84">as </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing&amp;sa=D&amp;source=editors&amp;ust=1730413583288925&amp;usg=AOvVaw14-9s0lLlTP9DlpL5fk3bh">Nvidia&rsquo;s Blackwell GPUs</a></span><span class="c14">&nbsp;(see Hardware Improvements subsection for more)</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>Andrew Ng is optimistic on AI agents: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AndrewYNg/status/1770897666702233815?ref_src%3Dtwsrc%255Etfw%257Ctwcamp%255Etweetembed%257Ctwterm%255E1770897666702233815%257Ctwgr%255E2764bd9a0773b00f9e4215c1d3fd948523962db6%257Ctwcon%255Es1_%26ref_url%3Dhttps%253A%252F%252Fwww.redditmedia.com%252Fmediaembed%252F1ed1y1h%252F%253Fresponsive%253Dtrueis_nightmode%253Dtrue&amp;sa=D&amp;source=editors&amp;ust=1730413583289367&amp;usg=AOvVaw1GXWSWcVv55zQJMsEgcNaT">https://x.com/AndrewYNg/status/1770897666702233815</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c10 li-bullet-0"><span class="c1">&gt;I think AI agentic workflows will drive massive AI progress this year &mdash; perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 353.37px; height: 199.07px;"><img alt="" src="images/image271.jpg" style="width: 353.37px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>Andrew Ng says he is 100% confident that AI is not hitting a wall and there are new advances that are just about to break because capabilities exceed what has been deployed so far: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1enttgu/andrew_ng_says_he_is_100_confident_that_ai_is_not/&amp;sa=D&amp;source=editors&amp;ust=1730413583289989&amp;usg=AOvVaw2HsXAPk7K_OQkynYXc2rbt">https://www.reddit.com/r/singularity/comments/1enttgu/andrew_ng_says_he_is_100_confident_that_ai_is_not/</a></span></li><li class="c4 li-bullet-0"><span>Francois Chollet on the impact of AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/fchollet/status/1819139182000066779&amp;sa=D&amp;source=editors&amp;ust=1730413583290328&amp;usg=AOvVaw3MM1G5J2Hxz50RH8iib2G5">https://x.com/fchollet/status/1819139182000066779</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span class="c1">&ldquo;Many people have been recognizing that AGI won&#39;t be coming from mere scaling of current tech, and that generative AI has been severely overhyped. This is all true. But those people often conclude, &quot;therefore AI is not going to be transformative -- this is a nothingburger&quot;. Absolutely not. AI (both current and near-future tech) *will* transform nearly every industry, and we&#39;re still only in the very first steps of that process. Generative AI may be a bubble, but AI is going to be bigger in the long run than what almost all observers currently anticipate.&rdquo;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>Leading AI scientists from China and the U.S. issue a joint statement: &ldquo;We believe AI may pose an </span><span class="c15">existential risk </span><span>to humanity.&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://humancompatible.ai/?p%3D4695&amp;sa=D&amp;source=editors&amp;ust=1730413583290848&amp;usg=AOvVaw1TEeTHwwIGWGmzN7dC7T7K">https://humancompatible.ai/?p=4695</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span class="c1">&ldquo;Coordinated global action on AI safety research and governance is critical to prevent uncontrolled frontier AI development from posing unacceptable risks to humanity.&rdquo;</span></li><li class="c10 li-bullet-0"><span>&ldquo;We face near-term risks from malicious actors misusing frontier AI systems, with current safety filters integrated by developers easily bypassed. Frontier AI systems produce compelling misinformation and </span><span class="c15">may soon be capable enough to help terrorists develop weapons of mass destruction</span><span>. Moreover, </span><span class="c15">there is a serious risk that future AI systems may escape human control altogether</span><span>. Even </span><span class="c15">aligned AI systems could destabilize or disempower existing institutions</span><span class="c1">. Taken together, we believe AI may pose an existential risk to humanity in the coming decades.</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>&ldquo;China President Xi Jinping sent his clearest signal yet that he takes the doomers&rsquo; [extinction] concerns seriously.&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.is/7E6Ea%23selection-1091.8-1129.1&amp;sa=D&amp;source=editors&amp;ust=1730413583291487&amp;usg=AOvVaw3o6mRdPTFgCeVsZrg4unYx">https://archive.is/7E6Ea#selection-1091.8-1129.1</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span>&ldquo;</span><span class="c15">China should &ldquo;abandon uninhibited growth that comes at the cost of sacrificing safety</span><span class="c1">&rdquo;.</span></li><li class="c10 li-bullet-0"><span>Since AI will determine &ldquo;</span><span class="c15">the fate of all mankind&rdquo;, it must always be controllable</span><span class="c1">.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">&ldquo;Accelerationists are getting pushback from a clique of elite scientists with the Communist Party&rsquo;s ear.</span></li><li class="c10 li-bullet-0"><span>Most prominent among them is </span><span class="c33 c15">Andrew Chi-Chih Yao, the only Chinese person to have won the Turing award for advances in computer science. In July Mr Yao said AI poses a greater existential risk to humans than nuclear or biological weapons.</span></li><li class="c10 li-bullet-0"><span>Zhang Ya-Qin, the former president of Baidu, a Chinese tech giant, and Xue Lan, the chair of the state&rsquo;s expert committee on AI governance, also reckon that </span><span class="c33 c15">AI may threaten the human race. </span></li><li class="c10 li-bullet-0"><span>Yi Zeng of the Chinese Academy of Sciences believes that AGI models will </span><span class="c33 c15">eventually see humans as humans see ants.</span></li><li class="c10 li-bullet-0"><span class="c1">China will probably create an AI-safety institute to observe cutting-edge research, as America and Britain have done. For now Chinese officials are emphasizing the need to share the responsibility of regulating AI and to improve co-ordination.</span></li><li class="c10 li-bullet-0"><span>&ldquo;</span><span class="c15">The official [CCP] report from the plenum listed AI risks alongside other big concerns, such as biohazards and natural disasters</span><span>. For the first time it called for monitoring AI safety, a reference to the technology&rsquo;s potential to endanger humans. The report may lead to </span><span class="c15">new restrictions on AI-research activities</span><span class="c1">.&rdquo;</span></li><li class="c10 li-bullet-0"><span>Note: </span><span class="c15">slowing down AI advancement goes AGAINST their interests</span><span class="c1">&nbsp;of dominating the AI industry, so these are very likely legitimate concerns.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>Dario Amodei says AI models are approaching </span><span class="c15">graduate-level intelligence </span><span>and Anthropic aim to release </span><span class="c15">a more sophisticated model every few months: </span><span class="c37 c65 c60 c68"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/tsarnick/status/1806067476947775719?ref_src%3Dtwsrc%255Egoogle%257Ctwcamp%255Eserp%257Ctwgr%255Etweet&amp;sa=D&amp;source=editors&amp;ust=1730413583293045&amp;usg=AOvVaw2F8Gj48ZBjEh0Mu7JOX3J6">https://twitter.com/tsarnick/status/1806067476947775719?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet</a></span></li><li class="c4 li-bullet-0"><span class="c14">Sam Altman says OpenAI will soon add &quot;capability to </span><span class="c15">take actions on your behalf</span><span class="c1 c14">&quot; to ChatGPT</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 493.38px; height: 380.31px;"><img alt="" src="images/image200.png" style="width: 493.38px; height: 380.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>Employees Say OpenAI and Google DeepMind Are Hiding Dangers from the Public: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://time.com/6985504/openai-google-deepmind-employees-letter/&amp;sa=D&amp;source=editors&amp;ust=1730413583293651&amp;usg=AOvVaw1cFGwEpGAji5rpuNSnZ6mx">https://time.com/6985504/openai-google-deepmind-employees-letter/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c8 li-bullet-0"><span>Thirteen employees, eleven of which are current or former employees of </span><span class="c20 c160"><a class="c13" href="https://www.google.com/url?q=https://time.com/6980478/openai-2/&amp;sa=D&amp;source=editors&amp;ust=1730413583293928&amp;usg=AOvVaw2LUGIpVh4kKxZRx613hXOo">OpenAI</a></span><span>, the company behind ChatGPT, signed </span><span class="c20 c160"><a class="c13" href="https://www.google.com/url?q=https://righttowarn.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583294100&amp;usg=AOvVaw1-vPCKB-oxG_0RAuabPrfw">the letter</a></span><span>&nbsp;entitled: &ldquo;A Right to Warn about Advanced Artificial Intelligence.&rdquo; The</span><span class="c34">&nbsp;</span><span>two</span><span class="c34">&nbsp;</span><span>other signatories</span><span class="c34">&nbsp;</span><span class="c1">are current and former employees of Google DeepMind. Six individuals are anonymous.</span></li><li class="c8 li-bullet-0"><span class="c1">The coalition cautions that AI systems are powerful enough to pose serious harms without proper regulation. &ldquo;These risks range from the further entrenchment of existing inequalities, to manipulation and misinformation, to the loss of control of autonomous AI systems potentially resulting in human extinction,&rdquo; the letter says.</span></li><li class="c8 li-bullet-0"><span class="c1">This makes the companies look bad, so it is likely a legitimate concern rather than an attempt to build hype (which could be easily done without denigrating their employers).</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span>2024 McKinsey survey on AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583294806&amp;usg=AOvVaw2T_b9w4PclcYXmwLNlS6tG">https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span>For the past six years, AI adoption by respondents&rsquo; organizations has hovered at about 50 percent. This year, the survey finds that </span><span class="c15">adoption has jumped to 72 percent</span><span class="c1">&nbsp;(Exhibit 1). And the interest is truly global in scope. Our 2023 survey found that AI adoption did not reach 66 percent in any region; however, this year more than two-thirds of respondents in nearly every region say their organizations are using AI</span></li><li class="c10 li-bullet-0"><span class="c1">In the latest McKinsey Global Survey on AI, 65 percent of respondents report that their organizations are regularly using gen AI, nearly double the percentage from our previous survey just ten months ago.</span></li><li class="c10 li-bullet-0"><span>Respondents&rsquo;</span><span class="c15">&nbsp;expectations for gen AI&rsquo;s impact remain as high as they were last year</span><span class="c1">, with three-quarters predicting that gen AI will lead to significant or disruptive change in their industries in the years ahead</span></li><li class="c10 li-bullet-0"><span>Organizations are </span><span class="c15">already seeing material benefits from gen AI use, reporting both cost decreases and revenue jumps</span><span class="c1">&nbsp;in the business units deploying the technology.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 413.33px;"><img alt="" src="images/image192.png" style="width: 624.00px; height: 413.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 448.00px;"><img alt="" src="images/image239.png" style="width: 624.00px; height: 448.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image257.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span class="c18">Marc Andreessen (cofounder of Netscape) says general-purpose robotics will enable everybody to have their own domestic servants, freeing their time to be more productive and pursue self-actualization: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1792813912372699402&amp;sa=D&amp;source=editors&amp;ust=1730413583296118&amp;usg=AOvVaw0PLet-JIcv8ci0LWzaI8M9">https://x.com/tsarnick/status/1792813912372699402</a></span><span class="c40 c18">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c18 c14">French President Emmanuel Macron says AI is a revolution and the challenge is to &quot;accelerate, innovate and invest:&rdquo;</span><span class="c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793806071515238573?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583296437&amp;usg=AOvVaw0Q27QfG9UchH6w92ZICBOz">&nbsp;</a></span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793806071515238573?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583296600&amp;usg=AOvVaw0fh033uYf1bgVSM6E6S06H">https://x.com/tsarnick/status/1793806071515238573?s=46</a></span><span class="c40 c18 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c40 c18 c14">&quot; We&#39;ll get up to 50% of superintelligence within 5-20 years. 100% superintelligence in less than 100 years.&quot; - Geoffrey Hinton</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://t.co/Q8dEEono5Z&amp;sa=D&amp;source=editors&amp;ust=1730413583296909&amp;usg=AOvVaw2bntOvXPhCQBE8sf56ZdIc">https://t.co/Q8dEEono5Z</a></span><span class="c40 c18 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span class="c18 c14">33,707 experts and business leaders sign a letter stating that AI has the potential to &ldquo; </span><span class="c23 c92 c185 c14">pose profound risks to society and humanity&rdquo;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://futureoflife.org/open-letter/pause-giant-ai-experiments/&amp;sa=D&amp;source=editors&amp;ust=1730413583297281&amp;usg=AOvVaw0OiZe8GGSDcXr77mHNMf8B">https://futureoflife.org/open-letter/pause-giant-ai-experiments/</a></span></li><li class="c10 li-bullet-0"><span class="c23 c92 c185 c14">Signatories include Yoshua Bengio (highest H-index of any computer science researcher and a Turing Award winner for contributions in AI), Stuart Russell (UC Berkeley professor and writer of widely used machine learning textbook), Steve Wozniak, Max Tegmark (MIT professor), John J Hopfield (Princeton University Professor Emeritus and inventor of associative neural networks), Zachary Kenton (DeepMind, Senior Research Scientist), Ramana Kumar (DeepMind, Research Scientist), Olle H&auml;ggstr&ouml;m (Chalmers University of Technology, Professor of mathematical statistics, Member, Royal Swedish Academy of Science), Michael Osborne (University of Oxford, Professor of Machine Learning), Raja Chatila (Sorbonne University, Paris, Professor Emeritus AI, Robotics and Technology Ethics, Fellow, IEEE), Gary Marcus (prominent AI skeptic who has frequently stated that AI is plateauing), and many more </span></li><li class="c10 li-bullet-0"><span class="c23 c185 c14">Geoffrey Hinton said he should have signed it but didn&rsquo;t because he didn&rsquo;t think it would work but still believes it is true:</span><span class="c23 c185 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/n4IQOBka8bc?si%3DwM423YLd-48YC-eY?t%3D840&amp;sa=D&amp;source=editors&amp;ust=1730413583297760&amp;usg=AOvVaw1zz4q0pZYPbUnnvvJILLQt">&nbsp;</a></span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/n4IQOBka8bc?si%3DwM423YLd-48YC-eY?t%3D840&amp;sa=D&amp;source=editors&amp;ust=1730413583297926&amp;usg=AOvVaw2UEQ-kasgZImwrke_s5J0c">https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c4 li-bullet-0"><span class="c14">Dan Schulman (former PayPal CEO) on the impact of AI:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/woloski/status/1778783006389416050&amp;sa=D&amp;source=editors&amp;ust=1730413583298174&amp;usg=AOvVaw2hHAtR6NpwmhxipCV0BOz3">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/woloski/status/1778783006389416050&amp;sa=D&amp;source=editors&amp;ust=1730413583298317&amp;usg=AOvVaw3XsVk9U1fluFOE-cTlFYai">https://x.com/woloski/status/1778783006389416050</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;gpt5 will be a freak out moment&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;80% of the jobs out there will be reduced 80% in scope&rdquo;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span class="c40 c30 c37 c14">Nobel Prize winning and well-recognized AI experts thinks AI will become more intelligent and even existentially threatening: </span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c30 c37 c14">Geoffrey Hinton: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/world-us-canada-65452940&amp;sa=D&amp;source=editors&amp;ust=1730413583298864&amp;usg=AOvVaw2nFs7Wd5lzdeu0x1EvZ94C">https://www.bbc.com/news/world-us-canada-65452940</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-2"><li class="c22 c104 c86 li-bullet-0"><span class="c40 c30 c37 c14">&quot;Right now, they&#39;re not more intelligent than us, as far as I can tell. But I think they soon may be.&quot;</span></li><li class="c22 c104 c86 li-bullet-0"><span class="c40 c30 c37 c14">&quot;And given the rate of progress, we expect things to get better quite fast. So we need to worry about that.&quot;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c40 c30 c37 c14">&quot;Almost everybody I know who is an expert on AI believes that they will exceed human intelligence, it&#39;s just a question of when&rdquo;</span></li><li class="c22 c72 li-bullet-0"><span class="c40 c30 c37 c14">&quot;Between 5 and 20 years from now there&rsquo;s a probability of about a half that we&#39;ll have to confront the problem of [AI] trying to take over&quot;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-3 start"><li class="c22 c104 c26 li-bullet-0"><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1792403377646924146&amp;sa=D&amp;source=editors&amp;ust=1730413583299497&amp;usg=AOvVaw0njiybLivqMIEF2dTzFOLG">https://x.com/tsarnick/status/1792403377646924146</a></span><span class="c40 c30 c37 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2"><li class="c22 c104 c86 li-bullet-0"><span class="c30 c37 c14">More information: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?t%3D1383%26v%3DN1TEjTeQeg0%26feature%3Dyoutu.be&amp;sa=D&amp;source=editors&amp;ust=1730413583299777&amp;usg=AOvVaw1Kn24-wCo1vjx8Y7lr7U7Y">https://m.youtube.com/watch?v=N1TEjTeQeg0&amp;feature=youtu.be</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c40 c30 c37 c14">Ilya Sutskever: </span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2 start"><li class="c22 c104 c86 li-bullet-0"><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583300246&amp;usg=AOvVaw37LNAao0wkwtVHLmilpB4E">https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-3"><li class="c22 c104 c26 li-bullet-0"><span class="c40 c30 c37 c14">He thinks ChatGPT just might be conscious (if you squint). He thinks the world needs to wake up to the true power of the technology his company and others are racing to create. And he thinks some humans will one day choose to merge with machines.</span></li><li class="c22 c104 c26 li-bullet-0"><span class="c40 c30 c37 c14">&ldquo;It&rsquo;s important to talk about where it&rsquo;s all headed,&rdquo; he says, before predicting the development of artificial general intelligence (by which he means machines as smart as humans) as if it were as sure a bet as another iPhone: &ldquo;At some point we really will have AGI. Maybe OpenAI will build it. Maybe some other company will build it.&rdquo;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2"><li class="c22 c104 c86 li-bullet-0"><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DYEUclZdj_Sc&amp;sa=D&amp;source=editors&amp;ust=1730413583300758&amp;usg=AOvVaw09pB0-75F9QpQQeGQHqc62">https://www.youtube.com/watch?v=YEUclZdj_Sc</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-3 start"><li class="c22 c104 c26 li-bullet-0"><span class="c40 c30 c37 c14">&ldquo;Because if you think about it, what does it mean to predict the next token well enough? It&#39;s actually a much deeper question than it seems. Predicting the next token well means that you understand the underlying reality that led to the creation of that token. It&#39;s not statistics. Like it is statistics but what is statistics? In order to understand those statistics to compress them, you need to understand what is it about the world that creates this set of statistics.&rdquo;</span></li><li class="c22 c104 c26 li-bullet-0"><span class="c40 c30 c15">Believes next-token prediction can reach AGI</span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c30 c37 c14">Yoshua Bengio: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/&amp;sa=D&amp;source=editors&amp;ust=1730413583301456&amp;usg=AOvVaw0h2HkewLxH8wFTnvXnLkDc">https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/</a></span></li></ul><p class="c22 c44"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_dacire7nzy6o-2"><li class="c22 c104 c86 li-bullet-0"><span class="c40 c30 c37 c14">many experts agree that superhuman capabilities could arise in just a few years (but it could also be decades) and digital technologies have advantages over biological machines </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c79 c23 c14">I would strongly argue that there is a scientific consensus that brains are biological machines and that there is no evidence of inherent impossibility of building machines at least as intelligent as us. Finally, an AI system would not need to be better than us on all fronts in order to have a catastrophic impact (even the least intelligent entity, a virus, could destroy humanity).</span></li><li class="c22 c104 c86 li-bullet-0"><span class="c23 c14 c84">My current estimate places a </span><span class="c79 c35 c65 c34 c14">95% confidence interval for the time horizon of superhuman intelligence at 5 to 20 years. </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c23 c14 c84">&nbsp;Research on bridging the gap to superhuman capabilities is making progress, for example to improve </span><span class="c20 c35 c65 c34 c14 c84"><a class="c13" href="https://www.google.com/url?q=https://royalsocietypublishing.org/doi/full/10.1098/rspa.2021.0068&amp;sa=D&amp;source=editors&amp;ust=1730413583302144&amp;usg=AOvVaw11Ra-6ALfv0Uq_BXCFylYX">system 2 abilities</a></span><span class="c79 c23 c14">&nbsp;(reasoning, world model, causality, epistemic uncertainty estimation). </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c79 c23 c14">I used to think&hellip; that superhuman intelligence was still far in the future, but ChatGPT and GPT-4 have considerably reduced my prediction horizon (from 20 to 100 years to 5 to 20 years)... The unexpected speed at which LLMs have acquired their current level of competence simply because of scale suggests that we could also see the rest of the gap being filled in just a few years with minor algorithmic changes. Even if someone disagrees with the temporal horizon distribution, I don&rsquo;t see how one could reject that possibility.</span></li><li class="c22 c104 c86 li-bullet-0"><span class="c23 c14 c84">He believes it can become advanced enough to become an existential risk to humanity: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/&amp;sa=D&amp;source=editors&amp;ust=1730413583302586&amp;usg=AOvVaw3k1EFB8nc-JUoG7uCm-R9v">https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/</a></span></li><li class="c7 li-bullet-0"><span>Yoshua Bengio: Some say &ldquo;None of these risks have materialized yet, so they are purely hypothetical&rdquo;. But (1) AI is rapidly getting better at abilities that increase the likelihood of these risks (2) We should not wait for a major catastrophe before protecting the public.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Yoshua_Bengio/status/1836530574334529964&amp;sa=D&amp;source=editors&amp;ust=1730413583302893&amp;usg=AOvVaw0aSXSd42Zp-9diGJ9QyVgo">https://x.com/Yoshua_Bengio/status/1836530574334529964</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c23 c14 c84">Andrej Karpathy: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://analyticsindiamag.com/andrej-karpathy-says-the-pathway-to-agi-is-through-a-language-model-operating-system/&amp;sa=D&amp;source=editors&amp;ust=1730413583303206&amp;usg=AOvVaw1jpTrTG3kaWOM-5CVaVkX3">https://analyticsindiamag.com/andrej-karpathy-says-the-pathway-to-agi-is-through-a-language-model-operating-system/</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2 start"><li class="c22 c104 c86 li-bullet-0"><span class="c35">&ldquo;</span><span class="c126">Karpathy expressed his sense of anticipation and excitement for the future of AGI, and believes that the prospect of deploying self-contained agents capable of handling high-level tasks in specialized ways holds promise for groundbreaking advancements across various fields.</span><span class="c40 c37 c35 c48">&rdquo;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c10 li-bullet-0"><span>Max Tegmark: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D_-Xdkzi8H_o&amp;sa=D&amp;source=editors&amp;ust=1730413583303642&amp;usg=AOvVaw1rboP7xww4gSF0zcVd4CZD">https://m.youtube.com/watch?v=_-Xdkzi8H_o</a></span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2 start"><li class="c7 li-bullet-0"><span class="c1">Believes LLMs are the vacuum tubes (rudimentary prototype) of AI that can do the same thing with less data and energy</span></li><li class="c7 li-bullet-0"><span class="c1">Says LLMs like LLAMA 2 has an internal map and can generalize based on it</span></li><li class="c7 li-bullet-0"><span>Researchers were able to get a language to language dictionary from matching word </span><span class="c40 c37 c35 c48">embeddings of different languages </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">Believes it can supersede humans and they would be able to control robots well</span></li><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">Next goal is to create agents that can do things autonomously, which he believes could become like a new species </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">Can revolutionize education by making connections and finding patterns to help students and help them stay engaged </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">AI will help AI development go faster and could even eventually lead to no humans being involved </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">Used AI to do research in climate science and published in a paper</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c35">OpenAI president Greg Brockman: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://t.co/MIBFLfgdqh&amp;sa=D&amp;source=editors&amp;ust=1730413583304443&amp;usg=AOvVaw0-9IKIBPL1-UHzMhlzG8GH">https://t.co/MIBFLfgdqh</a></span><span class="c40 c37 c35 c48">&nbsp;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2 start"><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">Says we will all get AI superpowers and will be able to achieve things we couldn&#39;t otherwise</span></li><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">we will encounter an increasing series of stakes as we progress with AI and we will graduate to new classes of benefits and risks that go hand in hand</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-1"><li class="c22 c72 li-bullet-0"><span class="c35">OpenAI cofounder John Schulman: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://t.co/0ebe6YvM0O&amp;sa=D&amp;source=editors&amp;ust=1730413583304792&amp;usg=AOvVaw3Wtm35eRuanIE9KFi5uOlW">https://t.co/0ebe6YvM0O</a></span><span class="c40 c37 c35 c48">&nbsp;</span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-2 start"><li class="c22 c104 c86 li-bullet-0"><span class="c40 c37 c35 c48">says AI models are optimized to do what humans like or find useful and in a year or two will be able to complete entire projects for you </span></li></ul><ul class="c0 lst-kix_dacire7nzy6o-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37 c14">Geoffrey Hinton (Turing Award winner for machine learning) says AI language models aren&#39;t just predicting the next symbol, they&#39;re actually reasoning and understanding in the same way we are, and they&#39;ll continue improving as they get bigger: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1791584514806071611&amp;sa=D&amp;source=editors&amp;ust=1730413583305110&amp;usg=AOvVaw23Yfscm_0TBrJrfaHe_ZAy">https://x.com/tsarnick/status/1791584514806071611</a></span></li><li class="c4 li-bullet-0"><span class="c1 c14">Joscha Bach says if AI systems are allowed to self-improve, they could reach self-awareness and enlightenment faster than a human can</span></li></ul><p class="c129 c226"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1789557937255666060?s%3D4&amp;sa=D&amp;source=editors&amp;ust=1730413583305391&amp;usg=AOvVaw1KTbmgjJPW3uckG9LnV_XZ">https://x.com/tsarnick/status/1789557937255666060?s=4</a></span></p><p class="c9 c93"><span class="c1 c14"></span></p><ul class="c0 lst-kix_thg0lt5umapc-0 start"><li class="c4 li-bullet-0"><span class="c14">OpenAI CEO Sam Altman says huge improvements are coming soon:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-gb/news/techandscience/gpt-4-is-the-dumbest-model-any-of-you-will-ever-have-to-use-declares-openai-ceo-sam-altman-as-he-bets-big-on-a-superingtelligence/ar-AA1o2q6f?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583305755&amp;usg=AOvVaw3lGwwE1NDICNlGqA4KWRry">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-gb/news/techandscience/gpt-4-is-the-dumbest-model-any-of-you-will-ever-have-to-use-declares-openai-ceo-sam-altman-as-he-bets-big-on-a-superingtelligence/ar-AA1o2q6f?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583305991&amp;usg=AOvVaw1UpTnB9_j3J85rVaEUHMmk">https://www.msn.com/en-gb/news/techandscience/gpt-4-is-the-dumbest-model-any-of-you-will-ever-have-to-use-declares-openai-ceo-sam-altman-as-he-bets-big-on-a-superingtelligence/ar-AA1o2q6f?darkschemeovr=1</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c14">Also says we could be only one or two breakthroughs away from AGI:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://t.co/UffGrKbAAs&amp;sa=D&amp;source=editors&amp;ust=1730413583306226&amp;usg=AOvVaw2ZsftAfyqJtajClA35REhi">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://t.co/UffGrKbAAs&amp;sa=D&amp;source=editors&amp;ust=1730413583306350&amp;usg=AOvVaw0Z_9LLKPJ2tb_4zuq2y7wB">https://t.co/UffGrKbAAs</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c14">Thinks it will be powerful enough to cause extinction:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2023/10/31/tech/sam-altman-ai-risk-taker/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583306625&amp;usg=AOvVaw3tJLjUGwSL3JMEvjAk5nHx">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2023/10/31/tech/sam-altman-ai-risk-taker/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583306782&amp;usg=AOvVaw1EUa1RxCAIhSOEcQJKYYvc">https://www.cnn.com/2023/10/31/tech/sam-altman-ai-risk-taker/index.html</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c14">Former Google CEO agrees:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1cmoa52/former_google_ceo_on_ai_its_underhyped/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583307129&amp;usg=AOvVaw2ZDniqnmubl836E2omMAx_">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1cmoa52/former_google_ceo_on_ai_its_underhyped/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583307346&amp;usg=AOvVaw09YxdfsGnMWwkpaQEV9c1e">https://www.reddit.com/r/singularity/comments/1cmoa52/former_google_ceo_on_ai_its_underhyped/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li><li class="c10 li-bullet-0"><span class="c14">Microsoft CEO says AI performance is doubling every 6 months:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793416617256468689&amp;sa=D&amp;source=editors&amp;ust=1730413583307576&amp;usg=AOvVaw06CEqrKEF4L_XnXMmNB5OC">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793416617256468689&amp;sa=D&amp;source=editors&amp;ust=1730413583307703&amp;usg=AOvVaw1aDUd3Jbpz-mp9msJvgSP9">https://x.com/tsarnick/status/1793416617256468689</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c22 c32 li-bullet-0"><span class="c31">With Spatial Intelligence, AI Will Understand the Real World | Fei-Fei Li (Stanford professor) | TED: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dy8NtMZ7VGmU&amp;sa=D&amp;source=editors&amp;ust=1730413583307961&amp;usg=AOvVaw0SmIJypd12G6Y8QFntqUeB">https://www.youtube.com/watch?v=y8NtMZ7VGmU</a></span></li><li class="c22 c32 li-bullet-0"><span class="c31">AI could be smarter than people in 20 years, says &#39;godfather of AI` Geoffrey Hinton: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DbEuNgY7Olbo&amp;sa=D&amp;source=editors&amp;ust=1730413583308278&amp;usg=AOvVaw09qsDn4XkkV5pDvLLD2cQR">https://www.youtube.com/watch?v=bEuNgY7Olbo</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c22 c72 li-bullet-0"><span class="c40 c37 c48 c31">He also believes it could be an existential threat: </span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-2 start"><li class="c22 c104 c86 li-bullet-0"><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DY6Sgp7y178k&amp;sa=D&amp;source=editors&amp;ust=1730413583308620&amp;usg=AOvVaw0xSxwP6cPbG_mfJKrVLX89">https://www.youtube.com/watch?v=Y6Sgp7y178k</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li><li class="c22 c104 c86 li-bullet-0"><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D0oyegCeCcbA&amp;sa=D&amp;source=editors&amp;ust=1730413583308867&amp;usg=AOvVaw0EIxV1b6NtH0Zk9pxwpeDw">https://www.youtube.com/watch?v=0oyegCeCcbA</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li><li class="c22 c104 c86 li-bullet-0"><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DsitHS6UDMJc&amp;sa=D&amp;source=editors&amp;ust=1730413583309102&amp;usg=AOvVaw0ZQP4_g4mWaKuGWQVdycNB">https://www.youtube.com/watch?v=sitHS6UDMJc</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c22 c32 li-bullet-0"><span class="c31">Renowned MIT professor Max Tegmark believes AI could be dangerous in the future: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DxUNx_PxNHrY&amp;sa=D&amp;source=editors&amp;ust=1730413583309317&amp;usg=AOvVaw2LjvI0Dr4cyPqi5hcLtFZX">https://www.youtube.com/watch?v=xUNx_PxNHrY</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c31">Prominent AI skeptic Gary Marcus believes AI could be dangerous in the future: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DJL5OFXeXenA&amp;sa=D&amp;source=editors&amp;ust=1730413583309524&amp;usg=AOvVaw3wfG8xLvASTCOSRyf1NIm3">https://www.youtube.com/watch?v=JL5OFXeXenA</a></span><span class="c31">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c35">Microsoft CTO Kevin Scott says we are riding an exponential wave in the scaling of AI compute and the end is nowhere in sight: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793027868366147818&amp;sa=D&amp;source=editors&amp;ust=1730413583309788&amp;usg=AOvVaw0Q9qf_RqZBRaZqJEn90zMB">https://x.com/tsarnick/status/1793027868366147818</a></span><span class="c35">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c14">Reid Hoffman says deepfake videos which are indistinguishable from the real thing are only months away: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1797739922478235686&amp;sa=D&amp;source=editors&amp;ust=1730413583310166&amp;usg=AOvVaw3J6Xg2d2J0RIKXXKw0O6iJ">https://x.com/tsarnick/status/1797739922478235686</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 398.67px;"><img alt="" src="images/image139.png" style="width: 624.00px; height: 398.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c22 c72 li-bullet-0"><span class="c1 c14">&lt;40% of Harvard students who took an AI class do not think AI will be more capable than humans in almost all regards in 30 years</span></li><li class="c22 c72 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/GabrielDWu1/status/1797811385663172961&amp;sa=D&amp;source=editors&amp;ust=1730413583310751&amp;usg=AOvVaw3VgI9qwQi8uvB-SsTmiDJa">https://x.com/GabrielDWu1/status/1797811385663172961</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 185.33px;"><img alt="" src="images/image156.png" style="width: 624.00px; height: 185.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c22 c72 li-bullet-0"><span class="c1 c14">About half of Harvard students who took an AI class think AI will be advanced enough to pose a risk of extinction, &lt;30% disagree</span></li><li class="c22 c72 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/GabrielDWu1/status/1797811385663172961&amp;sa=D&amp;source=editors&amp;ust=1730413583311290&amp;usg=AOvVaw1ol57J_c2_hOGGdHnqXxMX">https://x.com/GabrielDWu1/status/1797811385663172961</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c22 c32 li-bullet-0"><span class="c14">Computer science professor and director of Cyber Security Laboratory in the department of Computer Engineering and Computer Science at the Speed School of Engineering believes AI will become advanced enough to almost certainly cause existential catastrophe: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/romanyam/status/1767575356155027503&amp;sa=D&amp;source=editors&amp;ust=1730413583311653&amp;usg=AOvVaw2pSLHzSDL9nA6b7K-_Vs-N">https://x.com/romanyam/status/1767575356155027503</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c14">Microsoft CTO Kevin Scott says what he&#39;s seeing in early previews of forthcoming AI models are systems with memory and reasoning at a level that can pass PhD qualifying exams: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1798167323893002596&amp;sa=D&amp;source=editors&amp;ust=1730413583311986&amp;usg=AOvVaw3OfLc2nGpIZ4w98n7OM2_9">https://x.com/tsarnick/status/1798167323893002596</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c14">ex-OpenAI employee says OpenAI believes AGI can be achieved by 2027-2028: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/steph_palazzolo/status/1798041967118750118&amp;sa=D&amp;source=editors&amp;ust=1730413583312298&amp;usg=AOvVaw3KUbxfx8H-N4uMvtUPZZhH">https://x.com/steph_palazzolo/status/1798041967118750118</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span>&quot; By 2025/26, these machines will outpace many college graduates. By the end of the decade, they will be smarter than you or I; we will have superintelligence, in the true sense of the word. &quot; &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://situational-awareness.ai/from-gpt-4-to-agi/&amp;sa=D&amp;source=editors&amp;ust=1730413583312659&amp;usg=AOvVaw1WzikfRjT1vnqY9xpx7lr8">https://situational-awareness.ai/from-gpt-4-to-agi/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Ex-OpenAI employee Leopold Aschenbrenner says there will soon be GPU clusters running the equivalent of 100 million AI researchers, leading to AI vastly smarter than humans and an intelligence explosion: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1798463279339274626&amp;sa=D&amp;source=editors&amp;ust=1730413583312997&amp;usg=AOvVaw0pYfXLdtIJ6k0dIz9yrR7e">https://x.com/tsarnick/status/1798463279339274626</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span class="c40 c30 c37">OpenAI employees Daniel Kokotajlo, Ilya Sutskever, Jan Leike, and many more quit OpenAI due to safety concerns, which would go HEAVILY against their financial interests</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c40 c30 c37">Additionally, why would they use this as a means to hype up AI if they were quitting from the company building the AI? They gain nothing from that. </span></li><li class="c10 li-bullet-0"><span class="c30 c37">Daniel Kokotajlo gave up 85% of his family&rsquo;s net worth in OpenAI stock equity so he could quit without signing a non-disparagement agreement: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/&amp;sa=D&amp;source=editors&amp;ust=1730413583313700&amp;usg=AOvVaw1dL7_n95zzyd8UPO5lhLRk">https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/</a></span><span class="c40 c30 c37">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 419.34px; height: 786.85px;"><img alt="" src="images/image587.png" style="width: 419.34px; height: 786.85px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>This is AI&#39;s &#39;next wave,&#39; according to Nvidia CEO Jensen Huang - The chipmaker&#39;s chief executive said robots and &quot;AI that understands the laws of physics&quot; are the next wave of the technology: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://qz.com/ai-next-wave-robots-nvidia-jensen-huang-blackwell-rubin-1851515953&amp;sa=D&amp;source=editors&amp;ust=1730413583314265&amp;usg=AOvVaw3VMfrwF3JVGfrQM2-FFm4l">https://qz.com/ai-next-wave-robots-nvidia-jensen-huang-blackwell-rubin-1851515953</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Former Microsoft &amp; Google research scientist Kai-Fu Lee- About 50% Of Jobs Will Be Displaced By AI Within 3 Years: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DzZs447dgMjg&amp;sa=D&amp;source=editors&amp;ust=1730413583314617&amp;usg=AOvVaw3e0rflMsrO3mRiLXj9D374">https://www.youtube.com/watch?v=zZs447dgMjg</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c1">Since he&rsquo;s no longer employed at those companies, he does not have an incentive to lie </span></li><li class="c10 li-bullet-0"><span>Consistent with claims from Anthropic&rsquo;s Chief of Staff: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/&amp;sa=D&amp;source=editors&amp;ust=1730413583315095&amp;usg=AOvVaw3PkV_GNig4QZubI2dbC2ho">https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c92 c99 c37 c65 c60 c144">his prediction from 2017 still holds that in 10-15 years around 40-50% of all jobs will be replaced by AI.</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>OpenAI engineer James Betker estimates 3 years until we have a generally intelligent embodied agent (his definition of AGI): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://nonint.com/2024/06/03/general-intelligence-2024/&amp;sa=D&amp;source=editors&amp;ust=1730413583315590&amp;usg=AOvVaw36HVd1bq2n4_lDv1P14ir2">https://nonint.com/2024/06/03/general-intelligence-2024/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">we&rsquo;ve basically solved building world models, have 2-3 years on system 2 thinking, and 1-2 years on embodiment. The latter two can be done concurrently. Once all of the ingredients have been built, we need to integrate them together and build the cycling algorithm I described above. I&rsquo;d give that another 1-2 years.</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">So my current estimate is 3-5 years for AGI. I&rsquo;m leaning towards 3 for something that looks an awful lot like a generally intelligent, embodied agent (which I would personally call an AGI). Then a few more years to refine it to the point that we can convince the Gary Marcus&rsquo; of the world.</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>OpenAI&#39;s Colin Jarvis predicts &quot;exponential&quot; advancements in large language model capabilities during AI Summit London keynote: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://aibusiness.com/nlp/openai-chief-architect-predicts-huge-large-language-model-leaps&amp;sa=D&amp;source=editors&amp;ust=1730413583316264&amp;usg=AOvVaw1O4B_OO1LrUPmQPIzSPBV1">https://aibusiness.com/nlp/openai-chief-architect-predicts-huge-large-language-model-leaps</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Andrew Ng says AI agents can iterate using thinking, research and revision, and the improvement is bigger than going from GPT-3.5 to 4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1801794605723357301&amp;sa=D&amp;source=editors&amp;ust=1730413583316612&amp;usg=AOvVaw14Q0gRkk6WyOwvwjBwj9E-">https://x.com/tsarnick/status/1801794605723357301</a></span></li><li class="c4 li-bullet-0"><span>Kai-Fu Lee says the cost of AI inference compute will reduce by 100x in the next 2 years due to the scaling law: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1802570392571466002&amp;sa=D&amp;source=editors&amp;ust=1730413583316915&amp;usg=AOvVaw3QNEhGu9vvtX8_BSI-T3tk">https://x.com/tsarnick/status/1802570392571466002</a></span></li><li class="c4 li-bullet-0"><span>Ilya Sutskever believes super intelligence is within reach: &nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 517.33px;"><img alt="" src="images/image661.jpg" style="width: 624.00px; height: 517.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Mira Murati: GPT-3 was toddler-level, GPT-4 was a smart high schooler and the next gen, to be released in a year and a half, will be PhD-level: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1803901130130497952&amp;sa=D&amp;source=editors&amp;ust=1730413583317397&amp;usg=AOvVaw02oj2qRK06MxDcRy09ZRpq">https://x.com/tsarnick/status/1803901130130497952</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c5 c37 c103 c126"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/&amp;sa=D&amp;source=editors&amp;ust=1730413583317740&amp;usg=AOvVaw1palkwdZQiexeAdg3hWfT2">https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/</a></span><span class="c79 c37 c103 c126">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c67 c37">&ldquo;I haven&rsquo;t seen deep learning hit a wall yet, and I&rsquo;ll leave it to researchers to speculate about the wall, but I think it&rsquo;s a little bit early to be coming to conclusions on that, especially if you look at the pace of innovation,&rdquo; he said. &ldquo;There&rsquo;s very rapid development and very rapid innovation, and I have no reason to believe that it&rsquo;s going to slow down.&rdquo;</span><span class="c23 c236">_ </span><span class="c79 c37 c103 c126">- Michael Gerstenhaber, product lead at Anthropic</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>The insiders at OpenAI (everyone), Microsoft (CTO, etc.), and Anthropic (CEO) have all been saying that they see no immediate end to the scaling laws that models are still improving rapidly: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 840.00px;"><img alt="" src="images/image240.png" style="width: 624.00px; height: 840.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Sam Altman says the day is approaching when we can ask an AI model to solve all of physics and it can actually do that: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1806071104148271434?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583318503&amp;usg=AOvVaw0q7ytLY1iqvIBm59Wuc-xa">https://x.com/tsarnick/status/1806071104148271434?s=46</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Anthropic CEO Dario Amodei says by 2027 AI models will cost up to $100 billion to train and will be &quot;better than most humans at most things&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dpk3lb/anthropic_ceo_dario_amodei_says_by_2027_ai_models/&amp;sa=D&amp;source=editors&amp;ust=1730413583318918&amp;usg=AOvVaw1_Xo7g_lZlmOLlragjOKkX">https://www.reddit.com/r/singularity/comments/1dpk3lb/anthropic_ceo_dario_amodei_says_by_2027_ai_models/</a></span><span class="c1">&nbsp;</span></li><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">Google researcher does not believe video generation is plateauing: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/giffmana/status/1807511985807908926&amp;sa=D&amp;source=editors&amp;ust=1730413583319270&amp;usg=AOvVaw3AlIzKxEAb5AuDyHziau8U">https://x.com/giffmana/status/1807511985807908926</a></span><span class="c40 c37 c48 c31">&nbsp;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c89 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 316.00px;"><img alt="" src="images/image636.png" style="width: 624.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c89 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 281.33px;"><img alt="" src="images/image448.png" style="width: 624.00px; height: 281.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c100 c53 c56 c78 c216 li-bullet-0"><span>&#39;50-50 chance&#39; that AI outsmarts humanity, Geoffrey Hinton says: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bnnbloomberg.ca/50-50-chance-that-ai-outsmarts-humanity-geoffrey-hinton-says-1.2085394&amp;sa=D&amp;source=editors&amp;ust=1730413583319988&amp;usg=AOvVaw0zgAOOCdEOoUKqfjO8_oGB">https://www.bnnbloomberg.ca/50-50-chance-that-ai-outsmarts-humanity-geoffrey-hinton-says-1.2085394</a></span></li><li class="c100 c53 c56 c78 c216 li-bullet-0"><span>Co-author of the original Transformers paper Aidan Gomez says the success of AI models so far has been due to an &quot;irrational conviction&quot; that scale would make models smarter and he thinks this will continue to hold true: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1810051877780009107&amp;sa=D&amp;source=editors&amp;ust=1730413583320337&amp;usg=AOvVaw2h9Mthe487kolgXntnV11i">https://x.com/tsarnick/status/1810051877780009107</a></span></li><li class="c100 c53 c56 c78 c216 li-bullet-0"><span>The @LumaLabsAI team is &lt;12 months away from real time video generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AnjneyMidha/status/1809824534876283171&amp;sa=D&amp;source=editors&amp;ust=1730413583320655&amp;usg=AOvVaw2WhuXgTuWUs5xnLvCQV7la">https://x.com/AnjneyMidha/status/1809824534876283171</a></span></li><li class="c22 c100 c78 li-bullet-0"><span>AI models that cost $1 billion to train are underway, $100 billion models coming &mdash; largest current models take &#39;only&#39; $100 million to train: Anthropic CEO: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo&amp;sa=D&amp;source=editors&amp;ust=1730413583321232&amp;usg=AOvVaw069VCwJ1KmqUOKOppxmtvx">https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo</a></span></li><li class="c22 c100 c78 li-bullet-0"><span>Microsoft CTO Kevin Scott says despite what some people think, scale will keep making AI models better in every way and the next generation will be proof of that: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1810846219499175965&amp;sa=D&amp;source=editors&amp;ust=1730413583321606&amp;usg=AOvVaw3uHMILWlDya2R4J0P9X_K5">https://x.com/tsarnick/status/1810846219499175965</a></span></li><li class="c22 c100 c78 li-bullet-0"><span>Demis Hassabis says it is obvious that artificial general intelligence will transform everything and be as revolutionary as electricity or fire, while accelerating the process of scientific discovery itself: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1810852880485863456&amp;sa=D&amp;source=editors&amp;ust=1730413583321966&amp;usg=AOvVaw3o9_eabx7IdYrHFGfmfBE6">https://x.com/tsarnick/status/1810852880485863456</a></span></li><li class="c22 c100 c78 li-bullet-0"><span>AI engineers believe AI will have a 40% chance of dooming humanity on average: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135%23694f89e86f9148cb855220ec05e9c631&amp;sa=D&amp;source=editors&amp;ust=1730413583322403&amp;usg=AOvVaw1VwSKosBP5N8vAQh782dL9">https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135#694f89e86f9148cb855220ec05e9c631</a></span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2024-07-11/openai-sets-levels-to-track-progress-toward-superintelligent-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583322796&amp;usg=AOvVaw0KhKxgGrmIh9Y5gRDQTrJI">https://www.bloomberg.com/news/articles/2024-07-11/openai-sets-levels-to-track-progress-toward-superintelligent-ai</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c1">OpenAI at an employee meeting on Tuesday &quot;gave a demonstration of a research project involving its GPT-4 AI model that OpenAI thinks shows some new skills that rise to human-like reasoning,&quot; </span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI executives told employees that the company believes it is currently on the first level, according to the spokesperson, but on the cusp of reaching the second, which it calls &quot;Reasoners.&quot; This refers to systems that can do basic problem-solving tasks as well as a human with a doctorate-level education who doesn&rsquo;t have access to any tools.</span></li><li class="c10 li-bullet-0"><span class="c1">Here&#39;s what Sam said in March: &quot;Better reasoning in these systems is an important direction that we&rsquo;d like to pursue. We haven&rsquo;t cracked the code yet&rdquo;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-2 start"><li class="c7 li-bullet-0"><span class="c1">If he was just trying to promote hype, why did he say this and change his stance 4 months later?</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>OpenAI whistleblowers call for an SEC investigation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AISafetyMemes/status/1812150637729403360&amp;sa=D&amp;source=editors&amp;ust=1730413583323613&amp;usg=AOvVaw2FbcEwx7dV2TwMkNXq_861">https://x.com/AISafetyMemes/status/1812150637729403360</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c1">&quot;OpenAI whistleblowers filed a complaint with the Securities and Exchange Commission alleging the AI company illegally prohibited its employees from warning regulators about the grave risks its technology may pose to humanity, calling for an investigation.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1">This makes the company look bad and risks federal interference and more regulation</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>Stuart Russel believes AI can be dangerous: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://edition.cnn.com/2023/05/31/opinions/artificial-intelligence-stuart-russell/&amp;sa=D&amp;source=editors&amp;ust=1730413583324223&amp;usg=AOvVaw3TrfDEgLRv2_JOkLze4IrR">https://edition.cnn.com/2023/05/31/opinions/artificial-intelligence-stuart-russell/</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c1">&ldquo;&hellip;even though we may understand how to build perfectly safe general purpose AI, what&rsquo;s to stop Dr. Evil building general purpose AI that&rsquo;s going to destroy the world?&rdquo;</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>Sparks of Artificial General Intelligence: Early experiments with GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/&amp;sa=D&amp;source=editors&amp;ust=1730413583324796&amp;usg=AOvVaw34kkdRN6Fxbm9r-BXAW5Gr">https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c40 c37 c35 c103 c14">In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google&rsquo;s PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4&rsquo;s performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4&rsquo;s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span class="c37 c35 c103 c14">OpenAI ex-chief scientist Ilya Sutskever predicts digital brains may soon outsmart human cognition: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/slow_developer/status/1812836529426890867&amp;sa=D&amp;source=editors&amp;ust=1730413583325444&amp;usg=AOvVaw0AZf4E81RLOQL783gaXzZq">https://x.com/slow_developer/status/1812836529426890867</a></span></li><li class="c4 li-bullet-0"><span class="c37 c35 c103 c14">25-year-old Anthropic employee says she may only have 3 years left to work because AI will replace her: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/&amp;sa=D&amp;source=editors&amp;ust=1730413583325833&amp;usg=AOvVaw2q-qW730ClR0TyTh99ZdRv">https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 321.33px;"><img alt="" src="images/image652.png" style="width: 624.00px; height: 321.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c37 c35 c103 c14">Bill Gates says we are not in an AI bubble because this is &quot;a fundamental advance as important as any in the history of digital technology&quot; and there will be some big winners in the AI space: c</span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1814036806410920023&amp;sa=D&amp;source=editors&amp;ust=1730413583326384&amp;usg=AOvVaw2HT3InaoIMWIyptHUk_wYg">https://x.com/tsarnick/status/1814036806410920023</a></span></li><li class="c4 li-bullet-0"><span class="c37 c35 c103 c14">Ben Goertzel believes in the singularity: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://bengoertzel.substack.com/p/the-coming-consciousness-explosion&amp;sa=D&amp;source=editors&amp;ust=1730413583326769&amp;usg=AOvVaw1jNq_G600WOVl-GATAr_tq">https://bengoertzel.substack.com/p/the-coming-consciousness-explosion</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c18 c108 c14">In 2023 Goertzel postulated that artificial intelligence could </span><span class="c18 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Technological_unemployment&amp;sa=D&amp;source=editors&amp;ust=1730413583327143&amp;usg=AOvVaw3y7cxyJ4An_TMlr1Im3gDE">replace</a></span><span class="c18 c108 c14">&nbsp;up to 80 percent of human jobs in the coming years &quot;without having an AGI, by my guess. Not with ChatGPT exactly as a product. But with systems of that nature&quot;.</span><span class="c29 c153 c107 c14">[</span><span class="c38 c37 c61 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed&amp;sa=D&amp;source=editors&amp;ust=1730413583327479&amp;usg=AOvVaw2ZgmgJKyCpLIv_MVPbxZOH">citation needed</a></span><span class="c29 c107 c14 c153">]</span><span class="c18 c108 c14">&nbsp;At the Web Summit 2023 in Rio de Janeiro, Goertzel spoke out against efforts to curb AI research and that AGI is only a few years away. Goertzel&#39;s belief is that AGI will be a net positive for humanity by assisting with societal problems such as, but not limited to, </span><span class="c18 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Climate_change&amp;sa=D&amp;source=editors&amp;ust=1730413583327781&amp;usg=AOvVaw2kxKri0zjnuUmlNkALXBkV">climate change</a></span><span class="c18 c92 c14 c108">.</span></li><li class="c10 li-bullet-0"><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Ben_Goertzel&amp;sa=D&amp;source=editors&amp;ust=1730413583328080&amp;usg=AOvVaw0wVtizo_1woQ0-Y-qqTWLi">https://en.m.wikipedia.org/wiki/Ben_Goertzel</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span class="c18 c108 c14">Roon, an employee of OpenAI (source: </span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://www.lesswrong.com/posts/jPZXx3iMaiJjdnMbv/read-the-roon&amp;sa=D&amp;source=editors&amp;ust=1730413583328413&amp;usg=AOvVaw1kyF-ah8Gg1DACvwOdarjh">https://www.lesswrong.com/posts/jPZXx3iMaiJjdnMbv/read-the-roon</a></span><span class="c18 c108 c14">), believes there is a 50% chance of AGI within 3 years and a 90% chance within 5 years: </span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tszzl/status/1814795458486907150&amp;sa=D&amp;source=editors&amp;ust=1730413583328660&amp;usg=AOvVaw2NAY50q0izS_GIzxiZchji">https://x.com/tszzl/status/1814795458486907150</a></span></li><li class="c4 li-bullet-0"><span>&quot;Geoff Hinton, one of the major developers of deep learning, is in the process of tidying up his affairs... he believes that we maybe have 4 years left.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1edbftl/geoff_hinton_one_of_the_major_developers_of_deep/&amp;sa=D&amp;source=editors&amp;ust=1730413583329071&amp;usg=AOvVaw3UJPJuixsPYGxISG1qe-Jr">https://www.reddit.com/r/singularity/comments/1edbftl/geoff_hinton_one_of_the_major_developers_of_deep/</a></span></li><li class="c4 li-bullet-0"><span>D&rsquo;Angelo, CEO and co-founder of Quora and OpenAI board member, made prediction during an event last week, that we will have AGI in 5-15 years: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pymnts.com/artificial-intelligence-2/2024/openai-board-member-agi-is-five-to-15-years-away/&amp;sa=D&amp;source=editors&amp;ust=1730413583329500&amp;usg=AOvVaw0SQGbKw6xq8co7wpE9dKer">https://www.pymnts.com/artificial-intelligence-2/2024/openai-board-member-agi-is-five-to-15-years-away/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 141.33px;"><img alt="" src="images/image357.png" style="width: 624.00px; height: 141.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Zuckerberg said at Q2 earnings call: &ldquo;The amount of computing needed to train Llama 4 will likely be almost 10 times more than what we used to train Llama 3 and it will be the most advanced [model] in the industry next year.&quot;: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theregister.com/2024/08/01/meta_q2_2024/&amp;sa=D&amp;source=editors&amp;ust=1730413583330037&amp;usg=AOvVaw1ljJKj5MmppJYOpwL8VRVv">https://www.theregister.com/2024/08/01/meta_q2_2024/</a></span></li><li class="c4 li-bullet-0"><span class="c213 c107">&#39;Microsoft&#39;s Chief Scientific Officer Eric Horvitz says AI systems are already impressively creative, but we riding an exponential curve that will leave no-one in any doubt as to their creativity in 18 months&#39; </span><span class="c5 c107 c213"><a class="c13" href="https://www.google.com/url?q=https://x.com/Scobleizer/status/1822747765128286441&amp;sa=D&amp;source=editors&amp;ust=1730413583330396&amp;usg=AOvVaw2-BBkmBz6tiPrOpedpKDw2">https://x.com/Scobleizer/status/1822747765128286441</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c1">He has the most patents at Microsoft. Thousands. Double the number of the second person. In other words, he knows what he is talking about.</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>Emad Mostaque says things will get really crazy in the next 5 years as we enter an industrial AI revolution with self-driving, autonomous agents and intelligence all coming at the same time: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1825297318561861634&amp;sa=D&amp;source=editors&amp;ust=1730413583330841&amp;usg=AOvVaw1W68uZqzRirp7tJXRESdk2">https://x.com/tsarnick/status/1825297318561861634</a></span></li><li class="c4 li-bullet-0"><span>Cohere CEO Aidan Gomez says the idea that AI models are plateauing or slowing down is wrong and in fact we are about to see a big change in capabilities with the introduction of reasoning and planning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DFUGosOgiTeI&amp;sa=D&amp;source=editors&amp;ust=1730413583331176&amp;usg=AOvVaw2I2tH8ZE6Fe-vAFxo1Xh7f">https://www.youtube.com/watch?v=FUGosOgiTeI</a></span></li><li class="c4 li-bullet-0"><span>In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8&amp;sa=D&amp;source=editors&amp;ust=1730413583331560&amp;usg=AOvVaw2LMgN5C2yo66a01BRzHuMK">https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_thg0lt5umapc-1"><li class="c10 li-bullet-0"><span class="c1">This isn&rsquo;t marketing hype since the recording was not meant to be public</span></li><li class="c10 li-bullet-0"><span class="c1">Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry </span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>Reid Hoffman says there will be at least two more generations of orders of magnitude improvement from scaling AI models, and the soonest we see an asymptote in capabilities will be after GPT-6: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f5c4rx/reid_hoffman_says_there_will_be_at_least_two_more/&amp;sa=D&amp;source=editors&amp;ust=1730413583332266&amp;usg=AOvVaw2-NvTd56OodUPDF9c3jbGH">https://www.reddit.com/r/singularity/comments/1f5c4rx/reid_hoffman_says_there_will_be_at_least_two_more/</a></span></li><li class="c4 li-bullet-0"><span>OpenAI CTO Mira Murati says the definition of intelligence will continue to evolve and we will have incredibly advanced AI systems within the next 5 years: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1830711272930975912&amp;sa=D&amp;source=editors&amp;ust=1730413583332664&amp;usg=AOvVaw02TAa271ljD3EUo-oaJOfL">https://x.com/tsarnick/status/1830711272930975912</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 469.33px;"><img alt="" src="images/image350.png" style="width: 624.00px; height: 469.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>OpenAI Japan CEO says new AI model GPT-Next is coming soon and it will be 100 times better than GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.indiatoday.in/technology/news/story/openai-japan-ceo-ai-model-gpt-next-coming-soon-100-times-better-gpt-4-2594250-2024-09-05&amp;sa=D&amp;source=editors&amp;ust=1730413583333247&amp;usg=AOvVaw3AYHFzRfKi5_VcEjqSqkne">https://www.indiatoday.in/technology/news/story/openai-japan-ceo-ai-model-gpt-next-coming-soon-100-times-better-gpt-4-2594250-2024-09-05</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span class="c1">Tadao Nagasaki, the CEO of OpenAI Japan, spoke about the GPT-Next at the KDDI Summit 2024. He says the AI model will be 100 times more powerful than GPT-4.</span></li><li class="c166 c53 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c48">Mira Murati claims GPT-Next may be smarter than humans</span></li><li class="c166 c53 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c48">GPT-Next promises improved multimodal capabilities</span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c166 c53 c56 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 712.00px;"><img alt="" src="images/image136.png" style="width: 624.00px; height: 712.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c53 c56 c78 c166 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 486.67px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 486.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c166 c53 c56 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 508.00px;"><img alt="" src="images/image518.png" style="width: 624.00px; height: 508.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>David Sacks says OpenAI recently gave investors a product roadmap update and said their AI models will soon be at PhD-level reasoning, act as agents and have the ability to use tools, meaning that the model can now pretend to be a human: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fhn6wo/david_sacks_says_openai_recently_gave_investors_a/&amp;sa=D&amp;source=editors&amp;ust=1730413583334347&amp;usg=AOvVaw3Rsl2ZRUdvJ7U2u8meBwZB">https://www.reddit.com/r/singularity/comments/1fhn6wo/david_sacks_says_openai_recently_gave_investors_a/</a></span></li><li class="c4 li-bullet-0"><span class="c35">Jensen Huang says technology has now reached a positive feedback loop where AI is designing new AI and is now advancing at the pace of &quot;Moore&#39;s Law squared&quot;, meaning that the progress we will see in the next year or two will be &quot;spectacular and surprising&quot; </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/apples_jimmy/status/1836283425743081988?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583334664&amp;usg=AOvVaw3OXNup6Jdo58nJTdPCgxh9">https://x.com/apples_jimmy/status/1836283425743081988?s=46</a></span></li><li class="c4 li-bullet-0"><span>In the past few days, I&rsquo;ve been testing OpenAI o1 models, mostly o1-mini, for developing PhD or postdoc level projects. I can confidently claim that the o1 model is comparable to an outstanding PhD student in biomedical sciences! I&rsquo;d rate it among the best PhDs I&rsquo;ve have trained! </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/deryatr_/status/1836434726774526381?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583334979&amp;usg=AOvVaw2FwXgx9b4bOjoh9YJj2nc_">https://x.com/deryatr_/status/1836434726774526381?s=46</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>ChatGPT is upgrading itself &mdash; Sam Altman says next-gen AI could invent breakthroughs, cure diseases: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tomsguide.com/ai/chatgpt/chatgpt-is-upgrading-itself-sam-altman-says-next-gen-ai-could-invent-breakthroughs-cure-diseases&amp;sa=D&amp;source=editors&amp;ust=1730413583335367&amp;usg=AOvVaw1y3N5QPfD9OnlKXEB0et9N">https://www.tomsguide.com/ai/chatgpt/chatgpt-is-upgrading-itself-sam-altman-says-next-gen-ai-could-invent-breakthroughs-cure-diseases</a></span></li><li class="c4 li-bullet-0"><span>The United Nations Wants to Treat AI With the Same Urgency as Climate Change: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/united-nations-artificial-intelligence-report/&amp;sa=D&amp;source=editors&amp;ust=1730413583335735&amp;usg=AOvVaw1a8onH_VlheXLxmFWmztmB">https://www.wired.com/story/united-nations-artificial-intelligence-report/</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-1 start"><li class="c10 li-bullet-0"><span>UN Secretary-General Ant&oacute;nio Guterres says there needs to be an International Scientific Council on AI, bringing together governments, industry, academia and civil society, because AI will evolve unpredictably and be the central element of change in the future: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fn4w87/un_secretarygeneral_ant%25C3%25B3nio_guterres_says_there/&amp;sa=D&amp;source=editors&amp;ust=1730413583336159&amp;usg=AOvVaw1A0x9jXwRNDx4INiP49Jap">https://www.reddit.com/r/singularity/comments/1fn4w87/un_secretarygeneral_ant%C3%B3nio_guterres_says_there/</a></span></li></ul><ul class="c0 lst-kix_thg0lt5umapc-0"><li class="c4 li-bullet-0"><span>Yann LeCun says we will have AI that matches or surpasses human intelligence in &ldquo;a number of years&rdquo; and we will have a team of AI assistants in smart glasses within a year or two that can translate hundreds of languages: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fnuysf/yann_lecun_says_we_will_soon_have_ai_that_matches/&amp;sa=D&amp;source=editors&amp;ust=1730413583336571&amp;usg=AOvVaw1XsIKNZ8AdCv5wjo3_OmJZ">https://www.reddit.com/r/singularity/comments/1fnuysf/yann_lecun_says_we_will_soon_have_ai_that_matches/</a></span></li><li class="c4 li-bullet-0"><span>Mark Zuckerberg says he is betting that the limit of scaling AI systems &quot;is not going to happen any time soon&quot;, as Llama 4 will train on 100,000+ GPUs and Llama 5 even more than that: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fprtz7/mark_zuckerberg_says_he_is_betting_that_the_limit/?sort%3Dconfidence&amp;sa=D&amp;source=editors&amp;ust=1730413583337126&amp;usg=AOvVaw3LZrBri98A1AAi0JoJHI4K">https://www.reddit.com/r/singularity/comments/1fprtz7/mark_zuckerberg_says_he_is_betting_that_the_limit/?sort=confidence</a></span></li><li class="c4 li-bullet-0"><span>eric schmidt thinks that infinite context windows and agents are coming this year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fqrt79/eric_schmidt_thinks_that_infinite_context_windows/?sort%3Dconfidence&amp;sa=D&amp;source=editors&amp;ust=1730413583337575&amp;usg=AOvVaw1qc0OBhjropaUton_N8Uy5">https://www.reddit.com/r/singularity/comments/1fqrt79/eric_schmidt_thinks_that_infinite_context_windows/?sort=confidence</a></span></li><li class="c4 li-bullet-0"><span>OpenAI&#39;s Noam Brown says when you give AI the ability to think for longer, it develops emergent capabilities like being able self-correct its reasoning and its clear that this is a scalable direction for future development: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1futcj8/openais_noam_brown_says_when_you_give_ai_the/&amp;sa=D&amp;source=editors&amp;ust=1730413583337998&amp;usg=AOvVaw1WE7n-0WN0wiJN7PwLhgLk">https://www.reddit.com/r/singularity/comments/1futcj8/openais_noam_brown_says_when_you_give_ai_the/</a></span></li><li class="c4 li-bullet-0"><span>Daphne Koller says although biology is 5-7 years behind language models, the explosion in biological data means that AI will soon be able to make causal inferences about disease pathways: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fwe58o/daphne_koller_says_although_biology_is_57_years/&amp;sa=D&amp;source=editors&amp;ust=1730413583338411&amp;usg=AOvVaw017u91NutxwPW9bMK-0_rG">https://www.reddit.com/r/singularity/comments/1fwe58o/daphne_koller_says_although_biology_is_57_years/</a></span></li><li class="c4 li-bullet-0"><span>Stanford&#39;s Erik Brynjolfsson predicts that within 5 years, AI will be so advanced that we will think of human intelligence as a narrow kind of intelligence and AI will transform the economy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fx8grs/stanfords_erik_brynjolfsson_predicts_that_within/&amp;sa=D&amp;source=editors&amp;ust=1730413583338836&amp;usg=AOvVaw2ESkP4UQA4BOIBG28NJQ90">https://www.reddit.com/r/singularity/comments/1fx8grs/stanfords_erik_brynjolfsson_predicts_that_within/</a></span></li><li class="c4 li-bullet-0"><span>Max Tegmark says crazy things will happen due to AI in the next 2 years so we can no longer plan 10 years into the future and although there is a lot of hype, the technology is here to stay and is &quot;going to blow our minds&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fyngp8/max_tegmark_says_crazy_things_will_happen_due_to/&amp;sa=D&amp;source=editors&amp;ust=1730413583339249&amp;usg=AOvVaw220TWKW65hPTXUij2jESRR">https://www.reddit.com/r/singularity/comments/1fyngp8/max_tegmark_says_crazy_things_will_happen_due_to/</a></span></li><li class="c4 li-bullet-0"><span>Geoffrey Hinton says AI development is not hitting a wall or slowing down and we will see as much change in AI in the next 10 years as we have seen in the last 10: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fzh3tl/geoffrey_hinton_says_ai_development_is_not/&amp;sa=D&amp;source=editors&amp;ust=1730413583339609&amp;usg=AOvVaw0bS7ugQCQUZSSCj-IOmNEk">https://www.reddit.com/r/singularity/comments/1fzh3tl/geoffrey_hinton_says_ai_development_is_not/</a></span></li><li class="c4 li-bullet-0"><span>Runway CEO Crist&oacute;bal Valenzuela says AI is coming to Hollywood and demos tools that move beyond text prompts to give filmmakers greater control over video generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g0uwdo/runway_ceo_crist%25C3%25B3bal_valenzuela_says_ai_is_coming/&amp;sa=D&amp;source=editors&amp;ust=1730413583340006&amp;usg=AOvVaw3Cr0N1QCuZyzKmYwTpJ1FK">https://www.reddit.com/r/singularity/comments/1g0uwdo/runway_ceo_crist%C3%B3bal_valenzuela_says_ai_is_coming/</a></span></li><li class="c4 li-bullet-0"><span>Sequoia Capital analysis of reasoning in AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.sequoiacap.com/article/generative-ais-act-o1/&amp;sa=D&amp;source=editors&amp;ust=1730413583340338&amp;usg=AOvVaw0gDsLDLqkMbwwKD397-HPg">https://www.sequoiacap.com/article/generative-ais-act-o1/</a></span></li><li class="c4 li-bullet-0"><span>Nobel laureate Geoffrey Hinton says AI is not slowing down: &quot;10 years ago, if I told you what we can do today with AI, you wouldn&#39;t have believed me. You&#39;d have said that&#39;s just science fiction.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/OpenAI/comments/1g0mbja/nobel_laureate_geoffrey_hinton_says_ai_is_not/&amp;sa=D&amp;source=editors&amp;ust=1730413583340733&amp;usg=AOvVaw2BMPde4hlOhqhHug7Ok8Ny">https://www.reddit.com/r/OpenAI/comments/1g0mbja/nobel_laureate_geoffrey_hinton_says_ai_is_not/</a></span></li><li class="c4 li-bullet-0"><span>Yann LeCun (famous LLM skeptic and Nobel laureate) says Mark Zuckerberg keeps asking him how long it will take to reach human-level AI and he tells him it is years, if not a decade, before systems can reason, plan and understand the world: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g4467s/yann_lecun_says_mark_zuckerberg_keeps_asking_him/&amp;sa=D&amp;source=editors&amp;ust=1730413583341018&amp;usg=AOvVaw0iwLcwMtoCi1vl1rGbOevV">https://www.reddit.com/r/singularity/comments/1g4467s/yann_lecun_says_mark_zuckerberg_keeps_asking_him/</a></span></li><li class="c4 li-bullet-0"><span>OpenAI&#39;s Noam Brown says the new o1 model beats GPT-4o at math and code, and outperforms expert humans at PhD-level questions, and &quot;these numbers, I can almost guarantee you, are going to go up over the next year or two&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g8anp0/openais_noam_brown_says_the_new_o1_model_beats/&amp;sa=D&amp;source=editors&amp;ust=1730413583341275&amp;usg=AOvVaw3MGrQKNNlhywjB4mqlrjv-">https://www.reddit.com/r/singularity/comments/1g8anp0/openais_noam_brown_says_the_new_o1_model_beats/</a></span></li></ul><h2 class="c64" id="h.w9u7npslb7x1"><span class="c40 c37 c48 c75">3.6. Recursive Self Improvement </span></h2><p class="c117"><span class="c33 c15">See section 14 for AI models training on AI-generated data to lead to improvements</span></p><p class="c117 c46"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0 start"><li class="c4 li-bullet-0"><span>G&ouml;del Agent: A Self-Referential Agent Framework for Recursive Self-Improvement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.04444&amp;sa=D&amp;source=editors&amp;ust=1730413583341689&amp;usg=AOvVaw0MUXAerE8VuvW9bTP-x-NH">https://arxiv.org/abs/2410.04444</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">In this paper, we introduce G&ouml;del Agent, a self-evolving framework inspired by the G&ouml;del machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. G&ouml;del Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of G&ouml;del Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c131 c78 li-bullet-0"><span>Recursive Introspection: Teaching Language Model Agents How to Self-Improve: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.18219&amp;sa=D&amp;source=editors&amp;ust=1730413583342088&amp;usg=AOvVaw3hAZDidnTAyE4l6cea3BHD">https://arxiv.org/abs/2407.18219</a></span></li></ul><p class="c131 c46"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c89 li-bullet-0"><span class="c14 c31">&gt;we propose strategies for multi-turn data collection and training so as to imbue an LLM with the capability to </span><span class="c34 c14 c31">recursively detect and correct its previous mistakes in subsequent iterations</span><span class="c14 c31">. Our experiments show that RISE enables Llama2, Llama3, and Mistral models to </span><span class="c15 c31">improve themselves with more turns on math reasoning tasks, outperforming several single-turn strategies given an equal amount of inference-time computation</span><span class="c14 c31">. We also find that RISE </span><span class="c15 c31">scales well, often attaining larger benefits with more capable models. Our analysis shows that RISE makes meaningful improvements to responses to arrive at the correct solution for challenging prompts</span><span class="c3">, without disrupting one-turn abilities as a result of expressing more complex distributions.</span></li></ul><p class="c131 c46"><span class="c3"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/hardmaru/status/1801074062535676193&amp;sa=D&amp;source=editors&amp;ust=1730413583342613&amp;usg=AOvVaw2vCN6Jstu3-ZuHBdMm6E73">https://x.com/hardmaru/status/1801074062535676193</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span>&gt;</span><span>We&rsquo;re excited to release DiscoPOP: a new SOTA preference optimization algorithm that was discovered and written by an LLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/OdRY60ihG8&amp;sa=D&amp;source=editors&amp;ust=1730413583342883&amp;usg=AOvVaw0KOYzvbAcBRoVMIx8qasAw">https://sakana.ai/llm-squared/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Our method leverages LLMs to propose and implement new preference optimization algorithms. We then train models with those algorithms and evaluate their performance, providing feedback to the LLM. By repeating this process for multiple generations in an evolutionary loop, the LLM discovers many highly-performant and novel preference optimization objectives!</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span>Paper:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/IBSOyUQ3jW&amp;sa=D&amp;source=editors&amp;ust=1730413583343235&amp;usg=AOvVaw2dCbbVRO_uMAJ4WGXpDoWH">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.08414&amp;sa=D&amp;source=editors&amp;ust=1730413583343351&amp;usg=AOvVaw1-90H1CZFVHj5lV8uCP8Fl">https://arxiv.org/abs/2406.08414</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span>GitHub:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/P4rhmIWPCN&amp;sa=D&amp;source=editors&amp;ust=1730413583343592&amp;usg=AOvVaw2OWkpm6qBcu07imCT47lQz">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/SakanaAI/DiscoPOP&amp;sa=D&amp;source=editors&amp;ust=1730413583343714&amp;usg=AOvVaw0HG2oUXNuUHntiEmUXBKk4">https://github.com/SakanaAI/DiscoPOP</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span>Model:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/jrKH1bFmaN&amp;sa=D&amp;source=editors&amp;ust=1730413583343956&amp;usg=AOvVaw3mamF_TuyPcTVKhUYLPOVI">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma&amp;sa=D&amp;source=editors&amp;ust=1730413583344094&amp;usg=AOvVaw1TxTLApVTxmV8TmHffdqX7">https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c21"><span class="c1">&nbsp;</span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c4 li-bullet-0"><span>Many papers on LLM self improvement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/rxlqn/awesome-llm-self-reflection&amp;sa=D&amp;source=editors&amp;ust=1730413583344379&amp;usg=AOvVaw1cLhQ2PyMRpehhI5KzA2bO">https://github.com/rxlqn/awesome-llm-self-reflection</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.15568&amp;sa=D&amp;source=editors&amp;ust=1730413583344587&amp;usg=AOvVaw3cQLSKSqDchWNWbXIboy0Q">https://arxiv.org/pdf/2405.15568</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span class="c1">&gt;OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent&rsquo;s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents&rsquo; learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms</span></li></ul><p class="c9 c129"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span>Project website with videos:</span><span class="c23 c236">&nbsp;</span><span class="c5 c23"><a class="c13" href="https://www.google.com/url?q=https://dub.sh/omniepic&amp;sa=D&amp;source=editors&amp;ust=1730413583344970&amp;usg=AOvVaw0IbnoNqk8RdJNfQde0zNXU">https://dub.sh/omniepic</a></span><span class="c90 c23">.</span></li></ul><p class="c9"><span class="c90 c23"></span></p><p class="c9"><span class="c90 c23"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c4 li-bullet-0"><span class="c55">[</span><span>Google DeepMind] Training Language Models to Self-Correct via Reinforcement Learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2409.12917&amp;sa=D&amp;source=editors&amp;ust=1730413583345251&amp;usg=AOvVaw0ATSzAzUeSuAuuWC-mRldV">https://arxiv.org/abs/2409.12917</a></span></li></ul><p class="c9"><span class="c90 c23"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span class="c3">&gt;When applied to Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models&#39; self-correction by 15.6% and 9.1% respectively on the MATH and HumanEval benchmarks.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c4 li-bullet-0"><span>Nvidia Uses GPU-Powered AI to Design Its Newest GPUs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/news/nvidia-gpu-powered-ai-improves-gpu-designs%23&amp;sa=D&amp;source=editors&amp;ust=1730413583345642&amp;usg=AOvVaw1CbgmKNIAx_TcUPvMofTKl">https://www.tomshardware.com/news/nvidia-gpu-powered-ai-improves-gpu-designs</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c22 c163 c78 li-bullet-0"><span>How AlphaChip transformed computer chip design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/&amp;sa=D&amp;source=editors&amp;ust=1730413583345918&amp;usg=AOvVaw1-TPYcAX2MFParDwQBLdXt">https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</a></span></li></ul><ul class="c0 lst-kix_vcrwp2bwzubh-1 start"><li class="c22 c27 li-bullet-0"><span class="c1">Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">The method has been used to design superhuman chip layouts in the last three generations of Google&rsquo;s custom AI accelerator, the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/tpu?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1730413583346202&amp;usg=AOvVaw3_PycqV1ELAjgMEi_aVxzd">Tensor Processing Unit</a></span><span class="c40 c37 c35 c48">&nbsp;(TPU).</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaChip has generated superhuman chip layouts used in every generation of Google&rsquo;s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google&rsquo;s </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/&amp;sa=D&amp;source=editors&amp;ust=1730413583346513&amp;usg=AOvVaw31y2VAlITANqBwKNcfmGRg">Transformer</a></span><span class="c40 c37 c35 c48">&nbsp;architecture.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu&amp;sa=D&amp;source=editors&amp;ust=1730413583346756&amp;usg=AOvVaw0PK4opqT5BSHt-NYxpKoOq">Google Axion Processors</a></span><span class="c40 c37 c35 c48">, our first Arm-based general-purpose data center CPUs.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips &mdash; like the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.mediatek.com/products/smartphones/dimensity-5g&amp;sa=D&amp;source=editors&amp;ust=1730413583347025&amp;usg=AOvVaw2S-sRitOZPrI_9h7SOkChF">Dimensity Flagship 5G</a></span><span class="c35">&nbsp;used in Samsung mobile phones &mdash; while improving power, performance and chip area.</span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 536.00px;"><img alt="" src="images/image76.png" style="width: 624.00px; height: 536.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c97 c105 c163 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image122.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-1"><li class="c10 li-bullet-0"><span class="c35">Better GPUs =&gt; better AI =&gt; better GPUs =&gt; &hellip;</span></li></ul><p class="c9"><span class="c90 c23"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c4 li-bullet-0"><span>Mustafa Suleyman says AI training is now done by AI itself: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1domqn4/mustafa_suleyman_says_ai_training_is_now_done_by/&amp;sa=D&amp;source=editors&amp;ust=1730413583347649&amp;usg=AOvVaw2GkOYL_SXz0jyT6F9khMoh">https://www.reddit.com/r/ChatGPT/comments/1domqn4/mustafa_suleyman_says_ai_training_is_now_done_by/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vcrwp2bwzubh-0"><li class="c4 li-bullet-0"><span class="c35">Jensen Huang says technology has now reached a positive feedback loop where AI is designing new AI and is now advancing at the pace of &quot;Moore&#39;s Law squared&quot;, meaning that the progress we will see in the next year or two will be &quot;spectacular and surprising&quot; </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/apples_jimmy/status/1836283425743081988?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583347935&amp;usg=AOvVaw1XIH7Lz1dgJ3Jwr6Kk0f4U">https://x.com/apples_jimmy/status/1836283425743081988?s=46</a></span><span class="c1">m</span></li><li class="c4 li-bullet-0"><span>Meta&#39;s Joe Spisak explains how AI models can train themselves by generating images, asking itself questions about them, and choosing the best answers, in order to move beyond human data and human fine-tuning, and teach itself from synthetic data: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1847789784078618640&amp;sa=D&amp;source=editors&amp;ust=1730413583348147&amp;usg=AOvVaw0D7PGgLSNKRE3FgaJZgKUo">https://x.com/tsarnick/status/1847789784078618640</a></span></li></ul><h1 class="c123" id="h.93mf85wk17ju"><span class="c14">4. </span><span class="c14">AI Is Useful</span></h1><p class="c117"><span class="c15">For use cases in coding and software development, see section 6!</span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0 start"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 487.07px; height: 652.50px;"><img alt="" src="images/image123.png" style="width: 487.07px; height: 652.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 c144 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 485.33px;"><img alt="" src="images/image637.png" style="width: 624.00px; height: 485.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c72 c14 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583348767&amp;usg=AOvVaw0LQfHQIK5FXN6PfjQrjTlH">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 572.50px; height: 1510.73px;"><img alt="" src="images/image464.png" style="width: 572.50px; height: 1510.73px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.visualcapitalist.com/ranked-the-most-popular-ai-tools/&amp;sa=D&amp;source=editors&amp;ust=1730413583349074&amp;usg=AOvVaw3dvdBRZqG4abwCt4z8FYvs">https://www.visualcapitalist.com/ranked-the-most-popular-ai-tools/</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>The US is currently restricting other countries from accessing GPUs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ft.com/content/be680102-5543-4867-9996-6fc071cb9212&amp;sa=D&amp;source=editors&amp;ust=1730413583349356&amp;usg=AOvVaw2Wyu1rO5FVjbro6YMy7Mko">https://www.ft.com/content/be680102-5543-4867-9996-6fc071cb9212</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c22 c72 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 272.00px;"><img alt="" src="images/image568.png" style="width: 624.00px; height: 272.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c72 c14 li-bullet-0"><span class="c1">GPUs have two main uses: AI training and graphics rendering for video games. Why would the US do this if AI is useless?</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c22 c104 c86 c14 li-bullet-0"><span>Hint: </span><span class="c40 c37 c35 c48">Commerce secretary Gina Raimondo said the goal of the update was to curb China&rsquo;s access to advanced chips that &ldquo;could fuel breakthroughs in artificial intelligence and sophisticated computers&rdquo; that are critical for the Chinese military.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>The</span><span>&nbsp;White House issued a National Security Memorandum declaring that &#39;AI is likely to affect almost all domains with national security significance&#39;. Attracting technical talent and building computational power are now official national security priorities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/&amp;sa=D&amp;source=editors&amp;ust=1730413583350073&amp;usg=AOvVaw1cyo4hEqnVymNs8eOxskLr">https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c71 c86 li-bullet-0"><span class="c1">DoS, DoD and DHS &#39;shall each use all available legal authorities to assist in attracting and rapidly bringing to the United States individuals with relevant technical expertise who would improve United States competitiveness in AI and related fields&#39;</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 400.49px; height: 120.74px;"><img alt="Comment Image" src="images/image478.png" style="width: 400.49px; height: 120.74px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c71 c86 li-bullet-0"><span>It is now the official policy that the United States must lead the world in the ability to train new foundation models. All government agencies will work to promote these capabilities.</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 400.49px; height: 288.59px;"><img alt="Comment Image" src="images/image499.png" style="width: 400.49px; height: 288.59px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c71 c86 li-bullet-0"><span class="c1">&#39;the United States Government must harness powerful AI ... to achieve national security objectives. Emerging AI capabilities ... offer profound opportunities for enhancing national security ... will require significant technical, organizational, and policy changes&#39;</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 400.49px; height: 375.17px;"><img alt="Comment Image" src="images/image543.png" style="width: 400.49px; height: 375.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span class="c1">&#39;It is therefore the policy of the United States Government to enhance innovation and competition by bolstering key drivers of AI progress, such as technical talent and computational power.&#39;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Federal agencies ordered to use &lsquo;most powerful&rsquo; AI systems in first-ever National Security Memo on AI&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/news/us/federal-agencies-ordered-to-use-most-powerful-ai-systems-in-first-ever-national-security-memo-on-ai/ar-AA1sRu7n?ocid%3Dmsedgntp%26pc%3DDCTS%26cvid%3D0224f96de91943e9ad66804c1e8d54dd%26ei%3D78&amp;sa=D&amp;source=editors&amp;ust=1730413583351807&amp;usg=AOvVaw1KWk_BuJOuer-Qe3TGHHNQ">https://www.msn.com/en-us/news/us/federal-agencies-ordered-to-use-most-powerful-ai-systems-in-first-ever-national-security-memo-on-ai/ar-AA1sRu7n?ocid=msedgntp&amp;pc=DCTS&amp;cvid=0224f96de91943e9ad66804c1e8d54dd&amp;ei=78</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span>The U.S. National Security Council released on Thursday its first-ever </span><span class="c34">memo on artificial Intelligence</span><span class="c1">&nbsp;(AI), ordering federal agencies to use the &quot;most powerful&quot; AI systems while balancing the risks associated with the new technology.</span></li><li class="c7 li-bullet-0"><span>&nbsp; &nbsp; The National Security Memorandum (NSM) details the U.S. approach to</span><span class="c33 c34">&nbsp;harnessing the power of AI for national security and foreign policy purposes &quot;to ensure that America leads the way in seizing the promise and managing the risks of AI,&quot; senior administration officials said.</span></li><li class="c7 li-bullet-0"><span>&nbsp; &nbsp; &quot;We are directing that the agencies gain access to the most powerful AI systems and put them to use, which often</span><span class="c34">&nbsp;involve substantial efforts on procurement</span><span class="c1">,&quot; the officials said.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>US National Security Advisor Jake Sullivan: The U.S. must accelerate its AI efforts and deploy AI much faster or risk losing its lead, as other countries are unlikely to adhere to the same regulations and values guiding the U.S. The stakes are high: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1gdu5cz/us_national_security_advisor_jake_sullivan_the_us/&amp;sa=D&amp;source=editors&amp;ust=1730413583352605&amp;usg=AOvVaw2MUxWfwZFI1gaRDFKVCPtE">https://www.reddit.com/r/singularity/comments/1gdu5cz/us_national_security_advisor_jake_sullivan_the_us/</a></span></li><li class="c10 li-bullet-0"><span class="c1">Other countries are doing the same:</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span>King Frederik of Denmark, in launching Denmark&#39;s first AI supercomputer Gefion with Jensen Huang: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1849592372654637473&amp;sa=D&amp;source=editors&amp;ust=1730413583352858&amp;usg=AOvVaw3WYd5cApcmsMId8-2Q1wQW">https://x.com/tsarnick/status/1849592372654637473</a></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 559.50px; height: 559.50px;"><img alt="" src="images/image571.png" style="width: 559.50px; height: 559.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.50px; height: 569.50px;"><img alt="" src="images/image201.png" style="width: 569.50px; height: 569.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>Pathchat by Modella, a multi-modal AI mo</span><span>del designed for medical and pathological purposes,</span><span class="c43">&nbsp;</span><span class="c15">capable of identifying tumors and diagnosing cancer patients</span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dyfd9t/pathchat_by_modella_a_multimodal_ai_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583353580&amp;usg=AOvVaw1bV7C_qzr7Zz_9AyvAWF9C">https://www.reddit.com/r/singularity/comments/1dyfd9t/pathchat_by_modella_a_multimodal_ai_model/</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>How AI is transforming the factory floor - Artificial intelligence (AI) is revolutionizing factory operations, optimizing production lines and cutting costs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.weforum.org/agenda/2024/10/ai-transforming-factory-floor-artificial-intelligence/&amp;sa=D&amp;source=editors&amp;ust=1730413583354133&amp;usg=AOvVaw0ue93-RHhs_DwTzsSeNWpu">https://www.weforum.org/agenda/2024/10/ai-transforming-factory-floor-artificial-intelligence/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emollick/status/1850558277710463435?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583354593&amp;usg=AOvVaw1BxkiUXZEfq-Vfg07bqkey">https://x.com/emollick/status/1850558277710463435?s=46</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 378.67px;"><img alt="" src="images/image578.png" style="width: 624.00px; height: 378.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnet.com/tech/mobile/25-of-smartphone-owners-dont-want-ai-as-apple-intelligence-debuts/&amp;sa=D&amp;source=editors&amp;ust=1730413583355045&amp;usg=AOvVaw1zGAY31_YtC6yNqHeoIFhL">https://www.cnet.com/tech/mobile/25-of-smartphone-owners-dont-want-ai-as-apple-intelligence-debuts/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c1">75% of smartphone users either find AI helpful or don&#39;t mind it</span></li><li class="c10 li-bullet-0"><span class="c1">Over half of users are not against paying for a subscription for AI (55%), including 68% of Gen Z</span></li><li class="c10 li-bullet-0"><span class="c1">A large majority doesn&#39;t even have privacy concerns (66%), including 71% of Gen Z</span></li><li class="c10 li-bullet-0"><span class="c1">18% say AI is their main motivation</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c1">What percent of code is now written by AI? &quot;I ask all the software companies I meet about this. The number is rarely lower than 40%. For some young programmers it&#39;s 90%.&quot; - Paul Graham of Y Combinator</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>AI Dominates Web Development: 63% of Developers Use AI Tools Like ChatGPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://flatlogic.com/starting-web-app-in-2024-research&amp;sa=D&amp;source=editors&amp;ust=1730413583355936&amp;usg=AOvVaw2BI6kbQXBV6t2OP3WqUsl-">https://flatlogic.com/starting-web-app-in-2024-research</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>New article says AI teachers are better than human teachers. Quote: &quot;Students who were given access to an AI tutor learned more than twice as much in less time compared to those who had in-class instruction.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/careersandeducation/ai-tutors-are-reshaping-higher-education/ar-AA1t76j3?ocid%3Dmsedgntp%26pc%3DDCTS%26cvid%3D71d0e0ea2cdf4485ab69c3356eb09d89%26ei%3D30&amp;sa=D&amp;source=editors&amp;ust=1730413583356381&amp;usg=AOvVaw1jd2ISJwaLDRsj3QCZsJws">https://www.msn.com/en-us/money/careersandeducation/ai-tutors-are-reshaping-higher-education/ar-AA1t76j3</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/?f%3Dflair_name%253A%2522AI%2522&amp;sa=D&amp;source=editors&amp;ust=1730413583356595&amp;usg=AOvVaw3CVPth_qjwhvh5EWMZDvmn"></a></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>&gt;</span><span class="c1">Generative AI is already transforming higher ed, giving students more access to professors&#39; expertise and boosting efficiency for both faculty and students in some fields</span></li><li class="c10 li-bullet-0"><span class="c1">In May, OpenAI released ChatGPT Edu, a more affordable tool for college students, faculty, researchers and campus administrators that OpenAI says includes &quot;enterprise-level&quot; security</span></li><li class="c10 li-bullet-0"><span class="c1">Since the summer of 2023 those students accessing the course through distance learning have had access to AI-powered &quot;teaching assistants,&quot; too, via the CS50 Duck &mdash; a chatbot built on OpenAI&#39;s API that helps students check their code and get answers to questions about the course.</span></li><li class="c10 li-bullet-0"><span class="c1">Malan tells Axios that genAI can already approximate a pretty good teaching assistant. &quot;It&#39;s wonderfully empowering for that demographic of folks who have never had nearly as much of a support structure&quot; as the students at elite private colleges, he says.</span></li><li class="c10 li-bullet-0"><span class="c1">By the numbers: Students who were given access to an AI tutor learned more than twice as much in less time compared to those who had in-class instruction, according to a study by two Harvard lecturers of 194 Harvard Physical Sciences 2 students.</span></li><li class="c10 li-bullet-0"><span class="c1">Malan cautions against seeing this as a risk to the jobs of professors or graduate student teaching assistants: &quot;We already have too few teachers as it is.&quot;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 571.00px; height: 471.00px;"><img alt="" src="images/image205.png" style="width: 571.00px; height: 471.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 354.67px;"><img alt="" src="images/image513.png" style="width: 624.00px; height: 354.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/protectai/vulnhuntr/&amp;sa=D&amp;source=editors&amp;ust=1730413583357527&amp;usg=AOvVaw0AVdqVyigUpRMRYghT9FVa">https://github.com/protectai/vulnhuntr/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c181 c143 c78 li-bullet-0"><span>OpenAI says ChatGPT usage has doubled since last year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.axios.com/2024/08/29/openai-chatgpt-200-million-weekly-active-users&amp;sa=D&amp;source=editors&amp;ust=1730413583357855&amp;usg=AOvVaw17r6Fu5A8EwneOn_LC6Udh">https://www.axios.com/2024/08/29/openai-chatgpt-200-million-weekly-active-users</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c181 c85 li-bullet-0"><span class="c58 c57 c37">OpenAI said on Thursday that ChatGPT now has more than 200 million weekly active users &mdash; twice as many as it had a year ago.</span></li><li class="c85 c181 li-bullet-0"><span class="c58 c57 c37">Meta said earlier on Thursday adoption of its open source Llama models has also grown sharply. Usage at the major cloud service providers has doubled between May and July of this year with the release of Llama 3.1.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>According to Similarweb, ChatGPT reportedly reached 3.1 billion visits in September 2024, a 112% year-over-year increase, surpassing Bing in US traffic with 442.9 million visits compared to Bing&#39;s 404.3 million: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 578.67px;"><img alt="" src="images/image475.png" style="width: 624.00px; height: 578.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Waymo has 7.1 million driverless miles. The Google spinoff&rsquo;s robotaxis led to a reduction in injury-related and police-reported crashes when compared to human benchmarks, according to new research: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2435896-driverless-cars-are-mostly-safer-than-humans-but-worse-at-turns/&amp;sa=D&amp;source=editors&amp;ust=1730413583358460&amp;usg=AOvVaw1wxCfTX9da44FBQf9pa8AA">https://www.newscientist.com/article/2435896-driverless-cars-are-mostly-safer-than-humans-but-worse-at-turns/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span>Driverless Waymo vehicles get into far fewer serious crashes than human-driven ones. The crashes that do happen are overwhelmingly the fault of the other driver: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.understandingai.org/p/human-drivers-are-to-blame-for-most&amp;sa=D&amp;source=editors&amp;ust=1730413583358721&amp;usg=AOvVaw2yVJ3VU_02ON4J8PUrBHJc">https://www.understandingai.org/p/human-drivers-are-to-blame-for-most</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>METR Evals - LLM agents vs skilled humans on diverse task completion: When agents can do a task, they do so at ~1/30th of the cost of the median hourly wage of a US bachelor&rsquo;s degree... Claude 3.5 Sonnet agent fixed bugs in an ORM library at a cost of &lt;$2, Human baseline took &gt;2 hours: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/METR_Evals/status/1820905731950055766&amp;sa=D&amp;source=editors&amp;ust=1730413583359042&amp;usg=AOvVaw0SQ72U0mTXbE4NL7d_W7sN">https://x.com/METR_Evals/status/1820905731950055766</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 176.69px;"><img alt="" src="images/image582.png" style="width: 471.17px; height: 176.69px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image102.png" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image249.jpg" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 353.37px;"><img alt="" src="images/image494.png" style="width: 471.17px; height: 353.37px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 li-bullet-0"><span>First AI to solve Internation</span><span class="c18">al Mathematical Olympiad problems at a silver medalist level: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/GoogleDeepMind/status/1816498082860667086&amp;sa=D&amp;source=editors&amp;ust=1730413583359618&amp;usg=AOvVaw3YEliiZXREF_AA9VyTGXOA">https://x.com/GoogleDeepMind/status/1816498082860667086</a></span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c22 c72 li-bullet-0"><span class="c40 c18">&gt;It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. </span></li><li class="c22 c72 li-bullet-0"><span class="c40 c18">Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.</span></li><li class="c10 li-bullet-0"><span class="c40 c18">It solved this year&rsquo;s IMO Problem 4 within 19 seconds</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image237.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Math professor on DeepMind&#39;s breakthrough: &quot;When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert&quot; </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/PoShenLoh/status/1816500461484081519&amp;sa=D&amp;source=editors&amp;ust=1730413583360183&amp;usg=AOvVaw24jjV6Elein9MmwKDG0j7V">https://x.com/PoShenLoh/status/1816500461484081519</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>OpenAI CFO Sarah Friar says lawyers are reporting that the new o1 reasoning model can do the work of a $2000/hour paralegal: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1geekyo/openai_cfo_sarah_friar_says_lawyers_are_reporting/&amp;sa=D&amp;source=editors&amp;ust=1730413583360525&amp;usg=AOvVaw3e_xWJadZy6AopOG8FtEer">https://www.reddit.com/r/singularity/comments/1geekyo/openai_cfo_sarah_friar_says_lawyers_are_reporting</a></span></li><li class="c4 li-bullet-0"><span>G</span><span>oogle has released the world&#39;s first &quot;AI Agents System&quot;, Project Oscar, an open-source platform that enables development teams to create and utilize AI agents for managing software projects, particularly in monitoring issues and bugs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ea1kz9/google_has_released_the_worlds_first_ai_agents/&amp;sa=D&amp;source=editors&amp;ust=1730413583360856&amp;usg=AOvVaw13z-XBUJZHQ6EhDfPvAzf7">https://www.reddit.com/r/singularity/comments/1ea1kz9/google_has_released_the_worlds_first_ai_agents/</a></span></li><li class="c4 li-bullet-0"><span>Agent-E, a breakthrough in agentic web automation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Chi_Wang_/status/1816526744935084278&amp;sa=D&amp;source=editors&amp;ust=1730413583361064&amp;usg=AOvVaw19UMmxWo_INcbCiQjmJRAe">https://x.com/Chi_Wang_/status/1816526744935084278</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">- hierarchical planning</span></li><li class="c10 li-bullet-0"><span class="c1">- a clever new method of interacting with DOM and performing stateful navigation</span></li><li class="c10 li-bullet-0"><span class="c1">- tops the WebVoyager benchmark with a 73% success rate even without using multi modality</span></li><li class="c10 li-bullet-0"><span>&#128240;Design principles: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=http://arxiv.org/pdf/2407.13032&amp;sa=D&amp;source=editors&amp;ust=1730413583361389&amp;usg=AOvVaw3egbxMfTm_RnkXJJE2-V4j">http://arxiv.org/pdf/2407.13032</a></span></li><li class="c10 li-bullet-0"><span>&#128230;Implementation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=http://github.com/EmergenceAI/Agent-E&amp;sa=D&amp;source=editors&amp;ust=1730413583361635&amp;usg=AOvVaw1zcyCavNYTOfCr34xxT1W9">http://github.com/EmergenceAI/Agent-E</a></span><span class="c1">&nbsp;(powered by #AutoGen)</span></li><li class="c10 li-bullet-0"><span>&#128250;Demo: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=http://youtube.com/watch?v%3DuyE7tfKkB0E&amp;sa=D&amp;source=editors&amp;ust=1730413583361927&amp;usg=AOvVaw3x60m_4bCmBC8T_vtCztW5">http://youtube.com/watch?v=uyE7tfKkB0E</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>Many uses of gen AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AlexReibman/status/1815534334503432626&amp;sa=D&amp;source=editors&amp;ust=1730413583362325&amp;usg=AOvVaw0yDw5MxJaVkM9bLs3M87Re">https://x.com/AlexReibman/status/1815534334503432626</a></span></li></ul><p class="c22 c44 c14 c129"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>LOTUS, a query engine for reasoning over large corpuses of data with LLMs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/lianapatel_/status/1813981153709441361&amp;sa=D&amp;source=editors&amp;ust=1730413583362759&amp;usg=AOvVaw3h8Mfo4gj7j7SWN8IxdECn">https://x.com/lianapatel_/status/1813981153709441361</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c72 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image496.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c44 c14 c129"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>Claude 3.5 Sonnet transformed a research paper into an interactive learning dashboard in just 30 seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Saboo_Shubham_/status/1805789967203156357&amp;sa=D&amp;source=editors&amp;ust=1730413583363155&amp;usg=AOvVaw3vlTvCYQ-hmFeoPmfVz8GM">https://x.com/Saboo_Shubham_/status/1805789967203156357</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>Ten examples of Claude Sonnet 3.5 in use: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/minchoi/status/1815024013812416567&amp;sa=D&amp;source=editors&amp;ust=1730413583363494&amp;usg=AOvVaw1j_nkS9QzhJOPpjDFPBXGf">https://x.com/minchoi/status/1815024013812416567</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>LLMs Can&#39;t Plan, But Can Help Planning in LLM-Modulo Frameworks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.01817&amp;sa=D&amp;source=editors&amp;ust=1730413583363761&amp;usg=AOvVaw1CXyeKs6H6PNPx3jH-fapd">https://arxiv.org/abs/2402.01817</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c22 c72 c14 li-bullet-0"><span>&gt;We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework </span><span class="c34">provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows </span><span class="c33 c15">extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.</span></li></ul><p class="c22 c44 c14"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>GPT-4 autonomously hacks zero-day security flaws with 53% success rate: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/gpt4-autonomously-hack-zero-day-security-flaws/&amp;sa=D&amp;source=editors&amp;ust=1730413583364198&amp;usg=AOvVaw3jJ_4gAAJzG6z-W2iCmpDM">https://newatlas.com/technology/gpt4-autonomously-hack-zero-day-security-flaws/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span>Note: it has access to the internet, where 11 of the 15 exploits used could be found. Four of the 15 vulnerabilities were also discovered before the cutoff training date of GPT4. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c33 c15">[2278 AI researchers were surveyed in 2023 and estimated that there is a 50% chance of AI being superior to humans in all possible tasks by 2047](https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf)</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 816.00px;"><img alt="" src="images/image428.png" style="width: 624.00px; height: 816.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c15 c35 c65 c84">List of GPT4&rsquo;s achievements: </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs/edit%23gid%3D1264523637&amp;sa=D&amp;source=editors&amp;ust=1730413583364767&amp;usg=AOvVaw3vNgUF4uEfJckBqVdLfnRA">https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c15">Claude 3.5 can make graphics to describe things: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/calixo888/status/1803873821654684026&amp;sa=D&amp;source=editors&amp;ust=1730413583365117&amp;usg=AOvVaw2ZaosthSgrg7738Vp8On4Y">https://x.com/calixo888/status/1803873821654684026</a></span><span class="c33 c15">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 522.71px; height: 387.47px;"><img alt="" src="images/image465.jpg" style="width: 522.71px; height: 387.47px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c33 c15">Over 32 techniques to reduce hallucinations:</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.01313&amp;sa=D&amp;source=editors&amp;ust=1730413583365598&amp;usg=AOvVaw1WTW0c2B_2apIFzInvh61d">https://arxiv.org/abs/2401.01313</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c45 li-bullet-0"><span class="c14">Many papers on AI embodied vision: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/rxlqn/awesome-embodied-vision&amp;sa=D&amp;source=editors&amp;ust=1730413583366013&amp;usg=AOvVaw2X7BrRdsDhSDXFFEqy7PaK">https://github.com/rxlqn/awesome-embodied-vision</a></span><span class="c14">&nbsp;</span></li></ul><p class="c9"><span class="c33 c15"></span></p><p class="c9"><span class="c33 c15"></span></p><p class="c21 c129"><span class="c33 c15">&nbsp;</span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 355.14px; height: 400.49px;"><img alt="" src="images/image260.png" style="width: 355.14px; height: 400.49px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c4 li-bullet-0"><span>DeepMind breaks 50-year math record using AI; new record falls a week later: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/&amp;sa=D&amp;source=editors&amp;ust=1730413583366712&amp;usg=AOvVaw0wLeEdirbi4DBspRfyfBD_">https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c178 c56 c97 c105 li-bullet-0"><span class="c1">AlphaTensor discovers better algorithms for matrix math, inspiring another improvement from afar.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c14">ChatGPT scores in top 1% of creativity: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2023/07/17/study-chatgpt-can-match-the-top-1percent-of-creative-human-thinkers.html&amp;sa=D&amp;source=editors&amp;ust=1730413583367046&amp;usg=AOvVaw1-RHhBLER_qux8xN_rNc7U">https://www.cnbc.com/2023/07/17/study-chatgpt-can-match-the-top-1percent-of-creative-human-thinkers.html</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c14">Study teaches ChatGPT to show accurate confidence levels in its output: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.20974&amp;sa=D&amp;source=editors&amp;ust=1730413583367285&amp;usg=AOvVaw2NhyZDr_l-LZnj46iQHJ0O">https://arxiv.org/abs/2405.20974</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c14">Wolfram gives ChatGPT computational superpowers by allowing it to call on Wolfram|Alpha&mdash;and Wolfram Language as well&mdash;for</span><span class="c15">&nbsp;powerful computation, curated knowledge, real-time data, visualization and even writing code</span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.wolfram.com/wolfram-plugin-chatgpt/&amp;sa=D&amp;source=editors&amp;ust=1730413583367581&amp;usg=AOvVaw19f8hZZ-RZVDU03Me0vCVE">https://www.wolfram.com/wolfram-plugin-chatgpt/</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 445.14px; height: 944.50px;"><img alt="" src="images/image150.png" style="width: 445.14px; height: 944.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 392.08px; height: 939.50px;"><img alt="" src="images/image643.png" style="width: 392.08px; height: 939.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 305.10px; height: 939.50px;"><img alt="" src="images/image190.png" style="width: 305.10px; height: 939.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c4 li-bullet-0"><span class="c14">26 uses of GPT 4o: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DGPNq0WiXa50&amp;sa=D&amp;source=editors&amp;ust=1730413583368030&amp;usg=AOvVaw0Nq6XblS1EKiwWpLbJyE_p">https://www.youtube.com/watch?v=GPNq0WiXa50</a></span></li></ul><p class="c22 c4 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c4 li-bullet-0"><span class="c14">AI beat humans at persuasion: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/&amp;sa=D&amp;source=editors&amp;ust=1730413583368370&amp;usg=AOvVaw10giKMj3CM-OnKRw6MO9Y_">https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c4 c46"><span class="c1 c14"></span></p><p class="c22 c4 c46"><span class="c1 c14"></span></p><p class="c22 c4 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c4 li-bullet-0"><span class="c14">LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.05961&amp;sa=D&amp;source=editors&amp;ust=1730413583368903&amp;usg=AOvVaw2tF9h3AgRp8-1YQuRU9EbB">https://arxiv.org/abs/2404.05961</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c10 li-bullet-0"><span class="c14 c31">We outperform encoder-only models by a large margin on word-level tasks and reach a new unsupervised state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB). Moreover, when combining LLM2Vec with supervised contrastive learning, we achieve state-of-the-art performance on MTEB among models that train only on publicly available data. Our strong empirical results and extensive analysis demonstrate that LLMs can be effectively transformed into universal text encoders in a parameter-efficient manner without the need for expensive adaptation or synthetic GPT-4 generated data.</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c4 li-bullet-0"><span class="c14">Used as a tutor to help someone quintuple income </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1cpe3sk/chatgpt_just_just_made_me_get_a_job_paying_5x_more/&amp;sa=D&amp;source=editors&amp;ust=1730413583369501&amp;usg=AOvVaw0Yv0ga2VNn_jR1CayyIijK">https://www.reddit.com/r/ChatGPT/comments/1cpe3sk/chatgpt_just_just_made_me_get_a_job_paying_5x_more/</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c4 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c4 li-bullet-0"><span class="c14">&ldquo;Here we show in two experimental studies that novice and experienced teachers could not identify texts generated by ChatGPT among student-written texts.&rdquo; </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S2666920X24000109&amp;sa=D&amp;source=editors&amp;ust=1730413583369902&amp;usg=AOvVaw2Svn1guH4khedpUdQuZqLF">https://www.sciencedirect.com/science/article/pii/S2666920X24000109</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c4 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c4 li-bullet-0"><span class="c14">AlphaZero, starting from scratch, became &quot;the greatest Chess playing entity that&#39;s ever existed&quot; in only 9 hours </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/OpenAI/comments/1chbw25/demis_hassabis_describes_how_alphazero_starting/&amp;sa=D&amp;source=editors&amp;ust=1730413583370354&amp;usg=AOvVaw1Hu6OGSY80eTYMsoqMhDqx">https://www.reddit.com/r/OpenAI/comments/1chbw25/demis_hassabis_describes_how_alphazero_starting/</a></span><span class="c14">&nbsp;</span></li></ul><p class="c22 c9 c97"><span class="c40 c124 c34 c14"></span></p><ul class="c0 lst-kix_dg9rb9temrvk-0 start"><li class="c22 c4 li-bullet-0"><span class="c14">Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what&rsquo;s available now </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/&amp;sa=D&amp;source=editors&amp;ust=1730413583370898&amp;usg=AOvVaw10oeXNhQKSi3Y17vbRSos-">https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/</a></span></li></ul><ul class="c0 lst-kix_dg9rb9temrvk-1 start"><li class="c22 c10 li-bullet-0"><span class="c40 c37 c60 c48 c14">The resulting model mastered the intricacies of a complex game. &quot;Cicero can deduce, for example, that later in the game it will need the support of one particular player,&quot; says Meta, &quot;and then craft a strategy to win that person&rsquo;s favor&mdash;and even recognize the risks and opportunities that that player sees from their particular point of view.&quot;</span></li><li class="c22 c10 li-bullet-0"><span class="c60 c14">Meta&#39;s Cicero research </span><span class="c60 c14"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.ade9097&amp;sa=D&amp;source=editors&amp;ust=1730413583371362&amp;usg=AOvVaw1dl6XnjOYd0nZD0gqqzWXS">appeared</a></span><span class="c40 c37 c60 c48 c14">&nbsp;in the journal Science under the title, &quot;Human-level play in the game of Diplomacy by combining language models with strategic reasoning.&quot;</span></li><li class="c22 c10 li-bullet-0"><span class="c92 c37 c35 c103 c14 c179">CICERO uses relationships with other players to keep its ally, Adam, in check.</span></li><li class="c22 c10 li-bullet-0"><span class="c37 c35 c173 c103 c14">When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_dg9rb9temrvk-0"><li class="c4 li-bullet-0"><span class="c6">The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item &ndash; so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. </span><span class="c6 c20"><a class="c13" href="https://www.google.com/url?q=https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html&amp;sa=D&amp;source=editors&amp;ust=1730413583372163&amp;usg=AOvVaw3GrR3Kjv7oHmPzPIYcgYsY">https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_dg9rb9temrvk-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://qz.com/ai-political-party-face-recognition-1851433898?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583372570&amp;usg=AOvVaw0tu-tK4QZkI5h-hPkWgTNF">https://qz.com/ai-political-party-face-recognition-1851433898?darkschemeovr=1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_q0wctjb2y8b-0 start"><li class="c4 li-bullet-0"><span class="c14">[Claude 3 Builds website](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/OpenAI/comments/1bm305k/what_the_hell_claud_3_opus_is_a_straight/?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583372947&amp;usg=AOvVaw2OjhdwH0b8gc4Th6Lb_qIT">https://www.reddit.com/r/OpenAI/comments/1bm305k/what_the_hell_claud_3_opus_is_a_straight/?darkschemeovr=1</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_h00g16e7ufft-0 start"><li class="c4 li-bullet-0"><span class="c14">More proof: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1cmk7dw/comment/l31tguw/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583373358&amp;usg=AOvVaw392SVZuL8GwEOhmQUrhBHi">https://www.reddit.com/r/LocalLLaMA/comments/1cmk7dw/comment/l31tguw/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c4 li-bullet-0"><span class="c14">Beat Turing test: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.washingtonpost.com/technology/2022/06/17/google-ai-lamda-turing-test/?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583373660&amp;usg=AOvVaw2jqJuLogpYLrxbPgkXmtQj">https://www.washingtonpost.com/technology/2022/06/17/google-ai-lamda-turing-test/?darkschemeovr=1</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c4 li-bullet-0"><span class="c6">[Claude 3 could tell it was being tested](</span><span class="c20 c124 c34 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/&amp;sa=D&amp;source=editors&amp;ust=1730413583373964&amp;usg=AOvVaw2Bujg_Qrrt_8Ydix-8btC2">https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/</a></span><span class="c124 c34 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c4 li-bullet-0"><span class="c14">Image Consistency: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2404.18919&amp;sa=D&amp;source=editors&amp;ust=1730413583374235&amp;usg=AOvVaw02cOp4rWpNWFApxd1paBXK">https://arxiv.org/pdf/2404.18919</a></span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c10 li-bullet-0"><span class="c14">Midjourney character consistency: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://docs.midjourney.com/docs/character-reference&amp;sa=D&amp;source=editors&amp;ust=1730413583374512&amp;usg=AOvVaw1W1qVABIjL8lM9CaC09FL0">https://docs.midjourney.com/docs/character-reference</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/fofrAI/status/1796547108478038355&amp;sa=D&amp;source=editors&amp;ust=1730413583374734&amp;usg=AOvVaw03xW3hUFuuw6OsBHQAuETA">https://x.com/fofrAI/status/1796547108478038355</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c4 li-bullet-0"><span class="c14">Waymo says its robotaxis are now making 50,000 paid trips every week: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.engadget.com/waymo-says-its-robotaxis-are-now-making-50000-paid-trips-every-week-130005096.html&amp;sa=D&amp;source=editors&amp;ust=1730413583374998&amp;usg=AOvVaw0mOPpgC-BmQrDa-mIZB02q">https://www.engadget.com/waymo-says-its-robotaxis-are-now-making-50000-paid-trips-every-week-130005096.html</a></span></li><li class="c22 c4 li-bullet-0"><span class="c1 c14">These incredibly funny videos by DougDoug would not be possible without AI</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c22 c10 li-bullet-0"><span class="c1 c14">https://youtu.be/HyqK2Tsujho</span></li><li class="c22 c10 li-bullet-0"><span class="c1 c14">https://youtu.be/W3id8E34cRQ?feature=shared</span></li><li class="c22 c10 li-bullet-0"><span class="c1 c14">https://youtu.be/pHDh_PWMTaU?feature=shared</span></li><li class="c22 c10 li-bullet-0"><span class="c1 c14">https://youtu.be/YnN6eBamwj4?feature=shared</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c4 li-bullet-0"><span class="c1 c14">[Game that uses LLM for character interaction](https://www.playsuckup.com/)</span></li><li class="c22 c4 li-bullet-0"><span class="c1 c14">Another Game that uses LLM for character interaction https://youtu.be/0Nl67LN_3rk?feature=shared</span></li><li class="c22 c4 li-bullet-0"><span class="c14">Skyrim mod powered by ChatGPT: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/skyrimmods/comments/15vej9k/every_single_skyrim_npc_ai_powered_with_chatgpt/&amp;sa=D&amp;source=editors&amp;ust=1730413583375583&amp;usg=AOvVaw0i90bYYLaZiYIlWFbF6F9q">https://www.reddit.com/r/skyrimmods/comments/15vej9k/every_single_skyrim_npc_ai_powered_with_chatgpt/</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c4 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2005.14165&amp;sa=D&amp;source=editors&amp;ust=1730413583375770&amp;usg=AOvVaw2fZGn2tgWNJUuJW3g0tn8Z">Language Models are Few-Shot Learners</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2005.14165&amp;sa=D&amp;source=editors&amp;ust=1730413583375895&amp;usg=AOvVaw00hs6jiDzIvzN0cdhowORX">https://arxiv.org/abs/2005.14165</a></span></li><li class="c4 li-bullet-0"><span class="c14">GPT 4o has excellent chess capabilities: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1crhkpi/gpt4o_is_a_chess_beast/&amp;sa=D&amp;source=editors&amp;ust=1730413583376109&amp;usg=AOvVaw0GhXXrZpuV9r5NuvkKwNjV">https://www.reddit.com/r/singularity/comments/1crhkpi/gpt4o_is_a_chess_beast/</a></span></li><li class="c51 li-bullet-0"><span class="c6">[Live AI video analysis](</span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GoogleDeepMind/status/1790463259822420239&amp;sa=D&amp;source=editors&amp;ust=1730413583376329&amp;usg=AOvVaw0PMW-EULZAkfP7Elo_69Yy">https://twitter.com/GoogleDeepMind/status/1790463259822420239</a></span><span class="c6 c40">)</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c49 li-bullet-0"><span class="c20 c91"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DnXVvvRhiGjI&amp;sa=D&amp;source=editors&amp;ust=1730413583376573&amp;usg=AOvVaw0MPiP6fePtTXApWMOZnZSy">Project Astra: Our vision for the future of AI assistants</a></span></li><li class="c49 li-bullet-0"><span class="c6">More examples of recognizing drawings: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/minchoi/status/1790873017150550354&amp;sa=D&amp;source=editors&amp;ust=1730413583376788&amp;usg=AOvVaw1niSzp9958IlMcE8FetEJi">https://twitter.com/minchoi/status/1790873017150550354</a></span><span class="c6 c40">&nbsp;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c51 li-bullet-0"><span class="c6">Live noise cancellation and translation with accurate voice in a tiny earpiece: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/interestingasfuck/s/vpmyWqNftF&amp;sa=D&amp;source=editors&amp;ust=1730413583377009&amp;usg=AOvVaw1myjgwL6n5KiaKSTTM1vyW">https://www.reddit.com/r/interestingasfuck/s/vpmyWqNftF</a></span></li><li class="c51 li-bullet-0"><span class="c6 c40">AI video allows people to create high quality AAA effects and scenes, allowing them to create without needing to get funding from studios. This would allow regular people to express their creativity and circumvent barriers in finding, time, or resources, similar to how the rise of YouTube allowed indie musicians to gain audiences without needing a record label and software like RPGMaker helped indie game developers do the same.</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c49 li-bullet-0"><span class="c6 c40">Even if it allows some people to create bad art, you don&rsquo;t have to consume it. In the same way we filter out bad human-made art with ratings, we can do the same with art made with AI. </span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c32 li-bullet-0"><span class="c18 c14">significant progress in Gemini 1.5 Pro across all key benchmarks; TL;DR: 1.5 Pro &gt; 1.0 Ultra, 1.5 Flash (our fastest model) ~= 1.0 Ultra. A math-specialised variant of Gemini 1.5 Pro performs strongly on competition-level math problems, including a breakthrough performance of 91.1% on Hendryck&rsquo;s MATH benchmark without tool-use: </span><span class="c20 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/OriolVinyalsML/status/1791521517211107515?t%3Duf0Sgqt_UpU_QsXB5w-HJA%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583377425&amp;usg=AOvVaw1_MsrznbK3TmSgtS5r7DRE">https://x.com/OriolVinyalsML/status/1791521517211107515?t=uf0Sgqt_UpU_QsXB5w-HJA&amp;s=19</a></span></li><li class="c22 c32 li-bullet-0"><span class="c40 c18 c14">AI scope hunts down colon polyps, aiding less experienced doctors: https://newatlas.com/medical/ai-colonoscopy-inexperienced-doctors/?itm_source=newatlas&amp;itm_medium=article-body</span></li><li class="c22 c32 li-bullet-0"><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://www.news-medical.net/news/20231219/AI-models-using-retinal-images-achieve-perfect-accuracy-in-diagnosing-autism.aspx&amp;sa=D&amp;source=editors&amp;ust=1730413583377796&amp;usg=AOvVaw0qlj8zVSsbvP2qNQxr6GaY">AI-screened eye pics diagnose childhood autism with 100% accuracy</a></span><span class="c18 c14">: https://www.news-medical.net/news/20231219/AI-models-using-retinal-images-achieve-perfect-accuracy-in-diagnosing-autism.aspx</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 234.67px;"><img alt="" src="images/image605.jpg" style="width: 624.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c32 li-bullet-0"><span class="c18">AI in space: Karpathy suggests AI chatbots as interstellar messengers to alien civilizations: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2024/05/ai-in-space-karpathy-suggests-ai-chatbots-as-interstellar-messengers-to-alien-civilizations&amp;sa=D&amp;source=editors&amp;ust=1730413583378223&amp;usg=AOvVaw38ipalhGxVzHDhrR5bt8lC">https://arstechnica.com/information-technology/2024/05/ai-in-space-karpathy-suggests-ai-chatbots-as-interstellar-messengers-to-alien-civilizations</a></span></li><li class="c22 c32 li-bullet-0"><span class="c18">DeepMind AI&#39;s new way to sort objects could speed up global computing: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2376512-deepmind-ais-new-way-to-sort-objects-could-speed-up-global-computing/&amp;sa=D&amp;source=editors&amp;ust=1730413583378503&amp;usg=AOvVaw0PPsBjPR5b9kVXx0B6BLve">https://www.newscientist.com/article/2376512-deepmind-ais-new-way-to-sort-objects-could-speed-up-global-computing/</a></span></li><li class="c22 c32 li-bullet-0"><span class="c18">DeepMind unveils first AI to discover faster matrix multiplication algorithms: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/deepmind-unveils-first-ai-to-discover-faster-matrix-multiplication-algorithms/&amp;sa=D&amp;source=editors&amp;ust=1730413583378767&amp;usg=AOvVaw2xSWVPTkYzSWhsFXUSxYTI">https://venturebeat.com/ai/deepmind-unveils-first-ai-to-discover-faster-matrix-multiplication-algorithms/</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c18">Andrej Karpathy (renowned AI researcher) is building an operating system using transformers: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://analyticsindiamag.com/andrej-karpathy-says-the-pathway-to-agi-is-through-a-language-model-operating-system/&amp;sa=D&amp;source=editors&amp;ust=1730413583379014&amp;usg=AOvVaw2h3DSaHUV-yR77mgZMSqph">https://analyticsindiamag.com/andrej-karpathy-says-the-pathway-to-agi-is-through-a-language-model-operating-system/</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c18">Excellent music recommendations from ChatGPT: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/s/MgdUj9ymQF&amp;sa=D&amp;source=editors&amp;ust=1730413583379221&amp;usg=AOvVaw18umg4rwmBePFh7pbjKXxJ">https://www.reddit.com/r/ChatGPT/s/MgdUj9ymQF</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c40 c18">Model weights be downloaded and transferred, so anything one model does well can be replicated everywhere </span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c22 c72 li-bullet-0"><span class="c40 c18">E.g. one model can connect to a model that&rsquo;s very good at coding (eg AlphaCode 2) and another model that&rsquo;s good at reasoning and call them as needed depending on the current needs similar to how the brain has different sections responsible for different tasks </span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c32 li-bullet-0"><span class="c18">Learning to use AI can increase pay by 25%: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2024/05/21/business/ai-jobs-higher-wages-productivity/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583379593&amp;usg=AOvVaw2AlPHjnDHXi4xHrSGEfvbV">https://www.cnn.com/2024/05/21/business/ai-jobs-higher-wages-productivity/index.html</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c18">Autonomous AI Robot Creates a Shock-Absorbing Shape No Human Ever Could: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://scitechdaily.com/crushing-it-autonomous-ai-robot-creates-a-shock-absorbing-shape-no-human-ever-could/&amp;sa=D&amp;source=editors&amp;ust=1730413583379847&amp;usg=AOvVaw0qCUBEYRv6SF1sRQsGIx_c">https://scitechdaily.com/crushing-it-autonomous-ai-robot-creates-a-shock-absorbing-shape-no-human-ever-could/</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c18">Jensen Huang says designing computer chips and writing and debugging software can no longer be done without AI and he wants to turn NVIDIA into one giant AI: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1793076745543073922&amp;sa=D&amp;source=editors&amp;ust=1730413583380058&amp;usg=AOvVaw3BCvBMK6UmhEU2CWIuTj6f">https://x.com/tsarnick/status/1793076745543073922</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c18">LLMs won&rsquo;t need data anymore. Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1793864788579090917?s%3D46%26t%3DlZJAHzXMXI1MgQuyBgEhgA&amp;sa=D&amp;source=editors&amp;ust=1730413583380305&amp;usg=AOvVaw265JwqZYHlr6hTHYidvVpz">https://x.com/_akhaliq/status/1793864788579090917?s=46&amp;t=lZJAHzXMXI1MgQuyBgEhgA</a></span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c22 c72 li-bullet-0"><span class="c40 c18">While this only works for things you can generate good or perfect data on, that would still be good enough for factual information like math or science. For subjective information like art, a good art generator (e.g. Midjourney or Pony Diffusion could work)</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c32 li-bullet-0"><span class="c18">Multimodal GPT-4o Interpreting Historical Documents (Letter Concerning Lady&#39;s Amber Collection, 1881): </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/s/897BxdUtQJ&amp;sa=D&amp;source=editors&amp;ust=1730413583380609&amp;usg=AOvVaw31V1CtXEESIwLpZA-o7vyi">https://www.reddit.com/r/singularity/s/897BxdUtQJ</a></span><span class="c40 c18">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Can act as a text-based game emulator where you can make any changes you want (e.g. Pokemon with guns where you can steal Pokemon): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1790183986096116189&amp;sa=D&amp;source=editors&amp;ust=1730413583380847&amp;usg=AOvVaw2dceO9k5xa1QhHOo-SDRhD">https://x.com/VictorTaelin/status/1790183986096116189</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>GPT-4 is consistently rated as higher in apparent empathy than humans in multiple controlled studies: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emollick/status/1794462493865329048&amp;sa=D&amp;source=editors&amp;ust=1730413583381051&amp;usg=AOvVaw1EjF_Pyk6TE7vMRQ2CTzRh">https://x.com/emollick/status/1794462493865329048</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 306.67px;"><img alt="" src="images/image247.png" style="width: 624.00px; height: 306.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 501.56px; height: 530.50px;"><img alt="" src="images/image572.png" style="width: 501.56px; height: 530.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c4 li-bullet-0"><span class="c1">Netflix co-CEO Ted Sarandos says &ldquo;A.I. is not going to take your job. The person who uses A.I. well might take your job&rdquo;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/oKDVFnu9cN&amp;sa=D&amp;source=editors&amp;ust=1730413583381422&amp;usg=AOvVaw1iAr7Q8MKDVCALvfsCi8ZU">https://t.co/oKDVFnu9cN</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c4 li-bullet-0"><span>SignLLM is the first multilingual sign language model that can generate sign language gestures from input text: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795060142473351423&amp;sa=D&amp;source=editors&amp;ust=1730413583381636&amp;usg=AOvVaw2veLDgJM7U4YZn_JmYmq1j">https://x.com/dreamingtulpa/status/1795060142473351423</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27&amp;sa=D&amp;source=editors&amp;ust=1730413583381909&amp;usg=AOvVaw1IJqML7nBjmyStmuL56rPS">https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI used for psychological therapy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/bQIzknuipj&amp;sa=D&amp;source=editors&amp;ust=1730413583382085&amp;usg=AOvVaw0YPhxeO27IGvhrRCbXfTll">https://t.co/bQIzknuipj</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Automation powered by GPT-4o generates Figma designs based on PRD: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/yancymin/status/1795308932216525229&amp;sa=D&amp;source=editors&amp;ust=1730413583382273&amp;usg=AOvVaw0LsZOpKeGLqVAzY62-8crE">https://x.com/yancymin/status/1795308932216525229</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Praktika raised a $35.5M Series A for its language learning app that uses AI avatars to simulate real-life conversational scenarios: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/chiefaioffice/status/1794854266189844576&amp;sa=D&amp;source=editors&amp;ust=1730413583382536&amp;usg=AOvVaw3l3berU7IdArPmRkAiFBpv">https://x.com/chiefaioffice/status/1794854266189844576</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI Predicts Fruit Fly Brain Behavior With Stunning Accuracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41586-024-07451-8&amp;sa=D&amp;source=editors&amp;ust=1730413583382822&amp;usg=AOvVaw0V9WOGaHfsT8O5i3swqNB_">https://www.nature.com/articles/s41586-024-07451-8</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>A robotics expert says that artificial intelligence (AI) technology could help fight loneliness, which is known to be very bad for people&rsquo;s health: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://theaiwired.com/ai-may-offer-companionship-to-people-feeling-lonely/&amp;sa=D&amp;source=editors&amp;ust=1730413583383074&amp;usg=AOvVaw1ByR2foJyenxIGR-LBXB73">https://theaiwired.com/ai-may-offer-companionship-to-people-feeling-lonely/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI can identify drawings: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/sundeep/status/1795576457978376224&amp;sa=D&amp;source=editors&amp;ust=1730413583383364&amp;usg=AOvVaw2K-IgHTedb1EijU4E5JGfk">https://x.com/sundeep/status/1795576457978376224</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Ten examples of GPT-4o being used: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/minchoi/status/1795456246994121089&amp;sa=D&amp;source=editors&amp;ust=1730413583383630&amp;usg=AOvVaw1n6mX40IAtpExH3383uHBX">https://x.com/minchoi/status/1795456246994121089</a></span><span class="c1">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c1">Make a song from any sound: </span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c22 c72 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/suno_ai_/status/1795878282631512512&amp;sa=D&amp;source=editors&amp;ust=1730413583383894&amp;usg=AOvVaw3c96k0vvyMzwt3Sno0iijQ">https://x.com/suno_ai_/status/1795878282631512512</a></span><span class="c1">&nbsp;</span></li><li class="c22 c72 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1794373423352934891&amp;sa=D&amp;source=editors&amp;ust=1730413583384087&amp;usg=AOvVaw0aqknqp7l3T4CZuHD4eWEb">https://x.com/nickfloats/status/1794373423352934891</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c32 li-bullet-0"><span class="c1">AI versus 100,000 humans in creativity in this careful study using the Divergent Association Test (a well-validated measure, but all measures of creativity have flaws)</span></li></ul><p class="c22 c32"><span>GPT-4 wins. Better prompting can further improve performance &amp; diversity of ideas. </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://researchgate.net/publication/380820358_Divergent_Creativity_in_Humans_and_Large_Language_Models/fulltext/6650085f22a7f16b4f47a12a/Divergent-Creativity-in-Humans-and-Large-Language-Models.pdf?origin%3Dpublication_detail%26_tp%3DeyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InB1YmxpY2F0aW9uIiwicGFnZSI6InB1YmxpY2F0aW9uRG93bmxvYWQiLCJwcmV2aW91c1BhZ2UiOiJwdWJsaWNhdGlvbiJ9fQ&amp;sa=D&amp;source=editors&amp;ust=1730413583384581&amp;usg=AOvVaw0-jpLOhmUztaWCnJXLX5fV">https://researchgate.net/publication/380820358_Divergent_Creativity_in_Humans_and_Large_Language_Models/fulltext/6650085f22a7f16b4f47a12a/Divergent-Creativity-in-Humans-and-Large-Language-Models.pdf</a></span></p><ul class="c0 lst-kix_q0wctjb2y8b-1"><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.50px; height: 758.61px;"><img alt="" src="images/image374.png" style="width: 624.50px; height: 758.61px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c22 c32 li-bullet-0"><span>NGPA, New high quality real time 3D avatar from the university of Munich, Germany: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1d41k42/impressive_photorealistic_avatars_npga_neural/?utm_source%3Dshare%26utm_medium%3Dweb3x%26utm_name%3Dweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583385034&amp;usg=AOvVaw2E3eBxg4GDhlB3xD0Kknl_">https://www.reddit.com/r/singularity/comments/1d41k42/impressive_photorealistic_avatars_npga_neural</a></span></li><li class="c22 c32 li-bullet-0"><span>New AI tech predicts cardiac events due to coronary inflammation The Lancet publishes results from landmark study showing inflammation-related cardiac events can be predicted 10 years in advance: </span><span class="c37 c65 c60 c68"><a class="c13" href="https://www.google.com/url?q=https://x.com/longevitytech/status/1796234620855533773?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583385298&amp;usg=AOvVaw342cJHHEHAjzg1zCHQwcbV">https://x.com/longevitytech/status/1796234620855533773?s=46</a></span></li><li class="c4 li-bullet-0"><span class="c14">Creating TV shows with diffusion: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://fablestudio.github.io/showrunner-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413583385565&amp;usg=AOvVaw30u9vUf70dovVyjPtwCKIe">https://fablestudio.github.io/showrunner-agents/</a></span><span class="c1 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c14">Claude 3 Opus understands and can write in very obscure languages: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/hahahahohohe/status/1765088860592394250&amp;sa=D&amp;source=editors&amp;ust=1730413583385787&amp;usg=AOvVaw12oA4OcTUpcpVyYpZ2m-lb">https://x.com/hahahahohohe/status/1765088860592394250</a></span><span class="c1 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Report: Generative AI can boost Estonia&rsquo;s GDP by up to 8%: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://e-estonia.com/report-generative-ai-can-boost-estonias-gdp-up-to-8/&amp;sa=D&amp;source=editors&amp;ust=1730413583386112&amp;usg=AOvVaw0lqYaw2Fr5pOH4i175Mez7">https://e-estonia.com/report-generative-ai-can-boost-estonias-gdp-up-to-8/</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c10 li-bullet-0"><span class="c6 c40">&quot; In the future, 61 per cent of Estonia&rsquo;s workforce is predicted to work together with generative AI. A gradual change will occur, where less than 10 per cent of highly exposed jobs will be replaced by automation. At the same time, new jobs will be created in the AI-powered economy. While the report expects employment levels to stay similar to today&rsquo;s, a rise in productivity is expected.&quot;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 313.33px;"><img alt="" src="images/image476.png" style="width: 624.00px; height: 313.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 228.00px;"><img alt="" src="images/image108.png" style="width: 624.00px; height: 228.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c100 c78 li-bullet-0"><span>AI can change the perspective of recorded videos and extrapolate unseen information: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1796519725129695650&amp;sa=D&amp;source=editors&amp;ust=1730413583386650&amp;usg=AOvVaw2NUVFZXDMTMwJmVnMiEE1i">https://x.com/dreamingtulpa/status/1796519725129695650</a></span><span class="c1">&nbsp;</span></li><li class="c100 c78 li-bullet-0"><span>Medicine, Technology and the End of Cancer: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2023/12/05/special-series/artificial-intelligence-cancer-vaccine-biontech.html&amp;sa=D&amp;source=editors&amp;ust=1730413583386977&amp;usg=AOvVaw0JNZEqmVTm6uwmQmSeVr9H">https://www.nytimes.com/2023/12/05/special-series/artificial-intelligence-cancer-vaccine-biontech.html</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_q0wctjb2y8b-1 start"><li class="c69 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 480.50px; height: 407.91px;"><img alt="" src="images/image396.png" style="width: 480.50px; height: 407.91px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c100 c46 c129"><span class="c1"></span></p><ul class="c0 lst-kix_a130djrb9y6e-0 start"><li class="c4 li-bullet-0"><span>Automatic dubbing + lipsync: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/artificial/comments/1d2qd8j/ai_dub_lipsync_of_mira_murati_into_russian/&amp;sa=D&amp;source=editors&amp;ust=1730413583387395&amp;usg=AOvVaw1psruA6C0WjpN471O5tZJf">https://www.reddit.com/r/artificial/comments/1d2qd8j/ai_dub_lipsync_of_mira_murati_into_russian/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>OpenAI&rsquo;s ChatGPT can improve its capabilities through self play and the use of Agents: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DewLMYLCWvcI&amp;sa=D&amp;source=editors&amp;ust=1730413583387634&amp;usg=AOvVaw3HvT5-uyEZm-zMb6lEhKLD">https://www.youtube.com/watch?v=ewLMYLCWvcI</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_a130djrb9y6e-1 start"><li class="c10 li-bullet-0"><span class="c1">Utilizing a multi-agent approach, this system effectively tackles the intricate nuances inherent in literary texts. </span></li><li class="c10 li-bullet-0"><span class="c1">Empirical findings indicate that despite lower d-BLEU scores, translations from TransAgents are preferred by both human evaluators and LLMs over human-written references, particularly in genres requiring domain-specific knowledge. </span></li></ul><ul class="c0 lst-kix_a130djrb9y6e-0"><li class="c4 li-bullet-0"><span>Firefox will use on-device ML to power translation and image alt text generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://hacks.mozilla.org/2024/05/experimenting-with-local-alt-text-generation-in-firefox-nightly/&amp;sa=D&amp;source=editors&amp;ust=1730413583388142&amp;usg=AOvVaw0_GCwevEVFoJl6h7A6Yo16">https://hacks.mozilla.org/2024/05/experimenting-with-local-alt-text-generation-in-firefox-nightly/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Turning Trash Into Treasure: How AI Is Revolutionizing Waste Sorting: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/ganeskesari/2024/05/31/turning-trash-into-treasure-how-ai-is-revolutionizing-waste-sorting/?sh%3D7adf348973d2&amp;sa=D&amp;source=editors&amp;ust=1730413583388438&amp;usg=AOvVaw36g43-fEu0z0AVgqCBAysQ">https://www.forbes.com/sites/ganeskesari/2024/05/31/turning-trash-into-treasure-how-ai-is-revolutionizing-waste-sorting/?sh=7adf348973d2</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_a130djrb9y6e-1 start"><li class="c22 c10 li-bullet-0"><span class="c70 c37 c76 c114">RecycleOS, can sort objects with over 95% accuracy. </span></li><li class="c22 c10 li-bullet-0"><span class="c70 c37 c76 c114">These systems improve over time and adapt to new types of waste, ensuring the adaptability of sorting processes even as the composition of waste changes. For example, Alameda County Industries (ACI) reduced its labor costs by 59% in three years thanks to EverestLabs&rsquo; robots, which have picked up approximately 30 million objects.</span></li><li class="c22 c10 li-bullet-0"><span class="c70 c37 c76 c114">Accurately identifying recyclable materials, such as fiber, PET, HDPE, or black plastic, helps reduce contamination rates and increase the purity of recyclables. For example, Glacier&rsquo;s robots can be trained to identify and remove plastic bags that accidentally end up in the paper stream. This makes the quality of the end paper product higher and more valuable.</span></li><li class="c22 c10 li-bullet-0"><span class="c70 c37 c76 c114">A recycling customer quantify a $900,000 annual revenue opportunity by identifying the value of recyclables that one site was incorrectly sending to landfills.</span></li><li class="c22 c10 li-bullet-0"><span class="c70 c37 c76 c114">&ldquo;It&rsquo;s capable of making thousands of picks per minute on conveyer belts that move at speeds of 600 feet-per-minute,&rdquo; Chase Brumfield - site reliability engineering manager of AMP, told me. In addition to consuming just a fraction of the manual effort, these systems need minimal downtime, vastly improving the throughput of waste facilities.</span></li><li class="c22 c10 li-bullet-0"><span class="c70 c37 c76 c114">Additionally, intelligent sorting systems can unlock novel value-creation opportunities. For example, if a buyer is looking for a specific type of recycled plastic material, say a white-colored, post-consumer polypropylene - this is possible thanks to AI-driven sortation systems that can see, remember, and act by separating the desired type of waste in real-time.</span></li></ul><ul class="c0 lst-kix_a130djrb9y6e-0"><li class="c4 li-bullet-0"><span>CLIPPyX: AI Powered Image search tool offers content-based, text, and visual similarity search system-wide: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/0ssamaak0/CLIPPyX&amp;sa=D&amp;source=editors&amp;ust=1730413583389332&amp;usg=AOvVaw1wwm0skyckbxKnDwKKwehn">https://github.com/0ssamaak0/CLIPPyX</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0 start"><li class="c22 c10 li-bullet-0"><span class="c65 c34 c60 c84 c138">Search by Image Caption</span><span class="c70 c37 c65 c60">: Enter descriptive text or phrases, using CLIP, CLIPPyX will return all images related to that semantic meaning or caption.</span></li><li class="c22 c10 li-bullet-0"><span class="c65 c34 c60 c84 c138">Search by Textual Content in Images</span><span class="c70 c37 c65 c60">: Provide descriptive text or phrases, and using Optical Character Recognition (OCR) and text embedding model, CLIPPyX will return all images with text semantically similar to the provided text.</span></li><li class="c22 c10 li-bullet-0"><span class="c65 c34 c60 c84 c138">Search by Image Similarity</span><span class="c70 c37 c65 c60">: Provide an existing image as a reference, and CLIPPyX will find visually similar images using CLIP</span></li><li class="c22 c10 li-bullet-0"><span class="c37 c65 c60 c84 c138">Demo: </span><span class="c5 c37 c65 c60 c138"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1d6nfe1/clippyx_ai_powered_image_search_tool_offers/&amp;sa=D&amp;source=editors&amp;ust=1730413583389859&amp;usg=AOvVaw0mgLeCYvKLtb7oMjVqxP8h">https://www.reddit.com/r/LocalLLaMA/comments/1d6nfe1/clippyx_ai_powered_image_search_tool_offers/</a></span><span class="c70 c37 c65 c60">&nbsp;</span></li><li class="c22 c10 li-bullet-0"><span class="c37 c65 c60 c84 c138">Jensen Huang introduces NIMs (NVIDIA Inference Microservices): expert AI agents that can work in teams to accomplish missions which humans assign to them: </span><span class="c5 c37 c65 c60 c138"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1797885992390762673&amp;sa=D&amp;source=editors&amp;ust=1730413583390138&amp;usg=AOvVaw1TaomZth329BrjKOrxut6k">https://x.com/tsarnick/status/1797885992390762673</a></span><span class="c37 c65 c60 c70">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Geoffrey Hinton says AI doctors who have seen 100 million patients will be much better than human doctors and able to diagnose rare conditions more accurately: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1797169362799091934&amp;sa=D&amp;source=editors&amp;ust=1730413583390373&amp;usg=AOvVaw1nE0SLnpHC0L9VZeFQ8PF0">https://x.com/tsarnick/status/1797169362799091934</a></span><span class="c1">&nbsp;</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c55 c14">No Language Left Behind (NLLB) is an AI model created by researchers at Meta capable of delivering high-quality translations directly between 200 languages &ndash; including low-resource languages: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41586-024-07335-x&amp;sa=D&amp;source=editors&amp;ust=1730413583390718&amp;usg=AOvVaw0gFb7QjXnHbM8X0xjXozBw">https://www.nature.com/articles/s41586-024-07335-x</a></span><span class="c40 c55 c37 c48 c14">&nbsp;</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c55 c14">Teams of LLM Agents can Exploit Zero-Day Vulnerabilities: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.01637&amp;sa=D&amp;source=editors&amp;ust=1730413583391033&amp;usg=AOvVaw2ZgolnMO5vDzRk51xfIcDk">https://arxiv.org/abs/2406.01637</a></span></li><li class="c10 li-bullet-0"><span>&nbsp;Fields Medalist Terence Tao explains how proof checkers and AI programs are dramatically changing mathematics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/&amp;sa=D&amp;source=editors&amp;ust=1730413583391413&amp;usg=AOvVaw1cCKWkWNyP1XM81oqvTNa1">https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>How Artificial Intelligence Is Reshaping Relationships - &quot;AI, I think I love you.&quot;: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.psychologytoday.com/us/blog/the-digital-self/202406/how-artificial-intelligence-is-reshaping-relationships&amp;sa=D&amp;source=editors&amp;ust=1730413583391813&amp;usg=AOvVaw0C2_YnLj2S4gUVCcG0DMbz">https://www.psychologytoday.com/us/blog/the-digital-self/202406/how-artificial-intelligence-is-reshaping-relationships</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c1">Forty percent of Gen Z is open to AI partners, raising questions about the future of relationships.</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.05719&amp;sa=D&amp;source=editors&amp;ust=1730413583392199&amp;usg=AOvVaw0qbBsA_gL27UtG9_tPj_0o">https://arxiv.org/abs/2404.05719</a></span><span class="c3">&nbsp;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c14 c31">Ferret-UI, a new MLLM tailored for enhanced understanding of mobile UI screens, equipped with referring, grounding, and reasoning capabilities. Given that UI screens typically exhibit a more elongated aspect ratio and contain smaller objects of interest (e.g., icons, texts) than natural images, we incorporate &quot;any resolution&quot; on top of Ferret to magnify details and leverage enhanced visual features. Specifically, each screen is divided into 2 sub-images based on the original aspect ratio (i.e., horizontal division for portrait screens and vertical division for landscape screens). Both sub-images are encoded separately before being sent to LLMs. We meticulously gather training samples from an extensive range of elementary UI tasks, such as icon recognition, find text, and widget listing. These samples are formatted for instruction-following with region annotations to facilitate precise referring and grounding. To augment the model&#39;s reasoning ability, we further compile a dataset for advanced tasks, including detailed description, perception/interaction conversations, and function inference. After </span><span class="c15 c31">training on the curated datasets, Ferret-UI exhibits outstanding comprehension of UI screens and the capability to execute open-ended instructions. </span><span class="c14 c31">For model evaluation, we establish a comprehensive benchmark encompassing all the aforementioned tasks. Ferret-UI </span><span class="c28 c43">excels not only beyond most open-source UI MLLMs, but also surpasses GPT-4V on all the elementary UI tasks.</span></li></ul><p class="c9"><span class="c28 c43"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c158 c97 c105 li-bullet-0"><span>A Starbucks run by 100 robots and 2 humans in South Korea: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/NorthstarBrain/status/1794819711240155594&amp;sa=D&amp;source=editors&amp;ust=1730413583393034&amp;usg=AOvVaw2wHP65xXtCW_VEI0Ft4nEp">https://x.com/NorthstarBrain/status/1794819711240155594</a></span></li></ul><p class="c158 c46"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>Restaurant robots can cook, serve and bus your meal now: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.axios.com/2024/06/11/restaurant-technology-robots-food-ramen&amp;sa=D&amp;source=editors&amp;ust=1730413583393483&amp;usg=AOvVaw1z6D5y3xL5vep9JIdB4ACE">https://www.axios.com/2024/06/11/restaurant-technology-robots-food-ramen</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>Robot chef that cooks meals: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/leeron/status/1800006993048170767&amp;sa=D&amp;source=editors&amp;ust=1730413583393904&amp;usg=AOvVaw1wlzrBf8IX6fliuIwb3GB4">https://x.com/leeron/status/1800006993048170767</a></span></li><li class="c10 li-bullet-0"><span class="c30 c37">LLMs can correct their own mistakes: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.01297&amp;sa=D&amp;source=editors&amp;ust=1730413583394252&amp;usg=AOvVaw0mzg19BoxNXU40S3hSgZaG">https://arxiv.org/abs/2406.01297</a></span><span class="c40 c30 c37">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c30 c37">AI used to streamline coding: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://x.com/GoogleAI/status/1800995872387518609&amp;sa=D&amp;source=editors&amp;ust=1730413583394595&amp;usg=AOvVaw3Gw_oDE0tLTaZW0URjZCzC">https://x.com/GoogleAI/status/1800995872387518609</a></span><span class="c40 c30 c37">&nbsp;</span></li><li class="c10 li-bullet-0"><span>AI is getting very popular among students and teachers, very quickly: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/06/11/ai-is-getting-very-popular-among-students-and-teachers-very-quickly.html&amp;sa=D&amp;source=editors&amp;ust=1730413583395006&amp;usg=AOvVaw2ET8GSypk4LN7XN9qtssi9">https://www.cnbc.com/2024/06/11/ai-is-getting-very-popular-among-students-and-teachers-very-quickly.html</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>Robots as psychological counselors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.economictimes.com/news/international/uk/robots-as-psychological-counsellors-this-factory-in-china-is-making-it-a-reality/articleshow/110916481.cms&amp;sa=D&amp;source=editors&amp;ust=1730413583395553&amp;usg=AOvVaw0Gj3_BiwYvhlq-4qyVmOMo">https://m.economictimes.com/news/international/uk/robots-as-psychological-counsellors-this-factory-in-china-is-making-it-a-reality/articleshow/110916481.cms</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>Robots for manufacturing cars: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/china-s-humanoid-robots-to-tackle-tricky-car-chores-at-dongfeng-motor/ar-BB1nAE9W?ocid%3DBingNewsSerp&amp;sa=D&amp;source=editors&amp;ust=1730413583396055&amp;usg=AOvVaw06q8903E6ur7Hz9r9TnVhj">https://www.msn.com/en-us/money/other/china-s-humanoid-robots-to-tackle-tricky-car-chores-at-dongfeng-motor/ar-BB1nAE9W?ocid=BingNewsSerp</a></span><span class="c1">&nbsp; </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c22 c72 c14 li-bullet-0"><span>LLMs Can&#39;t Plan, But Can Help Planning in LLM-Modulo Frameworks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.01817&amp;sa=D&amp;source=editors&amp;ust=1730413583396453&amp;usg=AOvVaw31hPQwSl2a5sL9xULiUWe3">https://arxiv.org/abs/2402.01817</a></span><span class="c1">&nbsp;</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-1"><li class="c22 c104 c86 c14 li-bullet-0"><span>&gt;We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework </span><span class="c34">provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows </span><span class="c33 c15">extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>Robot integrated with Huawei&#39;s Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583397159&amp;usg=AOvVaw0mgbnsZT1UCWjwrK0TMwii">https://x.com/TheHumanoidHub/status/1806033905147077045</a></span><span>&nbsp;</span></li><li class="c10 li-bullet-0"><span>AI powered responsive sex bots are available: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.scmp.com/news/china/science/article/3266964/chinas-next-gen-sexbots-powered-ai-are-about-hit-shelves&amp;sa=D&amp;source=editors&amp;ust=1730413583397587&amp;usg=AOvVaw33rifT8_fp7JifP_Edgf2L">https://www.scmp.com/news/china/science/article/3266964/chinas-next-gen-sexbots-powered-ai-are-about-hit-shelves</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.15568&amp;sa=D&amp;source=editors&amp;ust=1730413583397913&amp;usg=AOvVaw1TTc15HUuzCQBJgzKPM6s8">https://arxiv.org/pdf/2405.15568</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span>OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent&rsquo;s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents&rsquo; learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dub.sh/omniepic&amp;sa=D&amp;source=editors&amp;ust=1730413583398374&amp;usg=AOvVaw2ZG58bLcUkigESfQpLPs9S">https://dub.sh/omniepic</a></span><span class="c1">.</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>AI adjudicates every Supreme Court case: &quot;The results were otherworldly. Claude is fully capable of acting as a Supreme Court Justice right now.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://adamunikowsky.substack.com/p/in-ai-we-trust-part-ii&amp;sa=D&amp;source=editors&amp;ust=1730413583398753&amp;usg=AOvVaw03CVxzOB4BuX9gBrpMfhxc">https://adamunikowsky.substack.com/p/in-ai-we-trust-part-ii</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span>Correctly </span><span class="c15">predicted 27/37 rulings </span><span class="c1">that occurred after it had finished training (random guessing would be 18 or 19)</span></li><li class="c7 li-bullet-0"><span class="c1">&ldquo;Claude(3 Opus) is fully capable of acting as a Supreme Court Justice right now. When used as a law clerk, Claude is easily as insightful and accurate as human clerks, while towering over humans in efficiency.&quot;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>&ldquo;ChatGPT just coded me a little program that&#39;s already saving me so much time&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1dnrd9f/chatgpt_just_coded_me_a_little_program_thats/&amp;sa=D&amp;source=editors&amp;ust=1730413583399410&amp;usg=AOvVaw2Id8nXasxBn7ev_Nh54kfL">https://www.reddit.com/r/ChatGPT/comments/1dnrd9f/chatgpt_just_coded_me_a_little_program_thats/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 750.67px;"><img alt="" src="images/image142.jpg" style="width: 624.00px; height: 750.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Robot integrated with Huawei&#39;s Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583399968&amp;usg=AOvVaw38933glE2uwcr9kvlO_Yck">https://x.com/TheHumanoidHub/status/1806033905147077045</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>CriticGPT is intended to help identify hallucinations as models grow more sophisticated: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://spectrum.ieee.org/openai-rlhf&amp;sa=D&amp;source=editors&amp;ust=1730413583400313&amp;usg=AOvVaw3RjcKRCus9mqT-jQ0k3tT9">https://spectrum.ieee.org/openai-rlhf</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 469.33px;"><img alt="" src="images/image425.png" style="width: 624.00px; height: 469.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>Translating nearly dead language: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1b7iwej/today_while_testing_anthropicai_s_new_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583400841&amp;usg=AOvVaw2OYPxuxXxtXSWm4iGc8ekh">https://www.reddit.com/r/singularity/comments/1b7iwej/today_while_testing_anthropicai_s_new_model/</a></span><span class="c1">&nbsp;</span></li><li class="c97 c105 c122 li-bullet-0"><span>Saving Languages from Extinction: Claude 3 Opus Offers Hope for the Future of Endangered Languages: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://digialps.com/saving-languages-from-extinction-claude-3-opus-offers-hope-for-the-future-of-endangered-languages/?amp%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583401265&amp;usg=AOvVaw2J_0QKP-v8OflKQjNtg17L">https://digialps.com/saving-languages-from-extinction-claude-3-opus-offers-hope-for-the-future-of-endangered-languages/?amp=1</a></span><span class="c1">&nbsp;</span></li><li class="c122 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 817.33px;"><img alt="" src="images/image653.jpg" style="width: 624.00px; height: 817.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c10 li-bullet-0"><span>Mind-reading AI recreates what you&#39;re looking at with amazing accuracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2438107-mind-reading-ai-recreates-what-youre-looking-at-with-amazing-accuracy/&amp;sa=D&amp;source=editors&amp;ust=1730413583401839&amp;usg=AOvVaw1PqoBBaBgee5iVRe_cHoP9">https://www.newscientist.com/article/2438107-mind-reading-ai-recreates-what-youre-looking-at-with-amazing-accuracy/</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c22 c7 li-bullet-0"><span>Accomplished with human subjects too: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.smithsonianmag.com/smart-news/this-ai-used-brain-scans-to-recreate-images-people-saw-180981768/&amp;sa=D&amp;source=editors&amp;ust=1730413583402252&amp;usg=AOvVaw3oemMK2yg2N4eaCuAJs5Ig">https://www.smithsonianmag.com/smart-news/this-ai-used-brain-scans-to-recreate-images-people-saw-180981768/</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c22 c10 li-bullet-0"><span>Code refactoring made much faster: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/&amp;sa=D&amp;source=editors&amp;ust=1730413583402659&amp;usg=AOvVaw2l_kE22YkG1vdyhPmCdnW-">https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/</a></span><span class="c1">&nbsp;</span></li><li class="c22 c10 li-bullet-0"><span>AI is better than humans at lie detection: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2024/07/05/1094703/ai-lie-detectors-are-better-than-humans-at-spotting-lies/&amp;sa=D&amp;source=editors&amp;ust=1730413583403062&amp;usg=AOvVaw3TEiG8qK44LRwnScA6g0Gn">https://www.technologyreview.com/2024/07/05/1094703/ai-lie-detectors-are-better-than-humans-at-spotting-lies/</a></span></li><li class="c22 c10 li-bullet-0"><span>For Older People Who Are Lonely, Is the Solution a Robot Friend? New York officials believe a robotic companion called ElliQ, which can discuss complicated subjects, is helping older residents feel less alone: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.is/UxPWA%23selection-469.0-523.18&amp;sa=D&amp;source=editors&amp;ust=1730413583403398&amp;usg=AOvVaw2JD8Y6RvpB4wzwrvh1CcZz">https://archive.is/UxPWA#selection-469.0-523.18</a></span><span class="c1">&nbsp;</span></li><li class="c22 c10 li-bullet-0"><span>Washington Post creates chatbot to answer questions and summarize articles: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/sarafischer/status/1810706581572476957&amp;sa=D&amp;source=editors&amp;ust=1730413583403728&amp;usg=AOvVaw0HImcifWOrWX37wgOXz5p1">https://x.com/sarafischer/status/1810706581572476957</a></span></li><li class="c10 li-bullet-0"><span class="c31">Voice cloning: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1810573475309908261&amp;sa=D&amp;source=editors&amp;ust=1730413583404074&amp;usg=AOvVaw0yksSAZI9ta8H-1a6MS2b_">https://x.com/dreamingtulpa/status/1810573475309908261</a></span></li><li class="c10 li-bullet-0"><span>We show brief convos w GPT4 reduce conspiracy beliefs by ~20pp: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DG_Rand/status/1775618798717911424&amp;sa=D&amp;source=editors&amp;ust=1730413583404384&amp;usg=AOvVaw1NdZIgoJ9Cl6KioVF4Uer0">https://x.com/DG_Rand/status/1775618798717911424</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c1">&#129094;Tailored AI evidence rebut specific arguments offered by believers</span></li><li class="c7 li-bullet-0"><span class="c1">&#129094;Effect lasts 2+mo</span></li><li class="c7 li-bullet-0"><span class="c1">&#129094;Works on entrenched beliefs</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.07862&amp;sa=D&amp;source=editors&amp;ust=1730413583404960&amp;usg=AOvVaw1XnzFynXE0WDTMBD9rgk_N">https://arxiv.org/abs/2402.07862</a></span></li><li class="c10 li-bullet-0"><span class="c14 c31">xLSTMTime : Long-term Time Series Forecasting With xLSTM: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/ZReacc/status/1813196548337012943&amp;sa=D&amp;source=editors&amp;ust=1730413583405304&amp;usg=AOvVaw2GVodUiEuoK4ZTeh8OeGCW">https://x.com/ZReacc/status/1813196548337012943</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c14 c31">Our adopted architecture for LTSF termed as xLSTMTime surpasses current approaches. We compare xLSTMTime&#39;s performance against various state-of-the-art models across multiple real-world datasets,</span><span class="c15 c31">&nbsp;demonstrating superior forecasting capabilities</span><span class="c14 c31">. Our findings suggest that refined recurrent architectures can offer </span><span class="c15 c31">competitive alternatives to transformer-based models in LTSF tasks</span><span class="c3">, potentially redefining the landscape of time series forecasting</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span class="c14 c31">Automated Social Science: Language Models as Scientist and Subjects: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2404.11794&amp;sa=D&amp;source=editors&amp;ust=1730413583405910&amp;usg=AOvVaw3GaJtHZ2mg9QF2y3Mqovm_">https://arxiv.org/pdf/2404.11794</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c3">In each case, causal relationships are both proposed and tested by the system, finding evidence for some and not others. We provide evidence that the insights from these simulations of social interactions are not available to the LLM purely through direct elicitation. When given its proposed structural causal model for each scenario, the LLM is good at predicting the signs of estimated effects, but it cannot reliably predict the magnitudes of those estimates. In the auction experiment, the in silico simulation results closely match the predictions of auction theory, but elicited predictions of the clearing prices from the LLM are inaccurate. However, the LLM&rsquo;s predictions are dramatically improved if the model can condition on the fitted structural causal model. In short, the LLM knows more than it can (immediately) tell.</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span class="c14 c31">Chrome extension to show yourself wearing clothes from Amazon: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1e7ltua/i_made_a_chrome_extension_to_wear_clothes_from/&amp;sa=D&amp;source=editors&amp;ust=1730413583406526&amp;usg=AOvVaw3a26DkwmUZHW05QmKGpKaJ">https://www.reddit.com/r/StableDiffusion/comments/1e7ltua/i_made_a_chrome_extension_to_wear_clothes_from/</a></span></li><li class="c10 li-bullet-0"><span class="c14 c31">Andrew Ng is on how AI agents wil be useful: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/AndrewYNg/status/1770897666702233815&amp;sa=D&amp;source=editors&amp;ust=1730413583406851&amp;usg=AOvVaw1ofvrdwPEsk7BVgWV5g-th">https://x.com/AndrewYNg/status/1770897666702233815</a></span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-1"><li class="c7 li-bullet-0"><span class="c3">&gt;I think AI agentic workflows will drive massive AI progress this year &mdash; perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 353.37px; height: 199.07px;"><img alt="" src="images/image271.jpg" style="width: 353.37px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 c144 li-bullet-0"><span class="c14">The CLM is a new model that remembers interactions, learns skills autonomously, and thinks in its free time, just like humans: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/aidan_mclau/status/1818071890755469365?t%3DbiE9iwV1_1CzcE8CHDYhGw%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583407594&amp;usg=AOvVaw1e_q3q0VZFnyK1gtyi9XVb">https://x.com/aidan_mclau/status/1818071890755469365?t=biE9iwV1_1CzcE8CHDYhGw&amp;s=19</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span>OpenAI patent for using</span><span>&nbsp;machine learning to train and use a model to perform automatic interface actions based on video and input datasets: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://patents.google.com/patent/US11887367B1/en&amp;sa=D&amp;source=editors&amp;ust=1730413583407990&amp;usg=AOvVaw0O0wZcM3DQb4si2F4V0aOC">https://patents.google.com/patent/US11887367B1/en</a></span></li><li class="c10 li-bullet-0"><span>President of Chile says he uses ChatGPT for his daily work: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ehoe8v/president_of_chile_says_he_uses_chatgpt_for_his/&amp;sa=D&amp;source=editors&amp;ust=1730413583408404&amp;usg=AOvVaw08MaeyrpMo03SJAJj9RSQ5">https://www.reddit.com/r/singularity/comments/1ehoe8v/president_of_chile_says_he_uses_chatgpt_for_his/</a></span></li><li class="c22 c97 c105 c247 li-bullet-0"><span>How Google uses AI to reduce stop-and-go traffic on your route &mdash; and fight fuel emissions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blog.google/outreach-initiatives/sustainability/google-ai-project-greenlight/&amp;sa=D&amp;source=editors&amp;ust=1730413583408915&amp;usg=AOvVaw1tuwfnh3h_dK_zsHeUbUgI">https://blog.google/outreach-initiatives/sustainability/google-ai-project-greenlight/</a></span></li><li class="c10 li-bullet-0"><span>Watch a robot peel a squash with human-like dexterity: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2440687-watch-a-robot-peel-a-squash-with-human-like-dexterity/&amp;sa=D&amp;source=editors&amp;ust=1730413583409315&amp;usg=AOvVaw0oASjzZ2SsFROFwUXVhidv">https://www.newscientist.com/article/2440687-watch-a-robot-peel-a-squash-with-human-like-dexterity/</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c100 c86 li-bullet-0"><span class="c1">A robot can hold a squash, pumpkin or melon in one hand, while it is peeled by the other</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>&lsquo;Yell at your robot&rsquo; technique teaches robots household chores: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2425023-yell-at-your-robot-technique-teaches-robots-household-chores/&amp;sa=D&amp;source=editors&amp;ust=1730413583409836&amp;usg=AOvVaw2ZgbBCu5AbNUPiuryIUYso">https://www.newscientist.com/article/2425023-yell-at-your-robot-technique-teaches-robots-household-chores/</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c100 c86 li-bullet-0"><span class="c1">AI allows robots to listen to verbal instructions while learning to correctly perform household tasks. That could enable more natural interactions between humans and robots</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span class="c14">GPT-4 scored higher than 100% of psychologists on a test of social intelligence:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413583410305&amp;usg=AOvVaw1hI4HaG4h-sPYQReopmQIK">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413583410555&amp;usg=AOvVaw2O8LHsjH2HzLdhS2WuYuE6">https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/&amp;sa=D&amp;source=editors&amp;ust=1730413583410960&amp;usg=AOvVaw2UecTLzKy1vfmnsIyLLYlk">https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/</a></span></li><li class="c10 li-bullet-0"><span class="c14">AI agent that can control a computer: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.adept.ai/blog/act-1&amp;sa=D&amp;source=editors&amp;ust=1730413583411255&amp;usg=AOvVaw1N1ueC-KiJQ07a4icQf6yn">https://www.adept.ai/blog/act-1</a></span></li><li class="c10 li-bullet-0"><span>A new technique that allows LLMs to act, not just react: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Schindler___/status/1745986132737769573&amp;sa=D&amp;source=editors&amp;ust=1730413583411607&amp;usg=AOvVaw3RSj_SeAwwhU2xp4m1QdZg">https://x.com/Schindler___/status/1745986132737769573</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c1">Dynamic speech: Samantha can speak whenever it chooses to, influenced by its context and thoughts. In stark contrast to normal LLMs which are limited to reacting, Samantha can act. It is also not limited to solving tasks, like all other autonomous agents.</span></li><li class="c7 li-bullet-0"><span class="c1">-Live visual capabilities: Visuals are only mentioned and acted upon directly if relevant, but always influences thoughts and behavior.</span></li><li class="c7 li-bullet-0"><span class="c1">-External categorized memory: Gets dynamically written and read by Samantha, which chooses the most relevant information to write, and to retrieve to context.</span></li><li class="c7 li-bullet-0"><span class="c1">-Evolving at every moment: Experiences that get stored in the memory can influence and shape subsequent Samantha behavior, like personality, frequency, and style of speech, etc.</span></li><li class="c7 li-bullet-0"><span class="c1">In other tests, when we talked about a light subject, the agent was very active on the conversation, often speaking two or three times before I even came up with an answer, but later when switching to a heavier theme (Said I was going through a divorce) and appearing sad on the camera, it would speak once then think about the need to, and give me time to process and reply. Saying that I would prefer the agent to speak the same way on other occasions would prompt it to save that wish on its memory, influencing future conversations.</span></li><li class="c7 c46 li-bullet-0"><span class="c1"></span></li><li class="c7 li-bullet-0"><span class="c1">-Leaving it running outside of conversations, although expensive, allows the agent to reflect on past conversations and experiences, think about general subjects in its memory, and from that maybe decide to start a conversation with the user.</span></li><li class="c7 c46 li-bullet-0"><span class="c1"></span></li><li class="c7 li-bullet-0"><span class="c1">-Going out with the agent, if you go to a restaurant with the agent and talk about how pretty it is and how your buddy Eric loves it as well, and the next day walking by it the agent will see the restaurant, retrieve memories from the restaurant, remember you find it pretty and comment on it, then retrieve memories and information it knows about Eric, and mention how fitting to his personality it is to love that restaurant.</span></li><li class="c7 c46 li-bullet-0"><span class="c1"></span></li><li class="c7 li-bullet-0"><span class="c1">-The agent has time notion so you can ask it to remind you to do something 10 minutes into the future, and it might remind your, or it might forget it because it was thinking about something more interesting. Very human!</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>AI will have an estimated 21% net increase on the United States GDP by 2030: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/advisor/business/ai-statistics/%23sources_section&amp;sa=D&amp;source=editors&amp;ust=1730413583413206&amp;usg=AOvVaw3EhTWglWL6M7Fp5V5RWkkS">https://www.forbes.com/advisor/business/ai-statistics</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>56% of people use AI at least once a day: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pewresearch.org/science/2023/02/15/public-awareness-of-artificial-intelligence-in-everyday-activities/&amp;sa=D&amp;source=editors&amp;ust=1730413583413627&amp;usg=AOvVaw32vuN7dUQcoD_Wb52uY0xw">https://www.pewresearch.org/science/2023/02/15/public-awareness-of-artificial-intelligence-in-everyday-activities/</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c1">People with more education and higher incomes tend to use it more</span></li><li class="c7 li-bullet-0"><span>For reference, only 14% of US citizens own cryptocurrencies in 2023 and only 31% have any experience with it at all despite 81% hearing about it:</span><span><a class="c13" href="https://www.google.com/url?q=https://coinweb.com/trends/how-many-americans-own-crypto/&amp;sa=D&amp;source=editors&amp;ust=1730413583414078&amp;usg=AOvVaw2Daw4JZf8Tr1KiokFH85T_">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://coinweb.com/trends/how-many-americans-own-crypto/&amp;sa=D&amp;source=editors&amp;ust=1730413583414296&amp;usg=AOvVaw0g0Tjjpf-lT1qCIFl0ytaC">https://coinweb.com/trends/how-many-americans-own-crypto/</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>A class of 20 pupils at a $35,000 per year private London school won&#39;t have a human teacher this year. They&#39;ll just be taught by AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.md/wkIZZ&amp;sa=D&amp;source=editors&amp;ust=1730413583414664&amp;usg=AOvVaw0l3MY_dtvv-8VIj1DkR9MH">https://archive.md/wkIZZ</a></span></li><li class="c10 li-bullet-0"><span>We&#39;ve created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DanHendrycks/status/1833152719756116154&amp;sa=D&amp;source=editors&amp;ust=1730413583415012&amp;usg=AOvVaw2ZiVOgr4_HUh4iXmvt-OEM">https://x.com/DanHendrycks/status/1833152719756116154</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters</span></li><li class="c7 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.</span></li><li class="c7 li-bullet-0"><span class="c141 c14">On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% &plusmn; 1.4. A link to the technical report is </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Tc_xY1NM-US4mZ4OpzxrpTudyo1W4KsE/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1730413583415642&amp;usg=AOvVaw0-IHOZPAMgzwS3GaMPg6aR">here</a></span><span class="c57 c37 c154 c48 c141 c14">. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they&rsquo;re similarly accurate.</span></li><li class="c7 li-bullet-0"><span class="c141 c14">The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=http://forecast.safe.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583416040&amp;usg=AOvVaw2Kwai5ZG3ydje4ykJ53uJ9">forecast.safe.ai</a></span><span class="c141 c14">.) Moreover, probabilities from AIs are also known to lead to </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Automation_bias&amp;sa=D&amp;source=editors&amp;ust=1730413583416264&amp;usg=AOvVaw1nYS4wLYahYhwtQlgQ0EFn">automation bias</a></span><span class="c57 c37 c154 c48 c141 c14">, and improvements in the interface could ameliorate this.</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>Large Language Models for Idea Generation in Innovation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4526071&amp;sa=D&amp;source=editors&amp;ust=1730413583416625&amp;usg=AOvVaw0lwWtuzJ_eW4NQwiJQTWvP">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-1"><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. </span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413583417195&amp;usg=AOvVaw2o8iNngoZZOPK6_RZWWA0e">https://m.youtube.com/watch?v=a8QvnIAGjPA</a></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 486.67px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 486.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs &amp; this lasts for months: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.adq1814&amp;sa=D&amp;source=editors&amp;ust=1730413583417818&amp;usg=AOvVaw3F3oXARk4EsLrCdLKga39w">https://www.science.org/doi/10.1126/science.adq1814</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 622.67px;"><img alt="" src="images/image279.png" style="width: 624.00px; height: 622.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span class="c1">Scores of o1-preview and GPT-4o on &quot;official national exam in abstract mathematics used in Dutch high schools.&quot; Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: &quot;System 2 thinking in OpenAI&rsquo;s o1-preview model: Near-perfect performance on a mathematics exam&quot; &nbsp;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 406.67px;"><img alt="" src="images/image132.png" style="width: 624.00px; height: 406.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c22 c161 c97 c105 li-bullet-0"><span>China declares all crypto-currency transactions illegal: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/technology-58678907&amp;sa=D&amp;source=editors&amp;ust=1730413583418580&amp;usg=AOvVaw2W_iqayVWjRSqpXJLfD4Qw">https://www.bbc.com/news/technology-58678907</a></span></li></ul><p class="c22 c161 c97 c46"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-1"><li class="c7 li-bullet-0"><span>But China Is Closing the A.I. Gap With the United States: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.is/3M7Jt&amp;sa=D&amp;source=editors&amp;ust=1730413583418916&amp;usg=AOvVaw0z3w02-SYft0ezXhETe2dj">https://archive.is/3M7Jt</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qy2pejxz7e1k-1"><li class="c7 li-bullet-0"><span class="c1">This means that they believe AI is useful and worth investing in, even though they didn&rsquo;t care for cryptocurrency </span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>OpenAI&#39;s Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583419296&amp;usg=AOvVaw3U85BkAT-6bYEJrxvycwsK">https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/</a></span></li><li class="c10 li-bullet-0"><span>A thread of a researcher sharing his team&#39;s findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/robertghrist/status/1841462507543949581?t%3D5zV3VpQI0mbrSU9_QRtfkQ%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583419563&amp;usg=AOvVaw3tvIslP19CQXrQNftx5jaL">https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&amp;s=19</a></span></li><li class="c10 li-bullet-0"><span>OpenAI on autonomous agents: As of mid-2024, Altera&#39;s digital humans can operate autonomously for up to four hours at a time&mdash;a substantial increase compared to other AI models on the market: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/altera/&amp;sa=D&amp;source=editors&amp;ust=1730413583419843&amp;usg=AOvVaw1Zi1IwGVHO3uOmNhqG56ot">https://openai.com/index/altera/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 554.67px;"><img alt="" src="images/image93.png" style="width: 624.00px; height: 554.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span>LLM skeptic Internet of Bugs says </span><span>ChatGPT-O1 Changes Programming as a Profession. I really hated saying that: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Dj0yKLumIbaM&amp;sa=D&amp;source=editors&amp;ust=1730413583420246&amp;usg=AOvVaw248K7yVT_6RmFdT8x14W1Z">https://youtube.com/watch?v=j0yKLumIbaM</a></span></li><li class="c10 li-bullet-0"><span>DeepMind researchers find LLMs can serve as effective mediators: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://techxplore.com/news/2024-10-deepmind-llms-effective.html&amp;sa=D&amp;source=editors&amp;ust=1730413583420475&amp;usg=AOvVaw2Za45c7OH3bjScW3sPLbrO">https://techxplore.com/news/2024-10-deepmind-llms-effective.html</a></span></li><li class="c10 li-bullet-0"><span class="c35 c208 c14">Content moderation: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/using-gpt-4-for-content-moderation/&amp;sa=D&amp;source=editors&amp;ust=1730413583420687&amp;usg=AOvVaw0r5IfxTKbCbqfSZOTrHA_3">https://openai.com/index/using-gpt-4-for-content-moderation/</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Beats humans with little training</span></li><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Saves time for humans</span></li><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Less trauma from moderators seeing disturbing images or messages</span></li><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Can label harmful vs non harmful content</span></li><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Can identify edge cases (e.g. user is referring to a video game instead of real violence or is pretending to refer to a video game for a real threat)</span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-0"><li class="c10 li-bullet-0"><span class="c35 c208 c14">Linus Torvalds (creator of Linux) thinks AI is 90% hype but also says it&rsquo;s a great thing and will change the world: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/tech-industry/artificial-intelligence/linus-torvalds-reckons-ai-is-90-percent-marketing-and-10-percent-reality&amp;sa=D&amp;source=editors&amp;ust=1730413583421220&amp;usg=AOvVaw0XxZPPbFAVTchnCotre0nL">https://www.tomshardware.com/tech-industry/artificial-intelligence/linus-torvalds-reckons-ai-is-90-percent-marketing-and-10-percent-reality</a></span></li></ul><ul class="c0 lst-kix_qy2pejxz7e1k-1 start"><li class="c7 li-bullet-0"><span class="c1">Stuff linus has also downplayed in the past:</span></li><li class="c7 li-bullet-0"><span class="c1">mobile phones</span></li><li class="c7 li-bullet-0"><span class="c1">cloud computing</span></li><li class="c7 li-bullet-0"><span>github</span></li></ul><h2 class="c64" id="h.24w5g0b2lc9m"><span>4.1. Media Creation</span></h2><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c15">Say goodbye to GPTisms and slop! XTC sampler for llama.cpp: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1fv5kos/say_goodbye_to_gptisms_and_slop_xtc_sampler_for/&amp;sa=D&amp;source=editors&amp;ust=1730413583422009&amp;usg=AOvVaw0aZYI9MV1rv7CWo2hrY9nC">https://www.reddit.com/r/LocalLLaMA/comments/1fv5kos/say_goodbye_to_gptisms_and_slop_xtc_sampler_for/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">It&#39;s a way to ignore the top X tokens (exclude top choices = XTC) during sampling. It removes all except the least likely token meeting a given threshold, with a given probability, which in theory keeps coherence but increases creativity and kills GPT-isms and other predictable slop.</span></li><li class="c10 li-bullet-0"><span class="c1">My personal opinion: It&rsquo;s amazing for creative use cases. It makes your model feel like a completely different model and much improved. I hope people come up with more new samplers in the future because, in my opinion, it&#39;s still an under-explored area that can solve issues without needing to retrain your model or anything like that.</span></li><li class="c10 li-bullet-0"><span>Alternative: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/sam-paech/antislop-sampler&amp;sa=D&amp;source=editors&amp;ust=1730413583422500&amp;usg=AOvVaw3aNROHUpIe0Vc6vMQbeuTZ">https://github.com/sam-paech/antislop-sampler</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Excellent amateur quality AI photos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/&amp;sa=D&amp;source=editors&amp;ust=1730413583422738&amp;usg=AOvVaw3LVUJrZthnEBvv-giT3o6Y">https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/</a></span></li><li class="c100 c78 li-bullet-0"><span>AI Is Already Taking Jobs in the Video Game Industry: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/ai-is-already-taking-jobs-in-the-video-game-industry/&amp;sa=D&amp;source=editors&amp;ust=1730413583422979&amp;usg=AOvVaw1PJYclOYSc6mCJDVKW7qvg">https://www.wired.com/story/ai-is-already-taking-jobs-in-the-video-game-industry/</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c69 li-bullet-0"><span class="c15">&gt;NOTE: The part that says workers are being forced to use AI by their bosses </span><span class="c15 c61">IS A LIE</span><span class="c33 c15">. See [section 4.2](https://docs.google.com/document/d/15myK_6eTxEPuKnDi5krjBM_0jrv3GELs8TGmqOYBvug/edit#heading=h.akz9hanp4wxi) for strong evidence to the contrary from multiple sources.</span></li><li class="c69 li-bullet-0"><span>A WIRED investigation finds that major players like Activision Blizzard, which recently laid off scores of workers, are </span><span class="c33 c15">using generative AI for game development.</span></li><li class="c69 li-bullet-0"><span class="c41 c14">A </span><span class="c20 c41"><a class="c13" href="https://www.google.com/url?q=https://images.reg.techweb.com/Web/UBMTechweb/%257B4fe03be1-d6b1-4f91-95f4-b4bdea9e739e%257D_GDC24-SOTI-Report_Final.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583423495&amp;usg=AOvVaw2aQH3e_1cpCyJ-ooDhOdsJ">recent survey</a></span><span class="c41 c14">&nbsp;from the organizers of the </span><span class="c20 c41"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/the-video-game-industry-is-just-starting-to-feel-the-impacts-of-2023s-layoffs/&amp;sa=D&amp;source=editors&amp;ust=1730413583423686&amp;usg=AOvVaw0rONf5ydPCD6KP7ky4sBQ3">Game Developers Conference</a></span><span class="c41 c14">&nbsp;found that </span><span class="c92 c41 c15 c48">49 percent of the survey&rsquo;s more than 3,000 respondents said their workplace used AI.</span></li><li class="c69 li-bullet-0"><span class="c92 c41 c37 c48 c14">&ldquo;It&rsquo;s here. It&rsquo;s definitely here, right now,&rdquo; says Violet, a game developer, technical artist, and a veteran of the industry who has worked on AAA games for over a decade. &ldquo;I think everyone&rsquo;s seen it get used, and it&rsquo;s a matter of how and to what degree. The genie is out of the bottle, Pandora&#39;s box is opened.&rdquo;</span></li><li class="c69 li-bullet-0"><span class="c41 c14">Treyarch, a Southern California-based studio that produces some elements of Activision&rsquo;s </span><span class="c41 c61 c14">Call of Duty</span><span class="c41 c14">&nbsp;games, </span><span class="c20 c41 c14"><a class="c13" href="https://www.google.com/url?q=https://careers.activision.com/job/ACPUUSR023151EXTERNAL/2D-Artist-Animator-Treyarch-Los-Angeles?utm_source%3Dgameartrecruiterjobs&amp;sa=D&amp;source=editors&amp;ust=1730413583424223&amp;usg=AOvVaw0tQ6RyJbgpyZN0e9qbehR4">posted a job listing</a></span><span class="c14 c41">&nbsp;for a &ldquo;2D Artist Animator.&rdquo; The first thing listed under the &ldquo;To succeed you should have &hellip;&rdquo; section was &ldquo;exceptional skills and expertise in digital sketching, drawing, and painting, as well as </span><span class="c41 c15">advanced expertise in working with generative AI tools such as Stable Diffusion, Vizcom, Dall-E, or equivalent</span><span class="c92 c41 c37 c48 c14">.&rdquo; </span></li><li class="c69 li-bullet-0"><span class="c41 c14">Blizzard is building its own AI system too, which at one time was named </span><span class="c20 c41 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2023/05/22/arts/blizzard-diffusion-ai-video-games.html&amp;sa=D&amp;source=editors&amp;ust=1730413583424656&amp;usg=AOvVaw0MGtKkVfVwJdVCsda5gU1G">Blizzard Diffusion</a></span><span class="c92 c41 c37 c48 c14">&mdash;though details are scarce, beyond a patent the company filed for a &ldquo;machine-learning based 2D structured image generation&rdquo; system. &ldquo;Blizzard&#39;s &lsquo;internal AI&rsquo; that they trained is still super secretive. Only those who have access to it work with it, and no one else knows how it works,&rdquo; Warner claims.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Workflow of an artist using AI for an ad: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1eyotd7/how_artists_are_using_ai_in_their_workflow/?chainedPosts%3Dt3_1f17de3&amp;sa=D&amp;source=editors&amp;ust=1730413583425062&amp;usg=AOvVaw2s76UOh3lOM0w0tLLqZHih">https://www.reddit.com/r/aiwars/comments/1eyotd7/how_artists_are_using_ai_in_their_workflow/?chainedPosts=t3_1f17de3</a></span></li><li class="c4 li-bullet-0"><span>Activision Blizzard is reportedly already making games with AI, and quietly sold an AI-generated microtransaction in Call of Duty: Modern Warfare 3: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.gamesradar.com/games/call-of-duty/activision-blizzard-is-reportedly-already-making-games-with-ai-and-quietly-sold-an-ai-generated-microtransaction-in-call-of-duty-modern-warfare-3/&amp;sa=D&amp;source=editors&amp;ust=1730413583425406&amp;usg=AOvVaw3A9AFtPsxRI7dS_Xi0-mYw">https://www.gamesradar.com/games/call-of-duty/activision-blizzard-is-reportedly-already-making-games-with-ai-and-quietly-sold-an-ai-generated-microtransaction-in-call-of-duty-modern-warfare-3/</a></span></li><li class="c4 li-bullet-0"><span>AI-generated song made it to 72nd highest ranking song in Germany: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DtUA7mBxCpb4&amp;sa=D&amp;source=editors&amp;ust=1730413583425725&amp;usg=AOvVaw20Vh27dsBTeUWu4XGeVEKg">https://www.youtube.com/watch?v=tUA7mBxCpb4</a></span></li><li class="c4 li-bullet-0"><span>New open source AI image generator beats Midjourney: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blackforestlabs.ai/announcing-black-forest-labs/&amp;sa=D&amp;source=editors&amp;ust=1730413583425941&amp;usg=AOvVaw22RR8SXE0EBJd5PwUio5je">https://blackforestlabs.ai/announcing-black-forest-labs/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">API costs $0.025 per image. It&#39;s cheaper than Dalle 3 and can do realism.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image364.png" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image107.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Very realistic images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/&amp;sa=D&amp;source=editors&amp;ust=1730413583426495&amp;usg=AOvVaw2E3JySUMrQV3kd5MkpJEQl">https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1106.67px;"><img alt="" src="images/image120.png" style="width: 624.00px; height: 1106.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image278.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1094.67px;"><img alt="" src="images/image46.png" style="width: 624.00px; height: 1094.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 501.33px;"><img alt="" src="images/image233.png" style="width: 624.00px; height: 501.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image37.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 249.72px; height: 240.88px;"><img alt="" src="images/image82.png" style="width: 249.72px; height: 240.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 885.33px;"><img alt="" src="images/image42.png" style="width: 624.00px; height: 885.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c1">First attempt: &quot;Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat.&quot;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 636.00px;"><img alt="" src="images/image85.png" style="width: 624.00px; height: 636.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: person take photo of Graffiti art spelling out the words &quot;WAFERSELAMAT&quot;, graffiti, white wall, dynamic color, spray paint,</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 640.00px;"><img alt="" src="images/image186.png" style="width: 624.00px; height: 640.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura&#39;s styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Google&rsquo;s new image diffusion model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/&amp;sa=D&amp;source=editors&amp;ust=1730413583427884&amp;usg=AOvVaw2xG38u1T-agUIQOB7qXxWv">https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image189.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image177.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 629.33px;"><img alt="" src="images/image130.png" style="width: 624.00px; height: 629.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 630.67px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 630.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Lumina-GPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/Alpha-VLLM/Lumina-mGPT&amp;sa=D&amp;source=editors&amp;ust=1730413583428439&amp;usg=AOvVaw1aBC1wr10XHEepyQvqZvjx">https://github.com/Alpha-VLLM/Lumina-mGPT</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c1">A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. </span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1013.33px;"><img alt="" src="images/image275.png" style="width: 624.00px; height: 1013.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c15">HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1815616891022418231&amp;sa=D&amp;source=editors&amp;ust=1730413583428915&amp;usg=AOvVaw284kWi1W17TT33LTB3koxO">https://x.com/_akhaliq/status/1815616891022418231</a></span></li><li class="c4 li-bullet-0"><span class="c14">Midjourney has over 20 million users: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 497.33px;"><img alt="" src="images/image8.png" style="width: 624.00px; height: 497.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c14">Japanese writer </span><span class="c15">wins prestigious Akutagawa Prize with a book partially written by ChatGPT: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt&amp;sa=D&amp;source=editors&amp;ust=1730413583429403&amp;usg=AOvVaw32tMHByE6wt1nkuWjH0Y7C">https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt</a></span></li><li class="c4 li-bullet-0"><span>AI used by official Disney show for intro: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits&amp;sa=D&amp;source=editors&amp;ust=1730413583429798&amp;usg=AOvVaw3Xg-3OGBEtIXGGU2nt5yUf">https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Humorous AI video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/&amp;sa=D&amp;source=editors&amp;ust=1730413583430060&amp;usg=AOvVaw2JOcCI17yECCAy5N-NqIyt">https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>New Runway video models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1802691475391566108&amp;sa=D&amp;source=editors&amp;ust=1730413583430285&amp;usg=AOvVaw0kPD4u1PAmsAk21fnZrUgh">https://x.com/runwayml/status/1802691475391566108</a></span><span>&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c4 li-bullet-0"><span class="c15">ChatGPT vs. Humans: Even Linguistic experts Can&rsquo;t Tell Who Wrote What: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.researchgate.net/publication/372957869_Can_linguists_distinguish_between_ChatGPTAI_and_human_writing_A_study_of_research_ethics_and_academic_publishing&amp;sa=D&amp;source=editors&amp;ust=1730413583430830&amp;usg=AOvVaw0Ya6zKc9LaOSDSMTkjV0Oq">https://www.researchgate.net/publication/372957869_Can_linguists_distinguish_between_ChatGPTAI_and_human_writing_A_study_of_research_ethics_and_academic_publishing</a></span><span class="c33 c15">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>GPT just churned out a 10-panel comic-book explaining &quot;Gravitational Waves&quot; in a one-shot prompt: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/electrik_dreams/status/1802421281876238354&amp;sa=D&amp;source=editors&amp;ust=1730413583431135&amp;usg=AOvVaw3lyN6ZmSVXiqkpBBhqltxw">https://x.com/electrik_dreams/status/1802421281876238354</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c4 li-bullet-0"><span class="c15">Image to animation: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://github.com/Fictiverse/ToonCrafter-for-windows&amp;sa=D&amp;source=editors&amp;ust=1730413583431412&amp;usg=AOvVaw0iUcJzSLBL3v1ZCoXDilN3">https://github.com/Fictiverse/ToonCrafter-for-windows</a></span></li><li class="c4 li-bullet-0"><span class="c15">Much stronger control of image output:</span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.01300&amp;sa=D&amp;source=editors&amp;ust=1730413583431718&amp;usg=AOvVaw1f33y-hk9Sklryfta5mRwE">https://arxiv.org/pdf/2406.01300</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.05282&amp;sa=D&amp;source=editors&amp;ust=1730413583431973&amp;usg=AOvVaw3oG_RROmC1M0rvhqeNRWUS">https://arxiv.org/pdf/2407.05282</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04324&amp;sa=D&amp;source=editors&amp;ust=1730413583432176&amp;usg=AOvVaw0i83e8TPXJjuldl_whRL5N">https://huggingface.co/papers/2406.04324</a></span><span class="c92 c37 c35 c48 c14 c54">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">We show that, through the adversarial training, the multi-steps video diffusion model, i.e., Stable Video Diffusion (SVD), </span><span class="c15 c35 c54">can be trained to perform single forward pass to synthesize high-quality videos, capturing both temporal and spatial dependencies in the video data</span><span class="c35 c14 c54">. Extensive experiments demonstrate that our method achieves </span><span class="c15 c35 c54">competitive generation quality of synthesized videos with significantly reduced computational overhead for the denoising process </span><span class="c35 c14 c54">(i.e., around </span><span class="c15 c35 c54">23 times speedup compared with SVD and 6 times speedup compared with existing works, with even better generation quality</span><span class="c35 c14 c54">), paving the way for </span><span class="c2">real-time video synthesis and editing. </span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04277&amp;sa=D&amp;source=editors&amp;ust=1730413583432722&amp;usg=AOvVaw2LaFLX3Xt79JKs-aRp0pdZ">https://huggingface.co/papers/2406.04277</a></span><span class="c92 c37 c35 c48 c14 c54">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">Specifically, we propose spatio-temporal compositional diffusion to </span><span class="c15 c35 c54">precisely follow complex textual semantics</span><span class="c35 c14 c54">&nbsp;by manipulating and composing the attention maps of denoising networks spatially and temporally. Moreover, we propose an enhanced video data preprocessing to </span><span class="c15 c35 c54">enhance the training data regarding motion dynamics and prompt understanding</span><span class="c35 c14 c54">, equipped with a new reference frame attention mechanism to </span><span class="c15 c35 c54">improve the consistency of auto-regressive video generation</span><span class="c35 c14 c54">. Extensive experiments demonstrate that our VideoTetris </span><span class="c2">achieves impressive qualitative and quantitative results in compositional T2V generation. </span></li><li class="c4 li-bullet-0"><span class="c1">Image2Model</span></li><li class="c10 li-bullet-0"><span>From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://stability.ai/news/introducing-stable-fast-3d&amp;sa=D&amp;source=editors&amp;ust=1730413583433304&amp;usg=AOvVaw0EkuOJErkpbi95UewVb5T9">https://stability.ai/news/introducing-stable-fast-3d</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c10 li-bullet-0"><span>Very consistent AI 3D models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emmanuel_2m/status/1796118855237939346&amp;sa=D&amp;source=editors&amp;ust=1730413583433587&amp;usg=AOvVaw3ETOCZHzHcG4HjEWyz4o3F">https://x.com/emmanuel_2m/status/1796118855237939346</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c69 li-bullet-0"><span>Game made with 3D assets and textures made with AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CSM_ai/status/1796200041280925713&amp;sa=D&amp;source=editors&amp;ust=1730413583433872&amp;usg=AOvVaw3mXI7riUBBH57tU9Mmg2ed">https://x.com/CSM_ai/status/1796200041280925713</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://3d.makedraft.com/gallery&amp;sa=D&amp;source=editors&amp;ust=1730413583434100&amp;usg=AOvVaw1eDbJRxHNHXnrmt1m9zr8h">https://3d.makedraft.com/gallery</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://charmed.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583434330&amp;usg=AOvVaw1fi-UPw0IPaJFkZ-yLCXgy">https://charmed.ai/</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://medium.com/echo3d/7-generative-ai-tools-for-3d-asset-creation-97dd88153b7&amp;sa=D&amp;source=editors&amp;ust=1730413583434634&amp;usg=AOvVaw0XUlXqT2LlQObl3iYczKaA">https://medium.com/echo3d/7-generative-ai-tools-for-3d-asset-creation-97dd88153b7</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.masterpiecex.com/blog/creating-usable-3d-models-with-generative-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583434962&amp;usg=AOvVaw2HyLNH8hMtDlzsIp5jVQZ9">https://www.masterpiecex.com/blog/creating-usable-3d-models-with-generative-ai</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1797104351204524516&amp;sa=D&amp;source=editors&amp;ust=1730413583435208&amp;usg=AOvVaw3wv4ah6b4vY96x-69wF2Cn">https://x.com/AIWarper/status/1797104351204524516</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://costwen.github.io/Ouroboros3D/&amp;sa=D&amp;source=editors&amp;ust=1730413583435448&amp;usg=AOvVaw0PsSUWKwMnhnxQrAu25kfn">https://costwen.github.io/Ouroboros3D/</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Sparsecraft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1815204831679664191&amp;sa=D&amp;source=editors&amp;ust=1730413583435767&amp;usg=AOvVaw3_4Tv7vda_IsngW1ACHomL">https://x.com/_akhaliq/status/1815204831679664191</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c7 li-bullet-0"><span class="c1">&gt;our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://assetgen.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583436175&amp;usg=AOvVaw24GnqESsdgt8SYLTcZwUK8">https://assetgen.github.io/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 570.50px; height: 300.79px;"><img alt="" src="images/image74.png" style="width: 570.50px; height: 300.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Retexturing 3D models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eev502/with_this_tool_you_can_texture_3d_models_with_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583436716&amp;usg=AOvVaw0ZKCaD8VrRLbCK_wdpkRts">https://www.reddit.com/r/singularity/comments/1eev502/with_this_tool_you_can_texture_3d_models_with_ai/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>MeshAnything V2: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1ela7od/meshanything_v2/&amp;sa=D&amp;source=editors&amp;ust=1730413583437125&amp;usg=AOvVaw3KJ-CnSWl5WtQOUSjytDh8">https://www.reddit.com/r/StableDiffusion/comments/1ela7od/meshanything_v2/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ilumine_ai/status/1681811934163931137&amp;sa=D&amp;source=editors&amp;ust=1730413583437487&amp;usg=AOvVaw1ibNRJg92ylB9cuwDmh7EK">https://x.com/ilumine_ai/status/1681811934163931137</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1798536799737741361&amp;sa=D&amp;source=editors&amp;ust=1730413583437753&amp;usg=AOvVaw0DbJQL176gRdNt_nzKcIJz">https://x.com/_akhaliq/status/1798536799737741361</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Portrait 3D: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jinkun-hao.github.io/Portrait3D/&amp;sa=D&amp;source=editors&amp;ust=1730413583437994&amp;usg=AOvVaw2C7Ve6wpgUt56FDAGGvuy4">https://jinkun-hao.github.io/Portrait3D/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nrqa__/status/1795469205934141463&amp;sa=D&amp;source=editors&amp;ust=1730413583438215&amp;usg=AOvVaw3Y_c5MNgJGx4RnuYYEA-02">https://x.com/nrqa__/status/1795469205934141463</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.13897&amp;sa=D&amp;source=editors&amp;ust=1730413583438549&amp;usg=AOvVaw16jP6ww1B8RiqGH2JUgQaF">https://huggingface.co/papers/2406.13897</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Tripo: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fjylow/tripo_v20_is_out_now_you_can_create_stunning_3d/&amp;sa=D&amp;source=editors&amp;ust=1730413583438931&amp;usg=AOvVaw1uPxVmqoBCtVsJ8CaD2Zyf">https://www.reddit.com/r/singularity/comments/1fjylow/tripo_v20_is_out_now_you_can_create_stunning_3d/</a></span></li><li class="c4 li-bullet-0"><span class="c1">Human camouflage:</span></li></ul><p class="c21 c129"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q&amp;sa=D&amp;source=editors&amp;ust=1730413583439291&amp;usg=AOvVaw3ADkFxGm9u9ocm6aTkL2V6">https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q</a></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c4 li-bullet-0"><span>Animation from a single image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1d2saw7/its_coming_but_its_not_animateanyone/&amp;sa=D&amp;source=editors&amp;ust=1730413583439622&amp;usg=AOvVaw0Iv64xcoTAHt_kjMCzos4N">https://www.reddit.com/r/StableDiffusion/comments/1d2saw7/its_coming_but_its_not_animateanyone/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Style changes</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c10 li-bullet-0"><span>Papercraft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1d2hdia/what_if_pixars_up_was_papercraft_style/?utm_source%3Dshare%26utm_medium%3Dweb3x%26utm_name%3Dweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583440106&amp;usg=AOvVaw3x-U6Xh4k40mwj59t6XxEJ">https://www.reddit.com/r/StableDiffusion/comments/1d2hdia/what_if_pixars_up_was_papercraft_style/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Pixel art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1792570014454727149&amp;sa=D&amp;source=editors&amp;ust=1730413583440427&amp;usg=AOvVaw26CPkgw4cHu1rMGSWBQI_b">https://x.com/AIWarper/status/1792570014454727149</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-3 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 301.64px; height: 346.50px;"><img alt="" src="images/image589.png" style="width: 301.64px; height: 346.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span>3D models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1780251522905083919&amp;sa=D&amp;source=editors&amp;ust=1730413583440892&amp;usg=AOvVaw1dRqZpMm9h2bDilz0baDOD">https://x.com/AIWarper/status/1780251522905083919</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1811045840313799162&amp;sa=D&amp;source=editors&amp;ust=1730413583441185&amp;usg=AOvVaw0pciSdkfwZf3rG_whZP7Ug">https://x.com/AIWarper/status/1811045840313799162</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c4 li-bullet-0"><span>Editing videos from one frame: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://i2vedit.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583441476&amp;usg=AOvVaw19QWdlo_3ak64Fv2lZd3vQ">https://i2vedit.github.io/</a></span><span class="c1 c43">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI object removal: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1795917964610351177&amp;sa=D&amp;source=editors&amp;ust=1730413583441796&amp;usg=AOvVaw2UTI2FKi5v7tL4CF4AFc_k">https://x.com/AIWarper/status/1795917964610351177</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Upscaling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/Hillobar/Rope&amp;sa=D&amp;source=editors&amp;ust=1730413583442083&amp;usg=AOvVaw3PxNHqJQZTLx5cP21WFRCz">https://github.com/Hillobar/Rope</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c10 li-bullet-0"><span>Image: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 391.07px; height: 227.50px;"><img alt="" src="images/image126.png" style="width: 391.07px; height: 227.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/henryruhs/status/1795102994549055968&amp;sa=D&amp;source=editors&amp;ust=1730413583442567&amp;usg=AOvVaw1pt1T7GE0dlII8n-uvpHoJ">https://x.com/henryruhs/status/1795102994549055968</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c4 li-bullet-0"><span>Lip syncing: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1795157663266881929&amp;sa=D&amp;source=editors&amp;ust=1730413583442886&amp;usg=AOvVaw1KQ8sf3WElcX5vWCUB9ECX">https://x.com/AIWarper/status/1795157663266881929</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>VFX: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1780663596181287317&amp;sa=D&amp;source=editors&amp;ust=1730413583443181&amp;usg=AOvVaw1SkYA7E4AjxHSEMIf7D54I">https://x.com/AIWarper/status/1780663596181287317</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Replacing people in videos: </span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1789011656049324075&amp;sa=D&amp;source=editors&amp;ust=1730413583443517&amp;usg=AOvVaw2cSA-9QZLHcDlNmJhWPEDU">https://x.com/AIWarper/status/1789011656049324075</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1779952562843848981&amp;sa=D&amp;source=editors&amp;ust=1730413583443774&amp;usg=AOvVaw3Htxt1ZoT7zpTUS3D2RfYz">https://x.com/AIWarper/status/1779952562843848981</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Alibaba presents MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fp0ti3/alibaba_presents_mimo_controllable_character/&amp;sa=D&amp;source=editors&amp;ust=1730413583444102&amp;usg=AOvVaw2GrE4azp0Wsnkd005Pn3bU">https://www.reddit.com/r/singularity/comments/1fp0ti3/alibaba_presents_mimo_controllable_character/</a></span></li><li class="c4 li-bullet-0"><span>Adding moving objects in video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1796062121215615031&amp;sa=D&amp;source=editors&amp;ust=1730413583444334&amp;usg=AOvVaw11FreaB0eT6EQ0SMcMWVCm">https://x.com/dreamingtulpa/status/1796062121215615031</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Morphing images together: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/krea_ai/status/1788465406971453814&amp;sa=D&amp;source=editors&amp;ust=1730413583444557&amp;usg=AOvVaw0xh3X0jCHE8u_82UZFj3PK">https://x.com/krea_ai/status/1788465406971453814</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Image drag editing: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795858080908890242&amp;sa=D&amp;source=editors&amp;ust=1730413583444807&amp;usg=AOvVaw2spV_OnwutP6cnShKzkCOW">https://x.com/dreamingtulpa/status/1795858080908890242</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>ViViD can transfer a clothing item onto the video of a target person: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795786351733772479&amp;sa=D&amp;source=editors&amp;ust=1730413583445121&amp;usg=AOvVaw0pLwMRHxRItRNB6e5H4Gfo">https://x.com/dreamingtulpa/status/1795786351733772479</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c10 li-bullet-0"><span class="c1">The method is able to capture garment details and human posture, resulting in more coherent and lifelike videos.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c4 li-bullet-0"><span>Video movement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795698989708325273&amp;sa=D&amp;source=editors&amp;ust=1730413583445469&amp;usg=AOvVaw0yOlbEnHZit7Sb6qZhOyac">https://x.com/dreamingtulpa/status/1795698989708325273</a></span><span class="c1">&nbsp; </span></li><li class="c4 li-bullet-0"><span>Era3D: A new AI model that creates high-res &#128511;3D images from multiple viewpoints using just one input image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Gradio/status/1795866944568000697&amp;sa=D&amp;source=editors&amp;ust=1730413583445744&amp;usg=AOvVaw1SKa5OFNlLKQatq4zEXRbB">https://x.com/Gradio/status/1795866944568000697</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c10 li-bullet-0"><span class="c1">- Generates high-quality images up to 512&times;512 pixels&#127919;</span></li><li class="c10 li-bullet-0"><span class="c1">- Uses efficient row-wise attention to reduce computation&#9889;</span></li><li class="c10 li-bullet-0"><span class="c1">- 12x more efficient than sota methods&#128170;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Generating short films, trailers, and teasers with AI tools: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/minchoi/status/1795834164333433232&amp;sa=D&amp;source=editors&amp;ust=1730413583446208&amp;usg=AOvVaw3FfC89jgSFf57uZEKYuOtF">https://x.com/minchoi/status/1795834164333433232</a></span><span class="c1">&nbsp;</span></li><li class="c22 c32 li-bullet-0"><span class="c1">SFX: </span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c72 li-bullet-0"><span>Text2audio: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/elevenlabsio/status/1759240084342059260&amp;sa=D&amp;source=editors&amp;ust=1730413583446520&amp;usg=AOvVaw2XP3Jdaw3EMIABy17y-ZDL">https://x.com/elevenlabsio/status/1759240084342059260</a></span><span class="c1">&nbsp;</span></li><li class="c22 c72 li-bullet-0"><span>Img2audio: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795729964764987631&amp;sa=D&amp;source=editors&amp;ust=1730413583446771&amp;usg=AOvVaw0sDZ1O0wxzAjooHGaM77dR">https://x.com/dreamingtulpa/status/1795729964764987631</a></span><span class="c1">&nbsp;</span></li><li class="c22 c72 li-bullet-0"><span class="c18">SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound Generation: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2405.18503&amp;sa=D&amp;source=editors&amp;ust=1730413583447063&amp;usg=AOvVaw29w6XISefY9rOuepbelYeA">https://huggingface.co/papers/2405.18503</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c72 li-bullet-0"><span class="c18">ElevenLabs version: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1d50x9m/elevenlabs_text_to_sound_effects_is_here/&amp;sa=D&amp;source=editors&amp;ust=1730413583447373&amp;usg=AOvVaw3GUuFYAFvQUy6qerVfUWco">https://www.reddit.com/r/singularity/comments/1d50x9m/elevenlabs_text_to_sound_effects_is_here/</a></span><span class="c18">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c100 c78 li-bullet-0"><span>Game made with 3D assets and textures made with AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CSM_ai/status/1796200041280925713&amp;sa=D&amp;source=editors&amp;ust=1730413583447654&amp;usg=AOvVaw0PQ3blUogr10VEkU3zAF2K">https://x.com/CSM_ai/status/1796200041280925713</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c69 li-bullet-0"><span>A chest: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tejasdkulkarni/status/1796730715851157620&amp;sa=D&amp;source=editors&amp;ust=1730413583447881&amp;usg=AOvVaw2SAJnJOfUAffQhKCokqCwm">https://x.com/tejasdkulkarni/status/1796730715851157620</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>MagicPose4D can generate 3D objects from text or images and transfer precise motions and trajectories from objects and characters in a video or mesh sequence: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/FvMgUNcjy9&amp;sa=D&amp;source=editors&amp;ust=1730413583448072&amp;usg=AOvVaw0Z-nMq1erqUTEmVyfJoceQ">https://t.co/FvMgUNcjy9</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>RemoCap can reconstruct 3D human bodies (included &nbsp;occluded body parts) from motion sequences: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/HydtPXJifC&amp;sa=D&amp;source=editors&amp;ust=1730413583448264&amp;usg=AOvVaw2AAKw3X7am5XeWYMANT5VT">https://t.co/HydtPXJifC</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>NOVA-3D can generate 3D anime characters from non-overlapped front and back views: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/NOVA-3D-Anime-Character-Synthesis/NOVA-3D&amp;sa=D&amp;source=editors&amp;ust=1730413583448483&amp;usg=AOvVaw2s2AJl9s2fPUO1S1XCPm-W">https://github.com/NOVA-3D-Anime-Character-Synthesis/NOVA-3D</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI used for 3D rendering: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/mickmumpitz/status/1795016363066417396&amp;sa=D&amp;source=editors&amp;ust=1730413583448674&amp;usg=AOvVaw0j3_SDw05rdTd9ldVNk6xs">https://x.com/mickmumpitz/status/1795016363066417396</a></span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://research.nvidia.com/labs/dir/edgerunner/&amp;sa=D&amp;source=editors&amp;ust=1730413583448879&amp;usg=AOvVaw3kXEbQKyLhAAEpEhb6q5_l">https://research.nvidia.com/labs/dir/edgerunner/</a></span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://buaacyw.github.io/mesh-anything/&amp;sa=D&amp;source=editors&amp;ust=1730413583449063&amp;usg=AOvVaw3C3Uwnmu9Tf7HIos2onSVC">https://buaacyw.github.io/mesh-anything/</a></span></li><li class="c4 li-bullet-0"><span>MotionCraft can animate an image based on physics: </span><span class="c20 c55 c37 c65 c217"><a class="c13" href="https://www.google.com/url?q=https://t.co/iddB4CQ6lM&amp;sa=D&amp;source=editors&amp;ust=1730413583449249&amp;usg=AOvVaw3DNty64_mjgu3ab_jYdtie">mezzelfo.github.io/MotionCraft/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">The method is able to simulate different physics, such as fluid dynamics, rigid motion, and multi-agent systems, and can also be combined with animation software to generate the required optical flows.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>CondMDI can generate precise and diverse motions that conform to flexible user-specified spatial constraints and text descriptions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795363597243035969&amp;sa=D&amp;source=editors&amp;ust=1730413583449605&amp;usg=AOvVaw38OT3id2QVMIKXG2D3MNGL">https://x.com/dreamingtulpa/status/1795363597243035969</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">This enables the creation of high-quality animations from just text prompts and inpainting between keyframes.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 li-bullet-0"><span class="c18">Used for animation: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/s/AtaCsdxvBY&amp;sa=D&amp;source=editors&amp;ust=1730413583449934&amp;usg=AOvVaw3G8g3Y7O3W18rq2Ng6cbrb">https://www.reddit.com/r/StableDiffusion/s/AtaCsdxvBY</a></span><span class="c40 c18">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c22 c72 li-bullet-0"><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/s/9QupjshrfE&amp;sa=D&amp;source=editors&amp;ust=1730413583450132&amp;usg=AOvVaw1xc00blf7Kk_bg5vIOWQFJ">https://www.reddit.com/r/StableDiffusion/s/9QupjshrfE</a></span><span class="c40 c18">&nbsp;</span></li><li class="c22 c72 li-bullet-0"><span class="c18">AI tools now allow to retexture specific areas of 3D models: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/artificial/s/SfAcl7dTwS&amp;sa=D&amp;source=editors&amp;ust=1730413583450339&amp;usg=AOvVaw1ZV3FAoZvz_Tt8ApI5ZoNo">https://www.reddit.com/r/artificial/s/SfAcl7dTwS</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>EditWorld can add, replace, delete, and move objects in images, as well as change their attributes and perform other operations based on text instructions grounded in real-world scenarios: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1794972116472770659&amp;sa=D&amp;source=editors&amp;ust=1730413583450558&amp;usg=AOvVaw3a_k-kM1Mx9G8K49JNfIPt">https://x.com/dreamingtulpa/status/1794972116472770659</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Image to video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.02230&amp;sa=D&amp;source=editors&amp;ust=1730413583450758&amp;usg=AOvVaw18kef5_25xeg8lYdqGL14f">https://huggingface.co/papers/2406.02230</a></span></li><li class="c4 li-bullet-0"><span>Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1811751431453450449&amp;sa=D&amp;source=editors&amp;ust=1730413583450978&amp;usg=AOvVaw1xPg_VVivDu3EDEhWgl2DU">https://x.com/runwayml/status/1811751431453450449</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 612.50px; height: 704.21px;"><img alt="" src="images/image252.png" style="width: 612.50px; height: 704.21px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Pixel sprite animation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1797367653226643865&amp;sa=D&amp;source=editors&amp;ust=1730413583451391&amp;usg=AOvVaw0XlRcCbW0XpoLC_krjzk-W">https://x.com/AIWarper/status/1797367653226643865</a></span></li><li class="c4 li-bullet-0"><span class="c18">Sony Will Use AI to Cut Film Costs, Says CEO Tony Vinciquerra: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.indiewire.com/news/breaking-news/sony-pictures-will-cut-film-costs-using-ai-1235010605/&amp;sa=D&amp;source=editors&amp;ust=1730413583451803&amp;usg=AOvVaw3FnK5gT8cPB4dViRPYBwHH">https://www.indiewire.com/news/breaking-news/sony-pictures-will-cut-film-costs-using-ai-1235010605/</a></span><span class="c18">&nbsp;</span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Translation dubbing for NPCs in video games: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/elevenlabsio/status/1797655062350565433&amp;sa=D&amp;source=editors&amp;ust=1730413583452040&amp;usg=AOvVaw3pO8djGVpvHJIaZ6dSsaah">https://x.com/elevenlabsio/status/1797655062350565433</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Reskinning 3D models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emmanuel_2m/status/1797735403761610916&amp;sa=D&amp;source=editors&amp;ust=1730413583452295&amp;usg=AOvVaw00U8E5dS50rqVLdrJaAp6V">https://x.com/emmanuel_2m/status/1797735403761610916</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c35 c14 c54">Controllable video generation: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.20222v2&amp;sa=D&amp;source=editors&amp;ust=1730413583452590&amp;usg=AOvVaw1pywogRC6UMiXUTK8rHc5E">https://arxiv.org/pdf/2405.20222v2</a></span></li><li class="c4 li-bullet-0"><span class="c35 c14 c54">&nbsp;</span><span>New Runway video models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1802691475391566108&amp;sa=D&amp;source=editors&amp;ust=1730413583452822&amp;usg=AOvVaw1vfiECCS1lOic6I-gqnmY6">https://x.com/runwayml/status/1802691475391566108</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Generating audio for video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/generating-audio-for-video/&amp;sa=D&amp;source=editors&amp;ust=1730413583453063&amp;usg=AOvVaw1oceXYULUAeQhCoRMfeL2l">https://deepmind.google/discover/blog/generating-audio-for-video/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Stream diffusion brushes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/AIStoxiaArt/comments/1abnmmi/interactive_streamdiffusion_brush/&amp;sa=D&amp;source=editors&amp;ust=1730413583453307&amp;usg=AOvVaw0Skn4cpIvPOyJo5CZrVQqD">https://www.reddit.com/r/AIStoxiaArt/comments/1abnmmi/interactive_streamdiffusion_brush/</a></span></li><li class="c4 li-bullet-0"><span>Guy commissioned and properly credited artists in the past, multiple times got backstabbed by artists who copy-striked his videos, threatening to take his channel down: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DknUkXwJXcpY&amp;sa=D&amp;source=editors&amp;ust=1730413583453543&amp;usg=AOvVaw1PA5gfMiJvCt7UrZX6Bgp7">https://www.youtube.com/watch?v=knUkXwJXcpY</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Claude Sonnet 3.5 can generate complex shapes with SVG: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dm6b57/comment/l9twj24/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583453801&amp;usg=AOvVaw3eZMz7GrG_f1T99Orx4d1T">https://www.reddit.com/r/singularity/comments/1dm6b57/comment/l9twj24/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c14">sound to music: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/LinusEkenstam/status/1797761904640954430&amp;sa=D&amp;source=editors&amp;ust=1730413583454020&amp;usg=AOvVaw0XZgTTzcmYPtJKh1HF_rOk">https://x.com/LinusEkenstam/status/1797761904640954430</a></span><span class="c1 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c99 c37 c65 c60 c144">Toys R Us uses Sora generated promo: </span><span class="c5 c37 c65 c60 c144"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/&amp;sa=D&amp;source=editors&amp;ust=1730413583454267&amp;usg=AOvVaw3I4A-RrY32BHav89KP-Lf4">https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo</a></span></li><li class="c4 li-bullet-0"><span>Generating Anatomically Controllable Consistent Text-to-3D Animals: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.16273&amp;sa=D&amp;source=editors&amp;ust=1730413583454501&amp;usg=AOvVaw27GE37N5rIgsrm5ESxLzNx">https://arxiv.org/pdf/2406.16273</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>3D model generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/murchellcruft/status/1805679588627861632&amp;sa=D&amp;source=editors&amp;ust=1730413583454731&amp;usg=AOvVaw1Rf9jLa_DuRNiOlWrKu-R7">https://x.com/murchellcruft/status/1805679588627861632</a></span><span class="c1">&nbsp;</span></li><li class="c100 c78 li-bullet-0"><span>Cheap AI voice clones may wipe out jobs of 5,000 Australian actors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia&amp;sa=D&amp;source=editors&amp;ust=1730413583454974&amp;usg=AOvVaw1Q4pd7CQVQQS6bykOfwkHn">https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c69 li-bullet-0"><span class="c1">Industry group says rise of vocal technology could upend many creative fields, including audiobooks &ndash; the canary in the coalmine for voice actors</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>HOIFH generates synchronized object motion, full-body human motion, and detailed finger motion: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://hoifhli.github.io&amp;sa=D&amp;source=editors&amp;ust=1730413583455221&amp;usg=AOvVaw1XMZGOcx9jJJdeb4G5JyGM">https://hoifhli.github.io</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">It is designed for manipulating large objects within contextual environments, guided by human-level instructions.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Merging image elements together: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/alex_peys/status/1806719131791876418&amp;sa=D&amp;source=editors&amp;ust=1730413583455475&amp;usg=AOvVaw06PDphKU3Shx03sw3k3Lcg">https://x.com/alex_peys/status/1806719131791876418</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 564.26px; height: 297.50px;"><img alt="" src="images/image341.png" style="width: 564.26px; height: 297.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 484.00px;"><img alt="" src="images/image62.png" style="width: 624.00px; height: 484.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 329.33px;"><img alt="" src="images/image263.png" style="width: 624.00px; height: 329.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c1">High quality upscaling: </span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://shuweis.github.io/ResMaster/&amp;sa=D&amp;source=editors&amp;ust=1730413583455939&amp;usg=AOvVaw3ETftG0SpP0n7bmTLNGlEV">https://shuweis.github.io/ResMaster/</a></span></li><li class="c7 li-bullet-0"><span>Consistent upscaling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/mervenoyann/status/1810592224830193781&amp;sa=D&amp;source=editors&amp;ust=1730413583456141&amp;usg=AOvVaw30UG-6a2cSmqJAzy2jicK5">https://x.com/mervenoyann/status/1810592224830193781</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Square Enix says it used AI art in upcoming Foamstars game: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney&amp;sa=D&amp;source=editors&amp;ust=1730413583456361&amp;usg=AOvVaw3lbR9KfAzVjnJcKWd-QVbp">https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney</a></span></li><li class="c89 c53 c56 li-bullet-0"><span class="c31">Human level text to speech: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/&amp;sa=D&amp;source=editors&amp;ust=1730413583456590&amp;usg=AOvVaw3c02xIZF8uV67-4IWSNj7H">https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/</a></span></li><li class="c10 li-bullet-0"><span>Great video creation </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://boyuan.space/diffusion-forcing/&amp;sa=D&amp;source=editors&amp;ust=1730413583456803&amp;usg=AOvVaw1AjvJzb6Pp27QNNEn4Y39C">https://boyuan.space/diffusion-forcing/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 548.50px; height: 172.00px;"><img alt="" src="images/image121.png" style="width: 548.50px; height: 172.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Direct control over image generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1809654865724862917&amp;sa=D&amp;source=editors&amp;ust=1730413583457091&amp;usg=AOvVaw0ImMaSWAZTvizVxBFefaVb">https://x.com/dreamingtulpa/status/1809654865724862917</a></span></li><li class="c10 li-bullet-0"><span>LivePortrait face animation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/venturetwins/status/1809686031312027933&amp;sa=D&amp;source=editors&amp;ust=1730413583457289&amp;usg=AOvVaw1zwXV0ZBVSejrpl2unlf-1">https://x.com/venturetwins/status/1809686031312027933</a></span></li><li class="c10 li-bullet-0"><span class="c1">Realistic/good AI videos:</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span>OpenAI is already training a new version of Sora with even higher quality and longer videos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign%3DEditorial%26utm_content%3DNewsletter%252CAI%2BAgenda%26utm_medium%3Dorganic_social%26utm_source%3Dtwitter&amp;sa=D&amp;source=editors&amp;ust=1730413583457595&amp;usg=AOvVaw2-nH5n-2Z56pcNHNGdFAbD">https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign=Editorial&amp;utm_content=Newsletter%2CAI+Agenda&amp;utm_medium=organic_social&amp;utm_source=twitter</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/&amp;sa=D&amp;source=editors&amp;ust=1730413583457820&amp;usg=AOvVaw2BU8NVjbjcASSkGCyUbdq5">https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1810547329356771827/&amp;sa=D&amp;source=editors&amp;ust=1730413583458011&amp;usg=AOvVaw10y_VIIhpTykAPmOVNxuzg">https://x.com/kimmonismus/status/1810547329356771827/</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1809322314225578158&amp;sa=D&amp;source=editors&amp;ust=1730413583458188&amp;usg=AOvVaw3tEYBmtT3Yw4YkyT8vTsPi">https://x.com/kimmonismus/status/1809322314225578158</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsumotokai/status/1810128665889685596&amp;sa=D&amp;source=editors&amp;ust=1730413583458362&amp;usg=AOvVaw1TDIW63Di0MpxCBJR6iAmE">https://x.com/tsumotokai/status/1810128665889685596</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Diesol/status/1810468576882770109&amp;sa=D&amp;source=editors&amp;ust=1730413583458548&amp;usg=AOvVaw1oagioRax94UkgjH8Kep-w">https://x.com/Diesol/status/1810468576882770109</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1810949448584855729&amp;sa=D&amp;source=editors&amp;ust=1730413583458760&amp;usg=AOvVaw00V12eww8Mi_XhSfAVVXEx">https://x.com/kimmonismus/status/1810949448584855729</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1810952037246349739&amp;sa=D&amp;source=editors&amp;ust=1730413583458951&amp;usg=AOvVaw0czMaSqzlHyDX7Wr8tSe5n">https://x.com/CharaspowerAI/status/1810952037246349739</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1811105682000671147&amp;sa=D&amp;source=editors&amp;ust=1730413583459138&amp;usg=AOvVaw3wjJEV1VeOw_KF0zLHV31R">https://x.com/CharaspowerAI/status/1811105682000671147</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/&amp;sa=D&amp;source=editors&amp;ust=1730413583459359&amp;usg=AOvVaw28rJuYqFATPO54ZdqDH1jd">https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/shanef3d/status/1811505820129214687&amp;sa=D&amp;source=editors&amp;ust=1730413583459548&amp;usg=AOvVaw3QCIVKhRVI6zLMTeC6mTWn">https://x.com/shanef3d/status/1811505820129214687</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ai_for_success/status/1811576761617928300&amp;sa=D&amp;source=editors&amp;ust=1730413583459735&amp;usg=AOvVaw1KcCBuFTna0JtJBtMSUI0O">https://x.com/ai_for_success/status/1811576761617928300</a></span></li><li class="c7 li-bullet-0"><span>Hands: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/arohaAIX/status/1811381195676307623&amp;sa=D&amp;source=editors&amp;ust=1730413583459920&amp;usg=AOvVaw2ZA9y5wTAj1HKln4vhSlb-">https://x.com/arohaAIX/status/1811381195676307623</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1813578798283255823&amp;sa=D&amp;source=editors&amp;ust=1730413583460090&amp;usg=AOvVaw0Yt_-z5Y36747C6_FD6rDc">https://x.com/_akhaliq/status/1813578798283255823</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/&amp;sa=D&amp;source=editors&amp;ust=1730413583460307&amp;usg=AOvVaw1fTELcvq-fbVwCaqKkv7u9">https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/</a></span></li><li class="c7 li-bullet-0"><span>Grand Theft Auto in India: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/&amp;sa=D&amp;source=editors&amp;ust=1730413583460539&amp;usg=AOvVaw37QJrYv7E5FIBNh2eJG5gN">https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1816096185016357030&amp;sa=D&amp;source=editors&amp;ust=1730413583460757&amp;usg=AOvVaw1Z7miaRUkWeTa8nePzZ_9p">https://x.com/runwayml/status/1816096185016357030</a></span></li><li class="c7 li-bullet-0"><span>Apples to guinea pigs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/&amp;sa=D&amp;source=editors&amp;ust=1730413583460973&amp;usg=AOvVaw31sdDb780TcNMR3AHVo1qR">https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/</a></span></li><li class="c7 li-bullet-0"><span>Person speaking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/&amp;sa=D&amp;source=editors&amp;ust=1730413583461181&amp;usg=AOvVaw3SLJ-zQ-VXl9mGru81r7Tz">https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/</a></span></li><li class="c7 li-bullet-0"><span>Burger King commercial parody: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583461410&amp;usg=AOvVaw3ar9SlYmT_3HGSO_3GgPMV">https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>This was done in less than 24h by one person using AI as the ground tooling, some post in AE and that&rsquo;s it. Imagine the time and cost a real spot like this would cost. 100x less expensive due to AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/&amp;sa=D&amp;source=editors&amp;ust=1730413583461675&amp;usg=AOvVaw3rrBOQN8wC_5f0IK1MdYZ1">https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/</a></span></li><li class="c10 li-bullet-0"><span class="c14">Image Consistency: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2404.18919&amp;sa=D&amp;source=editors&amp;ust=1730413583461888&amp;usg=AOvVaw2m-Q3fwiRkYYUJBF3YznZx">https://arxiv.org/pdf/2404.18919</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.17661&amp;sa=D&amp;source=editors&amp;ust=1730413583462068&amp;usg=AOvVaw2_3yFshoZLV8JKbRISn3mE">https://arxiv.org/pdf/2405.17661</a></span><span class="c1 c14">&nbsp;(has video consistency too)</span></li><li class="c7 li-bullet-0"><span class="c14">Consistent image to video: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2402.04324&amp;sa=D&amp;source=editors&amp;ust=1730413583462273&amp;usg=AOvVaw1cCA07R2sWi53U1DQ2If92">https://arxiv.org/pdf/2402.04324</a></span><span class="c1 c14">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c14">Midjourney character consistency: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://docs.midjourney.com/docs/character-reference&amp;sa=D&amp;source=editors&amp;ust=1730413583462490&amp;usg=AOvVaw2wKfMJryiF-3AzxtZ0Yoci">https://docs.midjourney.com/docs/character-reference</a></span><span class="c1 c14">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/fofrAI/status/1796547108478038355&amp;sa=D&amp;source=editors&amp;ust=1730413583462678&amp;usg=AOvVaw3RrsKCk3iNxjXkcXgOkDt2">https://x.com/fofrAI/status/1796547108478038355</a></span><span class="c1 c14">&nbsp;</span></li><li class="c7 li-bullet-0"><span>Very consistent video to video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/&amp;sa=D&amp;source=editors&amp;ust=1730413583462918&amp;usg=AOvVaw15grtD9pFHTGRGb9HBWcam">https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span>NVIDIA Research solved subject consistency: &quot;Joint-image Diffusion Models for Finetuning-free Personalized Text-to-image Generation&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://research.nvidia.com/labs/dir/jedi/&amp;sa=D&amp;source=editors&amp;ust=1730413583463120&amp;usg=AOvVaw05ZcFtuwc2JiEPeXoIbdVX">https://research.nvidia.com/labs/dir/jedi/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>drag-and-drop a subject from an image with an arbitrary style onto another target image with a vastly different style and achieve a style-aware and realistic insertion of the subject into the target image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://magicinsert.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583463312&amp;usg=AOvVaw1B-SjOPaPLdk1LpMhXDTow">https://magicinsert.github.io/</a></span></li><li class="c10 li-bullet-0"><span>Code-free game development in a few minutes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1799134111334121892&amp;sa=D&amp;source=editors&amp;ust=1730413583463511&amp;usg=AOvVaw1jp-2l2Eqbq-yvbZCdK9Zt">https://x.com/CharaspowerAI/status/1799134111334121892</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ZReacc/status/1813196548337012943&amp;sa=D&amp;source=editors&amp;ust=1730413583463728&amp;usg=AOvVaw2unG7N3piE69BJi6bshWSv">https://x.com/ZReacc/status/1813196548337012943</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Multi-modal (text and image) long story generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.08683&amp;sa=D&amp;source=editors&amp;ust=1730413583463916&amp;usg=AOvVaw0RQtE2dWgCDP4sRFWfPIWe">https://huggingface.co/papers/2407.08683</a></span></li><li class="c10 li-bullet-0"><span>Image movement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1753710085447074104&amp;sa=D&amp;source=editors&amp;ust=1730413583464107&amp;usg=AOvVaw1orNYdk4Ca6ZMI7wN2r9oQ">https://x.com/dreamingtulpa/status/1753710085447074104</a></span></li><li class="c10 li-bullet-0"><span>Adding and tweaking concepts to a pre-existing image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/gytdau/status/1811530283747000386&amp;sa=D&amp;source=editors&amp;ust=1730413583464292&amp;usg=AOvVaw0og1dB3fMDFgIdmMup_zNW">https://x.com/gytdau/status/1811530283747000386</a></span></li><li class="c10 li-bullet-0"><span>Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics:</span><span><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1811751431453450449&amp;sa=D&amp;source=editors&amp;ust=1730413583464513&amp;usg=AOvVaw27GLBRXCbx97FDcP94cEE-">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1811751431453450449&amp;sa=D&amp;source=editors&amp;ust=1730413583464638&amp;usg=AOvVaw0j0JDPGK_WDB6JHbDKpvzE">https://x.com/runwayml/status/1811751431453450449</a></span></li><li class="c10 li-bullet-0"><span>Image + motion to video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/tencent/MimicMotion&amp;sa=D&amp;source=editors&amp;ust=1730413583464880&amp;usg=AOvVaw3YGbM0_E_s7t4LE4XPfGKQ">https://github.com/tencent/MimicMotion</a></span></li><li class="c10 li-bullet-0"><span class="c40 c18">CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation</span></li></ul><p class="c21 c105"><span class="c18">&#119823;&#119851;&#119848;&#119843;: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=http://gxyes.github.io/projects/CrowdMoGen.html&amp;sa=D&amp;source=editors&amp;ust=1730413583465151&amp;usg=AOvVaw2z4q6AduK85YmhGusW1YCJ">http://gxyes.github.io/projects/CrowdMoGen.html</a></span><span class="c40 c18">&nbsp;</span></p><p class="c21 c105"><span class="c18">&#119808;&#119835;&#119852;: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=http://arxiv.org/abs/2407.06188&amp;sa=D&amp;source=editors&amp;ust=1730413583465347&amp;usg=AOvVaw0TAtwlT7Jir-zhNav3U3Ri">http://arxiv.org/abs/2407.06188</a></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c7 li-bullet-0"><span class="c40 c18">a zero-shot text-driven framework that harnesses the power of LLMs to incorporate the collective intelligence into motion generation</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c18">Adding sound to video: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1812518092557193604&amp;sa=D&amp;source=editors&amp;ust=1730413583465649&amp;usg=AOvVaw0_cbu-qWPHjC8lhEbOrMzj">https://x.com/dreamingtulpa/status/1812518092557193604</a></span></li><li class="c10 li-bullet-0"><span class="c18">AI game generation: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1812677264892395837&amp;sa=D&amp;source=editors&amp;ust=1730413583465972&amp;usg=AOvVaw0q1TjFS_8gTqSjMFVKk59i">https://x.com/_akhaliq/status/1812677264892395837</a></span></li><li class="c10 li-bullet-0"><span>M2S is a new DDPM-based image inpainting method that is 60 times faster than RePaint: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/linghuyuhangyuan/M2S&amp;sa=D&amp;source=editors&amp;ust=1730413583466287&amp;usg=AOvVaw1ZPSyX_FAX3Brs8OTGSDoY">https://github.com/linghuyuhangyuan/M2S</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image114.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c22 c161 c97 c105 li-bullet-0"><span>How the computer games industry is embracing AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/business-68844761&amp;sa=D&amp;source=editors&amp;ust=1730413583466748&amp;usg=AOvVaw3oLxae59NIWwJp6Fjzza7v">https://www.bbc.com/news/business-68844761</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">Andrew Maximov has been working in the computer games industry for 12 years&hellip; he believes that artificial intelligence (AI) will play a crucial role in keeping the soaring costs of game production down, and save video game designers vital time by automating repetitive tasks.</span></li><li class="c22 c167 c86 li-bullet-0"><span class="c112 c37 c35 c48 c120">His company, Promethean AI offers developers a set of tools to craft their own virtual worlds. Mr Maximov hopes to disrupt the way games are currently produced.</span></li><li class="c22 c167 c86 li-bullet-0"><span class="c112 c37 c35 c48 c120">Californian software firm Inworld is also employing AI to build elements of computer games.</span></li><li class="c22 c167 c86 li-bullet-0"><span class="c112 c37 c35 c48 c120">It has created an engine that allows developers to add realism to game worlds and emotional depth to characters. The firm is also working on what it calls a narrative graph, developed in partnership with Xbox, which will use AI to help create storylines.</span></li><li class="c22 c167 c86 li-bullet-0"><span class="c112 c37 c35 c48 c120">&quot;The engine allows developers to add AI agents that can see, sense, and perceive the world around them, while also interacting with players and taking in-game actions. When you can imbue virtual characters with advanced cognitive capabilities, it unlocks a completely new paradigm for storytelling and gameplay,&quot; he says.</span></li><li class="c22 c167 c86 li-bullet-0"><span class="c112 c37 c35 c48 c120">Nick Walton is the chief executive of gaming firm Latitude.io, and he believes AI has the power to personalise the gaming experience.</span></li><li class="c22 c167 c86 li-bullet-0"><span class="c112 c37 c35 c48 c120">&quot;We are at the start with AI and as it advances we will see very dynamic, adaptive worlds with characters that feel alive, with story arcs where you as the hero are doing unique things and having a very unique impact on the world.</span></li><li class="c22 c86 c167 li-bullet-0"><span class="c112 c37 c35 c48 c120">&quot;You could play a game where you find a town that no-one else cares about and no other player has spent time in, and you can get really invested in it and develop relationships with all the characters in it,&quot; he tells the BBC.</span></li><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">The chief executive of computer games giant EA, Andrew Wilson, recently told delegates at a conference that around 60% of the game publisher&#39;s development processes could be affected by AI tools</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c24">PICA can generate high-fidelity animatable clothed human avatars with physics-accurate dynamics, even for loose clothing, from multi-view videos: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://ustc3dv.github.io/PICA/&amp;sa=D&amp;source=editors&amp;ust=1730413583467725&amp;usg=AOvVaw3hL8cv2ck3EO02gdlic9_i">https://ustc3dv.github.io/PICA/</a></span></li><li class="c10 li-bullet-0"><span class="c31">Extremely dynamic image to video: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1813486936868213073&amp;sa=D&amp;source=editors&amp;ust=1730413583467962&amp;usg=AOvVaw0MPJ6ldHiUIOvmZqGL1Xi8">https://x.com/dreamingtulpa/status/1813486936868213073</a></span></li><li class="c10 li-bullet-0"><span class="c24">&#39;AI will become the new normal&rsquo;: how the art world&#39;s technological boom is changing the industry: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.theartnewspaper.com/2023/02/28/ai-will-become-the-new-normal-how-the-art-worlds-technological-boom-is-changing-the-industry&amp;sa=D&amp;source=editors&amp;ust=1730413583468221&amp;usg=AOvVaw1kBlmIzRCHrI8b_Sq9INAt">https://www.theartnewspaper.com/2023/02/28/ai-will-become-the-new-normal-how-the-art-worlds-technological-boom-is-changing-the-industry</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">Art created using artificial intelligence (AI) is burgeoning. From commercial gallery shows&mdash;including Jon Rafman&rsquo;s large-scale, algorithmically generated paintings at Spr&uuml;th Magers in London (Ebrah k&rsquo;dabri, until 25 March)&mdash;to the PATH-AI artist residency organised in collaboration with London&rsquo;s Somerset House, AI-related art projects are springing up everywhere.</span></li><li class="c7 li-bullet-0"><span class="c24">Artists in the field stress that AI is prompting a paradigm shift. Rafman says: &quot;</span><span class="c24 c34">I have been using AI in one form or another since I began making art on computers in the 1990s.</span><span class="c112 c37 c35 c48 c120">&nbsp;I only truly started using image-generating AI tools around 2020.&quot;</span></li><li class="c7 li-bullet-0"><span class="c24 c15">His 40-minute film at Spr&uuml;th Magers, Counterfeit Poast (2023), is entirely generated from AI imagery</span><span class="c24">; the characters in it are animated using an iPhone facial motion-capture app. &ldquo;AI has the potential to </span><span class="c24 c34">open the gates for new perceptions of image-making just as the development of photography liberated painting from pure factual representation and allowed painters to focus on other dimensions</span><span class="c112 c37 c35 c48 c120">, such as colour, light, and movement,&rdquo; Rafman adds.</span></li><li class="c7 li-bullet-0"><span class="c24">The German digital artist Mario Klingemann </span><span class="c24 c15">has been working with AI since 2015, developing works such as Memories of Passersby 1 (2018), which employ a system of neural networks to generate a never-ending stream of portraits</span><span class="c24">. &ldquo;I think </span><span class="c24 c34">artists should embrace or at least try out the possibilities that AI offers</span><span class="c24">,&rdquo; he says. &ldquo;This technology will become the new normal.&rdquo;Klingemann explains how he harnesses AI, creating works where the boundaries between human influence and machine creation become increasingly blurred. Botto, for instance, is a project to create an entity that can be perceived as an autonomous artist. &ldquo;It is set up as a </span><span class="c24 c34">hybrid between an AI that makes its own creative decisions and a community of human stewards that vote on Botto&rsquo;s proposals and thereby curate the output and indirectly steer the artistic development of the machine</span><span class="c112 c37 c35 c48 c120">,&rdquo; he says.</span></li><li class="c7 li-bullet-0"><span class="c24">Three artists have been selected for the six-month remote artist residency programme PATH-AI, which has been developed by the Alan Turing Institute in London, the University of Edinburgh and the RIKEN research institute in Japan. The AI-inspired works of Nouf Aljowaysir, Chris Zhongtian Yuan, and Juan Covelli are presented on Somerset House&rsquo;s online curated space known as Channel. Brooklyn-based Aljowaysir has made a film, Ana Min Wein (Where Am I From?), which tracks her immigration path to the US, charting her family&rsquo;s migration history across Saudi Arabia and Iraq. </span><span class="c112 c15 c35 c48 c120">An AI assistant supports her journey in a film.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c24">Video frame interpolation: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1813969140517904831&amp;sa=D&amp;source=editors&amp;ust=1730413583469187&amp;usg=AOvVaw1zcFPiFUhCQ6i0UVemyHP3">https://x.com/dreamingtulpa/status/1813969140517904831</a></span></li><li class="c10 li-bullet-0"><span class="c24">Creating specific colors and shapes in images: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1814212221649457512/photo/4&amp;sa=D&amp;source=editors&amp;ust=1730413583469436&amp;usg=AOvVaw0zt6EJkgq-etHx4m5pkinY">https://x.com/dreamingtulpa/status/1814212221649457512/</a></span></li><li class="c10 li-bullet-0"><span class="c24">We recently announced JASCO, a music-generation model with improved controllability using conditioning inputs like chords or beat: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIatMeta/status/1814405505789706253&amp;sa=D&amp;source=editors&amp;ust=1730413583469653&amp;usg=AOvVaw35A64hANT6ARJWSuaw3tht">https://x.com/AIatMeta/status/1814405505789706253</a></span></li><li class="c10 li-bullet-0"><span class="c24">4D reconstruction from a video: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1814156712175083539&amp;sa=D&amp;source=editors&amp;ust=1730413583469867&amp;usg=AOvVaw2NEl1hdtATm5OXcCqkeyDs">https://x.com/_akhaliq/status/1814156712175083539</a></span></li><li class="c10 li-bullet-0"><span class="c24">Combining AI with CGI: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/c_valenzuelab/status/1813954465667457412&amp;sa=D&amp;source=editors&amp;ust=1730413583470058&amp;usg=AOvVaw1nVgIkGBKXoc46rLPfRjjA">https://x.com/c_valenzuelab/status/1813954465667457412</a></span></li><li class="c10 li-bullet-0"><span class="c24">McDonalds ad: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/&amp;sa=D&amp;source=editors&amp;ust=1730413583470278&amp;usg=AOvVaw3FYi6zmviGgaZRL_f89d-0">https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c24">Change backgrounds and animate person based on an image and pose guidance video: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1815059351486316779&amp;sa=D&amp;source=editors&amp;ust=1730413583470502&amp;usg=AOvVaw3KRVno9by12KIOv28be76x">https://x.com/dreamingtulpa/status/1815059351486316779</a></span></li><li class="c4 li-bullet-0"><span class="c24">Animate3D can animate any static multi-view 3D model: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1815295122164068801&amp;sa=D&amp;source=editors&amp;ust=1730413583470719&amp;usg=AOvVaw18YZ5Smorq39Y2z9GX8613">https://x.com/dreamingtulpa/status/1815295122164068801</a></span></li><li class="c4 li-bullet-0"><span class="c14">MusiConGen, Rhythm and Chord Control for Transformer-Based Text-to-Music Generation: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.15060&amp;sa=D&amp;source=editors&amp;ust=1730413583470927&amp;usg=AOvVaw0gwSd3mGPJ9zw2Lgt704Ud">https://huggingface.co/papers/2407.15060</a></span></li><li class="c4 li-bullet-0"><span class="c24">Lite2Relight can relight human portraits while preserving 3D consistency and identity: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1816146758608605362&amp;sa=D&amp;source=editors&amp;ust=1730413583471125&amp;usg=AOvVaw1NOqqozSCbSw2wp39ZpcPr">https://x.com/dreamingtulpa/status/1816146758608605362</a></span></li><li class="c4 li-bullet-0"><span class="c24">Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency: We present Stable Video 4D (SV4D), a latent video diffusion model for multi-frame and multi-view consistent dynamic 3D content generation. Unlike previous methods that rely on separately trained </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1816146758608605362&amp;sa=D&amp;source=editors&amp;ust=1730413583471387&amp;usg=AOvVaw3_UMxfrSORJkVGWqoswdFB">https://x.com/dreamingtulpa/status/1816146758608605362</a></span></li><li class="c4 li-bullet-0"><span class="c24">Similar to creative upscaling in images, Noise Calibration can improve the visual quality of videos while maintaining the structure of the input video: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1816441922589708291&amp;sa=D&amp;source=editors&amp;ust=1730413583471714&amp;usg=AOvVaw0zckzVf6ELaglwse6Z47bF">https://x.com/dreamingtulpa/status/1816441922589708291</a></span></li><li class="c4 li-bullet-0"><span class="c24">Excellent video to video: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/8bit_e/status/1818246916129329464&amp;sa=D&amp;source=editors&amp;ust=1730413583472030&amp;usg=AOvVaw1np1zKv-osT2j0zWzJ38Kf">https://x.com/8bit_e/status/1818246916129329464</a></span></li><li class="c4 li-bullet-0"><span>Ubisoft and MiHoYo Among Publishers Signing Up for Nvidia&#39;s AI-Generated Video Character Tool: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ign.com/articles/ubisoft-and-mihoyo-nvidia-ace-ai-video-character-tool&amp;sa=D&amp;source=editors&amp;ust=1730413583472364&amp;usg=AOvVaw2qVZ390hvUo09-smvgy-UU">https://www.ign.com/articles/ubisoft-and-mihoyo-nvidia-ace-ai-video-character-tool</a></span></li><li class="c4 li-bullet-0"><span>Genshin Impact developers talk about how they used AI in their hit game Honkai: Star Rail: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.as.com/meristation/news/genshin-impact-developers-talk-about-how-they-used-ai-in-their-hit-game-honkai-star-rail-n/&amp;sa=D&amp;source=editors&amp;ust=1730413583472640&amp;usg=AOvVaw0xgh8M4qzQJVrbdKFr7u2f">https://en.as.com/meristation/news/genshin-impact-developers-talk-about-how-they-used-ai-in-their-hit-game-honkai-star-rail-n/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c1">The new miHoYo game already uses artificial intelligence techniques, but they have not used it to write narrative content, paying attention to &ldquo;its impact&rdquo;.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>miHoYo co-authors science paper outlining bold AI intentions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pocketgamer.biz/mihoyo-co-authors-science-paper-outlining-bold-ai-intentions/&amp;sa=D&amp;source=editors&amp;ust=1730413583473019&amp;usg=AOvVaw1v9n-DsW8p4DoMT0ie8GhF">https://www.pocketgamer.biz/mihoyo-co-authors-science-paper-outlining-bold-ai-intentions/</a></span></li><li class="c4 li-bullet-0"><span>LumaLabsAI - Dream Machine 1.5 is here. Now with higher-quality text-to-video, smarter understanding of your prompts, custom text rendering, and improved image-to-video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/LumaLabsAI/status/1825639918539817101&amp;sa=D&amp;source=editors&amp;ust=1730413583473253&amp;usg=AOvVaw1JxpU-yHBKL7Mytb-RXMOs">https://x.com/LumaLabsAI/status/1825639918539817101</a></span></li><li class="c4 li-bullet-0"><span>Ideagram 2.0: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/&amp;sa=D&amp;source=editors&amp;ust=1730413583473507&amp;usg=AOvVaw0368_rAFvHeH35bRi8ap-P">https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/</a></span></li><li class="c4 li-bullet-0"><span>Diffusion models as real-time interactive game engines: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://gamengen.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583473769&amp;usg=AOvVaw2EP2fclyEmxNmtK9z1diY5">https://gamengen.github.io/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://gamegen-o.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583473966&amp;usg=AOvVaw3EJn3CTiQfG1OdtucgowB5">https://gamegen-o.github.io/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Doodle to image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Holdmywallet/comments/1f5qqaf/ms_paint_may_not_be_so_useless_now/&amp;sa=D&amp;source=editors&amp;ust=1730413583474186&amp;usg=AOvVaw2ir1xLdxYRe-1uQUDfHN-M">https://www.reddit.com/r/Holdmywallet/comments/1f5qqaf/ms_paint_may_not_be_so_useless_now/</a></span></li><li class="c4 li-bullet-0"><span>Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1831530803635085766/mediaViewer?currentTweet%3D1831530803635085766%26currentTweetUser%3D_akhaliq&amp;sa=D&amp;source=editors&amp;ust=1730413583474424&amp;usg=AOvVaw0YHNg9BuLhZgFTgCoRsPmR">https://x.com/_akhaliq/status/1831530803635085766</a></span></li><li class="c4 li-bullet-0"><span>Domo AI just launched its video upscaler. It&#39;s fast and scales videos up to 4K: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fdw8xm/domo_ai_just_launched_its_video_upscaler_its_fast/&amp;sa=D&amp;source=editors&amp;ust=1730413583474749&amp;usg=AOvVaw142seE6Laxaifihzb27iob">https://www.reddit.com/r/singularity/comments/1fdw8xm/domo_ai_just_launched_its_video_upscaler_its_fast/</a></span></li><li class="c4 li-bullet-0"><span>NotebookLM now lets you listen to a conversation about your sources (Create a two person podcast from your sources): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blog.google/technology/ai/notebooklm-audio-overviews/&amp;sa=D&amp;source=editors&amp;ust=1730413583474965&amp;usg=AOvVaw0JDX39utcgxCNhyBOOXoua">https://blog.google/technology/ai/notebooklm-audio-overviews/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span>Example of Cicero&rsquo;s journal from Skyrim: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://vocaroo.com/1nTyEIEqGavr&amp;sa=D&amp;source=editors&amp;ust=1730413583475143&amp;usg=AOvVaw0kFp2lgOxAFzRxgQjt5LEw">https://vocaroo.com/1nTyEIEqGavr</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Hasbro&rsquo;s CEO Thinks D&amp;D&lsquo;s Adoption of AI Is Inevitable: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://gizmodo.com/hasbro-ceo-dungeons-dragons-ai-2000498007&amp;sa=D&amp;source=editors&amp;ust=1730413583475349&amp;usg=AOvVaw18k6NP95fMHcMn3yJGYkI_">https://gizmodo.com/hasbro-ceo-dungeons-dragons-ai-2000498007</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span>&ldquo;If you look at a typical D&amp;D player&hellip; I play with probably 30 or 40 people regularly. There&rsquo;s not a single person who doesn&rsquo;t use AI somehow for either campaign development or character development or story ideas,&rdquo;</span><span class="c92 c37 c63 c76 c241">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>New Dungeons &amp; Dragons Sourcebook Features AI Generated Art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://gizmodo.com/dnd-ai-art-bigbys-giants-book-artist-generators-wotc-1850710496&amp;sa=D&amp;source=editors&amp;ust=1730413583475685&amp;usg=AOvVaw1w9mCY7i0jxPsqARpK2PTz">https://gizmodo.com/dnd-ai-art-bigbys-giants-book-artist-generators-wotc-1850710496</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">An artist for Bigby Presents: Glory of the Giants! has admitted to using AI to generate &quot;certain details&quot; of new art for the sourcebook.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 457.33px;"><img alt="" src="images/image349.png" style="width: 624.00px; height: 457.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Runway and Lionsgate are partnering to explore the use of AI in film production: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://runwayml.com/news/runway-partners-with-lionsgate&amp;sa=D&amp;source=editors&amp;ust=1730413583476041&amp;usg=AOvVaw31ptHdrQPGXSI8VVPvGI7g">https://runwayml.com/news/runway-partners-with-lionsgate</a></span></li><li class="c4 li-bullet-0"><span>Adding movement to images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fk4tgp/kling_ai_showcasing_the_use_of_the_motion_brush/&amp;sa=D&amp;source=editors&amp;ust=1730413583476262&amp;usg=AOvVaw3NmGcrvbVZ1D7s76XGQCD5">https://www.reddit.com/r/singularity/comments/1fk4tgp/kling_ai_showcasing_the_use_of_the_motion_brush/</a></span></li><li class="c4 li-bullet-0"><span>EA demonstrates upcoming text-to-game system that can create playable game content in real time: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.instagram.com/p/DAIytFyg9Mh/?igsh%3DMTc4MmM1YmI2Ng%3D%3D&amp;sa=D&amp;source=editors&amp;ust=1730413583476539&amp;usg=AOvVaw3S-9zr1L1gzdAGFXaHf6rp">https://www.instagram.com/p/DAIytFyg9Mh/?igsh=MTc4MmM1YmI2Ng==</a></span></li><li class="c4 li-bullet-0"><span>SPARK can create high-quality 3D face avatars from regular videos and track expressions and poses in real time. It improves the accuracy of 3D face reconstructions for tasks like aging, face swapping, and digital makeup: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fnos0u/spark_can_create_highquality_3d_face_avatars_from/&amp;sa=D&amp;source=editors&amp;ust=1730413583476792&amp;usg=AOvVaw0wziUpqzpBCQq-5rpykfXy">https://www.reddit.com/r/singularity/comments/1fnos0u/spark_can_create_highquality_3d_face_avatars_from/</a></span></li><li class="c4 li-bullet-0"><span>Horror film made with AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1fom28b/the_cartoonist_horror_short_film/&amp;sa=D&amp;source=editors&amp;ust=1730413583477075&amp;usg=AOvVaw0Dbx_j3wLChlLp-yZ7U56j">https://www.reddit.com/r/aivideo/comments/1fom28b/the_cartoonist_horror_short_film/</a></span></li><li class="c4 li-bullet-0"><span>Humorous film: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1fo09ic/how_minimax_gordon_ramsay_videos_are_actually/&amp;sa=D&amp;source=editors&amp;ust=1730413583477304&amp;usg=AOvVaw16sE-dOQ-xuysDjxBZERJ_">https://www.reddit.com/r/aivideo/comments/1fo09ic/how_minimax_gordon_ramsay_videos_are_actually/</a></span></li><li class="c4 li-bullet-0"><span>New video generation AI can create videos with rack focus: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheoMediaAI/status/1840834127697703262&amp;sa=D&amp;source=editors&amp;ust=1730413583477503&amp;usg=AOvVaw2r9WSQkBKrztNJHNSFL_Rn">https://x.com/TheoMediaAI/status/1840834127697703262</a></span></li><li class="c4 li-bullet-0"><span>Snoop Dogg&#39;s latest music video is AI-generated and took months to create: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://community.designtaxi.com/topic/5461-snoop-doggs-latest-music-video-is-ai-generated-and-took-months-to-create/&amp;sa=D&amp;source=editors&amp;ust=1730413583477739&amp;usg=AOvVaw2ehwR0qUiAiJvErmaTJShf">https://community.designtaxi.com/topic/5461-snoop-doggs-latest-music-video-is-ai-generated-and-took-months-to-create/</a></span></li><li class="c4 li-bullet-0"><span>Late Night With the Devil movie uses AI art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://letterboxd.com/film/late-night-with-the-devil/&amp;sa=D&amp;source=editors&amp;ust=1730413583477941&amp;usg=AOvVaw1yy2_XN37zLrHho4RRYX4B">https://letterboxd.com/film/late-night-with-the-devil/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span>Recommended by Chainsaw Man/Look Back/Goodbye Eri author Tatsuki Fujimoto: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 464.00px;"><img alt="" src="images/image162.png" style="width: 624.00px; height: 464.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Other people like it too: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/&amp;sa=D&amp;source=editors&amp;ust=1730413583478302&amp;usg=AOvVaw1VPLkCYbyzL-Pdp_xXH-f4">https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/</a></span></li><li class="c10 li-bullet-0"><span class="c1">3.4 out of 5 on Letterboxed despite anti AI review bombing </span></li><li class="c10 li-bullet-0"><span>Photo manipulation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fwr3lg/realtime_head_transformation_demo/&amp;sa=D&amp;source=editors&amp;ust=1730413583478590&amp;usg=AOvVaw179AuExyp3qWIzohPAZAiA">https://www.reddit.com/r/singularity/comments/1fwr3lg/realtime_head_transformation_demo/</a></span></li><li class="c10 li-bullet-0"><span>Inverse Painting can generate time-lapse videos of the painting process for any artwork. The method learns from diverse drawing techniques, producing realistic results across different artistic styles: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://reddit.com/r/singularity/comments/1fybddi/inverse_painting_can_generate_timelapse_videos_of/&amp;sa=D&amp;source=editors&amp;ust=1730413583478829&amp;usg=AOvVaw3WhgasNLTKACq6octlASMo">https://reddit.com/r/singularity/comments/1fybddi/inverse_painting_can_generate_timelapse_videos_of/</a></span></li><li class="c10 li-bullet-0"><span>Runway CEO Crist&oacute;bal Valenzuela says AI is coming to Hollywood and demos tools that move beyond text prompts to give filmmakers greater control over video generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g0uwdo/runway_ceo_crist%25C3%25B3bal_valenzuela_says_ai_is_coming/&amp;sa=D&amp;source=editors&amp;ust=1730413583479092&amp;usg=AOvVaw0bg8Kjttxm_hjWhIb6PPwX">https://www.reddit.com/r/singularity/comments/1g0uwdo/runway_ceo_crist%C3%B3bal_valenzuela_says_ai_is_coming/</a></span></li><li class="c10 li-bullet-0"><span>Editing 3d scenes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/Fangkang515/CE3D&amp;sa=D&amp;source=editors&amp;ust=1730413583479319&amp;usg=AOvVaw1oL5Dw0ccdDSbgiMu1YWbE">https://github.com/Fangkang515/CE3D</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Very useful for VFX: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/sainimatic/status/1847677298549674007&amp;sa=D&amp;source=editors&amp;ust=1730413583479527&amp;usg=AOvVaw2aqHbA8uiaJMA2KCXCyYhu">https://x.com/sainimatic/status/1847677298549674007</a></span></li><li class="c4 li-bullet-0"><span>Introducing Voice Design by ElevenLabs - Generate a unique voice from a text prompt alone: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1gabx6a/introducing_voice_design_by_elevenlabs_generate_a/&amp;sa=D&amp;source=editors&amp;ust=1730413583479764&amp;usg=AOvVaw3P1FeXiuqSo_tSvF4Sni02">https://www.reddit.com/r/singularity/comments/1gabx6a/introducing_voice_design_by_elevenlabs_generate_a</a></span></li><li class="c4 li-bullet-0"><span>Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve &ldquo;hundreds&rdquo; of people at the company and will primarily focus on post-production and visual effects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.thewrap.com/disney-ai-initiative/&amp;sa=D&amp;source=editors&amp;ust=1730413583480068&amp;usg=AOvVaw0u08HIIHTZkZyQchS11-yj">https://www.thewrap.com/disney-ai-initiative/</a></span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language&amp;sa=D&amp;source=editors&amp;ust=1730413583480299&amp;usg=AOvVaw0kquFVBkoWHIFrLBNYaMXX">https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image419.png" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 560.80px; height: 421.50px;"><img alt="" src="images/image96.png" style="width: 560.80px; height: 421.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Style control: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 221.33px;"><img alt="" src="images/image7.png" style="width: 624.00px; height: 221.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h2 class="c64" id="h.akz9hanp4wxi"><span>4.2. Corporate Use</span></h2><ul class="c0 lst-kix_r953kfpy79kt-0 start"><li class="c4 li-bullet-0"><span class="c15">AI agents entering workplace: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bloomberg.com/news/newsletters/2024-10-24/ai-agents-have-officially-entered-the-workplace-flaws-and-all?srnd%3Dhomepage-americas&amp;sa=D&amp;source=editors&amp;ust=1730413583481205&amp;usg=AOvVaw1K7rIlFjcA6oswlYHETcmT">https://www.bloomberg.com/news/newsletters/2024-10-24/ai-agents-have-officially-entered-the-workplace-flaws-and-all</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span>&ldquo;</span><span class="c40 c37 c63 c14 c76">It is actually better than a human most of the time,&rdquo; said Amjad Masad, chief executive officer of Replit. &ldquo;Humans are kind of lazy and get annoyed and don&rsquo;t test everything. This is much more thorough.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c40 c37 c63 c14 c76">ServiceNow CEO Bill McDermott told my colleague Brody Ford this week that his company&rsquo;s new AI agents &ldquo;don&rsquo;t eat&rdquo; and can work 24/7. &ldquo;You don&rsquo;t have to give &lsquo;em a 401k!&rdquo; he added. The software company&rsquo;s agents are currently being tested out by some customers and will be released more broadly next month, he said.</span></li><li class="c10 li-bullet-0"><span class="c37 c63 c14 c76">In September, Salesforce Chief Operating Officer Brian Millham </span><span class="c5 c37 c63 c14 c76"><a class="c13" href="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2024-09-17/salesforce-ai-agent-strategy-acknowledges-job-losses-from-tech&amp;sa=D&amp;source=editors&amp;ust=1730413583481718&amp;usg=AOvVaw0aNLX9VhIxZzbZvvP3DDoJ">said</a></span><span class="c37 c63 c14 c76">&nbsp;customers using the company&rsquo;s agents may elect to hire fewer people going forward. He gave an example of a 5,000-person call center needing 30% fewer workers within five years.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Workers in a study got an AI assistant. They became happier, more productive, and less likely to quit: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/ai-boosts-productivity-happier-at-work-chatgpt-research-2023-4&amp;sa=D&amp;source=editors&amp;ust=1730413583482093&amp;usg=AOvVaw3iNWDGzSvqiAV-l9ARQyXN">https://www.businessinsider.com/ai-boosts-productivity-happier-at-work-chatgpt-research-2023-4</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span class="c1">From April 2023, before GPT 4 became widely used</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>randomized controlled trial using the older, </span><span class="c34">less-powerful GPT-3.5 powered Github Copilot </span><span>for 4,867 coders in Fortune 100 firms. It finds a </span><span class="c15">26.08% increase in completed tasks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4945566&amp;sa=D&amp;source=editors&amp;ust=1730413583482497&amp;usg=AOvVaw19SIc94iYJD6ICRHKQ-56g">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>According to Altman, </span><span class="c15">92 per cent of Fortune 500 companies were using OpenAI products,</span><span class="c1">&nbsp;including ChatGPT and its underlying AI model GPT-4, as of November 2023, while the chatbot has 100mn weekly users.</span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ft.com/content/81ac0e78-5b9b-43c2-b135-d11c47480119&amp;sa=D&amp;source=editors&amp;ust=1730413583482894&amp;usg=AOvVaw3J780601BDqk6CMNWq3SHh">https://www.ft.com/content/81ac0e78-5b9b-43c2-b135-d11c47480119</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span class="c15">Gen AI at work has surged 66% in the UK, but bosses aren&rsquo;t behind it: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://finance.yahoo.com/news/gen-ai-surged-66-uk-053000325.html&amp;sa=D&amp;source=editors&amp;ust=1730413583483177&amp;usg=AOvVaw3scNkPn2EQKP17Fhz3hPnn">https://finance.yahoo.com/news/gen-ai-surged-66-uk-053000325.html</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;of </span><span>the seven million British workers that Deloitte extrapolates have used GenAI at work, </span><span class="c15">only 27% reported that their employer officially encouraged this behavior</span><span class="c1">.</span></li><li class="c10 li-bullet-0"><span class="c15">Over 60% of people aged 16-34 have used GenAI, </span><span class="c1">compared with only 14% of those between 55 and 75 (older Gen Xers and Baby Boomers).</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 862.67px;"><img alt="" src="images/image331.png" style="width: 624.00px; height: 862.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span>Jobs impacted by AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.visualcapitalist.com/charted-the-jobs-most-impacted-by-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583483810&amp;usg=AOvVaw0jIfwfHQrttTosnANV2Ds6">https://www.visualcapitalist.com/charted-the-jobs-most-impacted-by-ai/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Big survey of 100,000 workers in Denmark 6 months ago finds </span><span class="c15">widespread adoption of ChatGPT </span><span>&amp; &ldquo;workers see a </span><span class="c15">large productivity potential of ChatGPT in their occupations, estimating it can halve working times in 37% of the job tasks for the typical worker</span><span>.&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://static1.squarespace.com/static/5d35e72fcff15f0001b48fc2/t/668d08608a0d4574b039bdea/1720518756159/chatgpt-full.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583484190&amp;usg=AOvVaw35T0-m6xsNg24F5SU6W1eb">https://static1.squarespace.com/static/5d35e72fcff15f0001b48fc2/t/668d08608a0d4574b039bdea/1720518756159/chatgpt-full.pdf</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;ChatGPT is widespread, with</span><span class="c15">&nbsp;over 50% of workers having used it,</span><span class="c1">&nbsp;but adoption rates vary across occupations.</span></li><li class="c10 li-bullet-0"><span>Workers see</span><span class="c33 c15">&nbsp;substantial productivity potential in ChatGPT, estimating it can halve working times in about a third of their job tasks.</span></li><li class="c10 li-bullet-0"><span>Barriers to adoption include employer restrictions, the need for training, and concerns about data confidentiality (</span><span class="c34">all fixable</span><span class="c1">, with the last one solved with locally run models or strict contracts with the provider).</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 414.67px;"><img alt="" src="images/image418.png" style="width: 624.00px; height: 414.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>AI Dominates Web Development: 63% of Developers Use AI Tools Like ChatGPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://flatlogic.com/starting-web-app-in-2024-research&amp;sa=D&amp;source=editors&amp;ust=1730413583484899&amp;usg=AOvVaw24rcrOpKeqpBZO9_CowZpm">https://flatlogic.com/starting-web-app-in-2024-research</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part&amp;sa=D&amp;source=editors&amp;ust=1730413583485202&amp;usg=AOvVaw0A9UdHUxlwSRQfelt7V_Qz">https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;Already, AI is being woven into the workplace at an unexpected scale. </span><span class="c15">75% of knowledge workers use AI at work today, </span><span class="c1">and 46% of users started using it less than six months ago.</span></li><li class="c10 li-bullet-0"><span>Users say AI helps them </span><span class="c33 c34">save time (90%), focus on their most important work (85%), be more creative (84%), and enjoy their work more (83%). </span></li><li class="c10 li-bullet-0"><span class="c15">78% of AI users are bringing their own AI tools to work </span><span>(BYOAI)&mdash;it&rsquo;s even </span><span class="c33 c34">more common at small and medium-sized companies (80%).</span></li><li class="c10 li-bullet-0"><span>53% of people who use AI at work worry that using it on important work tasks </span><span class="c33 c15">makes them look replaceable.</span></li><li class="c10 li-bullet-0"><span>While</span><span class="c15">&nbsp;some professionals worry AI will replace their job (45%),</span><span class="c1">&nbsp;about the same share (46%) say they&rsquo;re considering quitting in the year ahead&mdash;higher than the 40% who said the same ahead of 2021&rsquo;s Great Reshuffle.</span></li><li class="c10 li-bullet-0"><span class="c1">The heaviest Teams users (the top 5%) summarized 8 hours of meetings using Copilot in months of March, the equivalent of an entire workday.</span></li><li class="c10 li-bullet-0"><span class="c1">As AI use surges ahead, leaders who are &ldquo;extremely familiar&rdquo; with AI see its potential to be as transformational as the shift from a typewriter to a computer. Within the next five years, 41% of these leaders expect to redesign business processes from the ground up with AI. In the same time frame, they anticipate orchestrating (38%) and training a team of AI bots (42%), and ensuring the ethical use of AI (47%) will be a core part of their job.</span></li><li class="c10 li-bullet-0"><span class="c1">66% of leaders say they wouldn&rsquo;t hire someone without AI skill.</span></li><li class="c10 li-bullet-0"><span class="c1">71% say they&rsquo;d rather hire a less experienced candidate with AI skill than a more experienced candidate without them.</span></li><li class="c10 li-bullet-0"><span class="c1">And junior candidate may have a new edge: 77% of leaders say, with AI, early-in-career a talent will be given greater responsibilities.</span></li><li class="c10 li-bullet-0"><span>Documents: Overall, Copilot users </span><span class="c15">edited 10% more documents </span><span class="c1">in Word, Excel, and PowerPoint&mdash;the companies that saw the largest impact noticed a 20% increase. This may suggest that people are repurposing the time they save for high-value focus work like creating and consuming information.</span></li><li class="c10 li-bullet-0"><span>Power users are familiar to extremely familiar with AI, using it at work at least several times a week and saving more than 30 minutes a day. And it&rsquo;s paying off: power users say AI makes their ov</span><span class="c33 c34">erwhelming workload more manageable (92%), boosts their creativity (92%), and helps them focus on the most important work (93%)&mdash;and it helps them feel more motivated (91%) and enjoy work more (91%).</span></li><li class="c10 li-bullet-0"><span class="c1">Senior leaders lean in: AI power users are 61% more likely to hear from their CEO about the importance of using generative AI at work, 40% more likely to hear from the leader of their department, and 42% more likely to hear from their manager&rsquo;s manager.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 285.33px;"><img alt="" src="images/image620.png" style="width: 624.00px; height: 285.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-2 start"><li class="c7 li-bullet-0"><span class="c1">Skeptics are gray and even most of them say AI is helpful for productivity, motivation, and enjoyment</span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 256.00px;"><img alt="" src="images/image128.png" style="width: 624.00px; height: 256.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>2024 McKinsey survey on AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583487127&amp;usg=AOvVaw18Vr16OVIdm1hkzADJLo9V">https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;For the past six years, AI adoption by respondents&rsquo; organizations has hovered at about 50 percent. This year, the survey finds that </span><span class="c15">adoption has jumped to 72 percent</span><span>&nbsp;(Exhibit 1). And the interest is truly global in scope. Our 2023 survey found that AI adoption did not reach 66 percent in any region; however, this year </span><span class="c33 c15">more than two-thirds of respondents in nearly every region say their organizations are using AI</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;In the latest McKinsey Global Survey on AI, </span><span class="c33 c15">65 percent of respondents report that their organizations are regularly using gen AI, nearly double the percentage from our previous survey just ten months ago.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;Respondents&rsquo;</span><span class="c15">&nbsp;expectations for gen AI&rsquo;s impact remain as high as they were last year</span><span>, with </span><span class="c33 c15">three-quarters predicting that gen AI will lead to significant or disruptive change in their industries in the years ahead</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;Organizations are </span><span class="c15">already seeing material benefits from gen AI use, reporting both cost decreases and revenue jumps</span><span class="c1">&nbsp;in the business units deploying the technology.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span class="c99 c37 c65 c60 c144">They have a graph showing about 50% of companies decreased their HR, service operations, and supply chain management costs using gen AI and 62% increased revenue in risk, legal, and compliance, 56% in IT, and 53% in marketing </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 413.33px;"><img alt="" src="images/image192.png" style="width: 624.00px; height: 413.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 448.00px;"><img alt="" src="images/image239.png" style="width: 624.00px; height: 448.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image257.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c33 c34"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Scale.ai report says 85% of companies have seen benefits from gen AI. Only 8% that implemented it did not see any positive outcomes.: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://scale.com/ai-readiness-report%23section-download&amp;sa=D&amp;source=editors&amp;ust=1730413583488553&amp;usg=AOvVaw2rThAUz6GXLGg2ktQ9DqmS">https://scale.com/ai-readiness-report</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 524.00px;"><img alt="" src="images/image171.png" style="width: 624.00px; height: 524.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span>&gt;82% of companies surveyed are testing and evaluating models. </span></li></ul><p class="c238 c46"><span class="c1"></span></p><p class="c46 c238"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c78 c228 li-bullet-0"><span>Most office workers expect AI to improve their jobs, report reveals: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.peoplemanagement.co.uk/article/1878419/office-workers-expect-ai-improve-jobs-report-reveals&amp;sa=D&amp;source=editors&amp;ust=1730413583489105&amp;usg=AOvVaw3MhEKzrtMOVJCyyz8JJL9Z">https://www.peoplemanagement.co.uk/article/1878419/office-workers-expect-ai-improve-jobs-report-reveals</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c22 c95 c105 li-bullet-0"><span class="c40 c36">The vast majority (85 per cent) of office workers believe AI will enhance their roles instead of replace them, research by Jitterbit has revealed. </span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c36">According to the poll of 1,022 full-time office workers in the US and the UK, 96 per cent of office workers think AI can improve their professional skills.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c36 c14">&ldquo;The very fact that there&rsquo;s now less fear that AI is going to replace roles is a clear sign that confidence in AI is rising. With mounting economic pressures, workload and delivery expectations for employees are high, meaning more employees are using AI to save time and improve the quality and speed of their work, which is a clear benefit to business.</span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>People managers admit to using AI for performance reviews and feedback, research finds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.peoplemanagement.co.uk/article/1875801/people-managers-admit-using-ai-performance-reviews-feedback-research-finds&amp;sa=D&amp;source=editors&amp;ust=1730413583489903&amp;usg=AOvVaw0FhAjZvKJhgLOPIiS_SQ1D">https://www.peoplemanagement.co.uk/article/1875801/people-managers-admit-using-ai-performance-reviews-feedback-research-finds</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c22 c95 c105 li-bullet-0"><span class="c40 c36 c14">Half (52 per cent) of people managers in the UK have used generative AI tools in their role, research by Visier has revealed.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c36 c14">The survey of more than 750 people managers also found that three in five (59 per cent) UK respondents who already utilise the technology were using it for performance reviews and feedback. </span></li><li class="c22 c95 c105 li-bullet-0"><span class="c36 c14">A further 41 per cent said they used it to help make people-related decisions, while 36 per cent used it to develop scripts to use ahead of conversations.</span></li></ul><p class="c9"><span class="c40 c42 c37"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Workers turning to social media and AI to learn new skills, research finds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.peoplemanagement.co.uk/article/1874165/workers-turning-social-media-ai-learn-new-skills-research-finds&amp;sa=D&amp;source=editors&amp;ust=1730413583490847&amp;usg=AOvVaw3c0z5RkqXici47zJ5L2BD1">https://www.peoplemanagement.co.uk/article/1874165/workers-turning-social-media-ai-learn-new-skills-research-finds</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span class="c40 c36 c14">More than half (56 per cent) of employees aged 18-24 and 36 per cent of 25-34 year olds said they had explored generative AI as a way to develop these workplace skills, compared to just 15 per cent of those aged 55-64.</span></li><li class="c10 li-bullet-0"><span class="c36 c14">&nbsp;</span><span class="c20 c36 c242"><a class="c13" href="https://www.google.com/url?q=https://www.linkedin.com/posts/peoplemanagementmag_workers-are-finding-alternative-ways-to-learn-activity-7199406500082012161-mFZb?utm_source%3Dshare%26utm_medium%3Dmember_desktop&amp;sa=D&amp;source=editors&amp;ust=1730413583491396&amp;usg=AOvVaw2R6fv1rtfVQpoYL5dokkB-">People Management poll</a></span><span class="c40 c36 c14">&nbsp;revealed that 63 per cent agreed social media and AI are good ways for employees to learn workplace skills</span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Half of Gen Z think ChatGPT gives better career advice than managers &ndash; People Management puts it to the test </span><span class="c5 c36 c14"><a class="c13" href="https://www.google.com/url?q=https://www.peoplemanagement.co.uk/article/1862583/half-gen-z-think-chatgpt-gives-better-career-advice-managers-%25E2%2580%2593-people-management-puts-test&amp;sa=D&amp;source=editors&amp;ust=1730413583491867&amp;usg=AOvVaw1vGd5zzuVywk6ng2UlzLO5">https://www.peoplemanagement.co.uk/article/1862583/half-gen-z-think-chatgpt-gives-better-career-advice-managers-%E2%80%93-people-management-puts-test</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span class="c36 c14">Almost half (47 per cent) of Gen Z workers say they get better careers advice from ChatGPT than their managers, a </span><span class="c20 c36 c14 c230"><a class="c13" href="https://www.google.com/url?q=https://resources.intoo.com/about-intoo/intoo-unlocking-organizational-success-report-2024?aliId%3DeyJpIjoiS25zdFZtc1lxMnBmb2ZjVyIsInQiOiJwbW9Bb2o0bklxVVQzUEwxcEt4elBRPT0ifQ%25253D%25253D&amp;sa=D&amp;source=editors&amp;ust=1730413583492323&amp;usg=AOvVaw1a1piXUyd4x-EkNsjly7_R">report by INTOO and Workplace Intelligence</a></span><span class="c36 c14">&nbsp;has found.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>JP Morgan on adoption and cost savings led by generative AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583492902&amp;usg=AOvVaw0y2L-1CF96rYXC_AMxcjRQ">https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span class="c1">Says Nvidia&rsquo;s growth is not like the dot-com bubble because it has the earnings boost to back up its stock performance while companies during the bubble did not. Its earnings and revenue are still increasing, meaning companies are not slowing down their AI investments </span></li><li class="c10 li-bullet-0"><span class="c1">McKinsey says AI can add $8 trillion to the economy each year</span></li><li class="c10 li-bullet-0"><span class="c1">Y Combinator is all in on AI and it has a great track record (176% average annual return since 2005)</span></li><li class="c10 li-bullet-0"><span class="c1">AI performance metrics are quickly becoming obsolete </span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-2 start"><li class="c7 li-bullet-0"><span class="c1">Claude 3.5 Sonnet (which is weaker than the upcoming Claude 3.5 Opus model) scores about 60% in the GQPA. PhDs score about 65% in their field of expertise and 34% on all the subjects overall, even with unrestricted internet access</span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c10 li-bullet-0"><span class="c1">Google study found 80% of all jobs have at least 10% of tasks that can be done twice as quickly with AI</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 397.33px;"><img alt="" src="images/image49.jpg" style="width: 624.00px; height: 397.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 368.00px;"><img alt="" src="images/image503.jpg" style="width: 624.00px; height: 368.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 356.00px;"><img alt="" src="images/image55.jpg" style="width: 624.00px; height: 356.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 385.33px;"><img alt="" src="images/image27.jpg" style="width: 624.00px; height: 385.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c188 c78 li-bullet-0"><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/artificial-intelligence/china-leads-world-adoption-generative-ai-survey-shows-2024-07-09/&amp;sa=D&amp;source=editors&amp;ust=1730413583494542&amp;usg=AOvVaw2slIloP_D-7FpSLTxO4jx-">https://www.reuters.com/technology/artificial-intelligence/china-leads-world-adoption-generative-ai-survey-shows-2024-07-09/</a></span></li></ul><p class="c46 c188"><span class="c92 c37 c185 c35 c48"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c188 c97 c105 li-bullet-0"><span class="c92 c37 c185 c35 c48">&gt;In a survey of 1,600 decision-makers in industries worldwide by U.S. AI and analytics software company SAS and Coleman Parkes Research, 83% of Chinese respondents said they used generative AI, the technology underpinning ChatGPT.</span></li><li class="c188 c97 c105 li-bullet-0"><span class="c92 c37 c185 c35 c48">That was higher than the 16 other countries and regions in the survey, including the United States, where 65% of respondents said they had adopted GenAI.</span></li><li class="c188 c97 c105 li-bullet-0"><span class="c92 c37 c185 c35 c48">The global average was 54%.</span></li></ul><p class="c188 c46"><span class="c92 c37 c185 c35 c48"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 754.67px;"><img alt="" src="images/image593.png" style="width: 624.00px; height: 754.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c32 li-bullet-0"><span class="c5 c14 c169"><a class="c13" href="https://www.google.com/url?q=https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave&amp;sa=D&amp;source=editors&amp;ust=1730413583495482&amp;usg=AOvVaw3rRt5qhU9wNflg1WWHxsWf">https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave</a></span></li></ul><p class="c22 c44"><span class="c92 c83 c37 c48 c14"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c22 c72 li-bullet-0"><span class="c83 c14">&gt;&rdquo;Microsoft has previously disclosed its billion-dollar AI investments have brought developments and productivity savings. These include an HR Virtual Agent bot which it says has saved 160,000 hours</span><span class="c83 c34 c14">&nbsp;</span><span class="c92 c83 c37 c48 c14">for HR service advisors by answering routine questions.&rdquo;</span></li></ul><p class="c22 c44"><span class="c92 c83 c37 c48 c14"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Morgan Stanley CEO says AI could save financial advisers 10-15 hours a week: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://finance.yahoo.com/news/morgan-stanley-ceo-says-ai-170953107.html&amp;sa=D&amp;source=editors&amp;ust=1730413583496213&amp;usg=AOvVaw0rrTYIr2STokEQ2qhOj7i5">https://finance.yahoo.com/news/morgan-stanley-ceo-says-ai-170953107.html</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Goldman Sachs CIO on How the Bank Is Actually Using AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://omny.fm/shows/odd-lots/080624-odd-lots-marco-argenti-v1?in_playlist%3Dpodcast&amp;sa=D&amp;source=editors&amp;ust=1730413583496669&amp;usg=AOvVaw1hJw_6NqCPIjk1hDf3PrZf">https://omny.fm/shows/odd-lots/080624-odd-lots-marco-argenti-v1?in_playlist=podcast</a></span></li><li class="c22 c220 c78 li-bullet-0"><span>A year in: Nestl&eacute; employees save 45 minutes per week using internal generative AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.worklife.news/technology/nesgpt-nestle-genai/&amp;sa=D&amp;source=editors&amp;ust=1730413583497020&amp;usg=AOvVaw3EX6Eg-9zvtTicpT0Xk7t1">https://www.worklife.news/technology/nesgpt-nestle-genai/</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c22 c97 c105 c220 li-bullet-0"><span class="c83 c14">Multiply this for every employee and it adds up </span></li></ul><p class="c22 c44"><span class="c92 c83 c37 c48 c14"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c22 c32 li-bullet-0"><span class="c14">Goldman Sachs says generative A.I. could impact 300 million jobs: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2023/03/28/ai-automation-could-impact-300-million-jobs-heres-which-ones.html&amp;sa=D&amp;source=editors&amp;ust=1730413583497628&amp;usg=AOvVaw3Lat9_V20mHU5FvVmI3uzb">https://www.cnbc.com/2023/03/28/ai-automation-could-impact-300-million-jobs-heres-which-ones.html</a></span></li></ul><p class="c22 c44"><span class="c1 c14"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c22 c32 li-bullet-0"><span class="c14">Goldman Sachs says generative AI could raise global GDP by 7%: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html&amp;sa=D&amp;source=editors&amp;ust=1730413583498103&amp;usg=AOvVaw1UiHCv3v9oU-MOZGpIDdIG">https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Photos to ads: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/&amp;sa=D&amp;source=editors&amp;ust=1730413583498580&amp;usg=AOvVaw0v9JU1YoMZIQclh6gA0QaN">https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>&nbsp;Introducing StockBot, a lightning fast AI chatbot powered by Llama3-70b on Groq that responds with live stock charts, financials, news, and screeners. All open source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/BenjaminKlieger/status/1814445262968107104&amp;sa=D&amp;source=editors&amp;ust=1730413583499072&amp;usg=AOvVaw10iPb10iI6OGlDB1CxqPBy">https://x.com/BenjaminKlieger/status/1814445262968107104</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 528.00px;"><img alt="" src="images/image611.png" style="width: 624.00px; height: 528.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 496.00px;"><img alt="" src="images/image158.png" style="width: 624.00px; height: 496.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c129"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>Taco Bell to roll out AI drive-thru ordering in hundreds of locations by end of year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524&amp;sa=D&amp;source=editors&amp;ust=1730413583499829&amp;usg=AOvVaw1SUtYUhZLpOnPiRa3Pjvjj">https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span class="c1">Yum Brands said the tech has improved order accuracy, reduced wait times, decreased employees&rsquo; task load and fueled profitable growth.</span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>LlamaCloud Chat: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jerryjliu0/status/1814387708267209188&amp;sa=D&amp;source=editors&amp;ust=1730413583500285&amp;usg=AOvVaw18dEqYyggLBmAnjEa1-fAS">https://x.com/jerryjliu0/status/1814387708267209188</a></span></li></ul><ul class="c0 lst-kix_r953kfpy79kt-1 start"><li class="c10 li-bullet-0"><span class="c1">Get a full-blown ChatGPT UI over any production data source in minutes. Connect to data sources like S3, Sharepoint, Notion, Slack, parse and index complex document types (PDFs, powerpoints, spreadsheets), and get back an advanced retrieval endpoint.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">LlamaCloud provides the data interface for your LLM agent. Our goal is to help you centralize and manage your data pipelines for LLM apps. LlamaCloud Chat helps you get immediate validation from your data sources and is a nice UI experience in its own right.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-0"><li class="c4 li-bullet-0"><span>AI Agents Are Coming for Mundane&mdash;but Valuable&mdash;Office Task: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/chatbots-are-entering-the-stone-age/&amp;sa=D&amp;source=editors&amp;ust=1730413583501051&amp;usg=AOvVaw0Nv6EZx3LnS1JRECW9854o">https://www.wired.com/story/chatbots-are-entering-the-stone-age/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_r953kfpy79kt-1"><li class="c69 li-bullet-0"><span class="c1">&gt;Anthropic and other big AI startups are teaching chatbots &ldquo;tool use,&rdquo; to make them more useful in the workplace.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c45 li-bullet-0"><span>AI tools spark anxiety among Philippines&rsquo; call center workers: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://restofworld.org/2023/call-center-ai-philippines/&amp;sa=D&amp;source=editors&amp;ust=1730413583501682&amp;usg=AOvVaw0q9aEmsz21_o-FewIcLQYG">https://restofworld.org/2023/call-center-ai-philippines/</a></span></li></ul><p class="c73 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c59 li-bullet-0"><span class="c40 c124 c37 c157">&gt;Bernie now uses ChatGPT and Bing to compile all the technical information he needs for a query in less than five minutes. It&rsquo;s doubled the number of customer complaints he can handle in a day. </span></li></ul><p class="c73 c46"><span class="c40 c124 c37 c157"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c59 li-bullet-0"><span class="c124 c37 c157">&gt;&ldquo;It made my work easier. I can even get ideas on how to approach certain complaints, making [my answers] appear engaging, persuasive, empathetic. It can give you that, depending on the prompt that you input,&rdquo; Bernie told </span><span class="c11">Rest of World.</span></li></ul><p class="c73 c46"><span class="c11"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c111 c78 li-bullet-0"><span>OpenAI tech increased productivity of Philippine contact center agents by 12.8% &ndash; study: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.rappler.com/technology/openai-gpt-productivity-effects-philippines-contact-center-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413583502637&amp;usg=AOvVaw23UspKkE6wfm1QqysLzNIQ">https://www.rappler.com/technology/openai-gpt-productivity-effects-philippines-contact-center-agents/</a></span></li></ul><p class="c111 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c15">&ldquo;GenAI will save [Klarna] $10m in marketing this year. We&rsquo;re spending less on photographers, image banks, and marketing agencies</span><span class="c14">&rdquo;</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/&amp;sa=D&amp;source=editors&amp;ust=1730413583503144&amp;usg=AOvVaw2DP5ehPrwJA_UUUabXDHh2">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/&amp;sa=D&amp;source=editors&amp;ust=1730413583503395&amp;usg=AOvVaw0w5IIyHPhWFswTgsP-OBkU">https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c33 c15">- $6m less on producing images.</span></li><li class="c10 li-bullet-0"><span class="c1 c14">- 1,000 in-house AI-produced images in 3 months. Includes the creative concept, quality check, and legal compliance.</span></li><li class="c10 li-bullet-0"><span class="c14">- AI-image production </span><span class="c33 c15">reduced from 6 WEEKS TO 1 WEEK ONLY.</span></li><li class="c10 li-bullet-0"><span class="c14">- Customer response to AI images </span><span class="c33 c15">on par with human produced images.</span></li><li class="c10 li-bullet-0"><span class="c14">- Cutting external marketing agency costs by</span><span class="c15">&nbsp;25%</span><span class="c1 c14">&nbsp;(mainly translation, production, CRM, and social agencies).</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c14">Our in-house marketing team is </span><span class="c15">HALF the size</span><span class="c14">&nbsp;it was last year but is </span><span class="c15">producing MORE</span><span class="c1 c14">!</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c1 c14">We&rsquo;ve removed the need for stock imagery from image banks like </span></li><li class="c10 li-bullet-0"><span class="c1 c14">@gettyimages</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c1 c14">Now we use genAI tools like Midjourney, DALL-E, and Firefly to generate images, and Topaz Gigapixel and Photoroom to make final adjustments.</span></li><li class="c10 li-bullet-0"><span class="c14">Faster images means </span><span class="c15">more app updates</span><span class="c1 c14">, which is great for customers. And our employees get to work on more fun projects AND we&#39;re saving money.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0 start"><li class="c4 li-bullet-0"><span>Robots [Automates] jobs from unions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html%23google_vignette&amp;sa=D&amp;source=editors&amp;ust=1730413583505582&amp;usg=AOvVaw0FRtfAjzASR4KmkwFNHP8c">https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c22 c161 c78 li-bullet-0"><span>AI took their jobs. Now they get paid to make it sound human: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human&amp;sa=D&amp;source=editors&amp;ust=1730413583506059&amp;usg=AOvVaw0k5Ob-hFHioJIdK8_ugs7z">https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human</a></span></li></ul><ul class="c0 lst-kix_5chsivk2mkzi-1 start"><li class="c22 c161 c97 c105 li-bullet-0"><span class="c112 c42 c37 c61">&gt;In numerous industries, AI is being used to produce work that was once the exclusive domain of the human mind</span></li><li class="c22 c167 c97 c105 li-bullet-0"><span class="c24">&gt;He led a team of more than 60 writers and editors&hellip;. &quot; the business introduced an automated system. Miller&#39;s manager would plug a headline for an article into an online form, an AI model would generate an outline based on that title, and Miller would get an alert on his computer. Instead of coming up with their own ideas, his writers would create articles around those outlines, and Miller would do a final edit before the stories were published. Miller only had a few months to adapt before he got news of a second layer of automation. Going forward, ChatGPT </span><span class="c24 c34">would write the articles in their entirety,</span><span class="c24">&nbsp;and </span><span class="c24 c15">most of his team was fired</span><span class="c112 c37 c35 c48 c120">. The few people remaining were left with an even less creative task: editing ChatGPT&#39;s subpar text to make it sound more human.</span></li><li class="c22 c167 c97 c105 li-bullet-0"><span class="c24">&gt;By 2024, </span><span class="c24 c15">the company laid off the rest of Miller&#39;s team</span><span class="c24">, and he was alone. &quot;All of a sudden I was just doing everyone&#39;s job,&quot; Miller says. Every day, he&#39;d open the AI-written documents to fix the robot&#39;s formulaic mistakes, churning out the work that used to employ dozens of people.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c45 li-bullet-0"><span class="c6">BP Earnings Call: We need </span><span class="c15 c65 c60">70% less coders</span><span class="c6 c40">&nbsp;from third parties to code as the AI handles most of the coding, the human only needs to look at the final 30% to validate it, that&#39;s a big savings for the company moving forward.</span></li></ul><p class="c73 c129"><span class="c6 c40">Second things like call centers, the language models have become so sophisticated now. They can operate in multiple languages, 14, 15 languages easily. In the past, that hasn&#39;t been something we can do. So we can redeploy people off that given that the AI can do it. You heard my advertising example last quarter where advertising cycle times moved from four to five months down to a couple of weeks. So that&#39;s obviously reducing spend with third parties. We&#39;ve now got Gen AI in the hands through Microsoft Copilot across many, many parts of the business and we&#39;ll continue to update you with anecdotes as we go through</span></p><ul class="c0 lst-kix_f539m7fvzj9k-0 start"><li class="c59 li-bullet-0"><span class="c6">Source: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript&amp;sa=D&amp;source=editors&amp;ust=1730413583507744&amp;usg=AOvVaw2WbWsv5OFdXR5SJX-iO_mN">https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript</a></span><span class="c6 c40">&nbsp;</span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_f539m7fvzj9k-0"><li class="c59 li-bullet-0"><span class="c6 c40">This is almost certainly true because this is quoted from an earnings call from BP and lying to investors is a crime (securities fraud). This would include lying about the reason for getting rid of the workers (in other words, it can&rsquo;t just be layoffs). The numbers that are provided are also too specific to be exaggerations without also being a lie.</span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c4 li-bullet-0"><span>Leaked Memo Claims New York Times Fired Artists to Replace Them With AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://futurism.com/the-byte/new-york-times-fires-artists-ai-memo&amp;sa=D&amp;source=editors&amp;ust=1730413583508373&amp;usg=AOvVaw0FLhr3Hoy5faio5rsL3ZJ8">https://futurism.com/the-byte/new-york-times-fires-artists-ai-memo</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c100 c78 li-bullet-0"><span>Cheap AI voice clones may wipe out jobs of 5,000 Australian actors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia&amp;sa=D&amp;source=editors&amp;ust=1730413583508853&amp;usg=AOvVaw0gX3AJwM-8OUwfXBOnjC_N">https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c69 li-bullet-0"><span class="c1">&gt;Industry group says rise of vocal technology could upend many creative fields, including audiobooks &ndash; the canary in the coalmine for voice actors</span></li></ul><p class="c100 c46"><span class="c1"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c22 c95 c129 li-bullet-0"><span class="c43">Almost 65,000 Job Cuts Were Announced In April&mdash;And AI Was Blamed For The Most Losses Ever: </span><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/maryroeloffs/2024/05/02/almost-65000-job-cuts-were-announced-in-april-and-ai-was-blamed-for-the-most-losses-ever/&amp;sa=D&amp;source=editors&amp;ust=1730413583509645&amp;usg=AOvVaw2Q9--josPWw04MFvZEDaHi">https://www.forbes.com/sites/maryroeloffs/2024/05/02/almost-65000-job-cuts-were-announced-in-april-and-ai-was-blamed-for-the-most-losses-ever/</a></span></li></ul><p class="c22 c95 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c22 c74 c129 li-bullet-0"><span>In a survey of 450 executives in the US, </span><span class="c43">&quot;45 percent said they were automating tasks to reduce staffing and labour costs.&quot; </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.smh.com.au/world/north-america/nearly-half-of-us-firms-using-ai-say-goal-is-to-cut-staffing-costs-20240629-p5jpsl.html&amp;sa=D&amp;source=editors&amp;ust=1730413583510212&amp;usg=AOvVaw3-959b0Sfp-HAqOkr76w8D">https://www.smh.com.au/world/north-america/nearly-half-of-us-firms-using-ai-say-goal-is-to-cut-staffing-costs-20240629-p5jpsl.html</a></span></li></ul><p class="c22 c74 c46"><span class="c33 c15"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c22 c74 c129 li-bullet-0"><span class="c15">Bank of America CEO: AI helping cut call times, branch visits: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/companies/bank-of-america-ceo-ai-helping-cut-call-times-branch-visits/ar-AA1eCRVI&amp;sa=D&amp;source=editors&amp;ust=1730413583510691&amp;usg=AOvVaw3aDtHsPO07nQAOyJH_a-4m">https://www.msn.com/en-us/money/companies/bank-of-america-ceo-ai-helping-cut-call-times-branch-visits/ar-AA1eCRVI</a></span></li></ul><p class="c22 c46 c74"><span class="c33 c15"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c22 c206 c97 c105 li-bullet-0"><span>&gt;</span><span class="c1">AI virtual financial assistant has logged 1.5B customer interactions since 2018 launch</span></li></ul><p class="c22 c206 c97 c46"><span class="c1"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c4 li-bullet-0"><span class="c15">Klarna SUCCESSFULLY replaces call centers with AI </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/klarna/comments/1c1fwr3/klarna_ceo_on_using_ai_to_replace_700_workers/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583511464&amp;usg=AOvVaw2wUb2WAJCnK70-VykryXyq">https://www.reddit.com/r/klarna/comments/1c1fwr3/klarna_ceo_on_using_ai_to_replace_700_workers/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c10 li-bullet-0"><span class="c1 c14">- Klarnas AI assistant, powered by @OpenAI , has in its first 4 weeks handled 2.3 million customer service chats and the data and insights are staggering:</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c10 li-bullet-0"><span class="c1 c14">Handles 2/3 rd of our customer service enquires</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c10 li-bullet-0"><span class="c1 c14">On par with humans on customer satisfaction</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c10 li-bullet-0"><span class="c1 c14">Higher accuracy leading to a 25% reduction in repeat inquiries</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c10 li-bullet-0"><span class="c1 c14">customer resolves their errands in 2 min vs 11 min</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c10 li-bullet-0"><span class="c1 c14">&nbsp;Live 24/7 in over 23 markets, communicating in over 35 languages</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-1"><li class="c10 li-bullet-0"><span class="c1 c14">It performs the equivalent job of 700 full time agents</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_5chsivk2mkzi-0"><li class="c45 li-bullet-0"><span class="c124 c37 c157">Digital automation could make 1.1 million roles in the Philippines obsolete by 2028: </span><span class="c5 c124 c37 c157"><a class="c13" href="https://www.google.com/url?q=https://www.cisco.com/c/dam/global/en_sg/assets/csr/pdf/technology-and-the-future-of-asean-jobs.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583513137&amp;usg=AOvVaw3eEnUDYki43WjBPk3RZ5gR">https://www.cisco.com/c/dam/global/en_sg/assets/csr/pdf/technology-and-the-future-of-asean-jobs.pdf</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c14">&lsquo;I will never go back&rsquo;: Ontario family doctor says new AI notetaking saved her job:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583513596&amp;usg=AOvVaw2NRzsbBsUrS84LedjEZrN1">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583513827&amp;usg=AOvVaw13lHZoAPKoP5YbLvxhd87l">https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c14">&gt;&rdquo;If the physician is unhappy with the note, Lall said, they can ask the AI model to regenerate the information or add more detail to any one of the categories. While the tool has some imperfections, she said, the improvements have been noticeable over the 10 months since she began using it.&ldquo;I really feel this should be the</span><span class="c15">&nbsp;next gold standard for all of our doctors.</span><span class="c14">&nbsp;It decreases the cognitive load you feel at the end of the day,&rdquo; she said.The Ford government has been so impressed with the technology that it announced </span><span class="c15">a pilot program to allow 150 family physicians to use AI Scribe as part of their practices.</span><span class="c1 c14">&nbsp;The health minister said the early signs were promising but stressed government would proceed carefully.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Robotics makers embrace Nvidia digital twins to create autonomous AI-run factories: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.computerworld.com/article/2137856/robotics-makers-embrace-nvidia-digital-twins-to-create-autonomous-ai-run-factories.html&amp;sa=D&amp;source=editors&amp;ust=1730413583514718&amp;usg=AOvVaw39G2gVzVix8Be4nEruZDDt">https://www.computerworld.com/article/2137856/robotics-makers-embrace-nvidia-digital-twins-to-create-autonomous-ai-run-factories.html</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Former Microsoft &amp; Google research scientist Kai-Fu Lee- About 50% Of Jobs Will Be Displaced By AI Within 3 Years: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DzZs447dgMjg&amp;sa=D&amp;source=editors&amp;ust=1730413583515221&amp;usg=AOvVaw0k2q3vWnJWXua-AVMVaTJM">https://www.youtube.com/watch?v=zZs447dgMjg</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c1">Since he&rsquo;s no longer employed at those companies, he does not have an incentive to lie </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span>Consistent with claims from Anthropic&rsquo;s Chief of Staff: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/&amp;sa=D&amp;source=editors&amp;ust=1730413583515878&amp;usg=AOvVaw3dYvPowIifkC--jIV63r1s">https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c1">His prediction from 2017 still holds that in 10-15 years around 40-50% of all jobs will be replaced by AI</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Toys R Us uses Sora generated promo: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/&amp;sa=D&amp;source=editors&amp;ust=1730413583516588&amp;usg=AOvVaw1zteLhpGTpPUoJKz_gKAcD">https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Square Enix says it used AI art in upcoming Foamstars game: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney&amp;sa=D&amp;source=editors&amp;ust=1730413583517032&amp;usg=AOvVaw05jqkQ-7vDQniPR8hqj5_l">https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;AI technologies has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI to develop tools for developers to generate AI NPCs, quests, and stories. The Finals, a free-to-play multiplayer shooter, was criticized by voice actors for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>AI Agent Better than OpenAI&rsquo;s GPT-4o and costs just $1.60 per 1000 queries, making it 175% cheaper than GPT-4o. It is the world&rsquo;s first fully autonomous AI-powered sales development representative (SDR): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/&amp;sa=D&amp;source=editors&amp;ust=1730413583517728&amp;usg=AOvVaw2lOMCqLUNEHV8AVEZ_3gD2">https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 253.33px;"><img alt="" src="images/image166.png" style="width: 624.00px; height: 253.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 437.33px;"><img alt="" src="images/image199.png" style="width: 624.00px; height: 437.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>AI video could be used for marketing: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1810952037246349739&amp;sa=D&amp;source=editors&amp;ust=1730413583518370&amp;usg=AOvVaw0-3B2Xtj3cBoN2tlgqWNh8">https://x.com/CharaspowerAI/status/1810952037246349739</a></span></li><li class="c100 c78 li-bullet-0"><span>Intuit is laying off 1,800 employees as AI leads to a strategic shift: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://fortune.com/2024/07/10/intuit-layoffs-email-hiring-ai-transformation/&amp;sa=D&amp;source=editors&amp;ust=1730413583518744&amp;usg=AOvVaw1opnTu0PsCiyks3NTioWxB">https://fortune.com/2024/07/10/intuit-layoffs-email-hiring-ai-transformation/</a></span></li><li class="c100 c78 li-bullet-0"><span>RevOps team&rsquo;s AI-powered sales call assistant: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/wadefoster/status/1811049453916430596&amp;sa=D&amp;source=editors&amp;ust=1730413583519074&amp;usg=AOvVaw0ZxGM0btFuGo05UAv06j34">https://x.com/wadefoster/status/1811049453916430596</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c69 li-bullet-0"><span class="c1">This Zap integrates @ChatGPTapp + @Gong_io + @SlackHQ + @HubSpot to summarize calls, generate follow-ups, and update records.</span></li><li class="c69 li-bullet-0"><span class="c1">The result? +2 deals/rep/wk, +5% monthly inbound Revenue!</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c100 c78 li-bullet-0"><span>Using GPT-4o for parsing and synthesis for financial report RAG: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.linkedin.com/posts/hanane-d-algo-trader_amazon-10k-financial-report-using-llamaparse-activity-7216320268892282880-dK6w&amp;sa=D&amp;source=editors&amp;ust=1730413583519773&amp;usg=AOvVaw0IM93RSdpANe-B0CcXV7RY">https://www.linkedin.com/posts/hanane-d-algo-trader_amazon-10k-financial-report-using-llamaparse-activity-7216320268892282880-dK6w</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c69 li-bullet-0"><span class="c1">Financial reports can contain a lot of charts and tables that text-based parsers struggle with.</span></li><li class="c69 li-bullet-0"><span class="c1">LlamaParse is the easiest way to use multimodal models like gpt-4o to extract out text, diagram, and table information into well-structured representations.</span></li><li class="c69 li-bullet-0"><span class="c1">This leads to not only good answers, but also easily-interpretable sources and citations</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c100 c78 li-bullet-0"><span>SpreadsheetLLM from Microsoft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1812674543963578794&amp;sa=D&amp;source=editors&amp;ust=1730413583520384&amp;usg=AOvVaw3vG7X0OZuFWj3VlOV0IQ-l">https://x.com/_akhaliq/status/1812674543963578794</a></span></li><li class="c4 li-bullet-0"><span>GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27&amp;sa=D&amp;source=editors&amp;ust=1730413583520812&amp;usg=AOvVaw0Ox9S_ZQqvKCIrDvI1Jlxc">https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27</a></span></li><li class="c4 li-bullet-0"><span>Runway and Lionsgate are partnering to explore the use of AI in film production: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://runwayml.com/news/runway-partners-with-lionsgate&amp;sa=D&amp;source=editors&amp;ust=1730413583521032&amp;usg=AOvVaw0Ad9RwG0Bs2w0YvSuCcMBP">https://runwayml.com/news/runway-partners-with-lionsgate</a></span></li><li class="c4 li-bullet-0"><span>IDC: Artificial Intelligence Will Contribute $19.9 Trillion to the Global Economy through 2030 and Drive 3.5% of Global GDP in 2030: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.idc.com/getdoc.jsp?containerId%3DprUS52600524&amp;sa=D&amp;source=editors&amp;ust=1730413583521243&amp;usg=AOvVaw1zmkvWu79oX7LpdRZwEctP">https://www.idc.com/getdoc.jsp?containerId=prUS52600524</a></span></li><li class="c222 c78 li-bullet-0"><span>Bank of Canada&rsquo;s</span><span>&nbsp;Tiff Macklem warns AI could destroy more jobs than it creates: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.md/YK2cm&amp;sa=D&amp;source=editors&amp;ust=1730413583521465&amp;usg=AOvVaw3P0njlVnc88AEjyL6uw_fB">https://archive.md/YK2cm</a></span></li></ul><p class="c46 c222"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c1">He does not work in the tech industry and has no incentive to lie about this</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Salesforce is looking to deploy a billion AI agents in the next 12 months: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fmgz3b/marc_benioff_says_microsoft_copilot_is_the_new/&amp;sa=D&amp;source=editors&amp;ust=1730413583521833&amp;usg=AOvVaw3jnslK8mP6n13L-RCb4VyR">https://www.reddit.com/r/singularity/comments/1fmgz3b/marc_benioff_says_microsoft_copilot_is_the_new/</a></span></li><li class="c4 li-bullet-0"><span>&quot;Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027&amp;sa=D&amp;source=editors&amp;ust=1730413583522108&amp;usg=AOvVaw03expcvBKN_wIQ8fLL35H-">https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span class="c1">Short Term:</span></li></ul><ul class="c0 lst-kix_w9nfenze7id7-0 start"><li class="c7 li-bullet-0"><span class="c1">AI tools will slightly increase productivity by helping with tasks.</span></li><li class="c7 li-bullet-0"><span class="c1">Senior developers in well-run companies will benefit the most from these tools.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kviltkqr3kxc-0 start"><li class="c10 li-bullet-0"><span class="c1">Medium Term:</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kviltkqr3kxc-1 start"><li class="c7 li-bullet-0"><span class="c1">AI agents will change how developers work by automating more tasks.</span></li><li class="c7 li-bullet-0"><span class="c1">Most code will be made by AI, not humans.</span></li><li class="c7 li-bullet-0"><span class="c1">Developers need to learn new skills like prompt engineering and RAG.</span></li></ul><ul class="c0 lst-kix_kviltkqr3kxc-0"><li class="c10 li-bullet-0"><span class="c1">Long Term:</span></li></ul><ul class="c0 lst-kix_hw08zzin6mm8-0 start"><li class="c7 li-bullet-0"><span class="c1">More skilled software engineers are needed because of the growing demand for AI-powered software.</span></li><li class="c7 li-bullet-0"><span class="c1">A new type of engineer, called an AI engineer, who knows about software, data science, and AI/ML will be very important</span></li></ul><ul class="c0 lst-kix_hdamu5z1kajk-0 start"><li class="c4 li-bullet-0"><span>OpenAI CPO Kevin Weil says their o1 model can now write legal briefs that previously were the domain of $1000/hour associates: &quot;what does it mean when you can suddenly do $8000 of work in 5 minutes for $3 of API credits?&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g7v0ud/openai_cpo_kevin_weil_says_their_o1_model_can_now/&amp;sa=D&amp;source=editors&amp;ust=1730413583522912&amp;usg=AOvVaw3O5ow8Wohmo_YsH7Wkm8Pr">https://www.reddit.com/r/singularity/comments/1g7v0ud/openai_cpo_kevin_weil_says_their_o1_model_can_now/</a></span></li><li class="c4 li-bullet-0"><span>Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve &ldquo;hundreds&rdquo; of people at the company and will primarily focus on post-production and visual effects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.thewrap.com/disney-ai-initiative/&amp;sa=D&amp;source=editors&amp;ust=1730413583523116&amp;usg=AOvVaw2k7cKtq57knUypqpZJ6ohw">https://www.thewrap.com/disney-ai-initiative/</a></span></li></ul><h2 class="c64" id="h.qu94qw6h8i3v"><span class="c40 c37 c48 c75">4.3. Medical Use</span></h2><ul class="c0 lst-kix_gl7fpz1y51y1-0 start"><li class="c4 li-bullet-0"><span>BrainLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583523416&amp;usg=AOvVaw0HXT7vz-WzhhJE0Hq49kQD">https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf</a></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-1 start"><li class="c10 li-bullet-0"><span>Utilizing self-supervised masked-prediction training, BrainLM demonstrates </span><span class="c15">proficiency in both fine-tuning and zero-shot inference tasks</span><span>. Fine-tuning allows for the </span><span class="c15">accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states</span><span>. Critically, the model </span><span class="c15">generalizes well to entirely new external cohorts not seen during training.</span><span>&nbsp;In zero-shot inference mode, BrainLM can i</span><span class="c15">dentify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training</span><span>. The model also generates i</span><span class="c15">nterpretable latent representations that reveal relationships between brain activity patterns and cognitive states</span><span>. Overall, BrainLM offers a </span><span class="c34">versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. </span><span>It serves as a powerful &quot;lens&quot; through which m</span><span class="c15">assive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale</span><span class="c1">. The work demonstrates the potential of foundation models to advance computational neuroscience research. </span></li><li class="c10 li-bullet-0"><span class="c15">Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 683.68px; height: 485.94px;"><img alt="" src="images/image17.png" style="width: 683.68px; height: 485.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 601.33px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 601.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 568.00px;"><img alt="" src="images/image38.png" style="width: 624.00px; height: 568.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 160.00px;"><img alt="" src="images/image133.png" style="width: 624.00px; height: 160.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 653.33px;"><img alt="" src="images/image211.png" style="width: 624.00px; height: 653.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 613.96px; height: 520.50px;"><img alt="" src="images/image13.png" style="width: 613.96px; height: 520.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span>Tx-LLM: Supporting therapeutic development with large language models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413583524528&amp;usg=AOvVaw2s6gcj3GUwe77NVLNmFdNd">https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/</a></span></li><li class="c4 li-bullet-0"><span>In a historic moment for the dental profession, an AI-controlled autonomous robot has performed an entire procedure on a human patient for the first time, about eight times faster than a human dentist could do it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/health-wellbeing/robot-dentist-world-first/&amp;sa=D&amp;source=editors&amp;ust=1730413583524778&amp;usg=AOvVaw2pgeAp3vl5lSSezboHcyX6">https://newatlas.com/health-wellbeing/robot-dentist-world-first/</a></span></li><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image202.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c32 li-bullet-0"><span class="c15">Taiwan hospital deploys AI copilots to lighten workloads for doctors, nurses and pharmacists: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://news.microsoft.com/source/asia/features/taiwan-hospital-deploys-ai-copilots-to-lighten-workloads-for-doctors-nurses-and-pharmacists/?ocid%3DFY24_soc_omc_br_x_ChiMei&amp;sa=D&amp;source=editors&amp;ust=1730413583525147&amp;usg=AOvVaw1JQSuZ7o3R9om8LoqfHv2f">https://news.microsoft.com/source/asia/features/taiwan-hospital-deploys-ai-copilots-to-lighten-workloads-for-doctors-nurses-and-pharmacists/?ocid=FY24_soc_omc_br_x_ChiMei</a></span></li></ul><p class="c22 c44"><span class="c33 c15"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c32 li-bullet-0"><span class="c15">Great thread on medical uses of generative AI:</span><span class="c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/Sandbar101/status/1784620540092731827&amp;sa=D&amp;source=editors&amp;ust=1730413583525421&amp;usg=AOvVaw2Y3yVsvPQGYduFqk49NJX4">&nbsp;</a></span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/Sandbar101/status/1784620540092731827&amp;sa=D&amp;source=editors&amp;ust=1730413583525556&amp;usg=AOvVaw3Y9aTwiC-y0jM0rCDCzhSq">https://x.com/Sandbar101/status/1784620540092731827</a></span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c4 li-bullet-0"><span class="c14">New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S135964462400134X&amp;sa=D&amp;source=editors&amp;ust=1730413583525915&amp;usg=AOvVaw1QEmk69rKJnYceSnJ2pY3Q">https://www.sciencedirect.com/science/article/pii/S135964462400134X</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9 c129"><span class="c1"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span>AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients&rsquo; tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color&amp;sa=D&amp;source=editors&amp;ust=1730413583526242&amp;usg=AOvVaw39DO8bqQ3HK54A78wgH30O">https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-1"><li class="c10 li-bullet-0"><span>the paper itself shows that the best model has a f1 score, precision (accuracy), recall (avoidance of false positives) all above 98% </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mdpi.com/2227-7080/12/7/97&amp;sa=D&amp;source=editors&amp;ust=1730413583526527&amp;usg=AOvVaw0k_6-KD1B5ib-Cyrh0IpXK">https://www.mdpi.com/2227-7080/12/7/97</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span>&nbsp;</span><span>AI Detects More Breast Cancers with Fewer False Positives </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers&amp;sa=D&amp;source=editors&amp;ust=1730413583526798&amp;usg=AOvVaw06Hur5GHCQAJ2Uspg0m1Mu">https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-1"><li class="c10 li-bullet-0"><span class="c1">Recall (false positive) rate and radiologist reading workload decreased significantly in AI-screened group</span></li><li class="c10 li-bullet-0"><span class="c1">Using AI, breast radiologists in Denmark have improved breast cancer screening performance and reduced the rate of false-positive findings.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">In total, 60,751 women were screened without AI, and 58,246 women were screened with the AI system. In the AI implementation group, 66.9% (38,977) of the screenings were single-read, and 33.1% (19,269) were double-read with AI assistance. </span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">Compared to screening without AI, screening with the AI system detected significantly more breast cancers (0.82% versus 0.70%) and had a lower false-positive rate (1.63% versus 2.39%). </span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">&ldquo;In the AI-screened group, the recall rate decreased by 20.5 percent, and the radiologists&rsquo; reading workload was lowered by 33.4 percent,&rdquo; Dr. Lauritzen said.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">The positive predictive value of AI screening was also greater than that of screening without AI (33.5% versus 22.5%). In the AI group, a higher proportion of invasive cancers detected were 1 centimeter or less in size (44.93% vs. 36.60%).</span></li><li class="c10 li-bullet-0"><span class="c37 c65 c126 c81">&ldquo;All screening performance indicators improved except for the node-negative rate which showed no evidence of change,&rdquo; Dr. Lauritzen said.</span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c45 c46 li-bullet-0"><span class="c6 c40"></span></li><li class="c45 li-bullet-0"><span class="c6">Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx&amp;sa=D&amp;source=editors&amp;ust=1730413583527531&amp;usg=AOvVaw2dE3CkhzVRyWrByjlJNPJA">https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0 start"><li class="c4 li-bullet-0"><span>AI spots cancer and viral infections at nanoscale precision: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html&amp;sa=D&amp;source=editors&amp;ust=1730413583527960&amp;usg=AOvVaw38qhZx0-anAVPT9EG-M84n">https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/?f%3Dflair_name%253A%2522AI%2522&amp;sa=D&amp;source=editors&amp;ust=1730413583528169&amp;usg=AOvVaw0ZI2VdpQJBKCJlJ3-Mp_Zm"></a></span></p><ul class="c0 lst-kix_4nm4szcl7et4-1 start"><li class="c10 li-bullet-0"><span class="c1">Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c4 li-bullet-0"><span>AI D</span><span>etects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131&amp;sa=D&amp;source=editors&amp;ust=1730413583528496&amp;usg=AOvVaw2ckHJR2vu0DuT4OXInGTIp">https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c45 li-bullet-0"><span class="c6">GPs use AI to boost cancer detection rates in England by 8%: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8&amp;sa=D&amp;source=editors&amp;ust=1730413583528808&amp;usg=AOvVaw1e-XwKELLmlqrTD5D7OPPJ">https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8</a></span></li></ul><p class="c73 c46 c129"><span class="c6 c40"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c45 li-bullet-0"><span class="c6">ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583529107&amp;usg=AOvVaw1556PIqbTSPV-01JSSBBiU">https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_txo0zcn8hx7-0 start"><li class="c4 li-bullet-0"><span class="c6">AI is better than doctors at detecting breast cancer:</span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.bing.com/videos/search?q%3Dai%2Bbetter%2Bthan%2Bdoctors%2Busing%2Bai%26mid%3D6017EF2744FCD442BA926017EF2744FCD442BA92%26view%3Ddetail%26FORM%3DVIRE%26PC%3DEMMX04&amp;sa=D&amp;source=editors&amp;ust=1730413583529373&amp;usg=AOvVaw1wpCJtrKBxmNCxMlIYMz69">&nbsp;</a></span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/health-50857759&amp;sa=D&amp;source=editors&amp;ust=1730413583529512&amp;usg=AOvVaw0JhDAxFunXxqB9-Ky9lgqD">https://www.bbc.com/news/health-50857759</a></span></li></ul><p class="c73 c46 c129"><span class="c6 c40"></span></p><ul class="c0 lst-kix_snh8lpyqaleg-0 start"><li class="c45 li-bullet-0"><span class="c6">AI just as good at diagnosing illness as humans: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.medicalnewstoday.com/articles/326460?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583529797&amp;usg=AOvVaw2XO77Y6FTJRJewSrEkcQgE">https://www.medicalnewstoday.com/articles/326460</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0 start"><li class="c45 li-bullet-0"><span class="c6">Accurate prediction of disease risk factors: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://doheny.org/wp-content/uploads/2024/10/Nature-Accurate-Prediction-of-Disease-Risk-Factors-From-Volumetric-Medical-Scans-by-a-Deep-Vision-Model-Pre-trained-With-2D-Scan-Article.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583530169&amp;usg=AOvVaw3VlNH8rDwXx_ss-N4exu29">https://doheny.org/wp-content/uploads/2024/10/Nature-Accurate-Prediction-of-Disease-Risk-Factors-From-Volumetric-Medical-Scans-by-a-Deep-Vision-Model-Pre-trained-With-2D-Scan-Article.pdf</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_b966qb5z56w2-1 start"><li class="c59 li-bullet-0"><span class="c6 c40">SLIViT consistently outperformed domain-specific state-of-the-art models and was typically as accurate as clinical specialists who had spent considerable time manually annotating the analysed scans. Automating diagnosis tasks involving volumetric scans may save valuable clinician hours, reduce data acquisition costs and duration, and help expedite medical research and clinical applications.</span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 433.33px;"><img alt="" src="images/image129.png" style="width: 624.00px; height: 433.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 510.67px;"><img alt="" src="images/image315.png" style="width: 624.00px; height: 510.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583530717&amp;usg=AOvVaw2M61NHjaZeERWjgNxC_QbB">https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr=1</a></span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c32 li-bullet-0"><span class="c14 c31">Med-Gemini model achieves </span><span class="c15 c31">SoTA performance of 91.1% accuracy on USMLE</span><span class="c99 c37 c65 c60 c144">&nbsp;: h</span><span class="c37 c65 c60 c68"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.18416&amp;sa=D&amp;source=editors&amp;ust=1730413583531093&amp;usg=AOvVaw0pfy6sFf09b4p_H44Nu8-1">ttps://arxiv.org/abs/2404.18416</a></span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-1"><li class="c22 c72 li-bullet-0"><span class="c14 c31">&gt;We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves </span><span class="c15 c31">SoTA performance of 91.1% accuracy,</span><span class="c14 c31">&nbsp;using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health &amp; medicine), Med-Gemini </span><span class="c15 c31">improves over GPT-4V by an average relative margin of 44.5%</span><span class="c14 c31">. We demonstrate the effectiveness of Med-Gemini&#39;s long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini&#39;s performance suggests real-world utility by </span><span class="c15 c31">surpassing human experts</span><span class="c34 c14 c31">&nbsp;</span><span class="c14 c31">on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. </span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c32 li-bullet-0"><span class="c18">Double-blind study with Patient Actors and Doctors, who didn&#39;t know if they were communicating with a human, or an AI. Best performers were AI: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DjQwwLEZ2Hz8&amp;sa=D&amp;source=editors&amp;ust=1730413583531760&amp;usg=AOvVaw3Y098zgAYe_GToa_JqFWSr">https://m.youtube.com/watch?v=jQwwLEZ2Hz8</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-1"><li class="c22 c72 li-bullet-0"><span class="c15 c65 c114">Human doctors + AI did worse, than AI by itself.</span><span class="c40 c18">&nbsp;The mere involvement of a human reduced the accuracy of the diagnosis.</span></li><li class="c22 c72 li-bullet-0"><span class="c15 c65 c114">AI was consistently rated to have better bedside manner than human doctors</span><span class="c40 c18">.</span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span>In a new study, GPT4 outperformed human doctors at showing empathy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2821167&amp;sa=D&amp;source=editors&amp;ust=1730413583532239&amp;usg=AOvVaw2ogkHXiYFz5LgH_uyXIQn8">https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2821167</a></span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c32 li-bullet-0"><span class="c14">&lsquo;I will never go back&rsquo;: Ontario family doctor says new AI notetaking saved her job:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583532533&amp;usg=AOvVaw3gIdYTKiP4hbLo3NUssW7K">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583532677&amp;usg=AOvVaw0FMbTYXE9JT9cBLUBG9gIp">https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c44"><span class="c1 c14"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c32 li-bullet-0"><span class="c14">[Google&#39;s medical AI destroys GPT&#39;s benchmark and outperforms doctors](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/google-med-gemini-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583532967&amp;usg=AOvVaw2K4jq0vXrNnukeh_6_6Uta">https://newatlas.com/technology/google-med-gemini-ai/</a></span><span class="c1 c14">)</span></li></ul><p class="c22 c44"><span class="c1 c14"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c32 li-bullet-0"><span class="c14">[The first randomized trial of medical #AI to show it saves lives. ECG-AI alert in 16,000 hospitalized patients. 31% reduction of mortality (absolute 7 per 100 patients) in pre-specified high-risk group](</span><span class="c20 c124 c34 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/erictopol/status/1784936718283805124&amp;sa=D&amp;source=editors&amp;ust=1730413583533268&amp;usg=AOvVaw2MgdGUVhPFccnkN6aPDxIl">https://twitter.com/erictopol/status/1784936718283805124</a></span><span class="c40 c124 c34 c14">)</span></li></ul><p class="c22 c44"><span class="c40 c124 c34 c14"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c32 li-bullet-0"><span class="c18">Medical Text Written By Artificial Intelligence Outperforms Doctors: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/&amp;sa=D&amp;source=editors&amp;ust=1730413583533653&amp;usg=AOvVaw04asIaAkTDNDwGCJ6GnqtN">https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span class="c14">AI can make healthcare better and safer: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.economist.com/technology-quarterly/2024/03/27/ais-will-make-health-care-safer-and-better&amp;sa=D&amp;source=editors&amp;ust=1730413583533971&amp;usg=AOvVaw3s4C_0xDegrQm-Pmcrb6zT">https://www.economist.com/technology-quarterly/2024/03/27/ais-will-make-health-care-safer-and-better</a></span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span class="c18">CheXzero significantly outperformed humans, especially on uncommon conditions. Huge implications for improving diagnosis of neglected &quot;long tail&quot; diseases: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/pranavrajpurkar/status/1797292562333454597&amp;sa=D&amp;source=editors&amp;ust=1730413583534257&amp;usg=AOvVaw0IwWdCiNYYYhcdS35Sd9ai">https://x.com/pranavrajpurkar/status/1797292562333454597</a></span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 611.50px; height: 371.41px;"><img alt="" src="images/image101.png" style="width: 611.50px; height: 371.41px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-2 start"><li class="c7 li-bullet-0"><span class="c40 c18">Humans near chance level (50-55% accuracy) on rarest conditions, while CheXzero maintains 64-68% accuracy.</span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image57.png" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c45 li-bullet-0"><span class="c6">AI is better than doctors at detecting breast cancer: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3DhVA3aJOWpmc%26embeds_referring_euri%3Dhttps://www.bing.com/%26source_ve_path%3DMjM4NTE&amp;sa=D&amp;source=editors&amp;ust=1730413583534862&amp;usg=AOvVaw1EtB7IO3qsMWJ6vQaTdDtm">https://youtube.com/watch?v=hVA3aJOWpmc</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span class="c14 c63">AI Outperforms Radiologists in Detecting Prostate Cancer on MRI: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://www.insideprecisionmedicine.com/topics/patient-care/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/&amp;sa=D&amp;source=editors&amp;ust=1730413583535267&amp;usg=AOvVaw0LGZb040mv7fcqMI1B72l0">https://www.insideprecisionmedicine.com/topics/patient-care/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span>First NHS physiotherapy clinic run by AI to start this year. New platform to provide same-day appointments with digital physiotherapist in effort to cut waiting times: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year&amp;sa=D&amp;source=editors&amp;ust=1730413583535606&amp;usg=AOvVaw1UrM5F8feaQUkrkK0Yrcow">https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span>China&#39;s first (simulated) AI hospital town debuts: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.globaltimes.cn/page/202405/1313235.shtml&amp;sa=D&amp;source=editors&amp;ust=1730413583535892&amp;usg=AOvVaw0gK1pJv80qEgfiZUP15gx6">https://www.globaltimes.cn/page/202405/1313235.shtml</a></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-1 start"><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">Remarkably, AI doctors can treat 10,000 [simulated] &nbsp;patients in just a few days. It would take human doctors at least two years to treat that many patients. Furthermore, evolved doctor agents achieved an impressive 93.06 percent accuracy rate on the MedQA dataset (US Medical Licensing Exam questions) covering major respiratory diseases. They simulate the entire process of diagnosing and treating patients, including consultation, examination, diagnosis, treatment and follow-up. </span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">Research team leader of the Agent Hospital Liu Yang, also executive dean of Institute for AI Industry Research (AIR) and associate dean of the Department of Computer Science and Technology at Tsinghua University, told the Global Times that the AI hospital town is set to transform the way doctors diagnose and treat patients, bringing immense benefits to both medical professionals and the general public. </span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">For example, this innovative concept allows for virtual patients to be treated by real doctors, providing medical students with enhanced training opportunities. By simulating a variety of AI patients, medical students can confidently propose treatment plans without the fear of causing harm to real patients due to decision-making error, Liu said. </span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">This simulation training enables medical students to practice diagnosis and treatment in a risk-free environment, ultimately leading to the cultivation of highly skilled doctors, according to Liu.</span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">If the patients in the town are real and the doctors are virtual, online telemedicine services can be provided to patients. The AI hospital town utilizes a vast repository of authoritative medical knowledge, allowing AI doctors to handle thousands, even millions, of cases.</span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">The potential for high-quality, affordable and convenient healthcare services for the public is on the horizon, as the diagnostic capabilities of AI doctors evolve from the virtual world to the real world, Liu stated.</span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">Liu went on to say that the AI hospital town can simulate and predict various medical scenarios, such as the spread, development and control of infectious diseases in a region.</span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span class="c63 c14">Synchron CEO Tom Oxley says their brain-computer interface uses OpenAI&#39;s GPT-4o to generate prompts from multimodal inputs that users can choose from to express their intentions: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1811560070632947836&amp;sa=D&amp;source=editors&amp;ust=1730413583537250&amp;usg=AOvVaw1lBn52Thn0AUqWKlRk-cVk">https://x.com/tsarnick/status/1811560070632947836</a></span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span class="c63 c14">EvolutionaryScale, a frontier AI research lab, has unveiled ESM3, a groundbreaking generative AI model for protein design that simulates millions of years of evolution to create novel proteins, potentially revolutionizing fields from drug discovery to environmental sustainability: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/ai_for_success/status/1812369558097015292&amp;sa=D&amp;source=editors&amp;ust=1730413583537551&amp;usg=AOvVaw2P6AVD1XRqa26Ullhj-BVZ">https://x.com/ai_for_success/status/1812369558097015292</a></span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c100 c78 li-bullet-0"><span>Introducing Surgical Robot Transformer (SRT): Automating surgical tasks with end-to-end imitation learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jwbkim/status/1813263637429297381&amp;sa=D&amp;source=editors&amp;ust=1730413583537883&amp;usg=AOvVaw2fX9e18zaSQN68JBnV1cKF">https://x.com/jwbkim/status/1813263637429297381</a></span></li></ul><p class="c100 c46"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c100 c78 li-bullet-0"><span>Robot operated autonomous surgery: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html&amp;sa=D&amp;source=editors&amp;ust=1730413583538179&amp;usg=AOvVaw24fzqUYX0HtSoExdlugyd0">https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_gl7fpz1y51y1-1"><li class="c69 li-bullet-0"><span>With one claw, the machine lifted a tiny plastic ring from an equally tiny peg on the table, passed the ring from one claw to the other, moved it across the table and gingerly hooked it onto a new peg. Then the robot did the same with several more rings, completing the task as quickly as it had when guided by Dr. Fer. The training exercise was originally designed for humans; moving the rings from peg to peg is </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.flsprogram.org/wp-content/uploads/2014/03/Revised-Manual-Skills-Guidelines-February-2014.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583538561&amp;usg=AOvVaw0RHL6uilogNlDB-27VYHse">how surgeons learn to operate robots like the one in Berkeley</a></span><span class="c1">. Now, an automated robot performing the test can match or even exceed a human in dexterity, precision and speed, according to a new research paper from the Berkeley team.</span></li><li class="c69 li-bullet-0"><span>The project is a part of a much wider effort to bring artificial intelligence into the operating room. Using many of the same technologies that underpin </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2018/03/19/technology/how-driverless-cars-work.html&amp;sa=D&amp;source=editors&amp;ust=1730413583538905&amp;usg=AOvVaw2a5pmI3W6XRlV4ccHZlZs8">self-driving cars</a></span><span>, </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2021/02/26/technology/anduril-military-palmer-luckey.html&amp;sa=D&amp;source=editors&amp;ust=1730413583539127&amp;usg=AOvVaw0-99_FVEZozQQUseb0XWVP">autonomous drones</a></span><span>and </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2020/01/29/technology/warehouse-robot.html&amp;sa=D&amp;source=editors&amp;ust=1730413583539320&amp;usg=AOvVaw0nCip6rBYO_piDSYt0iK6u">warehouse robots</a></span><span class="c1">, researchers are working to automate surgical robots too. These methods are still a long way from everyday use, but progress is accelerating.</span></li><li class="c10 li-bullet-0"><span>Robots can already exceed human accuracy on some surgical tasks, like placing a pin into a bone (a particularly risky task during knee and hip replacements). The hope is that automated robots can bring greater accuracy to other tasks, like incisions or suturing, and reduce the risks that come with </span><span class="c92 c37 c63 c14 c76 c98">overworked surgeons.</span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c45 li-bullet-0"><span class="c63 c14">AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1814048365002596425&amp;sa=D&amp;source=editors&amp;ust=1730413583539789&amp;usg=AOvVaw1mYBRMigL8YgV_P9CpUBYL">https://x.com/tsarnick/status/1814048365002596425</a></span></li><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.00px; height: 925.00px;"><img alt="" src="images/image505.png" style="width: 569.00px; height: 925.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Caresyntax secures $180M to build AI-powered &lsquo;Android of robotic surgery&rsquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/business/caresyntax-secures-180m-to-build-ai-powered-android-of-robotic-surgery/&amp;sa=D&amp;source=editors&amp;ust=1730413583540295&amp;usg=AOvVaw0uN9b6Y6wr6WYLQEFpLVeK">https://venturebeat.com/business/caresyntax-secures-180m-to-build-ai-powered-android-of-robotic-surgery/</a></span></li><li class="c4 li-bullet-0"><span>Google DeepMind&#39;s AlphaProteo generates novel proteins for biology and health research: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source%3Dx%26utm_medium%3D%26utm_campaign%3Dgdm%26utm_content%3D&amp;sa=D&amp;source=editors&amp;ust=1730413583540612&amp;usg=AOvVaw3xs-c87jKkbyINSYdU49Q9">https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source=x&amp;utm_medium=&amp;utm_campaign=gdm&amp;utm_content=</a></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-1 start"><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaProteo can generate new protein binders for diverse target proteins, including </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www1.rcsb.org/structure/1BJ1&amp;sa=D&amp;source=editors&amp;ust=1730413583540835&amp;usg=AOvVaw3NOqQIU1TNbgJNRBN7foAr">VEGF-A</a></span><span class="c40 c37 c35 c48">, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.</span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c22 c95 c129 li-bullet-0"><span class="c35">Harnessing Synthetic Skin Lesion Data via Stable Diffusion Models for Enhanced Skin Disease Classification using ViT and CNN: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2401.05159v1&amp;sa=D&amp;source=editors&amp;ust=1730413583541163&amp;usg=AOvVaw1czNcYjwQUGHCgpdYUeYb6">https://arxiv.org/html/2401.05159v1</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 596.00px;"><img alt="" src="images/image575.jpg" style="width: 624.00px; height: 596.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DeryaTR_/status/1834630356286558336&amp;sa=D&amp;source=editors&amp;ust=1730413583541470&amp;usg=AOvVaw2wk4hpWw_gpxmYM-rLl2ig">https://x.com/DeryaTR_/status/1834630356286558336</a></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 620.00px;"><img alt="" src="images/image18.png" style="width: 624.00px; height: 620.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Cardiologists working with AI said it was equal or better than human cardiologists in most areas: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DKThomp/status/1843993273825964312&amp;sa=D&amp;source=editors&amp;ust=1730413583541768&amp;usg=AOvVaw3dKU7l0wul1_os-AnudJpW">https://x.com/DKThomp/status/1843993273825964312</a></span></li></ul><ul class="c0 lst-kix_gl7fpz1y51y1-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 209.33px;"><img alt="" src="images/image77.png" style="width: 624.00px; height: 209.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c37 c35 c48"></span></p><h2 class="c22 c80" id="h.rf2ly7btkvmg"><span class="c40 c37 c48 c75">4.4. Research Use</span></h2><ul class="c0 lst-kix_1jsoq3g3afbv-0 start"><li class="c4 li-bullet-0"><span>AI independently discovers number of variables in dynamic systems and can help discover new physics equations: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?time_continue%3D604%26v%3DXRL56YCfKtA%26embeds_referring_euri%3Dhttps%253A%252F%252Fwww.reddit.com%252F&amp;sa=D&amp;source=editors&amp;ust=1730413583542402&amp;usg=AOvVaw1iqyJRBK8TLxdKSD4RWzNL">https://www.youtube.com/watch/watch?v=XRL56YCfKtA</a></span></li><li class="c4 li-bullet-0"><span>Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08304&amp;sa=D&amp;source=editors&amp;ust=1730413583542682&amp;usg=AOvVaw38w3k1n2bdwU9hR-L0AjGQ">https://arxiv.org/abs/2410.08304</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 464.00px;"><img alt="" src="images/image416.png" style="width: 624.00px; height: 464.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 600.00px;"><img alt="" src="images/image354.png" style="width: 624.00px; height: 600.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 346.67px;"><img alt="" src="images/image333.png" style="width: 624.00px; height: 346.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413583543090&amp;usg=AOvVaw1h0S8lJhOWExaCsRPOh90S">https://arxiv.org/abs/2410.0620</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-1"><li class="c10 li-bullet-0"><span class="c1">LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c22 c4 li-bullet-0"><span class="c15">ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications:</span><span class="c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.00176&amp;sa=D&amp;source=editors&amp;ust=1730413583543463&amp;usg=AOvVaw0uS19lnVfiuU-stAnWoRns">&nbsp;</a></span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.00176&amp;sa=D&amp;source=editors&amp;ust=1730413583543576&amp;usg=AOvVaw3-cET7SxDd5uLvhBT1VZJv">https://arxiv.org/pdf/2311.00176</a></span></li></ul><p class="c22 c9 c97"><span class="c33 c15"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 c144 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 961.33px;"><img alt="" src="images/image64.png" style="width: 624.00px; height: 961.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span class="c1">Not as good as the Opus model they said is coming out later this year </span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">80% lower cost than Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">2x speed over Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">decent math and coding jump. 10% better on MATH 9% better on GPQA</span></li><li class="c10 li-bullet-0"><span class="c15 c65 c60">Can convert research paper descriptions to code: </span><span class="c5 c15 c65 c114"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1803816296410190286&amp;sa=D&amp;source=editors&amp;ust=1730413583544167&amp;usg=AOvVaw1Lo7e4b15qiCdNV4TG4Dz7">https://x.com/VictorTaelin/status/1803816296410190286</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-2 start"><li class="c7 li-bullet-0"><span>Yves does NOT explain how to implement the system at all, he just defines it in mathematical terms. By all means, ICs aren&#39;t hard to implement, but understanding what the paper is saying without images is tough. The best models so far always outputted 100% bullshit code. I just tested again and Opus/GPT-4 outputs are always just gibberish. Sonnet 3.5 did surprisingly well </span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>Stanford researchers: &ldquo;Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413583544578&amp;usg=AOvVaw0loatSi8pD-sD8QGrtu4u2">https://x.com/ChengleiSi/status/1833166031134806330</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-1"><li class="c10 li-bullet-0"><span>&gt;We also used an LLM to </span><span class="c34">standardize the writing styles of human and LLM ideas to avoid potential confounders</span><span class="c1">, while preserving the original content.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image152.jpg" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image91.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/&amp;sa=D&amp;source=editors&amp;ust=1730413583545217&amp;usg=AOvVaw0pxG1xiEzQcIgy3oK8DL3U">https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/</a></span></li></ul><p class="c22 c21 c97"><span class="c33 c15">&nbsp;</span></p><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c22 c4 li-bullet-0"><span class="c14">New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S135964462400134X&amp;sa=D&amp;source=editors&amp;ust=1730413583545520&amp;usg=AOvVaw2LRB7OizmmXwUnXj6QAANd">https://www.sciencedirect.com/science/article/pii/S135964462400134X</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span class="c14">We managed to fold, using #AlphaFold, in one year all </span><span class="c15">200 million proteins known to science</span><span class="c14">:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GoogleDeepMind/status/1786342523234861254&amp;sa=D&amp;source=editors&amp;ust=1730413583545877&amp;usg=AOvVaw2idEywLbxMK_Kc9hhqkWjS">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GoogleDeepMind/status/1786342523234861254&amp;sa=D&amp;source=editors&amp;ust=1730413583546014&amp;usg=AOvVaw2BQQOc479g1BxQnTUmJKUb">https://twitter.com/GoogleDeepMind/status/1786342523234861254</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span>Google DeepMind&rsquo;s new AI can model DNA, RNA, and &lsquo;all life&rsquo;s molecules&rsquo;</span><span><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold&amp;sa=D&amp;source=editors&amp;ust=1730413583546345&amp;usg=AOvVaw1PkCFmMs_jgUtjJbi-GCtW">&nbsp;</a></span><span class="c20"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold&amp;sa=D&amp;source=editors&amp;ust=1730413583546507&amp;usg=AOvVaw3QRjtw8l0vkTDkHS1XQrYB">https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 488.00px;"><img alt="" src="images/image70.png" style="width: 624.00px; height: 488.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-2 start"><li class="c7 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583546802&amp;usg=AOvVaw1yY99h1weUy1qVdyZWSiRS">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c22 c4 li-bullet-0"><span class="c14">[</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583547055&amp;usg=AOvVaw1AcQ90MV1aXcO84sCxzApq">Generative AI will be designing new drugs all on its own in the near future]</a></span><span class="c14">(</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583547224&amp;usg=AOvVaw3DiT8jUFgbXwVRqFuKzguv">https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html</a></span><span class="c1 c14">)</span></li><li class="c22 c4 li-bullet-0"><span class="c14">AI is speeding up human-like robot development | &ldquo;It has accelerated our entire research and development cycle.&rdquo;</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html&amp;sa=D&amp;source=editors&amp;ust=1730413583547470&amp;usg=AOvVaw3zyQUxvx3lEWfqA7o2Wqlm">&nbsp;</a></span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html&amp;sa=D&amp;source=editors&amp;ust=1730413583547620&amp;usg=AOvVaw15SrdWdthbPiR_JGv4Q3o1">https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html</a></span></li><li class="c22 c4 li-bullet-0"><span class="c14">[ChatGPT can do chemistry research better than AI designed for it and the creators didn&rsquo;t even know](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/0b03ibtVYhw?feature%3Dshared%26t%3D447&amp;sa=D&amp;source=editors&amp;ust=1730413583547832&amp;usg=AOvVaw3Pvo0wzdYvKS_5gpOMyZtV">https://youtu.be/0b03ibtVYhw?feature=shared&amp;t=447</a></span><span class="c1 c14">)</span></li><li class="c45 li-bullet-0"><span class="c14">Enveda presents PRISM -foundation AI model trained on 1.2 billion small molecule mass spectra to enhance mass spectrometry analysis in drug discovery. It uses self-supervised learning to predict molecular properties from complex mixtures without prior annotations: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.enveda.com/posts/prism-a-foundation-model-for-lifes-chemistry&amp;sa=D&amp;source=editors&amp;ust=1730413583548079&amp;usg=AOvVaw3YqHAY_q-SbOkhRA9_w0Wp">https://www.enveda.com/posts/prism-a-foundation-model-for-lifes-chemistry</a></span><span class="c1 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Perovskite discovery goes automatic: New platform expedites material development for next-gen tech: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://techxplore.com/news/2024-08-perovskite-discovery-automatic-platform-material.html&amp;sa=D&amp;source=editors&amp;ust=1730413583548309&amp;usg=AOvVaw0nrNkEUiUL8RQ-u2d9E7UZ">https://techxplore.com/news/2024-08-perovskite-discovery-automatic-platform-material.html</a></span></li><li class="c45 li-bullet-0"><span>Microsoft has built a weather forecasting model named &#39;Aurora&#39; - trained </span><span class="c14">on over a million hours of weather and climate simulations. MS estimates a 5000x computational speed-up over the state-of-the-art numerical forecasting system (IFS) while operating at a fraction of the cost: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/MSFTResearch/status/1797662278394827029&amp;sa=D&amp;source=editors&amp;ust=1730413583548544&amp;usg=AOvVaw1rjBcmWHLw3mPmfduaiKfp">https://x.com/MSFTResearch/status/1797662278394827029</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c59 li-bullet-0"><span class="c14">Can accurately forecast weather and air pollution for the whole world &mdash; and it does it in less than a minute: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/Nature/status/1798032169971118099&amp;sa=D&amp;source=editors&amp;ust=1730413583548743&amp;usg=AOvVaw1KRF9Sw7rk3GN38DoEcTwi">https://x.com/Nature/status/1798032169971118099</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c45 li-bullet-0"><span class="c14">Nvidia cloned Earth to Predict the weather Worldwide using AI: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/itaybachman/status/1797631338897686773&amp;sa=D&amp;source=editors&amp;ust=1730413583548951&amp;usg=AOvVaw0XIZuunqGDzpgddqd5unda">https://x.com/itaybachman/status/1797631338897686773</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c59 li-bullet-0"><span class="c14">EU did the same: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://thenextweb.com/news/eu-launches-ai-powered-digital-twin-of-the-earth&amp;sa=D&amp;source=editors&amp;ust=1730413583549158&amp;usg=AOvVaw3ngeqaAZMYHOaZBSEVaFoT">https://thenextweb.com/news/eu-launches-ai-powered-digital-twin-of-the-earth</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c45 li-bullet-0"><span class="c14">LLMs can outperform existing methods for identifying causal genes in genome-wide association studies: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.medrxiv.org/content/10.1101/2024.05.30.24308179v1%23:~:text%3DHere%252C%2520we%2520demonstrate%2520that%2520large%2520language%2520models%2520%2528LLMs%2529,outperform%2520state-of-the-art%2520methods%2520in%2520identifying%2520putative%2520causal%2520genes&amp;sa=D&amp;source=editors&amp;ust=1730413583549417&amp;usg=AOvVaw3g6I1hRzVI1qjZ0hGob5My">https://www.medrxiv.org/content/10.1101/2024.05.30.24308179v1</a></span><span class="c1 c14">. </span></li><li class="c45 li-bullet-0"><span class="c99 c37 c65 c60 c144">Predicting out of distribution(!!!) phenomenon of NaCl in solvent: </span><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.12535&amp;sa=D&amp;source=editors&amp;ust=1730413583549639&amp;usg=AOvVaw2cc93V92hZv2KZVFlkkrn6">https://arxiv.org/abs/2310.12535</a></span><span class="c6 c92 c99">: </span></li><li class="c51 li-bullet-0"><span class="c6 c99">&nbsp;</span><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GillVerd/status/1764901418664882327&amp;sa=D&amp;source=editors&amp;ust=1730413583549844&amp;usg=AOvVaw0er6wG92XrrezNt-xLOQW4">Claude 3 recreated an unpublished paper on quantum theory without ever seeing it</a></span><span class="c6 c99">&nbsp;: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GillVerd/status/1764901418664882327&amp;sa=D&amp;source=editors&amp;ust=1730413583549993&amp;usg=AOvVaw0Yr38twen2OGQxHTNhNXgO">https://twitter.com/GillVerd/status/1764901418664882327</a></span></li><li class="c51 li-bullet-0"><span>LLM solves previously unsolvable math problem: </span><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/&amp;sa=D&amp;source=editors&amp;ust=1730413583550238&amp;usg=AOvVaw3_d_TTI5a1f2-rCPzG-06S">https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/</a></span></li><li class="c51 li-bullet-0"><span>AI creates a faster sorting algorithm: </span><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41586-023-06004-9&amp;sa=D&amp;source=editors&amp;ust=1730413583550436&amp;usg=AOvVaw2rOW7V_VTQebztEywQqE-1">https://www.nature.com/articles/s41586-023-06004-9</a></span></li><li class="c51 li-bullet-0"><span>Matrix multiplication breakthrough due to AI: </span><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://www.quantamagazine.org/ai-reveals-new-possibilities-in-matrix-multiplication-20221123/&amp;sa=D&amp;source=editors&amp;ust=1730413583550752&amp;usg=AOvVaw2vuinZ5u8WD90uyErmB1ET">https://www.quantamagazine.org/ai-reveals-new-possibilities-in-matrix-multiplication-20221123/</a></span></li><li class="c53 c111 c56 c78 li-bullet-0"><span>Boosting Visual-Language Models with Synthetic Captions and Image Embeddings: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.07750&amp;sa=D&amp;source=editors&amp;ust=1730413583550963&amp;usg=AOvVaw1SWiG0BxsPAADy2n1kmlVq">https://arxiv.org/pdf/2403.07750</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c53 c111 c56 c97 c105 li-bullet-0"><span>Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator&rsquo;s ability to create </span><span class="c15">novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. </span><span>Extensive experiments demonstrate that our VLM, </span><span class="c15">finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. </span><span>Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up </span><span class="c33 c15">promising avenues for the development of self-improving multi-modal models.</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c53 c111 c56 c78 li-bullet-0"><span>ESM3: Simulating 500 million years of evolution with a language model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://evolutionaryscale.ai/blog/esm3-release&amp;sa=D&amp;source=editors&amp;ust=1730413583551533&amp;usg=AOvVaw2qZB-jOfKpzphtPDZREDnW">https://evolutionaryscale.ai/blog/esm3-release</a></span><span class="c1">&nbsp;</span></li><li class="c22 c111 c78 li-bullet-0"><span>This 20,000HP AI-generated rocket engine took just two weeks to design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet/&amp;sa=D&amp;source=editors&amp;ust=1730413583551841&amp;usg=AOvVaw3OXLzjbi6SIPp8iEAPVKJF">https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet</a></span></li><li class="c62 li-bullet-0"><span>OpenAI and Los Alamos National Laboratory announce bioscience research partnership: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together/&amp;sa=D&amp;source=editors&amp;ust=1730413583552098&amp;usg=AOvVaw3m7dqNp5_-WhiU3rvFIxru">https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together/</a></span></li><li class="c62 li-bullet-0"><span>Demis Hassabis says AI will enhance science: designing new drugs for medicine, discovering a room temperature superconductor, cracking mathematical conjectures and formulating its own new conjectures: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1814908695706255528&amp;sa=D&amp;source=editors&amp;ust=1730413583552395&amp;usg=AOvVaw3b_CVcz5ycJlWUPU_YfFuK">https://x.com/tsarnick/status/1814908695706255528</a></span></li><li class="c62 li-bullet-0"><span>Use of AI for social science experiments: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/RobbWiller/status/1821271270182547916&amp;sa=D&amp;source=editors&amp;ust=1730413583552674&amp;usg=AOvVaw1d9EXn7186mEXNeWGmTRSP">https://x.com/RobbWiller/status/1821271270182547916</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c170 c97 c105 li-bullet-0"><span class="c1">Across 70 studies, we find striking alignment (r = .85) between simulated and observed effects</span></li><li class="c170 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 501.50px; height: 501.50px;"><img alt="" src="images/image226.png" style="width: 501.50px; height: 501.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c170 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 360.00px; height: 360.00px;"><img alt="" src="images/image231.png" style="width: 360.00px; height: 360.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c170 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 509.50px; height: 509.50px;"><img alt="" src="images/image104.png" style="width: 509.50px; height: 509.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c97 c105 c170 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 412.00px;"><img alt="" src="images/image347.png" style="width: 624.00px; height: 412.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span class="c1">Automated Design of Agentic Systems: Presents Meta Agent Search to demonstrate that we can use agents to invent novel and powerful agent designs by programming in code</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span>proj:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/lGEL9nVFRw&amp;sa=D&amp;source=editors&amp;ust=1730413583553320&amp;usg=AOvVaw1t_BTsuyAfwG8f_uvy4skq">&nbsp;https://shengranhu.com/ADAS/</a></span></li><li class="c10 li-bullet-0"><span>abs:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/DAHuy2WTtc&amp;sa=D&amp;source=editors&amp;ust=1730413583553515&amp;usg=AOvVaw3xX2Eka1Tb3pyrd0HVbmVA">&nbsp;https://arxiv.org/abs/2408.08435</a></span></li><li class="c10 li-bullet-0"><span>github:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/r8OKfjWlN5&amp;sa=D&amp;source=editors&amp;ust=1730413583553689&amp;usg=AOvVaw0T7K9gNOJwM2yS4YBamPTS">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/ShengranHu/ADAS&amp;sa=D&amp;source=editors&amp;ust=1730413583553803&amp;usg=AOvVaw2jzeSqGwq1eajTROXODZ2K">https://github.com/ShengranHu/ADAS</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>FermiNet: Quantum physics and chemistry from first principles: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/&amp;sa=D&amp;source=editors&amp;ust=1730413583554033&amp;usg=AOvVaw2NyNc6gq9rd-fR31ylBkht">https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/</a></span></li><li class="c4 li-bullet-0"><span>Google DeepMind&#39;s AlphaProteo generates novel proteins for biology and health research: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source%3Dx%26utm_medium%3D%26utm_campaign%3Dgdm%26utm_content%3D&amp;sa=D&amp;source=editors&amp;ust=1730413583554455&amp;usg=AOvVaw0GoYFx0sGWKoYZtPfz7aKn">https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source=x&amp;utm_medium=&amp;utm_campaign=gdm&amp;utm_content=</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaProteo can generate new protein binders for diverse target proteins, including </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www1.rcsb.org/structure/1BJ1&amp;sa=D&amp;source=editors&amp;ust=1730413583554685&amp;usg=AOvVaw1H3ZYB_txyMQawjUWaEWgE">VEGF-A</a></span><span class="c40 c37 c35 c48">, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c78 c110 li-bullet-0"><span>Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2409.02522v1&amp;sa=D&amp;source=editors&amp;ust=1730413583554977&amp;usg=AOvVaw3FGcAUh1LIxSHOB9c0VTY1">https://arxiv.org/html/2409.02522v1</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span class="c1">Cog-GA, a generative agent founded on large language models (LLMs) tailored for VLN-CE tasks. Cog-GA employs a dual-pronged strategy to emulate human-like cognitive processes. Firstly, it constructs a cognitive map, integrating temporal, spatial, and semantic elements, thereby facilitating the development of spatial memory within LLMs. Secondly, Cog-GA employs a predictive mechanism for waypoints, strategically optimizing the exploration trajectory to maximize navigational efficiency. Each waypoint is accompanied by a dual-channel scene description, categorizing environmental cues into &rsquo;what&rsquo; and &rsquo;where&rsquo; streams as the brain. This segregation enhances the agent&rsquo;s attentional focus, enabling it to discern pertinent spatial information for navigation. A reflective mechanism complements these strategies by capturing feedback from prior navigation experiences, facilitating continual learning and adaptive replanning. Extensive evaluations conducted on VLN-CE benchmarks validate Cog-GA&rsquo;s state-of-the-art performance and ability to simulate human-like navigation behaviors. This research significantly contributes to the development of strategic and interpretable VLN-CE agents.</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>Introducing PaperQA2, the first AI agent that conducts entire scientific literature reviews on its own: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/SGRodriques/status/1833908643856818443&amp;sa=D&amp;source=editors&amp;ust=1730413583555345&amp;usg=AOvVaw0xIo2VYd40QThpUtJTl6Bi">https://x.com/SGRodriques/status/1833908643856818443</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span class="c1">PaperQA2 is also the first agent to beat PhD and Postdoc-level biology researchers on multiple literature research tasks, as measured both by accuracy on objective benchmarks and assessments by human experts. We are publishing a paper and open-sourcing the code.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">This is the first example of AI agents exceeding human performance on a major portion of scientific research, and will be a game-changer for the way humans interact with the scientific literature. </span></li><li class="c10 li-bullet-0"><span class="c1">PaperQA2 finds and summarizes relevant literature, refines its search parameters based on what it finds, and provides cited, factually grounded answers that are more accurate on average than answers provided by PhD and postdoc-level biologists. When applied to answer highly specific questions, like this one, it obtains SOTA performance on LitQA2, part of LAB-Bench focused on information retrieval</span></li><li class="c10 li-bullet-0"><span class="c1">PaperQA2 can also do broad-based literature reviews. WikiCrow, which is an agent based on PaperQA2, writes Wikipedia-style articles that are significantly more accurate on average than actual human-written articles on Wikipedia, as judged by PhD and postdoc-level biologists. </span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>NotebookLM now lets you listen to a conversation about your sources (Create a two person podcast from your sources): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blog.google/technology/ai/notebooklm-audio-overviews/&amp;sa=D&amp;source=editors&amp;ust=1730413583555873&amp;usg=AOvVaw1eQLwDI44Dt2jHwGUOxGwn">https://blog.google/technology/ai/notebooklm-audio-overviews/</a></span></li><li class="c4 li-bullet-0"><span>We&rsquo;re Entering Uncharted Territory for Math - Terrence Tao on o1 and the future of AI &amp; Math: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theatlantic.com/technology/archive/2024/10/terence-tao-ai-interview/680153/&amp;sa=D&amp;source=editors&amp;ust=1730413583556117&amp;usg=AOvVaw3Rc2goSROa8k5Gpc5N04ye">https://www.theatlantic.com/technology/archive/2024/10/terence-tao-ai-interview/680153/</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span class="c1">I was interested in using these tools as research assistants. A research project has a lot of tedious steps: You may have an idea and you want to flesh out computations, but you have to do it by hand and work it all out.</span></li><li class="c10 li-bullet-0"><span class="c1">It&rsquo;s the equivalent, in terms of serving as that kind of an assistant. But I do envision a future where you do research through a conversation with a chatbot. Say you have an idea, and the chatbot went with it and filled out all the details.</span></li><li class="c10 li-bullet-0"><span class="c1">In a Zoom call last week, he described a kind of AI-enabled, &ldquo;industrial-scale mathematics&rdquo; that has never been possible before: one in which AI, at least in the near future, is not a creative collaborator in its own right so much as a lubricant for mathematicians&rsquo; hypotheses and approaches. This new sort of math, which could unlock terra incognitae of knowledge, will remain human at its core, embracing how people and machines have very different strengths that should be thought of as complementary rather than competing.</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>This is an AI app that turns any piece of writing into a graph: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/MushtaqBilalPhD/status/1843170045704520152&amp;sa=D&amp;source=editors&amp;ust=1730413583556514&amp;usg=AOvVaw0V9Hw_IFqtj0m1M2Px0NeI">https://x.com/MushtaqBilalPhD/status/1843170045704520152</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span class="c1">This can help you brainstorm ideas, develop your research projects, and prepare impressive presentations.</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413583556766&amp;usg=AOvVaw0iHx7AufSPvgWGWJlGezJ7">https://arxiv.org/abs/2410.06209</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c10 li-bullet-0"><span class="c1">LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c4 li-bullet-0"><span>G&ouml;del Agent: A Self-Referential Agent Framework for Recursive Self-Improvement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.04444&amp;sa=D&amp;source=editors&amp;ust=1730413583557020&amp;usg=AOvVaw0SWONFzP0cmeXFmOAHM4Kp">https://arxiv.org/abs/2410.04444</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_1jsoq3g3afbv-1"><li class="c10 li-bullet-0"><span class="c3">In this paper, we introduce G&ouml;del Agent, a self-evolving framework inspired by the G&ouml;del machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. G&ouml;del Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of G&ouml;del Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.</span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-0"><li class="c22 c4 li-bullet-0"><span class="c14">The AI scientist: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2408.06292&amp;sa=D&amp;source=editors&amp;ust=1730413583557421&amp;usg=AOvVaw31vUH6DQ5gQ03p05m5A2rL">https://arxiv.org/abs/2408.06292</a></span></li></ul><ul class="c0 lst-kix_1jsoq3g3afbv-1 start"><li class="c22 c10 li-bullet-0"><span class="c14 c31">This paper presents the first comprehensive framework for fully </span><span class="c34 c14 c31">automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings</span><span class="c14 c31">. We introduce The AI Scientist, which generates </span><span class="c34 c14 c31">novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation.</span><span class="c14 c31">&nbsp;In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a </span><span class="c34 c14 c31">cost of less than $15 per paper.</span><span class="c14 c31">&nbsp;To evaluate the generated papers, we design and validate </span><span class="c34 c14 c31">an automated reviewer, which we show achieves near-human performance in evaluating paper scores</span><span class="c14 c31">. The AI Scientist </span><span class="c15 c31">can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer.</span><span class="c14 c31">&nbsp;This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world&#39;s most challenging problems. Our code is open-sourced at </span><span class="c239 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://github.com/SakanaAI/AI-Scientist&amp;sa=D&amp;source=editors&amp;ust=1730413583557936&amp;usg=AOvVaw0o9kGSuMGNWo09cUnWkwm3">this https URL</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/SakanaAI/AI-Scientist&amp;sa=D&amp;source=editors&amp;ust=1730413583558071&amp;usg=AOvVaw3Fx0UvWelwaxfbYBBpBDsu">https://github.com/SakanaAI/AI-Scientist</a></span></li></ul><h2 class="c64" id="h.kmz8peroobsl"><span class="c40 c37 c48 c75">4.5. Military Use</span></h2><ul class="c0 lst-kix_afne6v2lp0be-0 start"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/&amp;sa=D&amp;source=editors&amp;ust=1730413583558402&amp;usg=AOvVaw2fJpZ-BXxLyPBzqqdJR8h5">AI-powered F-16 impresses ride-along SECAF in dogfight</a></span><span class="c14">:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/&amp;sa=D&amp;source=editors&amp;ust=1730413583558579&amp;usg=AOvVaw1BYNJWznn-g5lgHBD1z_7D">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/&amp;sa=D&amp;source=editors&amp;ust=1730413583558746&amp;usg=AOvVaw3t4nKH_9sGwGhbcV1FrUzI">https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/</a></span></li><li class="c4 c46 li-bullet-0"><span class="c1"></span></li><li class="c22 c4 li-bullet-0"><span class="c14">China launched the world&#39;s first AI-operated &#39;mother ship,&#39; an unmanned carrier capable of launching dozens of drones: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/china-launches-worlds-first-ai-unmanned-drone-aircraft-carrier-2022-6&amp;sa=D&amp;source=editors&amp;ust=1730413583559084&amp;usg=AOvVaw2G5JSOKYYgI_vqN1uuCvOV">https://www.businessinsider.com/china-launches-worlds-first-ai-unmanned-drone-aircraft-carrier-2022-6</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c4 li-bullet-0"><span class="c14">China&rsquo;s &lsquo;AI Ship Designer&rsquo; Works At Unprecedented Speed; Performed A Year&rsquo;s Work Only In 24 Hours!: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/&amp;sa=D&amp;source=editors&amp;ust=1730413583559389&amp;usg=AOvVaw06NgfnzH6wHeZ8Q-oEnvWh">https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c4 li-bullet-0"><span class="c14">The military wants &lsquo;robot ships&rsquo; to replace sailors in battle: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html&amp;sa=D&amp;source=editors&amp;ust=1730413583559644&amp;usg=AOvVaw10Z-azY9Ug8rNF9LEe0fW3">https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c4 li-bullet-0"><span class="c14">Significant integration of AI in naval vessels to take less than ten years: Poll: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.naval-technology.com/news/significant-integration-of-ai-in-naval-vessels-to-take-less-than-ten-years-poll/&amp;sa=D&amp;source=editors&amp;ust=1730413583559901&amp;usg=AOvVaw1rgGhmg71OyMyJcng9Jkx9">https://www.naval-technology.com/news/significant-integration-of-ai-in-naval-vessels-to-take-less-than-ten-years-poll/</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c4 li-bullet-0"><span class="c14">Navy&rsquo;s new &lsquo;Project OpenShip&rsquo; aims to swiftly apply AI to data captured by vessels at sea: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://defensescoop.com/2023/03/20/navys-new-project-openship-aims-to-swiftly-apply-ai-to-data-captured-by-vessels-at-sea/&amp;sa=D&amp;source=editors&amp;ust=1730413583560154&amp;usg=AOvVaw3n1UvuyTMby1KfO8yH8KHI">https://defensescoop.com/2023/03/20/navys-new-project-openship-aims-to-swiftly-apply-ai-to-data-captured-by-vessels-at-sea/</a></span><span class="c1 c14">&nbsp;</span></li><li class="c22 c4 li-bullet-0"><span class="c14">Every Ship a Carrier: How Artificial Intelligence Can Revolutionize the Air and Sea Domains: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.usni.org/magazines/proceedings/2024/march/every-ship-carrier-how-artificial-intelligence-can-revolutionize&amp;sa=D&amp;source=editors&amp;ust=1730413583560386&amp;usg=AOvVaw3UGFAYj8UgG34AgkAdxSxJ">https://www.usni.org/magazines/proceedings/2024/march/every-ship-carrier-how-artificial-intelligence-can-revolutionize</a></span></li><li class="c4 li-bullet-0"><span>A.I. Begins Ushering In an Age of Killer Robots: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2024/07/02/technology/ukraine-war-ai-weapons.html&amp;sa=D&amp;source=editors&amp;ust=1730413583560649&amp;usg=AOvVaw27YRbDjChnq0ZZ0fDnQK28">https://www.nytimes.com/2024/07/02/technology/ukraine-war-ai-weapons.html</a></span></li><li class="c4 li-bullet-0"><span>AI-Powered Super Soldiers Are More Than Just a Pipe Dream: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/us-military-hyper-enabled-operator/&amp;sa=D&amp;source=editors&amp;ust=1730413583560956&amp;usg=AOvVaw3BXebdhGo02d5mOJF154c-">https://www.wired.com/story/us-military-hyper-enabled-operator/</a></span></li></ul><ul class="c0 lst-kix_afne6v2lp0be-1 start"><li class="c10 li-bullet-0"><span class="c1">The US military has abandoned its half-century dream of a suit of powered armor in favor of a &ldquo;hyper enabled operator,&rdquo; a tactical AI assistant for special operations forces.</span></li></ul><ul class="c0 lst-kix_afne6v2lp0be-0"><li class="c4 li-bullet-0"><span>One-third of the U.S. military could be robots in the next 15 years: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.axios.com/2024/07/11/military-robots-technology&amp;sa=D&amp;source=editors&amp;ust=1730413583561286&amp;usg=AOvVaw3AohPi-YNgQ1knPA-r8U7P">https://www.axios.com/2024/07/11/military-robots-technology</a></span></li><li class="c4 li-bullet-0"><span>AI&rsquo;s &lsquo;Oppenheimer moment&rsquo;: autonomous weapons enter the battlefield | The military use of AI-enabled weapons is growing, and the industry that provides them is booming: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/technology/article/2024/jul/14/ais-oppenheimer-moment-autonomous-weapons-enter-the-battlefield&amp;sa=D&amp;source=editors&amp;ust=1730413583561597&amp;usg=AOvVaw1RQlSoDJmG22XgKSRPIA5R">https://www.theguardian.com/technology/article/2024/jul/14/ais-oppenheimer-moment-autonomous-weapons-enter-the-battlefield</a></span></li><li class="c4 li-bullet-0"><span>S Army turns to &#39;Scylla&#39; AI to protect depot. Quote &quot;the Army said Scylla uses drones and wide-area cameras to monitor facilities, detect potential threats, and tell personnel when they need to respond with far more accuracy than humans&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/news/technology/us-army-turns-to-scylla-ai-to-protect-depot/ar-AA1t9bqN?ocid%3Dmsedgntp%26pc%3DDCTS%26cvid%3D2746d694ab1d4abb821d23a258593eb5%26ei%3D92&amp;sa=D&amp;source=editors&amp;ust=1730413583561870&amp;usg=AOvVaw2iJ-Hc2LOCHGFtwoZpvEsv">https://www.msn.com/en-us/news/technology/us-army-turns-to-scylla-ai-to-protect-depot/ar-AA1t9bqN</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_afne6v2lp0be-1"><li class="c10 li-bullet-0"><span class="c1">&nbsp; &nbsp; The US Army is testing a new AI product that it says can identify threats from a mile away, and all without the need for any new hardware. &hellip;</span></li><li class="c10 li-bullet-0"><span class="c1">&nbsp; &nbsp; Called Scylla after the man-eating sea monster of Greek legend, the Army has been testing the platform for the past eight month at the Blue Grass Army Depot (BGAD) in eastern Kentucky, a munitions depot and former chemical weapons stockpiling site, where it&#39;s been used to enhance physical security at the installation.</span></li><li class="c10 li-bullet-0"><span class="c1">&nbsp; &nbsp; The Physical security Enterprise and Analysis Group (PSEAG), which is leading the Scylla tests, has trained Scylla to &quot;detect and classify&quot; persons&#39; features, their the behavior, and whether they&#39;re armed in real time in order to eliminate wasted security responses to non-threatening situations.</span></li><li class="c10 li-bullet-0"><span class="c1">&nbsp; &nbsp; &quot;Scylla AI leverages any suitable video feed available to monitor, learn and alert in an instant, lessening the operational burden on security personnel,&quot; said Drew Walter, the US deputy assistant secretary of defense for nuclear matters. &quot;Scylla&#39;s transformative potential lies in its support to PSEAG&#39;s core mission, which is to safeguard America&#39;s strategic nuclear capabilities.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">&nbsp; &nbsp; Regardless of what it&#39;s protecting, the Army said Scylla uses drones and wide-area cameras to monitor facilities, detect potential threats, and tell personnel when they need to respond with far more accuracy than a puny human</span></li><li class="c10 li-bullet-0"><span class="c1">&nbsp; &nbsp; &quot;If you&#39;re the security operator, do you think you could watch 15 cameras at one time &hellip; and pick out a gun at 1,000 feet? Scylla can,&quot; Willoughby said &nbsp;</span></li><li class="c10 li-bullet-0"><span class="c1">&nbsp; &nbsp; In one example of a simulated Scylla response, the system was able to use a camera a mile away to detect an &quot;intruder&quot; with a firearm climbing a water tower. A closer camera was able to follow up to get a better look, identifying the person as kneeling on the tower&#39;s catwalk. &nbsp;</span></li><li class="c10 li-bullet-0"><span>&nbsp; &nbsp; In another example, Scylla reportedly alerted security personnel &quot;within seconds&quot; of two armed individuals who were identified via facial recognition as BGAD personnel. Scylla was also able to spot people breaching a fence and follow them with a drone before security was able to intercept, detect smoke coming from a vehicle from about 700 feet away, and identify a &quot;mock fight&quot; between two people &quot;within seconds.&quot;</span></li></ul><h2 class="c22 c21 c97 c140" id="h.jzup012nx2xb"><span class="c40 c37 c48 c75">4.6. Robotics</span></h2><p class="c117"><span class="c33 c15">More information in section 5.1</span></p><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0 start"><li class="c100 c78 li-bullet-0"><span>Humanoid robots that can detect objects, appraise their work and correct mistakes are coming to factories: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1807886268501839875&amp;sa=D&amp;source=editors&amp;ust=1730413583562986&amp;usg=AOvVaw0IqLVbLjHAxbJaC1dKrQtb">https://x.com/tsarnick/status/1807886268501839875</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c100 c78 li-bullet-0"><span>Language action model can perform tasks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1bfsysa/3d_visionlanguageaction_generative_world_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583563412&amp;usg=AOvVaw0XQ9ryMoqoNs69_htF4HYQ">https://www.reddit.com/r/singularity/comments/1bfsysa/3d_visionlanguageaction_generative_world_model/</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c22 c4 li-bullet-0"><span class="c14">ChatGPT trains robot dog to walk on Swiss ball | This demonstrates that AIs like GPT-4 can train robots to perform complex, real-world tasks much more effectively than we humans can: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/chatgpt-robot-yoga-ball/&amp;sa=D&amp;source=editors&amp;ust=1730413583563751&amp;usg=AOvVaw0ruUehPTp15tI_cvBFR-vx">https://newatlas.com/technology/chatgpt-robot-yoga-ball/</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1 start"><li class="c22 c10 li-bullet-0"><span class="c1 c14">&gt;&quot;DrEureka, a new open-source software package that anyone can play with, is used to train robots to perform real-world tasks using Large Language Models (LLMs) such as ChatGPT 4. It&#39;s a &quot;sim-to-reality&quot; system, meaning it teaches the robots in a virtual environment using simulated physics, before implementing them in meatspace.&quot;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c22 c10 li-bullet-0"><span class="c1 c14">&gt;&quot;After each simulation, GPT can also reflect on how well the virtual robot did, and how it can improve.&quot;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c22 c10 li-bullet-0"><span class="c1 c14">&gt;&quot;DrEureka is the first of its kind. It&#39;s able to go &quot;zero-shot&quot; from simulation to real-world. Imagine having almost no working knowledge of the world around you and being pushed out of the nest and left to just figure it out. That&#39;s zero-shot.&quot;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c22 c10 li-bullet-0"><span class="c1 c14">&gt;&quot;So how did it perform? Better than us. DrEureka was able to beat humans at training the robo-pooch, seeing a 34% advantage in forward velocity and 20% in distance traveled across real-world mixed terrains.&quot;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c22 c10 li-bullet-0"><span class="c1 c14">&gt;&quot;How? Well, according to the researchers, it&#39;s all about the teaching style. Humans tend towards a curriculum-style teaching environment &ndash; breaking tasks down into small steps and trying to explain them in isolation, whereas GPT has the ability to effectively teach everything, all at once. That&#39;s something we&#39;re simply not capable of doing.&quot;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c4 li-bullet-0"><span class="c1">University of Tokyo study uses GPT-4 to generate humanoid robot motions from simple text prompts, like &quot;take a selfie with your phone.&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c10 li-bullet-0"><span class="c1">LLMs have a robust internal representation of how words and phrases correspond to physical movements.</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/Vl8rN4Du3v&amp;sa=D&amp;source=editors&amp;ust=1730413583564660&amp;usg=AOvVaw0XC6VwFR9jVQfoE8D13wtN">https://tnoinkwms.github.io/ALTER-LLM/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c4 li-bullet-0"><span class="c14">Robot integrated with Huawei&#39;s Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583564995&amp;usg=AOvVaw2ZVFqJJKK2rnsHBJgavJMy">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1806033905147077045&amp;sa=D&amp;source=editors&amp;ust=1730413583565152&amp;usg=AOvVaw2Wj4Qc20veXJHtqY39WSQ1">https://x.com/TheHumanoidHub/status/1806033905147077045</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c100 c78 li-bullet-0"><span class="c35">Robotics researchers are exploring how large language models can give physical machines more smarts: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/WIRED/status/1811519957794009220&amp;sa=D&amp;source=editors&amp;ust=1730413583565522&amp;usg=AOvVaw1bK08kPKmyB38msxmZTFa7">https://x.com/WIRED/status/1811519957794009220</a></span></li></ul><p class="c100 c46"><span class="c40 c37 c35 c48"></span></p><p class="c100 c46"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c100 c78 li-bullet-0"><span class="c35">Google using Gemini 1.5 for robotics: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/GoogleDeepMind/status/1811401347477991932&amp;sa=D&amp;source=editors&amp;ust=1730413583565823&amp;usg=AOvVaw3Q4UGa51lJGXvw9u6YCm7q">https://x.com/GoogleDeepMind/status/1811401347477991932</a></span></li></ul><p class="c100 c46"><span class="c40 c37 c35 c48"></span></p><p class="c100 c46"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c100 c78 li-bullet-0"><span class="c35">We found that LLMs can be repurposed as &quot;imitation learning engines&quot; for robots, by representing both observations &amp; actions as 3D keypoints, and feeding into an LLM for in-context learning: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/Ed__Johns/status/1778115232965013680&amp;sa=D&amp;source=editors&amp;ust=1730413583566149&amp;usg=AOvVaw1uVfcUe958Ezubl5HhmDSW">https://x.com/Ed__Johns/status/1778115232965013680</a></span></li></ul><p class="c100 c46"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c69 li-bullet-0"><span class="c40 c37 c35 c48">This works really well across a range of everyday tasks with complex and arbitrary trajectories, whilst also outperforming Diffusion Policies.</span></li><li class="c69 li-bullet-0"><span class="c40 c37 c35 c48">Also, we don&#39;t need any training time: the robot can perform tasks immediately after the demonstrations, with rapid in-context learning.</span></li></ul><p class="c100 c46"><span class="c40 c37 c35 c48"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c100 c78 li-bullet-0"><span class="c35">SARA: Self-Adaptive Robust Attention: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://sites.google.com/view/rtsara/?pli%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583566545&amp;usg=AOvVaw3qA6Z7sM-LrRLk2kuamJrh">https://sites.google.com/view/rtsara/?pli=1</a></span></li></ul><ul class="c0 lst-kix_9l9kjglfjgjz-1 start"><li class="c69 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 542.71px; height: 350.50px;"><img alt="" src="images/image356.png" style="width: 542.71px; height: 350.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c69 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 549.85px; height: 355.11px;"><img alt="" src="images/image392.png" style="width: 549.85px; height: 355.11px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c100 c46"><span class="c40 c35 c34 c48"></span></p><p class="c100 c46"><span class="c40 c35 c34 c48"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c4 li-bullet-0"><span>MIT&#39;s Algorithm for Self-Training Robots: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.perplexity.ai/page/mit-s-algorithm-for-self-train-Lewzl1W_RfusEK8Lpd6VTw&amp;sa=D&amp;source=editors&amp;ust=1730413583567024&amp;usg=AOvVaw1rUaog6npeZ-cdWfY6GRq9">https://www.perplexity.ai/page/mit-s-algorithm-for-self-train-Lewzl1W_RfusEK8Lpd6VTw</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c10 li-bullet-0"><span class="c40 c23">Large language models (LLMs) play a crucial role in enhancing the capabilities of MIT&#39;s self-training robots. By connecting robot motion data with the &quot;common sense knowledge&quot; of LLMs, the system enables robots to logically parse household tasks into subtasks and physically adjust to disruptions.This integration allows robots to move on from errors without having to start a task from scratch, significantly improving their adaptability and efficiency. The approach uses LLMs to automate the identification and sequencing of subtasks, simplifying the process of teaching robots complex behaviors. This innovative combination of robotics and AI technologies paves the way for more versatile and intelligent household robots that can handle a wide range of tasks with minimal human intervention</span></li></ul><p class="c9"><span class="c40 c23"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c4 li-bullet-0"><span>VoicePilot - Harnessing LLMs as Speech Interfaces for Physically Assistive Robots: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f5ls69/voicepilot_harnessing_llms_as_speech_interfaces/&amp;sa=D&amp;source=editors&amp;ust=1730413583567454&amp;usg=AOvVaw13NQvst2XV5qmi0yT6Hw7s">https://www.reddit.com/r/singularity/comments/1f5ls69/voicepilot_harnessing_llms_as_speech_interfaces/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c4 li-bullet-0"><span>SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://spatial-vlm.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583567677&amp;usg=AOvVaw2ufzltIQGP7TrRwNgQPt2r">https://spatial-vlm.github.io/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c4 li-bullet-0"><span>Your robot has arrived - Robots could be performing more services for humans in the near future; food could be next: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/waymo-self-driving-taxis-chipotle-robots-future-of-service-2024-8&amp;sa=D&amp;source=editors&amp;ust=1730413583567937&amp;usg=AOvVaw3_77-RZtLn1a3EU0YgMyuN">https://www.businessinsider.com/waymo-self-driving-taxis-chipotle-robots-future-of-service-2024-8</a></span></li><li class="c4 li-bullet-0"><span>Robots can paint: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/BeAmazed/comments/1drw1wr/meanwhile_robots_are_slowly_taking_jobs_away_from/&amp;sa=D&amp;source=editors&amp;ust=1730413583568172&amp;usg=AOvVaw2bunraw5Mg-2RmOQZ8RK20">https://www.reddit.com/r/BeAmazed/comments/1drw1wr/meanwhile_robots_are_slowly_taking_jobs_away_from/</a></span></li><li class="c100 c78 li-bullet-0"><span>Digit in action at GXO&#39;s SPANX facility in Flowery Branch, Georgia: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1807307038458052730&amp;sa=D&amp;source=editors&amp;ust=1730413583568368&amp;usg=AOvVaw3UhiO_YtpEWbVwnz57oAL9">https://x.com/TheHumanoidHub/status/1807307038458052730</a></span></li><li class="c100 c78 li-bullet-0"><span>AI designs new robot from scratch in seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/mariogabriele/status/1807886901006770624&amp;sa=D&amp;source=editors&amp;ust=1730413583568637&amp;usg=AOvVaw2lmLA-Gu90NluzawltxUCg">https://x.com/mariogabriele/status/1807886901006770624</a></span><span class="c1">&nbsp;</span></li><li class="c100 c78 li-bullet-0"><span>New video of humanoid robot Walker S by Chinese company UBTECH driving a screw and applying glass coating: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1808009673897136249&amp;sa=D&amp;source=editors&amp;ust=1730413583568837&amp;usg=AOvVaw1YIl4izl5cs221umhFnrMY">https://x.com/TheHumanoidHub/status/1808009673897136249</a></span><span class="c1">&nbsp;</span></li><li class="c100 c78 li-bullet-0"><span>Automated farm picking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/robotics/comments/1dv19lg/hitbot_robot_farm_automated_picking/&amp;sa=D&amp;source=editors&amp;ust=1730413583569153&amp;usg=AOvVaw3N5anl92eQzW1NiwJNesHm">https://www.reddit.com/r/robotics/comments/1dv19lg/hitbot_robot_farm_automated_picking/</a></span></li><li class="c4 li-bullet-0"><span>China&rsquo;s first full-sized general-purpose humanoid robot, unveiled at World Artificial Intelligence Conference 2024: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://technode.com/2024/07/05/qinglong-chinas-first-full-sized-general-purpose-humanoid-robot-unveiled-at-world-artificial-intelligence-conference-2024/&amp;sa=D&amp;source=editors&amp;ust=1730413583569457&amp;usg=AOvVaw0a6GDzKypjmMzyTrFg1ejh">https://technode.com/2024/07/05/qinglong-chinas-first-full-sized-general-purpose-humanoid-robot-unveiled-at-world-artificial-intelligence-conference-2024/</a></span></li><li class="c4 li-bullet-0"><span>400 robotic surgeries, 98% survival rate: Saudi hospital achieves milestone: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://interestingengineering.com/health/robotic-surgeries-record-survival-saudi&amp;sa=D&amp;source=editors&amp;ust=1730413583569691&amp;usg=AOvVaw3at4EoCR3vb86-2ymHUCs0">https://interestingengineering.com/health/robotic-surgeries-record-survival-saudi</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_9l9kjglfjgjz-1"><li class="c10 li-bullet-0"><span class="c1">&gt;The program has also successfully performed robotic procedures on high-risk patients such as children under 18, those with morbid obesity, and those requiring redo surgeries.</span></li><li class="c10 li-bullet-0"><span class="c1">&gt;This reduction in hospital stays also translates to a 40% decrease in overall costs compared to conventional methods. Besides, it allows patients to return to their daily lives more quickly.</span></li><li class="c10 li-bullet-0"><span class="c1">&gt;Moreover, the minimally invasive nature of robotic procedures has significantly shortened hospital stays by over 50%.</span></li><li class="c95 c105 c232 li-bullet-0"><span class="c40 c37 c35 c48">&gt;Its journey in robotic cardiac surgery began with 105 procedures in its first year. Since then, the program has evolved rapidly, encompassing 400 successful surgeries to date.</span></li></ul><ul class="c0 lst-kix_9l9kjglfjgjz-0"><li class="c100 c78 li-bullet-0"><span>Meet Robbie - a bartender robot from Robbie Drink - Robot Barman! Robbie Drink is a Polish company offering a rental cell with a FANUC Europe robot that works as a reliable bartender at various events: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/WevolverApp/status/1810418899784966542&amp;sa=D&amp;source=editors&amp;ust=1730413583570235&amp;usg=AOvVaw1nfnFdpNxyKWY3z8PSmMq6">https://x.com/WevolverApp/status/1810418899784966542</a></span></li><li class="c22 c4 li-bullet-0"><span>Successful test of humanoid robots at BMW Group Plant Spartanburg: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.press.bmwgroup.com/global/article/detail/T0444265EN/successful-test-of-humanoid-robots-at-bmw-group-plant-spartanburg&amp;sa=D&amp;source=editors&amp;ust=1730413583570646&amp;usg=AOvVaw2TKvJh5_ZMCnHtv8qvW03C">https://www.press.bmwgroup.com/global/article/detail/T0444265EN/successful-test-of-humanoid-robots-at-bmw-group-plant-spartanburg</a></span></li><li class="c22 c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 518.67px;"><img alt="" src="images/image172.png" style="width: 624.00px; height: 518.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Our LLM-driven bi-level programming shows it&rsquo;s possible to l EA rn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the &ldquo;chain rule&rdquo; to guide reward search directly from video demos&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/&amp;sa=D&amp;source=editors&amp;ust=1730413583571222&amp;usg=AOvVaw1u06MbabxuBup2NNIYa6Lb">https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/</a></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.whlhbgq5lum2"><span class="c40 c37 c48 c75">4.7. Engineering/Design</span></h2><ul class="c0 lst-kix_yoaj41w0jig0-0 start"><li class="c22 c163 c78 li-bullet-0"><span>How AlphaChip transformed computer chip design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/&amp;sa=D&amp;source=editors&amp;ust=1730413583571801&amp;usg=AOvVaw3IhoyMZF1QoQmb42tocy5L">https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</a></span></li></ul><ul class="c0 lst-kix_yoaj41w0jig0-1 start"><li class="c22 c27 li-bullet-0"><span class="c1">Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">The method has been used to design superhuman chip layouts in the last three generations of Google&rsquo;s custom AI accelerator, the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/tpu?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1730413583572233&amp;usg=AOvVaw1t3iO-pcmN7c_L7869bGVa">Tensor Processing Unit</a></span><span class="c40 c37 c35 c48">&nbsp;(TPU).</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaChip has generated superhuman chip layouts used in every generation of Google&rsquo;s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google&rsquo;s </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/&amp;sa=D&amp;source=editors&amp;ust=1730413583572763&amp;usg=AOvVaw3WebqCm-IcxEC-x0vWPSMC">Transformer</a></span><span class="c40 c37 c35 c48">&nbsp;architecture.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu&amp;sa=D&amp;source=editors&amp;ust=1730413583573123&amp;usg=AOvVaw0xdbRZjdOnRfIJ9DPOnTLP">Google Axion Processors</a></span><span class="c40 c37 c35 c48">, our first Arm-based general-purpose data center CPUs.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips &mdash; like the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.mediatek.com/products/smartphones/dimensity-5g&amp;sa=D&amp;source=editors&amp;ust=1730413583573485&amp;usg=AOvVaw2a3gZDDv4c_F1ES1Gkmxpk">Dimensity Flagship 5G</a></span><span class="c35">&nbsp;used in Samsung mobile phones &mdash; while improving power, performance and chip area.</span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 536.00px;"><img alt="" src="images/image76.png" style="width: 624.00px; height: 536.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image122.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yoaj41w0jig0-0"><li class="c4 li-bullet-0"><span>Autonomous robot invents the world&#39;s best shock absorber: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/autonomous-ai-robot-building-crushing-breaks-record/&amp;sa=D&amp;source=editors&amp;ust=1730413583574143&amp;usg=AOvVaw3MTVFOetk_BtPLyeW2LpTd">https://newatlas.com/technology/autonomous-ai-robot-building-crushing-breaks-record/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yoaj41w0jig0-0"><li class="c4 li-bullet-0"><span>AI designs new robot from scratch in seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/mariogabriele/status/1807886901006770624&amp;sa=D&amp;source=editors&amp;ust=1730413583574549&amp;usg=AOvVaw2QQdZxPx4fCiXZr7_UF_eA">https://x.com/mariogabriele/status/1807886901006770624</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ag80f2hqwfhx-0 start"><li class="c4 li-bullet-0"><span>This 20,000HP AI-generated rocket engine took just two weeks to design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet/&amp;sa=D&amp;source=editors&amp;ust=1730413583575042&amp;usg=AOvVaw1u4oBgJMV9IhKgra9cZQG-">https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yoaj41w0jig0-0"><li class="c4 li-bullet-0"><span>Toyota Research Institute Unveils New Generative AI Technique for Vehicle Design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://pressroom.toyota.com/toyota-research-institute-unveils-new-generative-ai-technique-for-vehicle-design/&amp;sa=D&amp;source=editors&amp;ust=1730413583575515&amp;usg=AOvVaw14lPUGQ3F-pY0gJbovRmVB">https://pressroom.toyota.com/toyota-research-institute-unveils-new-generative-ai-technique-for-vehicle-design/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yoaj41w0jig0-0"><li class="c231 c78 li-bullet-0"><span>AI Creates A Radical New Magnet Without Rare-Earth Metals Is About to Change Motors Forever In </span><span class="c174">just 3 months: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.popularmechanics.com/science/green-tech/a61147476/ai-developed-magnet-free-of-rare-earth-metals/&amp;sa=D&amp;source=editors&amp;ust=1730413583576005&amp;usg=AOvVaw0AluKiAODmUzXFQasjSOpf">https://www.popularmechanics.com/science/green-tech/a61147476/ai-developed-magnet-free-of-rare-earth-metals/</a></span></li></ul><p class="c46 c231"><span class="c57 c37 c174 c154 c48"></span></p><ul class="c0 lst-kix_yoaj41w0jig0-0"><li class="c4 li-bullet-0"><span>Bosch uses AI at South Carolina plant to design new e-motors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://carsinsiders.com/2022/11/26/bosch-uses-ai-at-south-carolina-plant-to-design-new-e-motors/&amp;sa=D&amp;source=editors&amp;ust=1730413583576392&amp;usg=AOvVaw1uK7zR7VCz7Oa6w7vNABWl">https://carsinsiders.com/2022/11/26/bosch-uses-ai-at-south-carolina-plant-to-design-new-e-motors/</a></span></li></ul><p class="c9"><span class="c57 c37 c174 c154 c48"></span></p><ul class="c0 lst-kix_yoaj41w0jig0-0"><li class="c4 li-bullet-0"><span class="c174">Aitomatic&rsquo;s SemiKong uses AI to reshape chipmaking processes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/aitomatics-semikong-uses-ai-to-reshape-chipmaking-processes/&amp;sa=D&amp;source=editors&amp;ust=1730413583576663&amp;usg=AOvVaw2g6sulgZzQbAorm9_MzAMZ">https://venturebeat.com/ai/aitomatics-semikong-uses-ai-to-reshape-chipmaking-processes/</a></span></li></ul><p class="c9"><span class="c57 c37 c154 c48 c174"></span></p><ul class="c0 lst-kix_yoaj41w0jig0-0"><li class="c4 li-bullet-0"><span class="c174">3DWire can generate 3D house wireframes from text: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1814576128415175047&amp;sa=D&amp;source=editors&amp;ust=1730413583576935&amp;usg=AOvVaw23xPmSxNvYk4_Zm3FPVYZS">https://x.com/dreamingtulpa/status/1814576128415175047</a></span></li></ul><ul class="c0 lst-kix_yoaj41w0jig0-1 start"><li class="c10 li-bullet-0"><span>The wireframes can be easily segmented into distinct components, such as walls, roofs, and rooms, reflecting the semantic essence of the shape.</span></li></ul><h2 class="c64" id="h.drsj7z1askut"><span class="c40 c37 c48 c75">4.8. Writing</span></h2><ul class="c0 lst-kix_3jdd6arud0e0-0 start"><li class="c4 li-bullet-0"><span class="c1">Grammarly and Quillbot use AI</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3jdd6arud0e0-0"><li class="c22 c4 li-bullet-0"><span class="c14">&ldquo;Here we show in two experimental studies that novice and experienced teachers could not identify texts generated by ChatGPT among student-written texts.&rdquo; </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S2666920X24000109&amp;sa=D&amp;source=editors&amp;ust=1730413583577558&amp;usg=AOvVaw0sIj0KGM5VfHzrlEAmDz4u">https://www.sciencedirect.com/science/article/pii/S2666920X24000109</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_3jdd6arud0e0-0"><li class="c4 li-bullet-0"><span class="c30 c37 c14">GPT4 passes Turing test 54% of the time: </span><span class="c5 c30 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/camrobjones/status/1790766472458903926&amp;sa=D&amp;source=editors&amp;ust=1730413583577872&amp;usg=AOvVaw0WN3r42uVP4wzSNi7V5b92">https://twitter.com/camrobjones/status/1790766472458903926</a></span></li></ul><p class="c9"><span class="c40 c30 c37 c14"></span></p><ul class="c0 lst-kix_3jdd6arud0e0-0"><li class="c106 c56 c78 li-bullet-0"><span>In a new study, AI-generated humor was rated as funnier than most human-created jokes. In a second study, it was on par with The Onion: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.psypost.org/ai-outshines-humans-in-humor-study-finds-chatgpt-is-as-funny-as-the-onion/&amp;sa=D&amp;source=editors&amp;ust=1730413583578182&amp;usg=AOvVaw2Xl4V-cK8fAp9gEQHfo8a_">https://www.psypost.org/ai-outshines-humans-in-humor-study-finds-chatgpt-is-as-funny-as-the-onion/</a></span></li></ul><ul class="c0 lst-kix_3jdd6arud0e0-1 start"><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103">ChatGPT outperformed 73% of the human participants in the acronyms task, 63% of the human participants in the fill-in-the-blank task, and 87% of human participants in the roast joke task.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103">The results showed no significant difference in the average funniness ratings between the AI-generated headlines and those from The Onion. Among the top four highest-rated headlines, two were generated by ChatGPT and two by The Onion. Notably, the highest-rated headline was an AI-generated one: &ldquo;Local Man Discovers New Emotion, Still Can&rsquo;t Describe It Properly.&rdquo; This suggests that ChatGPT can produce satirical content that is on par with professional writers.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103">These findings indicate that AI, specifically ChatGPT 3.5, has a surprising proficiency in humor production. Despite lacking emotions and personal experiences, the AI was able to analyze patterns and create jokes that resonated well with people.</span></li><li class="c106 c56 c97 c105 li-bullet-0"><span class="c40 c37 c35 c103 c14">The researchers also explored whether demographic factors influenced humor ratings. It was found that age, sex, and political orientation did not significantly affect participants&rsquo; preferences for AI-generated versus human-generated jokes. This suggests that the AI&rsquo;s humor appeal was broad and not limited to specific demographic groups.</span></li></ul><p class="c56 c97 c46 c106"><span class="c40 c37 c35 c103 c14"></span></p><ul class="c0 lst-kix_3jdd6arud0e0-0"><li class="c4 li-bullet-0"><span class="c14">[ChatGPT scores in top 1% of creativity](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://scitechdaily.com/chatgpt-tests-into-top-1-for-original-creative-thinking/&amp;sa=D&amp;source=editors&amp;ust=1730413583578839&amp;usg=AOvVaw16NOXhOI7IfPwkM_QGkUjQ">https://scitechdaily.com/chatgpt-tests-into-top-1-for-original-creative-thinking/</a></span><span class="c14">)</span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_3jdd6arud0e0-0"><li class="c4 li-bullet-0"><span class="c14">Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt&amp;sa=D&amp;source=editors&amp;ust=1730413583579202&amp;usg=AOvVaw3heMFUJKGvyEDfhh6dbnia">https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt</a></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.2gjofo8ytyqz"><span class="c40 c37 c48 c75">4.9. Helping People</span></h2><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c69 li-bullet-0"><span class="c15">New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S135964462400134X&amp;sa=D&amp;source=editors&amp;ust=1730413583579712&amp;usg=AOvVaw2t3Oq4UiUZREeC5OLjeIWm">https://www.sciencedirect.com/science/article/pii/S135964462400134X</a></span></li></ul><p class="c100 c46"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c69 li-bullet-0"><span class="c15">Whisper Diarization Web: In-browser multilingual speech recognition with word-level timestamps and speaker segmentation</span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1e9nux8/whisper_diarization_web_inbrowser_multilingual/&amp;sa=D&amp;source=editors&amp;ust=1730413583580028&amp;usg=AOvVaw1TjYHkiUe8kpl1IOaombaN">https://www.reddit.com/r/LocalLLaMA/comments/1e9nux8/whisper_diarization_web_inbrowser_multilingual/</a></span></li></ul><p class="c9 c105"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c10 li-bullet-0"><span class="c15">OpenAI Whisper has superhuman transcription ability: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D04NUPxifGiQ&amp;sa=D&amp;source=editors&amp;ust=1730413583580270&amp;usg=AOvVaw0zYFH8VQ6JQZYcuGQiiSL3">https://www.youtube.com/watch?v=04NUPxifGiQ</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span>Report: Leveraging AI Tools Could Help US Teachers Avoid $43.4 Billion of Unpaid Overtime Work: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://myelearningworld.com/ai-tech-time-saved-education/&amp;sa=D&amp;source=editors&amp;ust=1730413583580495&amp;usg=AOvVaw0HxhZSkPcl_8LKm12XuWGT">https://myelearningworld.com/ai-tech-time-saved-education/</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 583.07px; height: 352.20px;"><img alt="" src="images/image600.png" style="width: 583.07px; height: 352.20px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0 start"><li class="c4 li-bullet-0"><span class="c15">First legally recognized nonbinary person with disabilities writes book with ChatGPT: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583580914&amp;usg=AOvVaw3e-cLKxECHW_SYOue2PE7G">https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span>The novel draws from Shupe&rsquo;s eventful life, </span><span class="c15">including her advocacy for more inclusive gender recognition</span><span class="c1">.</span></li><li class="c10 li-bullet-0"><span>Shupe believes fervently that she was </span><span class="c15">only able to complete her book with the assistance of generative AI tools</span><span class="c1">. She says she has been assessed as 100 percent disabled by the Department of Veterans Affairs and struggles to write due to cognitive impairment related to conditions including bipolar disorder, borderline personality disorder, and a brain stem malformation.</span></li><li class="c10 li-bullet-0"><span>She is proud of the finished work and sees working with a text generator as a </span><span class="c15">different but no less worthwhile method of expressing thoughts</span><span>. &ldquo;You don&#39;t just hit &lsquo;generate&rsquo; and get something worthy of publishing. That may come in the future, but we&#39;re still far from it,&rdquo; she says, noting that she spen</span><span class="c33 c15">t upwards of 14 hours a day working on her draft.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c22 c10 li-bullet-0"><span class="c14">GPT 4o used to help blind people: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/Uttupaaji/status/1790217787010617544&amp;sa=D&amp;source=editors&amp;ust=1730413583581719&amp;usg=AOvVaw095u3ufHJSS2hJzZSV02su">https://twitter.com/Uttupaaji/status/1790217787010617544</a></span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c53 c111 c56 c97 c105 li-bullet-0"><span>Excellent synthetic caption generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.07750&amp;sa=D&amp;source=editors&amp;ust=1730413583582003&amp;usg=AOvVaw0jE50OScTKUmlZBOgHJFmK">https://arxiv.org/pdf/2403.07750</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c53 c111 c56 c86 li-bullet-0"><span>Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator&rsquo;s ability to create </span><span class="c15">novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. </span><span>Extensive experiments demonstrate that our VLM, </span><span class="c15">finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. </span><span>Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up </span><span class="c33 c15">promising avenues for the development of self-improving multi-modal models.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c53 c111 c56 c97 c105 li-bullet-0"><span>Dataset of 7.45 million AI generated image descriptions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/datasets/KBlueLeaf/danbooru2023-florence2-caption&amp;sa=D&amp;source=editors&amp;ust=1730413583582497&amp;usg=AOvVaw2Jssb054TK8JacxOjwez_d">https://huggingface.co/datasets/KBlueLeaf/danbooru2023-florence2-caption</a></span></li></ul><p class="c53 c111 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c22 c10 li-bullet-0"><span class="c1 c14">Gen AI used to help:</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c22 c7 li-bullet-0"><span class="c14">Blind people: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/Uttupaaji/status/1790217787010617544&amp;sa=D&amp;source=editors&amp;ust=1730413583582809&amp;usg=AOvVaw0IahRmywt17M3LxOLQo8ub">https://twitter.com/Uttupaaji/status/1790217787010617544</a></span></li><li class="c22 c7 li-bullet-0"><span class="c14">Students: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/mckaywrigley/status/1790088880919818332&amp;sa=D&amp;source=editors&amp;ust=1730413583583011&amp;usg=AOvVaw06cZNXl-VoC0OyoAQoz5AD">https://twitter.com/mckaywrigley/status/1790088880919818332</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-3 start"><li class="c22 c21 c26 li-bullet-0"><span class="c14">This is an AI app that turns any piece of writing into a graph: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/MushtaqBilalPhD/status/1843170045704520152&amp;sa=D&amp;source=editors&amp;ust=1730413583584314&amp;usg=AOvVaw0DMsA3wGvRcaO8c72hkfQE">https://x.com/MushtaqBilalPhD/status/1843170045704520152</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-4 start"><li class="c22 c21 c165 c97 li-bullet-0"><span class="c14">This can help you brainstorm ideas, develop your research projects, and prepare impressive presentations.</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2"><li class="c22 c7 li-bullet-0"><span class="c14">Translation: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/tomwarren/status/1790074556981403997&amp;sa=D&amp;source=editors&amp;ust=1730413583584661&amp;usg=AOvVaw2jw2l0fc8-cFT9Se_r6hjL">https://twitter.com/tomwarren/status/1790074556981403997</a></span></li></ul><p class="c22 c9 c97"><span class="c1"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-1"><li class="c22 c10 li-bullet-0"><span>AI is getting very popular among students and teachers, very quickly:</span><span><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/06/11/ai-is-getting-very-popular-among-students-and-teachers-very-quickly.html&amp;sa=D&amp;source=editors&amp;ust=1730413583584959&amp;usg=AOvVaw0Zin_EzmqhS2AJLGnjXMXc">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/06/11/ai-is-getting-very-popular-among-students-and-teachers-very-quickly.html&amp;sa=D&amp;source=editors&amp;ust=1730413583585176&amp;usg=AOvVaw2ZSL41qujli-kE2aJxLGLx">https://www.cnbc.com/2024/06/11/ai-is-getting-very-popular-among-students-and-teachers-very-quickly.html</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-2 start"><li class="c7 li-bullet-0"><span class="c15">Claude 3.5 can make graphics to describe things: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/calixo888/status/1803873821654684026&amp;sa=D&amp;source=editors&amp;ust=1730413583585458&amp;usg=AOvVaw2KlKJHm26M6AdpeRKjCIv8">https://x.com/calixo888/status/1803873821654684026</a></span><span class="c33 c15">&nbsp;</span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-3 start"><li class="c21 c26 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 522.71px; height: 387.47px;"><img alt="" src="images/image465.jpg" style="width: 522.71px; height: 387.47px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c4 li-bullet-0"><span class="c15">Create images to show instructions: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=http://github.com/GAIR-NLP/anole&amp;sa=D&amp;source=editors&amp;ust=1730413583585758&amp;usg=AOvVaw2b7-Rx8f2PO-cRGarKQNDo">github.com/GAIR-NLP/anole</a></span></li></ul><ul class="c0 lst-kix_hvoiym2mrtz4-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image94.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 232.00px;"><img alt="" src="images/image342.png" style="width: 624.00px; height: 232.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c65 c34 c244 c114"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c4 li-bullet-0"><span class="c14">Used as a tutor to help someone quintuple income </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1cpe3sk/chatgpt_just_just_made_me_get_a_job_paying_5x_more/&amp;sa=D&amp;source=editors&amp;ust=1730413583586262&amp;usg=AOvVaw1vtpkbSP-4P9b4L_2xRrfe">https://www.reddit.com/r/ChatGPT/comments/1cpe3sk/chatgpt_just_just_made_me_get_a_job_paying_5x_more/</a></span></li></ul><p class="c22 c9 c97"><span class="c33 c15"></span></p><ul class="c0 lst-kix_hvoiym2mrtz4-0"><li class="c22 c32 c14 li-bullet-0"><span>Claude 3.5 Sonnet transformed a research paper into an interactive learning dashboard in just 30 seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Saboo_Shubham_/status/1805789967203156357&amp;sa=D&amp;source=editors&amp;ust=1730413583586642&amp;usg=AOvVaw27mS5YovLmMw0OtzUw2sbj">https://x.com/Saboo_Shubham_/status/1805789967203156357</a></span></li><li class="c100 c78 li-bullet-0"><span>Introducing Surgical Robot Transformer (SRT): Automating surgical tasks with end-to-end imitation learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jwbkim/status/1813263637429297381&amp;sa=D&amp;source=editors&amp;ust=1730413583586904&amp;usg=AOvVaw25iaja0EGwLaiiuwVwYdty">https://x.com/jwbkim/status/1813263637429297381</a></span></li><li class="c4 li-bullet-0"><span>ChatGPT Advanced Audio helping someone pronouce &quot;Croissant&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eg51gz/chatgpt_advanced_audio_helping_me_pronouce/&amp;sa=D&amp;source=editors&amp;ust=1730413583587144&amp;usg=AOvVaw0-WzK6GMRWEEb-FZp495UO">https://www.reddit.com/r/singularity/comments/1eg51gz/chatgpt_advanced_audio_helping_me_pronouce/</a></span></li><li class="c4 li-bullet-0"><span>VoicePilot - Harnessing LLMs as Speech Interfaces for Physically Assistive Robots: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f5ls69/voicepilot_harnessing_llms_as_speech_interfaces/&amp;sa=D&amp;source=editors&amp;ust=1730413583587371&amp;usg=AOvVaw06mTg2fG4c2OuHHnCFIBIV">https://www.reddit.com/r/singularity/comments/1f5ls69/voicepilot_harnessing_llms_as_speech_interfaces/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 484.00px;"><img alt="" src="images/image397.png" style="width: 624.00px; height: 484.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.65b598y7trme"><span class="c40 c37 c48 c75">4.10. Persuasion</span></h2><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">AI beat humans at being persuasive: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/&amp;sa=D&amp;source=editors&amp;ust=1730413583587871&amp;usg=AOvVaw0WdyD3SOBlF66j08QDgABM">https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>OpenAI CTO says AI models pose &quot;incredibly scary&quot; major risks due to their ability to persuade, influence and control people: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e0d3es/openai_cto_says_ai_models_pose_incredibly_scary/&amp;sa=D&amp;source=editors&amp;ust=1730413583588145&amp;usg=AOvVaw0yA7Ek7WUXZqofIa7EsAvU">https://www.reddit.com/r/singularity/comments/1e0d3es/openai_cto_says_ai_models_pose_incredibly_scary/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 c53 c14 li-bullet-0"><span class="c14">This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs &amp; this lasts for months: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.adq1814&amp;sa=D&amp;source=editors&amp;ust=1730413583588385&amp;usg=AOvVaw0O7lMNOnPI7R7GlfgDQ40q">https://www.science.org/doi/10.1126/science.adq1814</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 c53 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 622.67px;"><img alt="" src="images/image279.png" style="width: 624.00px; height: 622.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c53 c14"><span class="c5 c57 c37 c48 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c94 c4 c14 li-bullet-0"><span class="c14">Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what&rsquo;s available now </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/&amp;sa=D&amp;source=editors&amp;ust=1730413583588788&amp;usg=AOvVaw2n8u2n_qx5xdGhesE6OOJt">https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/</a></span></li></ul><ul class="c0 lst-kix_jjh106bq03g-0"><li class="c94 c7 c14 li-bullet-0"><span class="c40 c37 c60 c48 c14">The resulting model mastered the intricacies of a complex game. &quot;Cicero can deduce, for example, that later in the game it will need the support of one particular player,&quot; says Meta, &quot;and then craft a strategy to win that person&rsquo;s favor&mdash;and even recognize the risks and opportunities that that player sees from their particular point of view.&quot;</span></li><li class="c94 c7 c14 li-bullet-0"><span class="c60 c14">Meta&#39;s Cicero research </span><span class="c5 c60 c14"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.ade9097&amp;sa=D&amp;source=editors&amp;ust=1730413583589088&amp;usg=AOvVaw3gU9m8yrrjtkTnSBWLjSd4">appeared</a></span><span class="c40 c37 c60 c48 c14">&nbsp;in the journal Science under the title, &quot;Human-level play in the game of Diplomacy by combining language models with strategic reasoning.&quot;</span></li><li class="c94 c7 c14 li-bullet-0"><span class="c92 c37 c35 c103 c14 c179">CICERO uses relationships with other players to keep its ally, Adam, in check.</span></li><li class="c7 c14 c94 li-bullet-0"><span class="c92 c37 c35 c173 c103 c14">When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.</span></li></ul><ul class="c0 lst-kix_9x4yq5ss9tc1-0"><li class="c10 c53 c14 li-bullet-0"><span class="c6">The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item &ndash; so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html&amp;sa=D&amp;source=editors&amp;ust=1730413583589551&amp;usg=AOvVaw1pr3FRNYX-PkclnAqASCMw">https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html</a></span></li></ul><p class="c22 c14 c44"><span class="c1"></span></p><h1 class="c123" id="h.vr8jz2f8ry8b"><span class="c14">5. </span><span class="c40 c37 c48 c77 c14">AI Can Replace Jobs</span></h1><p class="c9"><span class="c1"></span></p><table class="c224"><tr class="c237"><td class="c234" colspan="1" rowspan="1"><ul class="c0 lst-kix_idsnzgd8q5di-0 start"><li class="c22 c74 c129 li-bullet-0"><span class="c15">A new study shows a 21% drop in demand for digital freelancers since ChatGPT was launched. The hype in AI is real but so is the risk of job displacement: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4602944&amp;sa=D&amp;source=editors&amp;ust=1730413583594022&amp;usg=AOvVaw15GGLkbiZm6P-QF6HNzmJg">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4602944</a></span></li></ul><p class="c22 c74 c46"><span class="c33 c15"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1 start"><li class="c22 c74 c105 li-bullet-0"><span class="c87 c37 c35 c48 c14">&gt;Our findings indicate a 21 percent decrease in the number of job posts for automation-prone jobs related to writing and coding compared to jobs requiring manual-intensive skills after the introduction of ChatGPT. We also find that the introduction of Image-generating AI technologies led to a significant 17 percent decrease in the number of job posts related to image creation. Furthermore, we use Google Trends to show that the more pronounced decline in the demand for freelancers within automation-prone jobs correlates with their higher public awareness of ChatGPT&#39;s substitutability.</span></li></ul><p class="c22 c74 c46"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Already replacing jobs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://tech.co/news/companies-replace-workers-with-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583595018&amp;usg=AOvVaw17D-ahJTp_yjtQ82NLunjq">https://tech.co/news/companies-replace-workers-with-ai</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Artificial intelligence will affect 60 million US and Mexican jobs within the year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://english.elpais.com/economy-and-business/2024-09-15/artificial-intelligence-will-affect-60-million-us-and-mexican-jobs-within-the-year.html&amp;sa=D&amp;source=editors&amp;ust=1730413583595844&amp;usg=AOvVaw3iy0bkVYNrlnzvsfig8iU5">https://english.elpais.com/economy-and-business/2024-09-15/artificial-intelligence-will-affect-60-million-us-and-mexican-jobs-within-the-year.html</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c37 c190 c14 c233">According to the index, 980 million jobs around the world will be affected in some way by this new technology within the year. That amounts to 28% of the global workforce. Within five years, that figure will rise to between 38%, and in 10 years, 44%.</span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 559.05px; height: 773.50px;"><img alt="" src="images/image331.png" style="width: 559.05px; height: 773.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.visualcapitalist.com/charted-the-jobs-most-impacted-by-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583596907&amp;usg=AOvVaw2IraO-pCvZtKat1RtDdFtB">https://www.visualcapitalist.com/charted-the-jobs-most-impacted-by-ai/</a></span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 528.50px; height: 943.50px;"><img alt="" src="images/image65.png" style="width: 528.50px; height: 943.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.visualcapitalist.com/sp/ranking-industries-by-their-potential-for-ai-automation/&amp;sa=D&amp;source=editors&amp;ust=1730413583597530&amp;usg=AOvVaw20GDuXgKIPJ2f4EaoGyU0E">https://www.visualcapitalist.com/sp/ranking-industries-by-their-potential-for-ai-automation/</a></span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>OpenAI&rsquo;s o1 model can get perfect scores on their research engineer interview coding questions:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 610.00px; height: 377.33px;"><img alt="" src="images/image137.png" style="width: 610.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c15">AI agents entering workplace: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bloomberg.com/news/newsletters/2024-10-24/ai-agents-have-officially-entered-the-workplace-flaws-and-all?srnd%3Dhomepage-americas&amp;sa=D&amp;source=editors&amp;ust=1730413583598231&amp;usg=AOvVaw2-r1E67DY31wTOBv4lElS6">https://www.bloomberg.com/news/newsletters/2024-10-24/ai-agents-have-officially-entered-the-workplace-flaws-and-all</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span>&ldquo;</span><span class="c40 c37 c63 c14 c76">It is actually better than a human most of the time,&rdquo; said Amjad Masad, chief executive officer of Replit. &ldquo;Humans are kind of lazy and get annoyed and don&rsquo;t test everything. This is much more thorough.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c40 c37 c63 c14 c76">ServiceNow CEO Bill McDermott told my colleague Brody Ford this week that his company&rsquo;s new AI agents &ldquo;don&rsquo;t eat&rdquo; and can work 24/7. &ldquo;You don&rsquo;t have to give &lsquo;em a 401k!&rdquo; he added. The software company&rsquo;s agents are currently being tested out by some customers and will be released more broadly next month, he said.</span></li><li class="c10 li-bullet-0"><span class="c37 c63 c14 c76">In September, Salesforce Chief Operating Officer Brian Millham </span><span class="c5 c37 c63 c14 c76"><a class="c13" href="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2024-09-17/salesforce-ai-agent-strategy-acknowledges-job-losses-from-tech&amp;sa=D&amp;source=editors&amp;ust=1730413583599275&amp;usg=AOvVaw3H9nCG97uYqFEUyZPzXTsG">said</a></span><span class="c40 c37 c63 c14 c76">&nbsp;customers using the company&rsquo;s agents may elect to hire fewer people going forward. He gave an example of a 5,000-person call center needing 30% fewer workers within five years.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Robots [Automates] jobs from unions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html%23google_vignette&amp;sa=D&amp;source=editors&amp;ust=1730413583599920&amp;usg=AOvVaw3mja4IdA9sfefeutzacBSk">https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Women are 40% more likely to have their work replaced by A.I. </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ippr.org/media-office/up-to-8-million-uk-jobs-at-risk-from-ai-unless-government-acts-finds-ippr&amp;sa=D&amp;source=editors&amp;ust=1730413583600838&amp;usg=AOvVaw1q0XheOOCKmmmHjTf1WPax">https://www.ippr.org/media-office/up-to-8-million-uk-jobs-at-risk-from-ai-unless-government-acts-finds-ippr</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c69 li-bullet-0"><span class="c92 c37 c35 c193 c48">&gt;To see which tasks and jobs will be affected by AI, IPPR produced a metric that indicates how many tasks could be transformed by AI and then scored each task with regards to whether a human could perform it 50% more quickly with the help of AI.</span></li><li class="c69 li-bullet-0"><span class="c1">Nearly two-thirds of tasks carried out by workers could be automated by AI</span></li><li class="c214 c97 c105 li-bullet-0"><span class="c1">Chatbots could take over eight million jobs in the UK - and women will be worst affected, a leading think tank has warned.</span></li><li class="c69 li-bullet-0"><span class="c1">Back office, entry level and part-time jobs most exposed to automation, and women significantly more affected </span></li><li class="c69 li-bullet-0"><span class="c1">11 per cent of tasks are exposed to existing generative AI, rising to 59 per cent if companies integrate AI more deeply</span></li><li class="c69 li-bullet-0"><span class="c1">Expected effects of current AI:</span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-2 start"><li class="c100 c86 li-bullet-0"><span class="c92 c37 c35 c193 c48">Worst case scenario &ndash; full displacement: 1.5 million jobs are lost, with no GDP gains </span></li><li class="c100 c86 li-bullet-0"><span class="c92 c37 c35 c193 c48">Central scenario: 545,000 jobs are lost, with GDP gains of 3.1 per cent (&pound;64bn per year) </span></li><li class="c100 c86 li-bullet-0"><span class="c35 c193">Best case scenario &ndash; full augmentation: no jobs are lost, with GDP gains of 4 per cent (&pound;92bn per year)</span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c69 li-bullet-0"><span class="c1">Expected effects of future AI:</span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-2 start"><li class="c100 c86 li-bullet-0"><span class="c1">Worst case scenario &ndash; full displacement: all jobs at risk are replaced by AI, with 7.9 million job losses and no GDP gains </span></li><li class="c100 c86 li-bullet-0"><span class="c1">Central scenario: 4.4 million jobs disappear, but with economic gains of 6.3 per cent of GDP (&pound;144bn per year) </span></li><li class="c100 c86 li-bullet-0"><span class="c1">Best case scenario &ndash; full augmentation: all jobs at risk are augmented to adapt to AI, instead of replaced, leading to no job losses and an economic boost of 13 per cent to GDP (&pound;306bn per year)</span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c69 li-bullet-0"><span class="c1">Carsten Jung, senior economist at IPPR, said: &quot;Already existing generative AI could lead to big labour market disruption or it could hugely boost economic growth, either way it is set to be a game changer for millions of us. Many firms are already investing in it, and it has potential to speed up many more tasks as more businesses adopt it. Over the next five years it could transform knowledge work. The question now is less whether AI can be useful, but rather how fast and in what manner employers will use it. History show that technological transition can be a boon if well managed, or can end in disruption if left to unfold without controls. Indeed, some occupations could be hard hit by generative AI, starting with back office jobs.&rdquo;</span></li><li class="c69 li-bullet-0"><span class="c1">Bhargav Srinivasa Desikan, senior research fellow at IPPR, said: &ldquo;We could see jobs such as copywriters, graphic designers and personal assistants roles being heavily affected by AI.&rdquo;</span></li></ul><p class="c100 c46"><span class="c1"></span></p><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>AI Is Already Taking Jobs in the Video Ga</span><span>me Industry: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/ai-is-already-taking-jobs-in-the-video-game-industry/&amp;sa=D&amp;source=editors&amp;ust=1730413583604586&amp;usg=AOvVaw1U_IUsdp66KPXWM_ITL2ZE">https://www.wired.com/story/ai-is-already-taking-jobs-in-the-video-game-industry/</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c69 li-bullet-0"><span class="c15">NOTE: The part that says workers are being forced to use AI by their bosses </span><span class="c15 c61">IS A LIE</span><span class="c33 c15">. See section 4.2 for strong evidence to the contrary from multiple sources.</span></li><li class="c69 li-bullet-0"><span>&gt;A WIRED investigation finds that major players like Activision Blizzard, which recently laid off scores of workers, are </span><span class="c33 c15">using generative AI for game development.</span></li><li class="c69 li-bullet-0"><span class="c41 c14">A </span><span class="c20 c41"><a class="c13" href="https://www.google.com/url?q=https://images.reg.techweb.com/Web/UBMTechweb/%257B4fe03be1-d6b1-4f91-95f4-b4bdea9e739e%257D_GDC24-SOTI-Report_Final.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583605901&amp;usg=AOvVaw1Zy2MTt4ouDX_3sqYZaJcj">recent survey</a></span><span class="c41 c14">&nbsp;from the organizers of the </span><span class="c20 c41"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/the-video-game-industry-is-just-starting-to-feel-the-impacts-of-2023s-layoffs/&amp;sa=D&amp;source=editors&amp;ust=1730413583606192&amp;usg=AOvVaw2extXqnmhegOnTMiCwas1L">Game Developers Conference</a></span><span class="c41 c14">&nbsp;found that </span><span class="c92 c41 c15 c48">49 percent of the survey&rsquo;s more than 3,000 respondents said their workplace used AI.</span></li><li class="c69 li-bullet-0"><span class="c92 c41 c37 c48 c14">&ldquo;It&rsquo;s here. It&rsquo;s definitely here, right now,&rdquo; says Violet, a game developer, technical artist, and a veteran of the industry who has worked on AAA games for over a decade. &ldquo;I think everyone&rsquo;s seen it get used, and it&rsquo;s a matter of how and to what degree. The genie is out of the bottle, Pandora&#39;s box is opened.&rdquo;</span></li><li class="c69 li-bullet-0"><span class="c41 c14">Treyarch, a Southern California-based studio that produces some elements of Activision&rsquo;s </span><span class="c41 c61 c14">Call of Duty</span><span class="c41 c14">&nbsp;games, </span><span class="c20 c41 c14"><a class="c13" href="https://www.google.com/url?q=https://careers.activision.com/job/ACPUUSR023151EXTERNAL/2D-Artist-Animator-Treyarch-Los-Angeles?utm_source%3Dgameartrecruiterjobs&amp;sa=D&amp;source=editors&amp;ust=1730413583607039&amp;usg=AOvVaw3DLgvcolkHxSCmF7Qbvy8d">posted a job listing</a></span><span class="c41 c14">&nbsp;for a &ldquo;2D Artist Animator.&rdquo; The first thing listed under the &ldquo;To succeed you should have &hellip;&rdquo; section was &ldquo;exceptional skills and expertise in digital sketching, drawing, and painting, as well as </span><span class="c41 c15">advanced expertise in working with generative AI tools such as Stable Diffusion, Vizcom, Dall-E, or equivalent</span><span class="c92 c41 c37 c48 c14">.&rdquo; </span></li><li class="c69 li-bullet-0"><span class="c41 c14">Blizzard is building its own AI system too, which at one time was named </span><span class="c20 c41 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2023/05/22/arts/blizzard-diffusion-ai-video-games.html&amp;sa=D&amp;source=editors&amp;ust=1730413583607596&amp;usg=AOvVaw0bWV6_6rO2XwLCAdU_xo-a">Blizzard Diffusion</a></span><span class="c92 c41 c37 c48 c14">&mdash;though details are scarce, beyond a patent the company filed for a &ldquo;machine-learning based 2D structured image generation&rdquo; system. &ldquo;Blizzard&#39;s &lsquo;internal AI&rsquo; that they trained is still super secretive. Only those who have access to it work with it, and no one else knows how it works,&rdquo; Warner claims.</span></li></ul><p class="c100 c46"><span class="c1"></span></p><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Activision Blizzard is reportedly already making games with AI, and quietly sold an AI-generated microtransaction in Call of Duty: Modern Warfare 3: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.gamesradar.com/games/call-of-duty/activision-blizzard-is-reportedly-already-making-games-with-ai-and-quietly-sold-an-ai-generated-microtransaction-in-call-of-duty-modern-warfare-3/&amp;sa=D&amp;source=editors&amp;ust=1730413583608544&amp;usg=AOvVaw3L00YTp8jxjGl4pSR25bDV">https://www.gamesradar.com/games/call-of-duty/activision-blizzard-is-reportedly-already-making-games-with-ai-and-quietly-sold-an-ai-generated-microtransaction-in-call-of-duty-modern-warfare-3/</a></span></li></ul><p class="c9"><span class="c92 c41 c37 c48 c14"></span></p><p class="c9"><span class="c92 c41 c37 c48 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c22 c32 li-bullet-0"><span class="c5 c14 c169"><a class="c13" href="https://www.google.com/url?q=https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave&amp;sa=D&amp;source=editors&amp;ust=1730413583609313&amp;usg=AOvVaw3d6TvKGMyemVd9wF1itQrc">https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave</a></span></li></ul><p class="c22 c44"><span class="c92 c83 c37 c48 c14"></span></p><p class="c22 c44"><span class="c92 c83 c37 c48 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c22 c72 li-bullet-0"><span class="c83 c14">&gt;&rdquo;Microsoft has previously disclosed its billion-dollar AI investments have brought developments and productivity savings. These include an HR Virtual Agent bot which it says has saved 160,000 hours</span><span class="c34 c14 c83">&nbsp;</span><span class="c92 c83 c37 c48 c14">for HR service advisors by answering routine questions.&rdquo;</span></li></ul><p class="c22 c44"><span class="c92 c83 c37 c48 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c22 c161 c78 li-bullet-0"><span>AI took their jobs. Now they get paid to make it sound human: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human&amp;sa=D&amp;source=editors&amp;ust=1730413583610528&amp;usg=AOvVaw2Yl4_fCijfe7catT5kYW0z">https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human</a></span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-1 start"><li class="c22 c161 c97 c105 li-bullet-0"><span class="c42 c37 c61 c112">&gt;In numerous industries, AI is being used to produce work that was once the exclusive domain of the human mind</span></li><li class="c22 c167 c97 c105 li-bullet-0"><span class="c24">&gt;He led a team of more than 60 writers and editors&hellip;. &quot; the business introduced an automated system. Miller&#39;s manager would plug a headline for an article into an online form, an AI model would generate an outline based on that title, and Miller would get an alert on his computer. Instead of coming up with their own ideas, his writers would create articles around those outlines, and Miller would do a final edit before the stories were published. Miller only had a few months to adapt before he got news of a second layer of automation. Going forward, ChatGPT </span><span class="c24 c34">would write the articles in their entirety,</span><span class="c24">&nbsp;and </span><span class="c24 c15">most of his team was fired</span><span class="c112 c37 c35 c48 c120">. The few people remaining were left with an even less creative task: editing ChatGPT&#39;s subpar text to make it sound more human.</span></li><li class="c22 c167 c97 c105 li-bullet-0"><span class="c24">&gt;By 2024, </span><span class="c24 c15">the company laid off the rest of Miller&#39;s team</span><span class="c24">, and he was alone. &quot;All of a sudden I was just doing everyone&#39;s job,&quot; Miller says. Every day, he&#39;d open the AI-written documents to fix the robot&#39;s formulaic mistakes, churning out the work that used to employ dozens of people.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Leaked Memo Claims New York Times Fired Artists to Replace Them With AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://futurism.com/the-byte/new-york-times-fires-artists-ai-memo&amp;sa=D&amp;source=editors&amp;ust=1730413583612171&amp;usg=AOvVaw2UTC4xNXleqaNoRaiV8ArE">https://futurism.com/the-byte/new-york-times-fires-artists-ai-memo</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Taco Bell to roll out AI drive-thru ordering in hundreds of locations by end of year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524&amp;sa=D&amp;source=editors&amp;ust=1730413583612825&amp;usg=AOvVaw1CorFBwvB8ksThCjGnOKyr">https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1">Yum Brands said the tech has improved order accuracy, reduced wait times, decreased employees&rsquo; task load and fueled profitable growth.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c100 c78 li-bullet-0"><span>Cheap AI voice clones may wipe out jobs of 5,000 Australian actors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia&amp;sa=D&amp;source=editors&amp;ust=1730413583613879&amp;usg=AOvVaw1eb2yDios8oPRbDewpVFZi">https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c69 li-bullet-0"><span class="c1">&gt;Industry group says rise of vocal technology could upend many creative fields, including audiobooks &ndash; the canary in the coalmine for voice actors</span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney&amp;sa=D&amp;source=editors&amp;ust=1730413583614801&amp;usg=AOvVaw2YTkDHQjoCFkcirUj_qMX1">https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney</a></span></li></ul><p class="c9"><span class="c40 c37 c63 c76"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c37 c63 c76">&gt;AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/11/6/23948454/microsoft-xbox-generative-ai-developer-tools-inworld-partnership&amp;sa=D&amp;source=editors&amp;ust=1730413583615418&amp;usg=AOvVaw33Vleej2XQnxBVMjpNNhik">to develop tools for developers to generate AI NPCs, quests, and stories</a></span><span class="c37 c63 c76">. </span><span class="c5 c37 c63 c61 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/12/7/23991851/the-finals-embark-studios-launch-xbox-ps5-pc-steam-available-now&amp;sa=D&amp;source=editors&amp;ust=1730413583615700&amp;usg=AOvVaw0U5KxiKUPferrHHkwLCrho">The Finals</a></span><span class="c37 c63 c76">, a free-to-play multiplayer shooter, </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/the-finals-uses-ai-text-to-speech-because-it-can-produce-lines-in-just-a-matter-of-hours-rather-than-months-baffles-actual-voice-actors/&amp;sa=D&amp;source=editors&amp;ust=1730413583616026&amp;usg=AOvVaw3-ZpCuNl41WARf8dcqEghL">was criticized by voice actors</a></span><span class="c40 c37 c63 c76">&nbsp;for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.</span></li></ul><p class="c9"><span class="c40 c37 c63 c76"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>AI used by official Disney show for intro: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits&amp;sa=D&amp;source=editors&amp;ust=1730413583616772&amp;usg=AOvVaw04HTGP2Gb30PrcWfDokBit">https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">Human level text to speech: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/&amp;sa=D&amp;source=editors&amp;ust=1730413583617352&amp;usg=AOvVaw3jmajYmaceSef_eKoP0t6k">https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/</a></span><span class="c31">&nbsp;</span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c33 c15">Over 32 techniques to reduce hallucinations:</span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-1 start"><li class="c10 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.01313&amp;sa=D&amp;source=editors&amp;ust=1730413583618112&amp;usg=AOvVaw3toP-2_DX_QWo2jNcsL6ES">https://arxiv.org/abs/2401.01313</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c22 c95 c129 li-bullet-0"><span class="c43">Almost 65,000 Job Cuts Were Announced In April&mdash;And AI Was Blamed For The Most Losses Ever: </span><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/maryroeloffs/2024/05/02/almost-65000-job-cuts-were-announced-in-april-and-ai-was-blamed-for-the-most-losses-ever/&amp;sa=D&amp;source=editors&amp;ust=1730413583618764&amp;usg=AOvVaw0fT-fE6MPk98nQA9jLuo7w">https://www.forbes.com/sites/maryroeloffs/2024/05/02/almost-65000-job-cuts-were-announced-in-april-and-ai-was-blamed-for-the-most-losses-ever/</a></span></li></ul><p class="c22 c95 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c22 c74 c129 li-bullet-0"><span>In a survey of 450 executives in the US, </span><span class="c43">&quot;45 percent said they were automating tasks to reduce staffing and labour costs.&quot; </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.smh.com.au/world/north-america/nearly-half-of-us-firms-using-ai-say-goal-is-to-cut-staffing-costs-20240629-p5jpsl.html&amp;sa=D&amp;source=editors&amp;ust=1730413583619481&amp;usg=AOvVaw2hn_lDeiGmMcGrzJY3Ic7h">https://www.smh.com.au/world/north-america/nearly-half-of-us-firms-using-ai-say-goal-is-to-cut-staffing-costs-20240629-p5jpsl.html</a></span></li></ul><p class="c22 c74 c46"><span class="c33 c15"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c22 c74 c129 li-bullet-0"><span class="c15">Bank of America CEO: AI helping cut call times, branch visits:</span><span class="c15">&nbsp;</span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/companies/bank-of-america-ceo-ai-helping-cut-call-times-branch-visits/ar-AA1eCRVI&amp;sa=D&amp;source=editors&amp;ust=1730413583620128&amp;usg=AOvVaw0qJ61X5Nb1T9fuoJpAssWy">https://www.msn.com/en-us/money/companies/bank-of-america-ceo-ai-helping-cut-call-times-branch-visits/ar-AA1eCRVI</a></span></li></ul><ul class="c0 lst-kix_idsnzgd8q5di-1 start"><li class="c22 c97 c105 c206 li-bullet-0"><span class="c1">AI virtual financial assistant has logged 1.5B customer interactions since 2018 launch</span></li></ul><p class="c22 c206 c97 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>&#39;Our Chatbots Perform The Tasks Of 700 People&#39;: Buy Now, Pay Later Company Klarna To Axe 2,000 Jobs As AI Takes On More Role: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ibtimes.co.uk/our-chatbots-perform-tasks-700-people-buy-now-pay-later-company-klarna-axe-2000-jobs-ai-1726522&amp;sa=D&amp;source=editors&amp;ust=1730413583620958&amp;usg=AOvVaw3l6JH0W3yu-UwhOB67fapW">https://www.ibtimes.co.uk/our-chatbots-perform-tasks-700-people-buy-now-pay-later-company-klarna-axe-2000-jobs-ai-1726522</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1">Klarna has already cut over 1,000 employees and plans to remove nearly 2,000 more</span></li><li class="c10 li-bullet-0"><span class="c92 c42 c37 c148 c14">A Swedish financial services firm specializing in direct payments, pay-after-delivery options, and installment plans is preparing to reduce its workforce by nearly 50 per cent as artificial intelligence automation becomes more prevalent.</span></li><li class="c10 li-bullet-0"><span class="c92 c42 c37 c148 c14">Klarna reported a 73 percent increase in average revenue per employee compared to last year. </span></li><li class="c10 li-bullet-0"><span class="c92 c42 c37 c148 c14">Klarna&#39;s interim results demonstrated a 27 percent increase in revenue, reaching 12.3 billion Swedish krona (&pound;990 million). Additionally, the company transitioned from a loss of 456 million krona in the previous year to an adjusted profit of 673 million krona. The job cuts occur amidst a turnaround strategy at Klarna.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c15">Klarna SUCCESSFULLY replaces call centers with AI </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/&amp;sa=D&amp;source=editors&amp;ust=1730413583622494&amp;usg=AOvVaw1ZtL6pBLSomLVsgTwk1AYJ">https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1 c14">- Klarnas AI assistant, powered by @OpenAI , has in its first 4 weeks handled 2.3 million customer service chats and the data and insights are staggering:</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1 c14">- Handles 2/3 rd of our customer service enquires</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1 c14">- On par with humans on customer satisfaction</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1 c14">- Higher accuracy leading to a 25% reduction in repeat inquiries</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1 c14">- customer resolves their errands in 2 min vs 11 min</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1 c14">- Live 24/7 in over 23 markets, communicating in over 35 languages</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c1 c14">- It performs the equivalent job of 700 full time agents</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c45 li-bullet-0"><span class="c124 c37 c157">Digital automation could make 1.1 million roles in the Philippines obsolete by 2028: </span><span class="c5 c124 c37 c157"><a class="c13" href="https://www.google.com/url?q=https://www.cisco.com/c/dam/global/en_sg/assets/csr/pdf/technology-and-the-future-of-asean-jobs.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583625160&amp;usg=AOvVaw0O3RxRdno-UFTd1THmugaU">https://www.cisco.com/c/dam/global/en_sg/assets/csr/pdf/technology-and-the-future-of-asean-jobs.pdf</a></span></li></ul><p class="c73 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c45 li-bullet-0"><span>AI tools spark anxiety among Philippines&rsquo; call center workers: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://restofworld.org/2023/call-center-ai-philippines/&amp;sa=D&amp;source=editors&amp;ust=1730413583625584&amp;usg=AOvVaw2jHtm4reDrYIsaTDzQ_O1c">https://restofworld.org/2023/call-center-ai-philippines/</a></span></li></ul><p class="c73 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c59 li-bullet-0"><span class="c40 c124 c37 c157">Bernie now uses ChatGPT and Bing to compile all the technical information he needs for a query in less than five minutes. It&rsquo;s doubled the number of customer complaints he can handle in a day. </span></li><li class="c59 li-bullet-0"><span class="c124 c37 c157">&ldquo;It made my work easier. I can even get ideas on how to approach certain complaints, making [my answers] appear engaging, persuasive, empathetic. It can give you that, depending on the prompt that you input,&rdquo; Bernie told </span><span class="c124 c37 c157 c61">Rest of World.</span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c158 c78 li-bullet-0"><span class="c15">Duolingo lays off staff as language learning app shifts toward AI</span><span class="c43">: </span><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://cnn.com/2024/01/09/tech/duolingo-layoffs-due-to-ai/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583626319&amp;usg=AOvVaw3I4ced1uXEG0hi-19ztT3T">https://cnn.com/2024/01/09/tech/duolingo-layoffs-due-to-ai/index.html</a></span></li></ul><p class="c158 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>Square Enix says it used AI art in upcoming Foamstars game: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney&amp;sa=D&amp;source=editors&amp;ust=1730413583626663&amp;usg=AOvVaw3lmI199VVWAMbT6h6U5s9j">https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span>&gt;</span><span class="c37 c63 c76">AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/11/6/23948454/microsoft-xbox-generative-ai-developer-tools-inworld-partnership&amp;sa=D&amp;source=editors&amp;ust=1730413583627033&amp;usg=AOvVaw00jfkymne1ocWaDrgNxRXJ">to develop tools for developers to generate AI NPCs, quests, and stories</a></span><span class="c37 c63 c76">. </span><span class="c5 c37 c63 c61 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/12/7/23991851/the-finals-embark-studios-launch-xbox-ps5-pc-steam-available-now&amp;sa=D&amp;source=editors&amp;ust=1730413583627203&amp;usg=AOvVaw2OwrALuYMV9DPTB4UAKxF_">The Finals</a></span><span class="c37 c63 c76">, a free-to-play multiplayer shooter, </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/the-finals-uses-ai-text-to-speech-because-it-can-produce-lines-in-just-a-matter-of-hours-rather-than-months-baffles-actual-voice-actors/&amp;sa=D&amp;source=editors&amp;ust=1730413583627396&amp;usg=AOvVaw2oczoSXz0Zd9WtbaHwRBlg">was criticized by voice actors</a></span><span class="c40 c37 c63 c76">&nbsp;for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.</span></li></ul><p class="c9"><span class="c40 c37 c63 c76"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c14">Voice Actor Replaced with AI: </span><span class="c6 c20"><a class="c13" href="https://www.google.com/url?q=https://www.dailymail.co.uk/tvshowbiz/article-13245821/Mamma-Mia-star-Sara-Poyzer-replaced-AI-BBC-production-calls-shock-decision-sobering-grim-times-industry.html&amp;sa=D&amp;source=editors&amp;ust=1730413583627908&amp;usg=AOvVaw2uCC13qERf7DwSQeKY9uXJ">https://www.dailymail.co.uk/tvshowbiz/article-13245821/Mamma-Mia-star-Sara-Poyzer-replaced-AI-BBC-production-calls-shock-decision-sobering-grim-times-industry.html</a></span></li></ul><p class="c158 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span>How to Make an Audiobook using AI in 2024: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://elevenlabs.io/blog/how-to-make-an-audiobook&amp;sa=D&amp;source=editors&amp;ust=1730413583628296&amp;usg=AOvVaw1VYz3bJzt42GX0h2MVpPl9">https://elevenlabs.io/blog/how-to-make-an-audiobook</a></span></li></ul><p class="c158 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c15">Ibanking jobs are being drastically reduced with AI</span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://archive.is/jrHmp&amp;sa=D&amp;source=editors&amp;ust=1730413583628654&amp;usg=AOvVaw0xMaPrR7_YBlX4z-pO8Wo1">https://archive.is/jrHmp</a></span></li></ul><p class="c9"><span class="c92 c37 c35 c14 c76 c98"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c92 c37 c35 c14 c76 c98">the consulting giant Accenture estimated that A.I. could replace or supplement nearly three-quarters of bank employees&rsquo; working hours across the industry.</span></li><li class="c10 li-bullet-0"><span class="c37 c35 c14 c76 c98">This week, JPMorgan Chase&rsquo;s chief executive, Jamie Dimon, </span><span class="c20 c37 c35 c14 c76 c235"><a class="c13" href="https://www.google.com/url?q=https://archive.is/o/jrHmp/https://www.nytimes.com/2024/04/08/business/dealbook/jamie-dimon-economy-inflation-letter.html&amp;sa=D&amp;source=editors&amp;ust=1730413583629204&amp;usg=AOvVaw3F7T1t0if7Dd5lT73DZTSk">wrote in his annual shareholder letter</a></span><span class="c92 c37 c35 c14 c76 c98">&nbsp;that A.I. &ldquo;may reduce certain job categories or roles,&rdquo; and labeled the technology top among the most important issues facing the nation&rsquo;s largest bank. Mr. Dimon compared the consequences to those of &ldquo;the printing press, the steam engine, electricity, computing and the internet, among others.&rdquo;</span></li><li class="c115 c97 c105 li-bullet-0"><span class="c92 c37 c35 c14 c76 c98">Deutsche Bank is uploading reams of financial data into proprietary A.I. tools that can instanteously answer questions about publicly traded companies and create summary documents on complementary financial moves that might benefit a client &mdash; and earn the bank a profit.</span></li><li class="c97 c105 c115 li-bullet-0"><span class="c92 c37 c35 c14 c76 c98">Mr. Horine said he could use A.I. to identify clients that might be ripe for a bond offering, the sort of bread-and-butter transaction for which investment bankers charge clients millions of dollars.</span></li><li class="c115 c97 c105 li-bullet-0"><span class="c92 c37 c35 c14 c76 c98">Goldman Sachs has assigned 1,000 developers to test A.I., including software that can turn what it terms &ldquo;corpus&rdquo; information &mdash; or enormous amounts of text and data collected from thousands of sources &mdash; into page presentations that mimic the bank&rsquo;s typeface, logo, styles and charts. One firm executive privately called it a &ldquo;Kitty Hawk moment,&rdquo; or one that would change the course of the firm&rsquo;s future.</span></li><li class="c97 c105 c214 li-bullet-0"><span class="c92 c37 c35 c14 c76 c98">That isn&rsquo;t limited to investment banking; BNY Mellon&rsquo;s chief executive said on a recent earnings call that his research analysts could now wake up two hours later than usual, because A.I. can read overnight economic data and create a written draft of analysis to work from.</span></li><li class="c115 c97 c105 li-bullet-0"><span class="c92 c37 c35 c14 c76 c98">A senior Morgan Stanley executive told employees in a January private meeting, a video of which was viewed by The New York Times, that he would &ldquo;get A.I. into every area of what we do,&rdquo; including wealth management, where the bank employs thousands of people to determine the proper mix of investments for well-off savers.</span></li><li class="c115 c97 c105 li-bullet-0"><span class="c37 c35 c14 c76 c98">B</span><span class="c20 c37 c35 c14 c76 c235"><a class="c13" href="https://www.google.com/url?q=https://archive.is/o/jrHmp/https://www.foxbusiness.com/markets/bank-of-america-ceo-ai-helping-cut-call-times-branch-visits&amp;sa=D&amp;source=editors&amp;ust=1730413583630325&amp;usg=AOvVaw16Da2fIVXcMzTaiykQ1X2x">ank of America&rsquo;s chief executive said last year</a></span><span class="c37 c35 c14 c76 c98">&nbsp;that</span><span class="c92 c37 c35 c14 c76 c98">&nbsp;the technology was already enabling the firm to hire less.</span></li><li class="c115 c97 c105 li-bullet-0"><span class="c92 c37 c35 c14 c76 c98">Among Goldman Sachs&rsquo;s sprawling A.I. efforts is a tool under development that can transfigure a lengthy PowerPoint document into a formal &ldquo;S-1,&rdquo; the legalese-packed document for initial public offerings required for all listed companies. The software takes less than a second to complete the job.</span></li></ul><p class="c115 c46"><span class="c92 c37 c35 c14 c76 c98"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c205 c78 li-bullet-0"><span>Super cheap robotaxi rides spark widespread anxiety in China: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2024/07/18/cars/china-baidu-apollo-go-robotaxi-anxiety-intl-hnk/index.html%23:~:text%3DIn%2520China%252C%2520it&#39;s%2520possible%2520to,million%2520people%2520in%2520central%2520China.China&amp;sa=D&amp;source=editors&amp;ust=1730413583631320&amp;usg=AOvVaw3pPlRc6PMqfTtVVMBbWTTH">https://www.cnn.com/2024/07/18/cars/china-baidu-apollo-go-robotaxi-anxiety-intl-hnk/index.html</a></span></li></ul><p class="c46 c205"><span class="c92 c37 c35 c14 c76 c98"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/&amp;sa=D&amp;source=editors&amp;ust=1730413583631739&amp;usg=AOvVaw2ss0aQws2bF17nd6AcbdTM">Nvidia&rsquo;s AI Bot Outperforms Nurses, Study Finds</a></span><span class="c35 c14">: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/&amp;sa=D&amp;source=editors&amp;ust=1730413583631950&amp;usg=AOvVaw0IlaS2kmTMZoxENglzwoXW">https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI&amp;sa=D&amp;source=editors&amp;ust=1730413583632345&amp;usg=AOvVaw2E8TT0FSy_8ZwDtiVzvinI">And they only cost $9 an hour</a></span><span class="c35 c14">: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI&amp;sa=D&amp;source=editors&amp;ust=1730413583632570&amp;usg=AOvVaw02QCFKzYNd6X3tLgFQmF26">https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c37 c76 c84 c138 c114">According to </span><span class="c37 c14 c76 c155 c114"><a class="c13" href="https://www.google.com/url?q=https://www.foxbusiness.com/technology/nvidia-announces-ai-powered-health-care-agents-outperform-nurses-cost-9-hour&amp;sa=D&amp;source=editors&amp;ust=1730413583632971&amp;usg=AOvVaw14c7QukVvMIxFfKvFC-X63">company-released data</a></span><span class="c37 c76 c84 c138 c114">, the AI bots are 16% better than nurses at identifying a medication&rsquo;s impact on lab values, 24% more accurate detecting toxic dosages of over-the-counter drugs, and 43% better at identifying condition-specific negative interactions from OTC meds. All that at $9 an hour compared to the $39.05 median hourly pay for U.S. nurses. These AI nurse-bots are designed to make new diagnoses, manage chronic disease, and give patients a detailed but clear explanation of clinicians&rsquo; advice.</span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c78 c14 c195 li-bullet-0"><span class="c35 c148">How will Language Modelers like ChatGPT Affect Occupations and Industries? </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4375268&amp;sa=D&amp;source=editors&amp;ust=1730413583633370&amp;usg=AOvVaw33WiuYXiGqSyCzrf-YcLhU">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4375268</a></span></li></ul><p class="c195 c14 c46"><span class="c87 c37 c35 c48"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c37 c35 c208 c14 c76">We find that the top occupations exposed to language modeling include telemarketers and a variety of post-secondary teachers such as English language and literature, foreign language and literature, and history teachers. We find the top industries exposed to advances in language modeling are legal services and securities, commodities, and investments. </span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">Big banks on Wall Street could pull back hiring plans as they lean more heavily on AI, cutting analyst hiring by two-thirds</span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/ai-job-cuts-finance-wall-street-investment-banking-analysts-hiring-2024-4&amp;sa=D&amp;source=editors&amp;ust=1730413583634185&amp;usg=AOvVaw3nYc8RFRptpMDYVGObeEzc">https://www.businessinsider.com/ai-job-cuts-finance-wall-street-investment-banking-analysts-hiring-2024-4</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c15">&ldquo;GenAI will save [Klarna] $10m in marketing this year. We&rsquo;re spending less on photographers, image banks, and marketing agencies</span><span class="c14">&rdquo;</span><span class="c14">&nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://archive.is/tVW2N&amp;sa=D&amp;source=editors&amp;ust=1730413583634553&amp;usg=AOvVaw2ikzdj34Ed3yCwxl77D-cq">https://archive.is/tVW2N</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-1"><li class="c10 li-bullet-0"><span class="c33 c15">- $6m less on producing images.</span></li><li class="c10 li-bullet-0"><span class="c1 c14">- 1,000 in-house AI-produced images in 3 months. Includes the creative concept, quality check, and legal compliance.</span></li><li class="c10 li-bullet-0"><span class="c14">- AI-image production </span><span class="c33 c15">reduced from 6 WEEKS TO 1 WEEK ONLY.</span></li><li class="c10 li-bullet-0"><span class="c14">- Customer response to AI images </span><span class="c33 c15">on par with human produced images.</span></li><li class="c10 li-bullet-0"><span class="c14">- Cutting external marketing agency costs by</span><span class="c15">&nbsp;25%</span><span class="c1 c14">&nbsp;(mainly translation, production, CRM, and social agencies).</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c14">- Our in-house marketing team is </span><span class="c15">HALF the size</span><span class="c14">&nbsp;it was last year but is </span><span class="c15">producing MORE</span><span class="c1 c14">!</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c1 c14">- We&rsquo;ve removed the need for stock imagery from image banks like </span></li><li class="c10 li-bullet-0"><span class="c1 c14">@gettyimages</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c1 c14">- Now we use genAI tools like Midjourney, DALL-E, and Firefly to generate images, and Topaz Gigapixel and Photoroom to make final adjustments.</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c14">- Faster images means </span><span class="c15">more app updates</span><span class="c1 c14">, which is great for customers. And our employees get to work on more fun projects AND we&#39;re saving money.</span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_tclc6bzuyhm-0 start"><li class="c45 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.41px; height: 570.34px;"><img alt="" src="images/image202.png" style="width: 569.41px; height: 570.34px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c45 li-bullet-0"><span class="c6">BP Earnings Call: We need </span><span class="c15 c65 c60">70% less coders</span><span class="c6 c40">&nbsp;from third parties to code as the AI handles most of the coding, the human only needs to look at the final 30% to validate it, that&#39;s a big savings for the company moving forward.</span></li></ul><p class="c73 c129"><span class="c6 c40">Second things like call centers, the language models have become so sophisticated now. They can operate in multiple languages, 14, 15 languages easily. In the past, that hasn&#39;t been something we can do. So we can redeploy people off that given that the AI can do it. You heard my advertising example last quarter where advertising cycle times moved from four to five months down to a couple of weeks. So that&#39;s obviously reducing spend with third parties. We&#39;ve now got Gen AI in the hands through Microsoft Copilot across many, many parts of the business and we&#39;ll continue to update you with anecdotes as we go through</span></p><ul class="c0 lst-kix_f539m7fvzj9k-0"><li class="c59 li-bullet-0"><span class="c6">Source: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript&amp;sa=D&amp;source=editors&amp;ust=1730413583636728&amp;usg=AOvVaw1m2D2mCKWHjpfNBLLjcD_E">https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_f539m7fvzj9k-0"><li class="c59 li-bullet-0"><span class="c6 c40">This is almost certainly true because this is quoted from an earnings call from BP and lying to investors is a crime (securities fraud). This would include lying about the reason for getting rid of the workers (in other words, it can&rsquo;t just be layoffs). The numbers that are provided are also too specific to be exaggerations without also being a lie.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_srn1fozfk9nn-0"><li class="c4 li-bullet-0"><span>2024 McKinsey survey on AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583637403&amp;usg=AOvVaw3U5gPugFPRC0_JyhopkeEW">https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai</a></span></li></ul><ul class="c0 lst-kix_srn1fozfk9nn-1 start"><li class="c10 li-bullet-0"><span>For the past six years, AI adoption by respondents&rsquo; organizations has hovered at about 50 percent. This year, the survey finds that </span><span class="c15">adoption has jumped to 72 percent</span><span class="c1">&nbsp;(Exhibit 1). And the interest is truly global in scope. Our 2023 survey found that AI adoption did not reach 66 percent in any region; however, this year more than two-thirds of respondents in nearly every region say their organizations are using AI</span></li><li class="c10 li-bullet-0"><span class="c1">In the latest McKinsey Global Survey on AI, 65 percent of respondents report that their organizations are regularly using gen AI, nearly double the percentage from our previous survey just ten months ago.</span></li><li class="c10 li-bullet-0"><span>Respondents&rsquo;</span><span class="c15">&nbsp;expectations for gen AI&rsquo;s impact remain as high as they were last year</span><span class="c1">, with three-quarters predicting that gen AI will lead to significant or disruptive change in their industries in the years ahead</span></li><li class="c10 li-bullet-0"><span>Organizations are </span><span class="c15">already seeing material benefits from gen AI use, reporting both cost decreases and revenue jumps</span><span class="c1">&nbsp;in the business units deploying the technology.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 462.78px; height: 306.50px;"><img alt="" src="images/image192.png" style="width: 462.78px; height: 306.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 507.50px; height: 363.95px;"><img alt="" src="images/image239.png" style="width: 507.50px; height: 363.95px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 511.45px; height: 402.86px;"><img alt="" src="images/image257.png" style="width: 511.45px; height: 402.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><p class="c9"><span class="c92 c37 c63 c14 c76 c98"></span></p><p class="c9"><span class="c92 c37 c63 c14 c76 c98"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c15">Image to animation: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://github.com/Fictiverse/ToonCrafter-for-windows&amp;sa=D&amp;source=editors&amp;ust=1730413583638945&amp;usg=AOvVaw386KegTnxpLZhDJz-U4N-j">https://github.com/Fictiverse/ToonCrafter-for-windows</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c14">Co</span><span class="c14">-founder of Dreamworks expects AI to replace 90% of animators: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.indiewire.com/news/business/jeffrey-katzenberg-ai-will-take-90-percent-animation-jobs-1234924809/&amp;sa=D&amp;source=editors&amp;ust=1730413583639347&amp;usg=AOvVaw1R45iKvgJTZUBlg-XsLppN">https://www.indiewire.com/news/business/jeffrey-katzenberg-ai-will-take-90-percent-animation-jobs-1234924809/</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c14">Google&#39;s medical AI destroys GPT&#39;s benchmark and outperforms doctors: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/google-med-gemini-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583639689&amp;usg=AOvVaw1N6xEFuJ850IEONhEkMFOE">https://newatlas.com/technology/google-med-gemini-ai/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_idsnzgd8q5di-0"><li class="c4 li-bullet-0"><span class="c14">[</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583640103&amp;usg=AOvVaw1vXTRR11lrqF5IVZGXCPSp">Generative AI will be designing new drugs all on its own in the near future]</a></span><span class="c14">(</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583640275&amp;usg=AOvVaw0dvwS4eik1J69nUMK5ePaD">https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_4j92pbqgy1h-0 start"><li class="c45 li-bullet-0"><span class="c6">Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx&amp;sa=D&amp;source=editors&amp;ust=1730413583640643&amp;usg=AOvVaw1eYr6wVLMqd7TBpEGGn8Mz">https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c45 li-bullet-0"><span class="c6">ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583641000&amp;usg=AOvVaw1UfkWL6wTtPcojn6No95m-">https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_txo0zcn8hx7-0"><li class="c4 li-bullet-0"><span class="c6">AI is better than doctors at detecting breast cancer:</span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.bing.com/videos/search?q%3Dai%2Bbetter%2Bthan%2Bdoctors%2Busing%2Bai%26mid%3D6017EF2744FCD442BA926017EF2744FCD442BA92%26view%3Ddetail%26FORM%3DVIRE%26PC%3DEMMX04&amp;sa=D&amp;source=editors&amp;ust=1730413583641359&amp;usg=AOvVaw1PbOs0h5jS728DqttjYV9C">&nbsp;</a></span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/health-50857759&amp;sa=D&amp;source=editors&amp;ust=1730413583641521&amp;usg=AOvVaw1Liaf87_XBv8IuVtxBAF6s">https://www.bbc.com/news/health-50857759</a></span></li></ul><p class="c73 c46 c129"><span class="c6 c40"></span></p><ul class="c0 lst-kix_snh8lpyqaleg-0"><li class="c45 li-bullet-0"><span class="c6">AI just as good at diagnosing illness as humans: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.medicalnewstoday.com/articles/326460?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583641888&amp;usg=AOvVaw35h6ZmJpkzUNKt31I1APkA">https://www.medicalnewstoday.com/articles/326460</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583642217&amp;usg=AOvVaw16pL8AbomCGNYN3XLS9_pp">https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr=1</a></span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c14">Large action model can interact with UIs and act independently </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/a-real-ai/pywinassistant&amp;sa=D&amp;source=editors&amp;ust=1730413583642538&amp;usg=AOvVaw2JDb0Jb5XRiNXRQF1fl9h2">https://github.com/a-real-ai/pywinassistant</a></span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c14">AI doing sales calls very well: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Futurology/comments/1ceeq17/comment/l1k8b7f/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583642926&amp;usg=AOvVaw3lX4qpkKPdXksKqyebOWit">https://www.reddit.com/r/Futurology/comments/1ceeq17/comment/l1k8b7f/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c46 c73"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c14">Generative AI could soon decimate the call center industry, says CEO | There could be &quot;minimal&quot; need for call centres within a year: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.techspot.com/news/102749-generative-ai-could-soon-decimate-call-center-industry.html&amp;sa=D&amp;source=editors&amp;ust=1730413583643270&amp;usg=AOvVaw1Vus7JL1nntFTk8Z5YfHZh">https://www.techspot.com/news/102749-generative-ai-could-soon-decimate-call-center-industry.html</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c14">AI for UI design: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://uizard.io/?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583643574&amp;usg=AOvVaw30-owV33gGU3yx45eTljw2">https://uizard.io/?darkschemeovr=1</a></span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c14">[First Results from Med-Gemini (the successor to Med-Palm, a medically fine tuned LLM). &quot;More accurate multimodal conversations about medical images&#129659;, surgical videos&#128253;&#65039;, genomics&#129516;, ultra-long health records&#128218;, ECGs&#129728; &amp; more with state-of-art performance across multiple benchmarks&quot;](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/alan_karthi/status/1785117444383588823&amp;sa=D&amp;source=editors&amp;ust=1730413583643912&amp;usg=AOvVaw1Z-3Q-nSzHg6OMrq2m8OjN">https://twitter.com/alan_karthi/status/1785117444383588823</a></span><span class="c1 c14">&nbsp;)</span></li></ul><p class="c100"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 530.06px; height: 441.72px;"><img alt="" src="images/image355.jpg" style="width: 530.06px; height: 441.72px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c1 c14">&nbsp;</span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://analyticsindiamag.com/googles-med-gemini-model-is-multimodal-achieves-91-1-accuracy-in-medical-diagnostics/&amp;sa=D&amp;source=editors&amp;ust=1730413583644527&amp;usg=AOvVaw38mPmZY36_9uspUQDO_y8L">https://analyticsindiamag.com/googles-med-gemini-model-is-multimodal-achieves-91-1-accuracy-in-medical-diagnostics/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span class="c14">[AI beats humans on all performance indicators](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/ai-index-report-global-impact/&amp;sa=D&amp;source=editors&amp;ust=1730413583644968&amp;usg=AOvVaw3BEVgNckoPlkQsGvbPzArM">https://newatlas.com/technology/ai-index-report-global-impact/</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.newsweek.com/first-ever-mcdonalds-served-robots-texas-1769116?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583645361&amp;usg=AOvVaw0gMY7v3BF8Fl28jqIg2s1v">https://www.newsweek.com/first-ever-mcdonalds-served-robots-texas-1769116?darkschemeovr=1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.psypost.org/chatgpt-4-outperforms-human-psychologists-in-test-of-social-intelligence-study-finds/&amp;sa=D&amp;source=editors&amp;ust=1730413583645806&amp;usg=AOvVaw2Vq_95mIsxsl-2x48B5st3">https://www.psypost.org/chatgpt-4-outperforms-human-psychologists-in-test-of-social-intelligence-study-finds/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/edrensi/2018/07/11/mcdonalds-says-goodbye-cashiers-hello-kiosks/?darkschemeovr%3D1%26sh%3D7fa37f66f140&amp;sa=D&amp;source=editors&amp;ust=1730413583646212&amp;usg=AOvVaw0uH_Un-6g0Ieet2YNbUPK-">https://www.forbes.com/sites/edrensi/2018/07/11/mcdonalds-says-goodbye-cashiers-hello-kiosks/?darkschemeovr=1&amp;sh=7fa37f66f140</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c4 li-bullet-0"><span class="c14">survey-finds-generative-ai-proving-major-threat-to-the-work-of-translators: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/books/2024/apr/16/survey-finds-generative-ai-proving-major-threat-to-the-work-of-translators&amp;sa=D&amp;source=editors&amp;ust=1730413583646655&amp;usg=AOvVaw34YO_nm9vLIxfJErgZnLj5">https://www.theguardian.com/books/2024/apr/16/survey-finds-generative-ai-proving-major-threat-to-the-work-of-translators</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">[Alphacode 2 beat 99.5% of competitive programming participants in TWO Codeforce competitions](</span><span class="c20 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://the-decoder.com/alphacode-2-is-the-hidden-champion-of-googles-gemini-project/%23:~:text%3DCompared%2520to%2520its%2520predecessor%252C%2520AlphaCode%25202%2520shows%2520a,the%2520basis%2520for%2520all%2520components%2520of%2520AlphaCode%25202&amp;sa=D&amp;source=editors&amp;ust=1730413583647149&amp;usg=AOvVaw1ozZdPoQQmSuPvV3ldwW-3">https://the-decoder.com/alphacode-2-is-the-hidden-champion-of-googles-gemini-project/</a></span><span class="c14">). </span><span class="c6">Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it&rsquo;s STILL much better than those guys.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c78 c221 li-bullet-0"><span class="c14">DeepMind Researchers Propose Naturalized Execution Tuning (NExT): A Self-Training Machine Learning Method that Drastically Improves the LLM&rsquo;s Ability to Reason about Code Execution</span><span class="c14">&nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.marktechpost.com/2024/04/26/deepmind-researchers-propose-naturalized-execution-tuning-next-a-self-training-machine-learning-method-that-drastically-improves-the-llms-ability-to-reason-about-code-execution/&amp;sa=D&amp;source=editors&amp;ust=1730413583647902&amp;usg=AOvVaw3UywthEM-B7VVfSMSrsPm5">https://www.marktechpost.com/2024/04/26/deepmind-researchers-propose-naturalized-execution-tuning-next-a-self-training-machine-learning-method-that-drastically-improves-the-llms-ability-to-reason-about-code-execution/</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/gadgets/2023/12/report-google-ads-restructure-could-replace-some-sales-jobs-with-ai/?darkschemeovr%3D1%23%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583648420&amp;usg=AOvVaw1KI-zcThNnfqWrZMIhssRq">https://arstechnica.com/gadgets/2023/12/report-google-ads-restructure-could-replace-some-sales-jobs-with-ai/</a></span><span class="c6">&nbsp;</span></li></ul><p class="c21"><span class="c6 c40">&nbsp; </span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c51 c46 li-bullet-0"><span class="c6 c40"></span></li><li class="c51 li-bullet-0"><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI?darkschemeovr%3D1%25C2%25A0%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583649093&amp;usg=AOvVaw1IvBXoMGCrdVUuw2X3Aio7">https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI</a></span><span class="c6">&nbsp;</span><span class="c6 c40">&nbsp; &nbsp; &nbsp; &nbsp;</span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c51 c46 li-bullet-0"><span class="c6 c40"></span></li><li class="c51 li-bullet-0"><span class="c6">Half of all managers aim to replace staff with AI: </span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.techspot.com/news/102385-survey-reveals-almost-half-all-managers-aim-replace.html&amp;sa=D&amp;source=editors&amp;ust=1730413583649658&amp;usg=AOvVaw1ltY4EOJeUVSBcTexpCQ0J">https://www.techspot.com/news/102385-survey-reveals-almost-half-all-managers-aim-replace.html</a></span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c51 li-bullet-0"><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://tech.co/news/ai-replacing-jobs?darkschemeovr%3D1%25C2%25A0%25C2%25A0%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583650094&amp;usg=AOvVaw11JO21DxWnxFTgLpiRgyTO">https://tech.co/news/ai-replacing-jobs</a></span><span class="c6 c40">&nbsp;</span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c51 li-bullet-0"><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits?darkschemeovr%3D1%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583650530&amp;usg=AOvVaw1Gcgg6pYI8JlFIfo6zBIof">https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits?darkschemeovr=1 &nbsp; &nbsp;</a></span><span class="c6 c40">&nbsp; &nbsp;</span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c51 li-bullet-0"><span class="c6 c40">&nbsp;</span></li><li class="c51 li-bullet-0"><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/technology/2024/feb/23/tyler-perry-halts-800m-studio-expansion-after-being-shocked-by-ai?darkschemeovr%3D1%25C2%25A0%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583651126&amp;usg=AOvVaw3uYrmHjHLFrq_LRnGL86nF">https://www.theguardian.com/technology/2024/feb/23/tyler-perry-halts-800m-studio-expansion-after-being-shocked-by-ai?darkschemeovr=1 &nbsp;</a></span><span class="c6 c40">&nbsp; </span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c51 li-bullet-0"><span class="c6">Animation made with AI by Corridor Digital: </span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://kotaku.com/anime-rock-paper-scissors-corridor-digital-ai-animation-1850186624?darkschemeovr%3D1%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583651596&amp;usg=AOvVaw1S770sprIrDIdst1v77kSC">https://kotaku.com/anime-rock-paper-scissors-corridor-digital-ai-animation-1850186624?darkschemeovr=1</a></span><span class="c6">&nbsp;</span></li></ul><p class="c71 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c51 li-bullet-0"><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/commentisfree/2023/jan/24/chatgpt-artificial-intelligence-jobs-economy?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583652119&amp;usg=AOvVaw3kSBk_KsYpdEgqF1_Gtv6S">https://www.theguardian.com/commentisfree/2023/jan/24/chatgpt-artificial-intelligence-jobs-economy</a></span><span class="c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">AI is taking over drug development: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1btmnhj/artificial_intelligence_is_taking_over_drug/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583652716&amp;usg=AOvVaw1UhYDkZHm19T4Yz4D4B2YE">https://www.reddit.com/r/singularity/comments/1btmnhj/artificial_intelligence_is_taking_over_drug/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c4 li-bullet-0"><span class="c14">AI Cuts Worker Numbers: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1bwjse7/ai_seen_cutting_worker_numbers_survey_by_staffing/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583653303&amp;usg=AOvVaw1vy7scK_1GASNSnG47YJGu">https://www.reddit.com/r/singularity/comments/1bwjse7/ai_seen_cutting_worker_numbers_survey_by_staffing/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1bvrgqn/steve_cohen_says_his_financial_firm_can_already/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583653792&amp;usg=AOvVaw3A4_8xBlhm95mFezQcbkI6">steve_cohen_says_his_financial_firm_can_already save $25 million with AI: </a></span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1bvrgqn/steve_cohen_says_his_financial_firm_can_already/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583654002&amp;usg=AOvVaw0ysnL_Xx16CVw_IgIAIjD9">https://www.reddit.com/r/singularity/comments/1bvrgqn/steve_cohen_says_his_financial_firm_can_already/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Walmart replacing employees in Canada: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1c2artf/walmart_canada_says_robots_are_coming_to_two/&amp;sa=D&amp;source=editors&amp;ust=1730413583654527&amp;usg=AOvVaw0FYBqxlpkdsebROOrHrCyG">https://www.reddit.com/r/singularity/comments/1c2artf/walmart_canada_says_robots_are_coming_to_two/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.washingtonpost.com/technology/2023/10/03/ai-customer-service-jobs/&amp;sa=D&amp;source=editors&amp;ust=1730413583655053&amp;usg=AOvVaw3x01XTalBYJTDXAG9_P-7A">https://www.washingtonpost.com/technology/2023/10/03/ai-customer-service-jobs/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ArtificialInteligence/comments/1c3wb3x/ai_outperforms_humans_in_providing_emotional/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583655588&amp;usg=AOvVaw2VAzg2Vn6SJ1I7FEw3h4_E">https://www.reddit.com/r/ArtificialInteligence/comments/1c3wb3x/ai_outperforms_humans_in_providing_emotional/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.resumebuilder.com/1-in-3-companies-will-replace-employees-with-ai-in-2024/?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583655990&amp;usg=AOvVaw1KJQtZeNVlyvQiQThp_XYI">https://www.resumebuilder.com/1-in-3-companies-will-replace-employees-with-ai-in-2024/?darkschemeovr=1</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c22 c176 c97 c105 li-bullet-0"><span class="c40 c37 c60 c48 c14">Of companies currently using AI, 37% say workers were laid off in 2023 because they were no longer needed due to the company&rsquo;s use of AI.</span></li><li class="c22 c176 c97 c105 li-bullet-0"><span class="c60 c14">In 2024, 44% of companies who use AI or plan to by next year say employees will definitely (21%) or probably (23%) be laid off due to the use of AI.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1c33pql/amazon_grows_to_over_750000_robots_as_worlds/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583656752&amp;usg=AOvVaw1Rh17tJF6pWChi0ibnd3EZ">https://www.reddit.com/r/singularity/comments/1c33pql/amazon_grows_to_over_750000_robots_as_worlds/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html&amp;sa=D&amp;source=editors&amp;ust=1730413583657593&amp;usg=AOvVaw39pGaDQX2TT6Z-2C-jY8aG">The military wants &lsquo;robot ships&rsquo; to replace sailors in battle</a></span><span class="c202">: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html&amp;sa=D&amp;source=editors&amp;ust=1730413583657785&amp;usg=AOvVaw1IS3EHCvNjZx-d2Wq-yCGs">https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html</a></span></li><li class="c4 li-bullet-0"><span class="c35 c14">Tech titans considering job replacement with AI: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1by5sj7/tech_titans_assemble_to_decide_which_jobs_ai_can/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_buttonurasi&amp;sa=D&amp;source=editors&amp;ust=1730413583658096&amp;usg=AOvVaw06QsWkPwIumx_W8TUXerys">https://www.reddit.com/r/singularity/comments/1by5sj7/tech_titans_assemble_to_decide_which_jobs_ai_can/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1by5sj7/tech_titans_assemble_to_decide_which_jobs_ai_can/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_buttonurasi&amp;sa=D&amp;source=editors&amp;ust=1730413583658316&amp;usg=AOvVaw019lQfCM5YAMlFJb8pwPC3">urasi</a></span></li><li class="c4 li-bullet-0"><span class="c1">AI analyst says plumbers and electricians&#39; jobs are safe, but AI models like GPT-4o &#39;will impact any job that has data&#39; https://www.yahoo.com/tech/ai-models-gpt-4o-could-102901684.html</span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/&amp;sa=D&amp;source=editors&amp;ust=1730413583658793&amp;usg=AOvVaw2_TzqShoXxxr4_RukR6W-T">China&rsquo;s &lsquo;AI Ship Designer&rsquo; Works At Unprecedented Speed; Performed A Year&rsquo;s Work Only In 24 Hours!</a></span><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/&amp;sa=D&amp;source=editors&amp;ust=1730413583658985&amp;usg=AOvVaw3OhBRBuOgIJCXZsG6LgiXq">https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/</a></span></li><li class="c45 li-bullet-0"><span class="c34 c103">McKinsey report on employment displacement due to AI: </span><span class="c5 c34 c103"><a class="c13" href="https://www.google.com/url?q=https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america&amp;sa=D&amp;source=editors&amp;ust=1730413583659271&amp;usg=AOvVaw1s3aaqbWt17ma86gfI1b7R">https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c59 li-bullet-0"><span class="c34 c103">By 2030, activities that account for up to 30 percent of hours currently worked across the US economy could be automated&mdash;a trend accelerated by generative AI.</span><span class="c40 c37 c103 c152">&nbsp;However, we see generative AI enhancing the way STEM, creative, and business and legal professionals work rather than eliminating a significant number of jobs outright. Automation&rsquo;s biggest effects are likely to hit other job categories. Office support, customer service, and food service employment could continue to decline.</span></li><li class="c59 li-bullet-0"><span class="c34 c103">An additional 12 million occupational transitions may be needed by 2030.</span><span class="c40 c37 c103 c152">&nbsp;As people leave shrinking occupations, the economy could reweight toward higher-wage jobs. Workers in lower-wage jobs are up to 14 times more likely to need to change occupations than those in highest-wage positions, and most will need additional skills to do so successfully. Women are 1.5 times more likely to need to move into new occupations than men.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c45 li-bullet-0"><span class="c37 c103">Graphic designer loses job to AI: </span><span class="c5 c37 c103"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?si%3DMH46UnqxUd20xw7C%26v%3DU2vq9LUbDGs%26feature%3Dyoutu.be&amp;sa=D&amp;source=editors&amp;ust=1730413583659914&amp;usg=AOvVaw0BjX74_JdXoGIUstC1XfEE">https://m.youtube.com/watch?si=MH46UnqxUd20xw7C&amp;v=U2vq9LUbDGs&amp;feature=youtu.be</a></span><span class="c40 c37 c103 c152">&nbsp;</span></li><li class="c45 li-bullet-0"><span class="c37 c103">Microsoft&rsquo;s new Copilot AI agents act like virtual employees to automate tasks: </span><span class="c5 c37 c103"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/5/21/24158030/microsoft-copilot-ai-automation-agents&amp;sa=D&amp;source=editors&amp;ust=1730413583660211&amp;usg=AOvVaw3q6JD2j6iKVqShu1zXPtUr">https://www.theverge.com/2024/5/21/24158030/microsoft-copilot-ai-automation-agents</a></span><span class="c40 c37 c103 c152">&nbsp;</span></li><li class="c45 li-bullet-0"><span class="c37 c103">Google might already be replacing some human workers with AI: </span><span class="c5 c37 c103"><a class="c13" href="https://www.google.com/url?q=https://www.techradar.com/pro/google-might-already-be-replacing-some-human-workers-with-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583660485&amp;usg=AOvVaw2pSJywzwLVzEv9VRjPPNSq">https://www.techradar.com/pro/google-might-already-be-replacing-some-human-workers-with-ai</a></span><span class="c40 c37 c103 c152">&nbsp;</span></li><li class="c45 li-bullet-0"><span class="c37 c103">&ldquo;Godfather of AI&rdquo; Geoffrey Hinton says Universal Basic Income may be needed to address the loss of jobs to AI and the distribution of wealth generated by AI, but it won&#39;t be enough to give people self-respect: </span><span class="c5 c37 c103"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1792398561881325754&amp;sa=D&amp;source=editors&amp;ust=1730413583660755&amp;usg=AOvVaw2rtlSZL-K3u8szHJWClOSQ">https://x.com/tsarnick/status/1792398561881325754</a></span><span class="c40 c37 c103 c152">&nbsp;</span></li><li class="c45 li-bullet-0"><span class="c37 c103">Kai-Fu Lee says 50% of jobs may be replaced by AI within 3 years and white collar jobs are most at risk: </span><span class="c5 c37 c103"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1794121874882122228&amp;sa=D&amp;source=editors&amp;ust=1730413583661016&amp;usg=AOvVaw05jWLtgawKhXu9P-RuiyEZ">https://x.com/tsarnick/status/1794121874882122228</a></span><span class="c40 c37 c103 c152">&nbsp;</span></li><li class="c4 li-bullet-0"><span>GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27&amp;sa=D&amp;source=editors&amp;ust=1730413583661354&amp;usg=AOvVaw0c60ZKLJGsnZ4eG_4jho9K">https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI used for psychological therapy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/bQIzknuipj&amp;sa=D&amp;source=editors&amp;ust=1730413583661612&amp;usg=AOvVaw3yveAa90O8t7wa9s1mLQ7D">https://t.co/bQIzknuipj</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Automation powered by GPT-4o generates Figma designs based on PRD: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/yancymin/status/1795308932216525229&amp;sa=D&amp;source=editors&amp;ust=1730413583661862&amp;usg=AOvVaw2jaS0kkuESpTbHKoculOJp">https://x.com/yancymin/status/1795308932216525229</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Generating short films, trailers, and teasers with AI tools: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/minchoi/status/1795834164333433232&amp;sa=D&amp;source=editors&amp;ust=1730413583662139&amp;usg=AOvVaw3LEMG9CNciMxLqBIyDkHa2">https://x.com/minchoi/status/1795834164333433232</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 529.74px; height: 907.50px;"><img alt="" src="images/image657.png" style="width: 529.74px; height: 907.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Era3D: A new AI model that creates high-res &#128511;3D images from multiple viewpoints using just one input image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Gradio/status/1795866944568000697&amp;sa=D&amp;source=editors&amp;ust=1730413583662568&amp;usg=AOvVaw0-v669sb-LpVxahDRjQu-E">https://x.com/Gradio/status/1795866944568000697</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">- Generates high-quality images up to 512&times;512 pixels&#127919;</span></li><li class="c10 li-bullet-0"><span class="c1">- Uses efficient row-wise attention to reduce computation&#9889;</span></li><li class="c10 li-bullet-0"><span class="c1">- 12x more efficient than sota methods&#128170;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Sony Will Use AI to Cut Film Costs, Says CEO Tony Vinciquerra: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.indiewire.com/news/breaking-news/sony-pictures-will-cut-film-costs-using-ai-1235010605/&amp;sa=D&amp;source=editors&amp;ust=1730413583663407&amp;usg=AOvVaw39-txveRWEKVyPvdOAfDpa">https://www.indiewire.com/news/breaking-news/sony-pictures-will-cut-film-costs-using-ai-1235010605/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI Agents Are Coming for Mundane&mdash;but Valuable&mdash;Office Task: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/chatbots-are-entering-the-stone-age/&amp;sa=D&amp;source=editors&amp;ust=1730413583663821&amp;usg=AOvVaw0bqxbzwMmwfI9RbhzbvEbJ">https://www.wired.com/story/chatbots-are-entering-the-stone-age/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span class="c1">Anthropic and other big AI startups are teaching chatbots &ldquo;tool use,&rdquo; to make them more useful in the workplace.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Game made with 3D assets and textures made with AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CSM_ai/status/1796200041280925713&amp;sa=D&amp;source=editors&amp;ust=1730413583664200&amp;usg=AOvVaw0xh72MO_lCGWMiwiJ4AEzD">https://x.com/CSM_ai/status/1796200041280925713</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span>A chest: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tejasdkulkarni/status/1796730715851157620&amp;sa=D&amp;source=editors&amp;ust=1730413583664453&amp;usg=AOvVaw3-8TQnqWu0KnvkpqFc2yx-">https://x.com/tejasdkulkarni/status/1796730715851157620</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Watch a team of EVEs work together to clean up our office: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/1x_tech/status/1796589816940986525&amp;sa=D&amp;source=editors&amp;ust=1730413583664736&amp;usg=AOvVaw0XljRVUA8n_fX5j4bKdKu6">https://x.com/1x_tech/status/1796589816940986525</a></span><span class="c1">&nbsp;</span></li><li class="c22 c78 c175 li-bullet-0"><span class="c5 c55"><a class="c13" href="https://www.google.com/url?q=https://www.oxfordmartin.ox.ac.uk/publications/the-future-of-employment&amp;sa=D&amp;source=editors&amp;ust=1730413583665020&amp;usg=AOvVaw1ML34B3e_ZMLVmfdKO-8-u">https://www.oxfordmartin.ox.ac.uk/publications/the-future-of-employment</a></span><span class="c92 c55 c37 c48 c142">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c22 c175 c97 c105 li-bullet-0"><span class="c92 c55 c37 c142 c48">According to their estimates, about 47 per cent of total US employment is at risk. They further provide evidence that wages and educational attainment exhibit a strong negative relationship with an occupation&rsquo;s probability of computerisation.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c175 c78 li-bullet-0"><span class="c55 c142">Google has a call center AI: </span><span class="c5 c55"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DN_q4CwVrCSo&amp;sa=D&amp;source=editors&amp;ust=1730413583665422&amp;usg=AOvVaw18ODze0Sse7KvMAkDpyb1Q">https://m.youtube.com/watch?v=N_q4CwVrCSo</a></span><span class="c92 c55 c37 c142 c48">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Geoffrey Hinton says AI doctors who have seen 100 million patients will be much better than human doctors and able to diagnose rare conditions more accurately: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1797169362799091934&amp;sa=D&amp;source=editors&amp;ust=1730413583665757&amp;usg=AOvVaw3MK8n1jkSHUQrVVERzugQy">https://x.com/tsarnick/status/1797169362799091934</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c14">Tech titans considering job replacement with AI: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1by5sj7/tech_titans_assemble_to_decide_which_jobs_ai_can/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583666082&amp;usg=AOvVaw1Mq5TCcWlV-VQnHrgeNRlN">https://www.reddit.com/r/singularity/comments/1by5sj7/tech_titans_assemble_to_decide_which_jobs_ai_can/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li><li class="c4 li-bullet-0"><span>Robotics makers embrace Nvidia digital twins to create autonomous AI-run factories: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.computerworld.com/article/2137856/robotics-makers-embrace-nvidia-digital-twins-to-create-autonomous-ai-run-factories.html&amp;sa=D&amp;source=editors&amp;ust=1730413583666387&amp;usg=AOvVaw02LwSYO9dYujEY8C0bUujz">https://www.computerworld.com/article/2137856/robotics-makers-embrace-nvidia-digital-twins-to-create-autonomous-ai-run-factories.html</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>First NHS physiotherapy clinic run by AI to start this year. New platform to provide same-day appointments with digital physiotherapist in effort to cut waiting times: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year&amp;sa=D&amp;source=editors&amp;ust=1730413583666757&amp;usg=AOvVaw3GYn43EF807DGF903nFw2-">https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Former Microsoft &amp; Google research scientist Kai-Fu Lee- About 50% Of Jobs Will Be Displaced By AI Within 3 Years: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DzZs447dgMjg&amp;sa=D&amp;source=editors&amp;ust=1730413583667025&amp;usg=AOvVaw0XJ6Fkztc8ZXed0s3RnlaR">https://www.youtube.com/watch?v=zZs447dgMjg</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">Since he&rsquo;s no longer employed at those companies, he does not have an incentive to lie </span></li><li class="c10 li-bullet-0"><span>Consistent with claims from Anthropic&rsquo;s Chief of Staff: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/&amp;sa=D&amp;source=editors&amp;ust=1730413583667387&amp;usg=AOvVaw2fCo7_0ZQ3iHcHZSlgZ7QX">https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span class="c1">his prediction from 2017 still holds that in 10-15 years around 40-50% of all jobs will be replaced by AI.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>AI used by official Disney show for intro: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits&amp;sa=D&amp;source=editors&amp;ust=1730413583667749&amp;usg=AOvVaw06Z7O3LB5uT_2uY_vYXrqh">https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits</a></span></li><li class="c4 li-bullet-0"><span>&nbsp;Guy commissioned and properly credited artists in the past, multiple times got backstabbed by arti</span><span>sts who copy-striked his videos, threatening to take his channel down: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DknUkXwJXcpY&amp;sa=D&amp;source=editors&amp;ust=1730413583668025&amp;usg=AOvVaw2VYG5rQTdHbraa40Vvbkvm">https://www.youtube.com/watch?v=knUkXwJXcpY</a></span><span class="c1">&nbsp;</span></li><li class="c204 c78 li-bullet-0"><span>OpenAI CTO: AI Could Kill Some Creative Jobs That Maybe Shouldn&#39;t Exist Anyway: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcmag.com/news/openai-cto-mira-murati-ai-could-take-some-creative-jobs&amp;sa=D&amp;source=editors&amp;ust=1730413583668296&amp;usg=AOvVaw099WsuDuCsmrZSLQOpqxTd">https://www.pcmag.com/news/openai-cto-mira-murati-ai-could-take-some-creative-jobs</a></span></li><li class="c4 li-bullet-0"><span>Photos to ads: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/&amp;sa=D&amp;source=editors&amp;ust=1730413583668578&amp;usg=AOvVaw3IVPOD16Z1kGPs-u8UowIz">https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Toys R Us uses Sora generated promo: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/&amp;sa=D&amp;source=editors&amp;ust=1730413583668998&amp;usg=AOvVaw1CzPnhMnoWc9g5cHUXOR9F">https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Kling AI videos could also be used for marketing: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1810952037246349739&amp;sa=D&amp;source=editors&amp;ust=1730413583669229&amp;usg=AOvVaw36qPSMHAMZjbRmU-3ZZL60">https://x.com/CharaspowerAI/status/1810952037246349739</a></span></li><li class="c4 li-bullet-0"><span>McDonalds ad: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/&amp;sa=D&amp;source=editors&amp;ust=1730413583669494&amp;usg=AOvVaw2CCN5TsPX_ehR998lkgBSa">https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/</a></span></li><li class="c4 li-bullet-0"><span class="c63 c14">AI Outperforms Radiologists in Detecting Prostate Cancer on MRI: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://humanprogress.org/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/&amp;sa=D&amp;source=editors&amp;ust=1730413583669819&amp;usg=AOvVaw27_gH9alZepNvboOPcrOrB">https://humanprogress.org/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 750.67px;"><img alt="" src="images/image142.jpg" style="width: 624.00px; height: 750.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c63 c14">Uber is partnering with a driverless trucking company. Uber Freight will begin work with Aurora Innovation this fall using human drivers. Then they&#39;ll transition to autonomous hauling from Dallas to Houston: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/MorePerfectUS/status/1805995973879255407&amp;sa=D&amp;source=editors&amp;ust=1730413583670313&amp;usg=AOvVaw2-dIA2Gz8cXeUlxrAoDqmJ">https://x.com/MorePerfectUS/status/1805995973879255407</a></span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c111 c78 li-bullet-0"><span>This 20,000HP AI-generated rocket engine took just two weeks to design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet/&amp;sa=D&amp;source=editors&amp;ust=1730413583670772&amp;usg=AOvVaw3JfBEUcEaFDvMlpkFkZkhm">https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet</a></span></li></ul><p class="c22 c111 c97 c46"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>This was done in less than 24h by one person using AI as the ground tooling, some post in AE and that&rsquo;s it. Imagine the time and cost a real spot like this would cost. 100x less expensive due to AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/&amp;sa=D&amp;source=editors&amp;ust=1730413583671483&amp;usg=AOvVaw0EwrxOLxI0iUp_UnY0wUOu">https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/</a></span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>AI Agent Better than OpenAI&rsquo;s GPT-4o and costs just $1.60 per 1000 queries, making it 175% cheaper than GPT-4o. It is the world&rsquo;s first fully autonomous AI-powered sales development representative (SDR): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/&amp;sa=D&amp;source=editors&amp;ust=1730413583672160&amp;usg=AOvVaw38DqLU4Dt4posyoim59gdm">https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 509.70px; height: 207.22px;"><img alt="" src="images/image166.png" style="width: 509.70px; height: 207.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 517.86px; height: 362.50px;"><img alt="" src="images/image199.png" style="width: 517.86px; height: 362.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 834.67px;"><img alt="" src="images/image123.png" style="width: 624.00px; height: 834.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c22 c72 c14 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583673129&amp;usg=AOvVaw2jYRMEe5RJoyUHWtHZpFpP">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 c14 li-bullet-0"><span class="c63 c14">CNN to lay off 100 staffers as it preps major revamp of digital efforts - exploring a &quot;strategic push into AI.&quot; </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://www.hollywoodreporter.com/business/business-news/cnn-layoffs-digital-revamp-mark-thompson-1235944428/&amp;sa=D&amp;source=editors&amp;ust=1730413583673662&amp;usg=AOvVaw3NUw8eQDTUpPqTRp1BoIQb">https://www.hollywoodreporter.com/business/business-news/cnn-layoffs-digital-revamp-mark-thompson-1235944428/</a></span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part&amp;sa=D&amp;source=editors&amp;ust=1730413583674134&amp;usg=AOvVaw2bWnMIqI5LbgHG-isLsDwc">https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span>&gt;Already, AI is being woven into the workplace at an unexpected scale. </span><span class="c15">75% of knowledge workers use AI at work today, </span><span class="c1">and 46% of users started using it less than six months ago. It&rsquo;s paying off: users</span></li><li class="c10 li-bullet-0"><span>Users say AI helps them </span><span class="c33 c34">save time (90%), focus on their most important work (85%), be more creative (84%), and enjoy their work more (83%). </span></li><li class="c10 li-bullet-0"><span class="c15">78% of AI users are bringing their own AI tools to work </span><span>(BYOAI)&mdash;it&rsquo;s even </span><span class="c33 c34">more common at small and medium-sized companies (80%).</span></li><li class="c10 li-bullet-0"><span>53% of people who use AI at work worry that using it on important work tasks </span><span class="c33 c15">makes them look replaceable.</span></li><li class="c10 li-bullet-0"><span>While</span><span class="c15">&nbsp;some professionals worry AI will replace their job (45%),</span><span class="c1">&nbsp;about the same share (46%) say they&rsquo;re considering quitting in the year ahead&mdash;higher than the 40% who said the same ahead of 2021&rsquo;s Great Reshuffle.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c161 c78 li-bullet-0"><span>How AI is fuelling uncertainty for game developers: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/articles/cl44mv0jnv5o&amp;sa=D&amp;source=editors&amp;ust=1730413583675702&amp;usg=AOvVaw0VC-qM9cpqb-631Hbz8a1e">https://www.bbc.com/news/articles/cl44mv0jnv5o</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c22 c97 c105 c176 li-bullet-0"><span class="c112 c37 c35 c48 c120">&quot;I&#39;m very aware that I could wake up tomorrow and my job could be gone,&rdquo; says Jess Hyland.</span></li><li class="c22 c176 c97 c105 li-bullet-0"><span class="c112 c37 c35 c48 c120">The video game artist says the industry she&rsquo;s spent almost 15 years working in is on &ldquo;shaky&rdquo; ground at the moment.</span></li><li class="c22 c176 c97 c105 li-bullet-0"><span class="c24 c37 c48 c92">Some bosses are talking up the potential of generative AI - the tech behind tools such as ChatGPT - as a potential saviour.</span></li><li class="c22 c176 c97 c105 li-bullet-0"><span class="c112 c37 c35 c48 c120">Tech giant Nvidia has shown off impressive development tool prototypes, and gaming industry heavyweights such as Electronic Arts and Ubisoft are investing in the tech.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c24">It&#39;s claimed AI tools can </span><span class="c20 c24"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.co.uk/news/business-68844761&amp;sa=D&amp;source=editors&amp;ust=1730413583676505&amp;usg=AOvVaw0Z6dqE4YHA3xpVW63DWC_a">save development time, free workers up to focus on creativity</a></span><span class="c24">&nbsp;and provide a more personalised user experience.</span></li><li class="c22 c176 c97 c105 li-bullet-0"><span class="c112 c37 c35 c48 c120">Against the backdrop of widespread layoffs, Jess says the suspicion among workers is that bosses see AI as a path to cutting costs when labour is their biggest expense.</span></li><li class="c22 c176 c97 c105 li-bullet-0"><span class="c112 c37 c35 c48 c120">Jess says she knows one person who&#39;s lost work due to AI, and has heard of it happening to others.</span></li><li class="c22 c176 c97 c105 li-bullet-0"><span class="c112 c37 c35 c48 c120">There are also dozens of accounts online suggesting that jobs in concept art and other traditionally entry-level roles have been affected.</span></li><li class="c22 c161 c97 c105 li-bullet-0"><span class="c112 c37 c35 c48 c120">Rather than creating their own material, says Jess, artists worry they could end up supplementing AI&#39;s efforts, rather than the other way around.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>An agency created an AI model who earns up to $11,000 a month because it was tired of influencers &#39;who have egos&#39; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/ai-influencer-aitana-clueless-agency-tech-spain-2023-11?op%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583677499&amp;usg=AOvVaw09hMUhav0D8p6pnpCBIK9_">https://www.businessinsider.com/ai-influencer-aitana-clueless-agency-tech-spain-2023-11?op=1</a></span></li><li class="c4 li-bullet-0"><span>JPMorgan CEO says AI is a living, breathing thing and they&#39;re putting AI into every process -- sometimes as a copilot, sometimes to replace humans. &ldquo;AI is doing all the equity hedging for us.&rdquo; </span><span class="c5 c37 c65 c60 c249"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e9z84s/jpmorgan_ceo_says_ai_is_a_living_breathing_thing/&amp;sa=D&amp;source=editors&amp;ust=1730413583677928&amp;usg=AOvVaw3Ig_r9QnfUgqCydQvhyOZ9">https://www.reddit.com/r/singularity/comments/1e9z84s/jpmorgan_ceo_says_ai_is_a_living_breathing_thing/</a></span></li><li class="c4 li-bullet-0"><span>Three in Four Americans Believe AI Will Reduce Jobs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://news.gallup.com/opinion/gallup/510635/three-four-americans-believe-reduce-jobs.aspx&amp;sa=D&amp;source=editors&amp;ust=1730413583678344&amp;usg=AOvVaw1JOIphtnN47v2zR_jssQBJ">https://news.gallup.com/opinion/gallup/510635/three-four-americans-believe-reduce-jobs.aspx</a></span></li><li class="c4 li-bullet-0"><span>AI Detects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131&amp;sa=D&amp;source=editors&amp;ust=1730413583678772&amp;usg=AOvVaw2MXf7SgFbWUONSeV3SVXHk">https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131</a></span></li><li class="c4 li-bullet-0"><span>From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://stability.ai/news/introducing-stable-fast-3d&amp;sa=D&amp;source=editors&amp;ust=1730413583679092&amp;usg=AOvVaw3QQd601JzhqUcRi7tV-OWl">https://stability.ai/news/introducing-stable-fast-3d</a></span></li><li class="c4 li-bullet-0"><span>METR Evals - LLM agents vs skilled humans on diverse task completion: When agents can do a task, they do so at ~1/30th of the cost of the median hourly wage of a US bachelor&rsquo;s degree... Claude 3.5 Sonnet agent fixed bugs in an ORM library at a cost of &lt;$2, Human baseline took &gt;2 hours: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/METR_Evals/status/1820905731950055766&amp;sa=D&amp;source=editors&amp;ust=1730413583679368&amp;usg=AOvVaw0OPU290XfuA6QtQ1EnaAjN">https://x.com/METR_Evals/status/1820905731950055766</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">40% fewer tasks means fewer staff needed </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 522.89px; height: 196.50px;"><img alt="" src="images/image582.png" style="width: 522.89px; height: 196.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 544.50px; height: 340.31px;"><img alt="" src="images/image102.png" style="width: 544.50px; height: 340.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image249.jpg" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 353.37px;"><img alt="" src="images/image494.png" style="width: 471.17px; height: 353.37px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">GPT-4 scored higher than 100% of psychologists on a test of social intelligence:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413583680364&amp;usg=AOvVaw3Wg7qyYEW4Dx1tAYD4M5uP">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full&amp;sa=D&amp;source=editors&amp;ust=1730413583680561&amp;usg=AOvVaw0qtdaJWhluZyBlNdNBTbb3">https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full</a></span></li><li class="c4 li-bullet-0"><span class="c1">What percent of code is now written by AI? &quot;I ask all the software companies I meet about this. The number is rarely lower than 40%. For some young programmers it&#39;s 90%.&quot; - Paul Graham of Y Combinator on Twitter</span></li><li class="c4 li-bullet-0"><span>AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients&rsquo; tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color&amp;sa=D&amp;source=editors&amp;ust=1730413583681062&amp;usg=AOvVaw172q-KpuRGQMnFZUq93Usb">https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span>the paper itself shows that the best model has a f1 score, precision, recall all above 98% </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mdpi.com/2227-7080/12/7/97&amp;sa=D&amp;source=editors&amp;ust=1730413583681390&amp;usg=AOvVaw2L22zeKBtHbXtFRwagchOf">https://www.mdpi.com/2227-7080/12/7/97</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>AI stole my job and my work, and my boss didn&rsquo;t know or care: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theregister.com/2024/08/15/robot_took_my_job/&amp;sa=D&amp;source=editors&amp;ust=1730413583681728&amp;usg=AOvVaw1YhXdYQ87ETjcjlq7xo1RC">https://www.theregister.com/2024/08/15/robot_took_my_job/</a></span></li><li class="c4 li-bullet-0"><span>You Will Lose Your Job to a Robot&mdash;and Sooner Than You Think: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.motherjones.com/politics/2017/10/you-will-lose-your-job-to-a-robot-and-sooner-than-you-think/&amp;sa=D&amp;source=editors&amp;ust=1730413583682153&amp;usg=AOvVaw3MAorzdC7W943mdE6q5es7">https://www.motherjones.com/politics/2017/10/you-will-lose-your-job-to-a-robot-and-sooner-than-you-think/</a></span></li><li class="c4 li-bullet-0"><span>In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8&amp;sa=D&amp;source=editors&amp;ust=1730413583682507&amp;usg=AOvVaw3X_5el0wIP13CMguEzsx1b">https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">This isn&rsquo;t marketing hype since the recording was not meant to be public</span></li><li class="c10 li-bullet-0"><span class="c1">Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry </span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">AI agent that can control a computer: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.adept.ai/blog/act-1&amp;sa=D&amp;source=editors&amp;ust=1730413583683050&amp;usg=AOvVaw3yjLganbdrr1iYQCeCDJ3L">https://www.adept.ai/blog/act-1</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">This can be especially powerful for manual tasks and complex tools &mdash; in this example, what might ordinarily take 10+ clicks in Salesforce can be now done with just a sentence.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">Working in-depth in tools like spreadsheets, ACT-1 demonstrates real-world knowledge, infers what we mean from context, and can help us do things we may not even know how to do.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">The model can also complete tasks that require composing multiple tools together; most things we do on a computer span multiple programs. In the future, we expect ACT-1 to be even more helpful by asking for clarifications about what we want.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">The internet contains a lot of knowledge about the world! When the model doesn&rsquo;t know something, it knows how to just look up the information online</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c35 c48 c14 c171">ACT-1 doesn&rsquo;t know how to do everything, but it&rsquo;s highly coachable. With 1 piece of human feedback, it can correct mistakes, becoming more useful with each interaction.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Call centers being automated with AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.hindustantimes.com/business/ais-impact-on-philippines-the-worlds-call-center-capital-shows-whats-to-come-101724827045422.html&amp;sa=D&amp;source=editors&amp;ust=1730413583684481&amp;usg=AOvVaw0jPn6xh5c3kQUx7h1JIHd9">https://www.hindustantimes.com/business/ais-impact-on-philippines-the-worlds-call-center-capital-shows-whats-to-come-101724827045422.html</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c69 li-bullet-0"><span class="c1">For some, the rapid deployment of such tools has been a harsh awakening. Christopher Bautista, 47, had worked in the call center industry for nearly two decades. In his last job on a tech support desk he&rsquo;d watched as AI took on more responsibility in gatekeeping customer calls and asking questions before routing to human agents. Then last November, along with about 70 other people, he says, he was abruptly put on so-called floating status &mdash; no work, no pay, but still on the books &mdash; after the client pulled the contract. He quit six months later for a job in sales while still waiting for reassignment. &quot;AI will take over our jobs,&rdquo; Bautista said. &ldquo;It&rsquo;s cheaper and more efficient.&quot;</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>A class of 20 pupils at a $35,000 per year private London school won&#39;t have a human teacher this year. They&#39;ll just be taught by AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.md/wkIZZ&amp;sa=D&amp;source=editors&amp;ust=1730413583685397&amp;usg=AOvVaw3or9TYoJM0tbI3AvA2J496">https://archive.md/wkIZZ</a></span></li><li class="c4 li-bullet-0"><span>Self driving bus in china: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fc8f3k/self_driving_bus_in_china/&amp;sa=D&amp;source=editors&amp;ust=1730413583685809&amp;usg=AOvVaw3isJbuAs3MXf3vwHyDH90M">https://www.reddit.com/r/singularity/comments/1fc8f3k/self_driving_bus_in_china/</a></span></li><li class="c4 li-bullet-0"><span>Automated shuttle: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://news.vt.edu/articles/2019/05/053019-vtti-autonomousshuttle.html&amp;sa=D&amp;source=editors&amp;ust=1730413583686193&amp;usg=AOvVaw0CkEZyoTQfaVvkicFBjPlu">https://news.vt.edu/articles/2019/05/053019-vtti-autonomousshuttle.html</a></span></li><li class="c4 li-bullet-0"><span>An AI Bot Named James Has My Old Local News Job: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/an-ai-bot-named-james-has-my-old-local-news-job/&amp;sa=D&amp;source=editors&amp;ust=1730413583686622&amp;usg=AOvVaw1ShkkSmtkQsotsWQKyLwLE">https://www.wired.com/story/an-ai-bot-named-james-has-my-old-local-news-job/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span class="c1">A local newspaper in Hawaii has turned to AI-generated presenters to draw in new audiences.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>NotebookLM now lets you listen to a conversation about your sources (Create a two person podcast from your sources): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blog.google/technology/ai/notebooklm-audio-overviews/&amp;sa=D&amp;source=editors&amp;ust=1730413583687162&amp;usg=AOvVaw0jrEqnACZmqtGH9EtWCBiR">https://blog.google/technology/ai/notebooklm-audio-overviews/</a></span></li><li class="c4 li-bullet-0"><span>AI medical receptionist: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fjqzsv/vocca_ai_an_ai_receptionist_for_medical_clinics/&amp;sa=D&amp;source=editors&amp;ust=1730413583687602&amp;usg=AOvVaw1YiQpge8CXAbvh_OiySkbY">https://www.reddit.com/r/singularity/comments/1fjqzsv/vocca_ai_an_ai_receptionist_for_medical_clinics/</a></span></li><li class="c4 li-bullet-0"><span>Billionaire tech CEO says corporate CEO&rsquo;s can&rsquo;t &ldquo;bulls---&rdquo; their employees about the impact of AI on the workforce and instead be honest that jobs will go away: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/09/19/billionaire-tech-ceo-bosses-shouldnt-bs-employees-about-ai-impact.html&amp;sa=D&amp;source=editors&amp;ust=1730413583688012&amp;usg=AOvVaw1qoIR4fexs-YdsQYmRp7ap">https://www.cnbc.com/2024/09/19/billionaire-tech-ceo-bosses-shouldnt-bs-employees-about-ai-impact.html</a></span></li><li class="c4 li-bullet-0"><span>Bank of Canada&rsquo;s Tiff Macklem warns AI could destroy more jobs than it creates: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.md/YK2cm&amp;sa=D&amp;source=editors&amp;ust=1730413583688350&amp;usg=AOvVaw3ai3KYBqG7AN82nktHz1dr">https://archive.md/YK2cm</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">He does not work in the tech industry and has no incentive to lie about this</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c32 c14 li-bullet-0"><span>Nvidia CEO says don&rsquo;t learn coding because of AI, tech giant exec says jobs will be hit: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.indiatoday.in/technology/features/story/nvidia-ceo-says-dont-learn-coding-because-ai-tech-giant-exec-says-jobs-will-be-hit-story-in-5-points-2509126-2024-03-01&amp;sa=D&amp;source=editors&amp;ust=1730413583688893&amp;usg=AOvVaw2aTBgoq_E3CmRKmZ3y8q8i">https://www.indiatoday.in/technology/features/story/nvidia-ceo-says-dont-learn-coding-because-ai-tech-giant-exec-says-jobs-will-be-hit-story-in-5-points-2509126-2024-03-01</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c22 c72 c14 li-bullet-0"><span class="c1">Lying about this goes against his interest as discouraging coders would make them harder to find and more expensive to employ due to a lower supply. It would be a very stupid and short-sighted way of generating hype for the sake of hype when there are many other ways to do it that would not increase long-term costs for his company. </span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8&amp;sa=D&amp;source=editors&amp;ust=1730413583689634&amp;usg=AOvVaw3bXxC9Ah_jXPBxyFDgjFU-">https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c10 li-bullet-0"><span class="c1">This isn&rsquo;t marketing hype since the recording was not meant to be public</span></li><li class="c10 li-bullet-0"><span class="c1">Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c159 c78 li-bullet-0"><span>Microsoft announces up to 1,500 layoffs, leaked memo blames &#39;AI wave&#39; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave&amp;sa=D&amp;source=editors&amp;ust=1730413583690445&amp;usg=AOvVaw0y1Ib6xTnoE9hscjqZqEu4">https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave</a></span></li></ul><p class="c159 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c97 c105 c159 li-bullet-0"><span class="c1">This isn&rsquo;t a PR move since the memo was not supposed to be publicized.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c22 c163 c78 li-bullet-0"><span>How AlphaChip transformed computer chip design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/&amp;sa=D&amp;source=editors&amp;ust=1730413583691152&amp;usg=AOvVaw1doBmcXP2VqlrOV4Ei2yBH">https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span class="c1">Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world</span></li><li class="c69 li-bullet-0"><span>The method has been used to design superhuman chip layouts in the last three generations of Google&rsquo;s custom AI accelerator, the </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/tpu?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1730413583691754&amp;usg=AOvVaw2SD64n452mwwGEWfasdDDW">Tensor Processing Unit</a></span><span class="c1">&nbsp;(TPU).</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaChip has generated superhuman chip layouts used in every generation of Google&rsquo;s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google&rsquo;s </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/&amp;sa=D&amp;source=editors&amp;ust=1730413583692436&amp;usg=AOvVaw0wGT2uLrO2PUfiTPuEs8un">Transformer</a></span><span class="c40 c37 c35 c48">&nbsp;architecture.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu&amp;sa=D&amp;source=editors&amp;ust=1730413583692873&amp;usg=AOvVaw3fcfV53z4nJ7-rZXiBtTPL">Google Axion Processors</a></span><span class="c40 c37 c35 c48">, our first Arm-based general-purpose data center CPUs.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c35">External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips &mdash; like the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.mediatek.com/products/smartphones/dimensity-5g&amp;sa=D&amp;source=editors&amp;ust=1730413583693316&amp;usg=AOvVaw3nG5xv5OhMDuP3wBVk3bJ1">Dimensity Flagship 5G</a></span><span class="c35">&nbsp;used in Samsung mobile phones &mdash; while improving power, performance and chip area.</span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 536.00px;"><img alt="" src="images/image76.png" style="width: 624.00px; height: 536.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c163 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image122.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Billionaire Predicts How AI Will Kill Jobs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://futurism.com/the-byte/billionaire-sips-margaritas-bragging-ai-kill-jobs&amp;sa=D&amp;source=editors&amp;ust=1730413583694300&amp;usg=AOvVaw2kvWXb50ou7N6R9DehE5hJ">https://futurism.com/the-byte/billionaire-sips-margaritas-bragging-ai-kill-jobs</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c149 c10 c14 li-bullet-0"><span class="c37 c63 c76">The company has already </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2024/01/09/tech/duolingo-layoffs-due-to-ai/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583694923&amp;usg=AOvVaw2MVoTeITbi3xJKHYb3fuOG">cut off contractors tasked</a></span><span class="c40 c37 c63 c76">&nbsp;with coming up with alternative ways to phrase translations in January.</span></li><li class="c10 c14 c149 li-bullet-0"><span class="c40 c37 c63 c76">Unsurprisingly, the changes were in large part thanks to the advent of AI.</span></li><li class="c149 c10 c14 li-bullet-0"><span class="c37 c63 c76">&quot;Generative AI is accelerating our work by helping us create new content dramatically faster,&quot; von Ahn wrote in a November </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://investors.duolingo.com/static-files/033ccf0a-f5ea-4897-ba7a-00b00bb48a2d&amp;sa=D&amp;source=editors&amp;ust=1730413583695633&amp;usg=AOvVaw0jBKHqreN1ogvv7XXb-JqS">shareholder letter</a></span><span class="c40 c37 c63 c76">.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>OpenAI&#39;s Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests, and Noam Brown says everyone will know AGI has been achieved internally when they take down all their job listings: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583696169&amp;usg=AOvVaw2_SJxce14oTQh7JGmaNHhi">https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/</a></span></li><li class="c4 li-bullet-0"><span>New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/&amp;sa=D&amp;source=editors&amp;ust=1730413583696707&amp;usg=AOvVaw3tJumnlkLCHgincwindcaa">https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/</a></span></li><li class="c4 li-bullet-0"><span>Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027&amp;sa=D&amp;source=editors&amp;ust=1730413583697245&amp;usg=AOvVaw3eV7dM-RbYm16s5VlqfG4t">https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">Short Term:</span></li></ul><ul class="c0 lst-kix_w9nfenze7id7-0"><li class="c7 li-bullet-0"><span class="c1">AI tools will slightly increase productivity by helping with tasks.</span></li><li class="c7 li-bullet-0"><span class="c1">Senior developers in well-run companies will benefit the most from these tools.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kviltkqr3kxc-0"><li class="c10 li-bullet-0"><span class="c1">Medium Term:</span></li></ul><ul class="c0 lst-kix_kviltkqr3kxc-1 start"><li class="c7 li-bullet-0"><span class="c1">AI agents will change how developers work by automating more tasks.</span></li><li class="c7 li-bullet-0"><span class="c1">Most code will be made by AI, not humans.</span></li><li class="c7 li-bullet-0"><span class="c1">Developers need to learn new skills like prompt engineering and RAG.</span></li></ul><ul class="c0 lst-kix_kviltkqr3kxc-0"><li class="c10 li-bullet-0"><span class="c1">Long Term:</span></li></ul><ul class="c0 lst-kix_hw08zzin6mm8-0"><li class="c7 li-bullet-0"><span class="c1">More skilled software engineers are needed because of the growing demand for AI-powered software.</span></li><li class="c7 li-bullet-0"><span class="c1">A new type of engineer, called an AI engineer, who knows about software, data science, and AI/ML will be very important</span></li></ul><ul class="c0 lst-kix_wt4lxomyh94s-0 start"><li class="c4 li-bullet-0"><span>Wimbledon will replace all 300 line judges next year with AI tech after 147 years of tradition.: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.skysports.com/tennis/news/12110/13230764/wimbledon-to-replace-line-judges-with-ai-after-147-years&amp;sa=D&amp;source=editors&amp;ust=1730413583699700&amp;usg=AOvVaw2Q2yjEuv3yfXsvppvzXsLo">https://www.skysports.com/tennis/news/12110/13230764/wimbledon-to-replace-line-judges-with-ai-after-147-year</a></span><span class="c1">s</span></li><li class="c4 li-bullet-0"><span>Cardiologists working with AI said it was equal or better than human cardiologists in most areas: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DKThomp/status/1843993273825964312&amp;sa=D&amp;source=editors&amp;ust=1730413583700158&amp;usg=AOvVaw36Ce1gYz2XCoNdiDTsdvpn">https://x.com/DKThomp/status/1843993273825964312</a></span></li></ul><ul class="c0 lst-kix_wt4lxomyh94s-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 209.33px;"><img alt="" src="images/image77.png" style="width: 624.00px; height: 209.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wt4lxomyh94s-0"><li class="c4 li-bullet-0"><span>LLM skeptic Internet of Bugs says ChatGPT-O1 Changes Programming as a Profession. I really hated saying that: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Dj0yKLumIbaM&amp;sa=D&amp;source=editors&amp;ust=1730413583700859&amp;usg=AOvVaw2NSqOxQx_qsiPk6Okg-_ae">https://youtube.com/watch?v=j0yKLumIbaM</a></span></li><li class="c4 li-bullet-0"><span>ACM writer who has been in CS since the 1980s predicts AI will make programmers obsolete: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cacm.acm.org/opinion/the-end-of-programming/&amp;sa=D&amp;source=editors&amp;ust=1730413583701272&amp;usg=AOvVaw0JjMN8I0joB0Rs_A8S0Pbs">https://cacm.acm.org/opinion/the-end-of-programming</a></span></li><li class="c4 li-bullet-0"><span>OpenAI CPO Kevin Weil says their o1 model can now write legal briefs that previously were the domain of $1000/hour associates: &quot;what does it mean when you can suddenly do $8000 of work in 5 minutes for $3 of API credits?&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g7v0ud/openai_cpo_kevin_weil_says_their_o1_model_can_now/&amp;sa=D&amp;source=editors&amp;ust=1730413583701820&amp;usg=AOvVaw0hPSilrHEbgvsQ3q0rNLWr">https://www.reddit.com/r/singularity/comments/1g7v0ud/openai_cpo_kevin_weil_says_their_o1_model_can_now/</a></span></li><li class="c4 li-bullet-0"><span>Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve &ldquo;hundreds&rdquo; of people at the company and will primarily focus on post-production and visual effects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.thewrap.com/disney-ai-initiative/&amp;sa=D&amp;source=editors&amp;ust=1730413583702288&amp;usg=AOvVaw3wD-4ZquqPoQbzFXklfBa4">https://www.thewrap.com/disney-ai-initiative/</a></span></li><li class="c4 li-bullet-0"><span>Sundar Pichai said on the earnings call today that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/&amp;sa=D&amp;source=editors&amp;ust=1730413583702801&amp;usg=AOvVaw1ggEqWmjVwHwHJ-vVkTo3t">https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_wt4lxomyh94s-1"><li class="c10 li-bullet-0"><span>Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said &ldquo;a large percentage&rdquo; instead of a specific and verifiable number.</span></li></ul><h2 class="c64" id="h.kwghsudjuuru"><span class="c40 c37 c48 c75">5.1. Robotics</span></h2><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 546.55px; height: 338.06px;"><img alt="" src="images/image244.jpg" style="width: 546.55px; height: 338.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c100 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 578.36px; height: 338.06px;"><img alt="" src="images/image417.jpg" style="width: 578.36px; height: 338.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c100 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 549.13px; height: 428.50px;"><img alt="" src="images/image165.png" style="width: 549.13px; height: 428.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c100 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 559.93px; height: 430.50px;"><img alt="" src="images/image411.png" style="width: 559.93px; height: 430.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c100 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.83px; height: 437.50px;"><img alt="" src="images/image43.png" style="width: 554.83px; height: 437.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583704918&amp;usg=AOvVaw1EDJcMJrnFXDb36jkC-pWl">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>In a historic moment for the dental profession, an AI-controlled autonomous robot has performed an entire procedure on a human patient for the first time, about eight times faster than a human dentist could do it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/health-wellbeing/robot-dentist-world-first/&amp;sa=D&amp;source=editors&amp;ust=1730413583705406&amp;usg=AOvVaw37SCqGjesQF56hCOpKKtDn">https://newatlas.com/health-wellbeing/robot-dentist-world-first/</a></span></li><li class="c100 c78 li-bullet-0"><span>7-foot robots are stacking shelves in Tokyo convenience stores using remote workers for $3.75 an hour. &quot;The robots will be remotely operated at first, until their AI learns to copy human movements.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AISafetyMemes/status/1810152092230877563&amp;sa=D&amp;source=editors&amp;ust=1730413583705886&amp;usg=AOvVaw1plrvkiqUmpgb8pc2kJarT">https://x.com/AISafetyMemes/status/1810152092230877563</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Successful test of humanoid robots at BMW Group Plant Spartanburg: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.press.bmwgroup.com/global/article/detail/T0444265EN/successful-test-of-humanoid-robots-at-bmw-group-plant-spartanburg&amp;sa=D&amp;source=editors&amp;ust=1730413583706703&amp;usg=AOvVaw2EQJQu3hPDGdvx03mbhXIP">https://www.press.bmwgroup.com/global/article/detail/T0444265EN/successful-test-of-humanoid-robots-at-bmw-group-plant-spartanburg</a></span></li><li class="c100 c78 li-bullet-0"><span>Humanoid robots that can detect objects, appraise their work and correct mistakes are coming to factories: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1807886268501839875&amp;sa=D&amp;source=editors&amp;ust=1730413583707254&amp;usg=AOvVaw1ekVpgIqxaW6SP_bsQETwe">https://x.com/tsarnick/status/1807886268501839875</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Digit in action at GXO&#39;s SPANX facility in Flowery Branch, Georgia: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1807307038458052730&amp;sa=D&amp;source=editors&amp;ust=1730413583707865&amp;usg=AOvVaw0CQDJA-d4nk-x7ig3gUlo7">https://x.com/TheHumanoidHub/status/1807307038458052730</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Robot operated autonomous surgery: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html&amp;sa=D&amp;source=editors&amp;ust=1730413583708466&amp;usg=AOvVaw0BQXiGLiL0nKNSuMY87ckA">https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c69 li-bullet-0"><span>With one claw, the machine lifted a tiny plastic ring from an equally tiny peg on the table, passed the ring from one claw to the other, moved it across the table and gingerly hooked it onto a new peg. Then the robot did the same with several more rings, completing the task as quickly as it had when guided by Dr. Fer. The training exercise was originally designed for humans; moving the rings from peg to peg is </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.flsprogram.org/wp-content/uploads/2014/03/Revised-Manual-Skills-Guidelines-February-2014.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583709194&amp;usg=AOvVaw2PbL_A2o2kh0MXP8N3UZSa">how surgeons learn to operate robots like the one in Berkeley</a></span><span class="c1">. Now, an automated robot performing the test can match or even exceed a human in dexterity, precision and speed, according to a new research paper from the Berkeley team.</span></li><li class="c69 li-bullet-0"><span>The project is a part of a much wider effort to bring artificial intelligence into the operating room. Using many of the same technologies that underpin </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2018/03/19/technology/how-driverless-cars-work.html&amp;sa=D&amp;source=editors&amp;ust=1730413583709657&amp;usg=AOvVaw1-iDJ6bWd-elPp_qGMTA7X">self-driving cars</a></span><span>, </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2021/02/26/technology/anduril-military-palmer-luckey.html&amp;sa=D&amp;source=editors&amp;ust=1730413583709905&amp;usg=AOvVaw08hGKo21q5KqB_267Xd54M">autonomous drones</a></span><span>and </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nytimes.com/2020/01/29/technology/warehouse-robot.html&amp;sa=D&amp;source=editors&amp;ust=1730413583710136&amp;usg=AOvVaw3a7Aa-WS_TxMelRr7B5WU9">warehouse robots</a></span><span class="c1">, researchers are working to automate surgical robots too. These methods are still a long way from everyday use, but progress is accelerating.</span></li><li class="c10 li-bullet-0"><span>Robots can already exceed human accuracy on some surgical tasks, like placing a pin into a bone (a particularly risky task during knee and hip replacements). The hope is that automated robots can bring greater accuracy to other tasks, like incisions or suturing, and reduce the risks that come with </span><span class="c92 c37 c63 c14 c76 c98">overworked surgeons.</span></li></ul><p class="c9"><span class="c92 c37 c63 c14 c76 c98"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Apple wants to replace 50% of iPhone final assembly line workers with automation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://9to5mac.com/2024/06/24/iphone-supply-chain-automation-workers/&amp;sa=D&amp;source=editors&amp;ust=1730413583711039&amp;usg=AOvVaw2d8Sii7svqJuNk52mfWbCw">https://9to5mac.com/2024/06/24/iphone-supply-chain-automation-workers/</a></span><span class="c1">&nbsp;</span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">Amazon Grows To Over 750,000 Robots As World&#39;s Second-Largest Private Employer Replaces Over 100,000 Humans:</span><span class="c14">&nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://finance.yahoo.com/news/amazon-grows-over-750-000-153000967.html&amp;sa=D&amp;source=editors&amp;ust=1730413583711720&amp;usg=AOvVaw1D_zNXlUgtoYLpeaO0kM5i">https://finance.yahoo.com/news/amazon-grows-over-750-000-153000967.html</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">Samsung builds all AI, no human chip factories</span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://asiatimes.com/2024/01/samsung-to-build-all-ai-no-human-chip-factories/&amp;sa=D&amp;source=editors&amp;ust=1730413583712421&amp;usg=AOvVaw0hOqzhhpOkM0YuvfG6jPvj">https://asiatimes.com/2024/01/samsung-to-build-all-ai-no-human-chip-factories/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Xiaomi&rsquo;s new &laquo;smart&raquo; factory will operate 24/7 without people and produce 60 smartphones per minute: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://itc.ua/en/news/xiaomi-s-new-smart-factory-will-operate-24-7-without-people-and-produce-60-smartphones-per-minute/&amp;sa=D&amp;source=editors&amp;ust=1730413583713109&amp;usg=AOvVaw3vWA7fon3LvyLbtZwIUU9u">https://itc.ua/en/news/xiaomi-s-new-smart-factory-will-operate-24-7-without-people-and-produce-60-smartphones-per-minute/</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">Japan introduces enormous humanoid robot to maintain train lines: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/world/article/2024/jul/04/japan-train-robot-maintain-railway-lines&amp;sa=D&amp;source=editors&amp;ust=1730413583713917&amp;usg=AOvVaw1lFoCg5NvypL4oz1f8RAeY">https://www.theguardian.com/world/article/2024/jul/04/japan-train-robot-maintain-railway-lines</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c158 c78 li-bullet-0"><span class="c43">Fully automated packing company: </span><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/robotics/comments/1dlcvjs/i_was_in_full_automated_packaging_company_and/&amp;sa=D&amp;source=editors&amp;ust=1730413583714568&amp;usg=AOvVaw3GTZR7GtQB8FlMaZmy0QaA">https://www.reddit.com/r/robotics/comments/1dlcvjs/i_was_in_full_automated_packaging_company_and/</a></span></li></ul><p class="c158 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c14">How many robots does it take to run a grocery store? </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DssZ_8cqfBlE&amp;sa=D&amp;source=editors&amp;ust=1730413583715158&amp;usg=AOvVaw1NOWXRwkwz1HsSLzySLII4">https://www.youtube.com/watch?v=ssZ_8cqfBlE</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c158 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c158 c78 li-bullet-0"><span class="c43">Robot operated McDonalds in Texas: </span><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://www.newsweek.com/first-ever-mcdonalds-served-robots-texas-1769116&amp;sa=D&amp;source=editors&amp;ust=1730413583715895&amp;usg=AOvVaw0mqqiuEL1LX5VVJqT-8cpJ">https://www.newsweek.com/first-ever-mcdonalds-served-robots-texas-1769116</a></span><span class="c1 c43">&nbsp;</span></li></ul><p class="c46 c158"><span class="c1 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c158 c78 li-bullet-0"><span class="c43">&nbsp;A Starbucks run by 100 robots and 2 humans in South Korea: </span><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://x.com/NorthstarBrain/status/1794819711240155594&amp;sa=D&amp;source=editors&amp;ust=1730413583716527&amp;usg=AOvVaw3ckN_57w_XciwDiyQ2La2H">https://x.com/NorthstarBrain/status/1794819711240155594</a></span></li></ul><p class="c158 c46"><span class="c1 c43"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span class="c15">Restaurant robots can cook, serve and bus your meal now: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.axios.com/2024/06/11/restaurant-technology-robots-food-ramen&amp;sa=D&amp;source=editors&amp;ust=1730413583717138&amp;usg=AOvVaw0gtAALn2Rejp7rS38_W4uC">https://www.axios.com/2024/06/11/restaurant-technology-robots-food-ramen</a></span><span class="c33 c15">&nbsp;</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Robot chef that cooks meals: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/leeron/status/1800006993048170767&amp;sa=D&amp;source=editors&amp;ust=1730413583717716&amp;usg=AOvVaw2jERE9352_vZt6oLHXRPAM">https://x.com/leeron/status/1800006993048170767</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Robots as psychological counselors: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.economictimes.com/news/international/uk/robots-as-psychological-counsellors-this-factory-in-china-is-making-it-a-reality/articleshow/110916481.cms&amp;sa=D&amp;source=editors&amp;ust=1730413583718396&amp;usg=AOvVaw1WX92WTj8iacoxYawDeNqg">https://m.economictimes.com/news/international/uk/robots-as-psychological-counsellors-this-factory-in-china-is-making-it-a-reality/articleshow/110916481.cms</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Robots for manufacturing cars: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/china-s-humanoid-robots-to-tackle-tricky-car-chores-at-dongfeng-motor/ar-BB1nAE9W?ocid%3DBingNewsSerp&amp;sa=D&amp;source=editors&amp;ust=1730413583719072&amp;usg=AOvVaw2lQ2z5mMDJzCvC11DckmII">https://www.msn.com/en-us/money/other/china-s-humanoid-robots-to-tackle-tricky-car-chores-at-dongfeng-motor/ar-BB1nAE9W?ocid=BingNewsSerp</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Robots can paint: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/BeAmazed/comments/1drw1wr/meanwhile_robots_are_slowly_taking_jobs_away_from/&amp;sa=D&amp;source=editors&amp;ust=1730413583719668&amp;usg=AOvVaw0gPMc47Yis8cKdk1ISFf46">https://www.reddit.com/r/BeAmazed/comments/1drw1wr/meanwhile_robots_are_slowly_taking_jobs_away_from/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Robots [Automates] jobs from unions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html%23google_vignette&amp;sa=D&amp;source=editors&amp;ust=1730413583720309&amp;usg=AOvVaw1aUESWVlIkTKdH-SLAUtUD">https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>ARK Invest says robots are falling in cost as more are built, they are working faster than humans and Amazon are now adding more robots than human employees: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1807929272491012440&amp;sa=D&amp;source=editors&amp;ust=1730413583720784&amp;usg=AOvVaw0ROUFQHHO_faERnCA3Ta3G">https://x.com/tsarnick/status/1807929272491012440</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Automated farm picking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/robotics/comments/1dv19lg/hitbot_robot_farm_automated_picking/&amp;sa=D&amp;source=editors&amp;ust=1730413583721159&amp;usg=AOvVaw0CsEO3aaZDuEd23a_L6j2d">https://www.reddit.com/r/robotics/comments/1dv19lg/hitbot_robot_farm_automated_picking/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c78 c100 li-bullet-0"><span>Language action model can perform tasks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1bfsysa/3d_visionlanguageaction_generative_world_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583721551&amp;usg=AOvVaw06eBhThKDyjhYQafj6zCyR">https://www.reddit.com/r/singularity/comments/1bfsysa/3d_visionlanguageaction_generative_world_model/</a></span></li><li class="c100 c78 li-bullet-0"><span>Meet Robbie - a bartender robot from Robbie Drink - Robot Barman! Robbie Drink is a Polish company offering a rental cell with a FANUC Europe robot that works as a reliable bartender at various events: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/WevolverApp/status/1810418899784966542&amp;sa=D&amp;source=editors&amp;ust=1730413583721832&amp;usg=AOvVaw3ifbAJdCEvq6FUm1Rwv2Gt">https://x.com/WevolverApp/status/1810418899784966542</a></span></li><li class="c100 c78 li-bullet-0"><span>This food robotics company has developed an AI-enabled robotic system for food manipulation after working in stealth mode. The company has already served 20 million meals in production, with robots deployed in 6 cities across the US and Canada: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emollick/status/1811893216658026999&amp;sa=D&amp;source=editors&amp;ust=1730413583722085&amp;usg=AOvVaw3GzBKFkMhZpkl76BSSVGvG">https://x.com/emollick/status/1811893216658026999</a></span></li><li class="c100 c78 li-bullet-0"><span>World&rsquo;s first mobile bricklayer robot that boosts construction speed enters US: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://interestingengineering.com/innovation/mobile-bricklayer-robot-hadrian-in-us&amp;sa=D&amp;source=editors&amp;ust=1730413583722366&amp;usg=AOvVaw2oD97G1BXHO1oyH-wRDUci">https://interestingengineering.com/innovation/mobile-bricklayer-robot-hadrian-in-us</a></span></li></ul><p class="c100 c46"><span class="c1"></span></p><ul class="c0 lst-kix_j6b3cjdkd1ra-1"><li class="c69 li-bullet-0"><span class="c1">The machine has a unique optimisation software that converts wall sketches into block positions.</span></li><li class="c69 li-bullet-0"><span class="c92 c37 c35 c48 c218">The world&rsquo;s first bricklayer robot that&rsquo;s capable of safely working outdoors in uncontrolled environments has arrived in the United States. Hadrian X can build the walls of a house in situ in as little as a day.</span></li><li class="c69 li-bullet-0"><span>The Hadrian X doesn&rsquo;t apply mortar between the bricks while placing them. Once the wall is completed, a strong construction adhesive is applied to bond the individual bricks in place, and the company claims that this is stronger than old-school mortar construction</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.therobotreport.com/1st-hadrian-x-bricklaying-robot-arrives-in-us/%23:~:text%3DFBR%2520is%2520developing%2520an%2520automated,structure%2520of%2520the%2520robot%2520arm.&amp;sa=D&amp;source=editors&amp;ust=1730413583722975&amp;usg=AOvVaw0VTRu2WKrw6_4oLky9aZ9q">.</a></span><span>&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.therobotreport.com/1st-hadrian-x-bricklaying-robot-arrives-in-us/%23:~:text%3DFBR%2520is%2520developing%2520an%2520automated,structure%2520of%2520the%2520robot%2520arm&amp;sa=D&amp;source=editors&amp;ust=1730413583723175&amp;usg=AOvVaw3WmBe1i6iDzkaxe4RZ4fcQ">https://www.therobotreport.com/1st-hadrian-x-bricklaying-robot-arrives-in-us/#:~:text=FBR%20is%20developing%20an%20automated,structure%20of%20the%20robot%20arm</a></span><span class="c1">.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Robot janitor in France: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e3ptns/comment/ldbq0tp/?reply%3Dt1_ldbq0tp&amp;sa=D&amp;source=editors&amp;ust=1730413583723479&amp;usg=AOvVaw1QiX_FAHr-jbBJppT7Exdj">https://www.reddit.com/r/singularity/comments/1e3ptns/comment/ldbq0tp/?reply=t1_ldbq0tp</a></span></li><li class="c100 c78 li-bullet-0"><span>Robotic welding: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.fanucamerica.com/solutions/applications/welding-robots/arc-welding-robots&amp;sa=D&amp;source=editors&amp;ust=1730413583723799&amp;usg=AOvVaw1tV1rk-O3Mqt3Hp3dAQ97J">https://www.fanucamerica.com/solutions/applications/welding-robots/arc-welding-robots</a></span></li><li class="c100 c78 li-bullet-0"><span>Introducing Surgical Robot Transformer (SRT): Automating surgical tasks with end-to-end imitation learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jwbkim/status/1813263637429297381&amp;sa=D&amp;source=editors&amp;ust=1730413583724154&amp;usg=AOvVaw0fC10lFshLDUkuBgk48kdn">https://x.com/jwbkim/status/1813263637429297381</a></span></li><li class="c100 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1813465013241397596&amp;sa=D&amp;source=editors&amp;ust=1730413583724409&amp;usg=AOvVaw059L7MN9ace_ohEZe9YWX2">https://x.com/TheHumanoidHub/status/1813465013241397596</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span class="c1">&#10687; Digit does 2 hour of work per 1 hour of charging. The next-gen will do 8-10 hours of work per 1 hour of charging. </span></li><li class="c69 li-bullet-0"><span class="c1">&#10687; Lifting capacity will go from 30 lbs to 50 lbs. </span></li><li class="c69 li-bullet-0"><span class="c1">&#10687; ROI goal for Digit is 2 years, based on $30/hour human labor.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Robot doing blue collar work: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1816586061080068471&amp;sa=D&amp;source=editors&amp;ust=1730413583725092&amp;usg=AOvVaw32G0YjInSD5H_3g7w8E66l">https://x.com/tsarnick/status/1816586061080068471</a></span></li><li class="c100 c78 li-bullet-0"><span>Autonomous AI workers that talk to each other will arrive in 2025, Capgemini predicts: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/07/22/ai-that-can-talk-with-other-ai-will-launch-in-2025-capgemini-predicts.html&amp;sa=D&amp;source=editors&amp;ust=1730413583725388&amp;usg=AOvVaw2gIx7BfKp1pcnVw-iJx6tb">https://www.cnbc.com/2024/07/22/ai-that-can-talk-with-other-ai-will-launch-in-2025-capgemini-predicts.html</a></span></li><li class="c4 li-bullet-0"><span>Watch a robot peel a squash with human-like dexterity: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2440687-watch-a-robot-peel-a-squash-with-human-like-dexterity/&amp;sa=D&amp;source=editors&amp;ust=1730413583725704&amp;usg=AOvVaw3OZpYl5vxtUbZGaetU7d79">https://www.newscientist.com/article/2440687-watch-a-robot-peel-a-squash-with-human-like-dexterity/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span class="c1">A robot can hold a squash, pumpkin or melon in one hand, while it is peeled by the other</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>&lsquo;Yell at your robot&rsquo; technique teaches robots household chores: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.newscientist.com/article/2425023-yell-at-your-robot-technique-teaches-robots-household-chores/&amp;sa=D&amp;source=editors&amp;ust=1730413583726112&amp;usg=AOvVaw3B31BbOPM9FBv1wOnOt5GU">https://www.newscientist.com/article/2425023-yell-at-your-robot-technique-teaches-robots-household-chores/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span class="c1">AI allows robots to listen to verbal instructions while learning to correctly perform household tasks. That could enable more natural interactions between humans and robots</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>Your robot has arrived - Robots could be performing more services for humans in the near future; food could be next: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/waymo-self-driving-taxis-chipotle-robots-future-of-service-2024-8&amp;sa=D&amp;source=editors&amp;ust=1730413583726580&amp;usg=AOvVaw3MePLZLrz4pIrw5ffAbMCm">https://www.businessinsider.com/waymo-self-driving-taxis-chipotle-robots-future-of-service-2024-8</a></span></li><li class="c4 li-bullet-0"><span>The new Astribot S1 &nbsp;has been unveiled by Chinese company Astribot, showcasing the bimanual wheeled robot performing many household tasks autonomously: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheHumanoidHub/status/1825342986957496598&amp;sa=D&amp;source=editors&amp;ust=1730413583726871&amp;usg=AOvVaw3nn_nLYsdXKZJRHHNQPxjl">https://x.com/TheHumanoidHub/status/1825342986957496598</a></span></li><li class="c100 c78 li-bullet-0"><span>Meet Galbot G1, the 1st-generation robot by Chinese startup Galbot, designed for generalizable, long-duration tasks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f2ilqg/meet_galbot_g1_the_1stgeneration_robot_by_chinese/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583727225&amp;usg=AOvVaw0I4VmV1oT29xUUKK5nbab4">https://www.reddit.com/r/singularity/comments/1f2ilqg/meet_galbot_g1_the_1stgeneration_robot_by_chinese/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li><li class="c4 li-bullet-0"><span>Bernt Bornich, CEO of 1X: Specs of NEO are far ahead of anything else announced. NEO weighs just 30kg and can deadlift 70kg. It can move as fast as I can. It can jump, it can run, it can do all kinds of dynamic things. It&#39;s got the same degrees of freedom with full hands: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f4893u/bernt_bornich_ceo_of_1x_specs_of_neo_are_far/&amp;sa=D&amp;source=editors&amp;ust=1730413583727522&amp;usg=AOvVaw3AUTooot__ghCah2vpBLI7">https://www.reddit.com/r/singularity/comments/1f4893u/bernt_bornich_ceo_of_1x_specs_of_neo_are_far/</a></span></li><li class="c4 li-bullet-0"><span>NEO from 1X emptying the dishwasher: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f51swd/neo_from_1x_emptying_the_dishwasher/&amp;sa=D&amp;source=editors&amp;ust=1730413583727790&amp;usg=AOvVaw1-aJJT6uVQZcANNnCtCb9b">https://www.reddit.com/r/singularity/comments/1f51swd/neo_from_1x_emptying_the_dishwasher/</a></span></li><li class="c4 li-bullet-0"><span>Gravis Robotics has been working on autonomous excavators: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f4zmup/gravis_robotics_has_been_working_on_autonomous/&amp;sa=D&amp;source=editors&amp;ust=1730413583728045&amp;usg=AOvVaw2NJsKdcZPjk_pcq0-p3QM-">https://www.reddit.com/r/singularity/comments/1f4zmup/gravis_robotics_has_been_working_on_autonomous/</a></span></li><li class="c4 li-bullet-0"><span>Robots Are Coming to the Kitchen&mdash;What That Could Mean for Society and Culture: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://singularityhub.com/2024/09/03/robots-are-coming-to-the-kitchen-what-that-could-mean-for-society-and-culture/&amp;sa=D&amp;source=editors&amp;ust=1730413583728332&amp;usg=AOvVaw23ar6-8x2_WbDvs0uLRU0k">https://singularityhub.com/2024/09/03/robots-are-coming-to-the-kitchen-what-that-could-mean-for-society-and-culture/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c88">Right now, robots are used to </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://foodondemand.com/07102024/a-behind-the-scenes-look-at-the-robot-run-restaurant-caliexpress-by-flippy/&amp;sa=D&amp;source=editors&amp;ust=1730413583728609&amp;usg=AOvVaw0fUSGIHR9kj2w9MTIwOT5j">flip burgers</a></span><span class="c88">, </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://abc7ny.com/post/robot-chefs-are-cooking-food-101-chicken-korean/15071977/&amp;sa=D&amp;source=editors&amp;ust=1730413583728837&amp;usg=AOvVaw0WQkT_KbuTQ4rbrBWuwA6p">fry chicken</a></span><span class="c88">, </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://thespoon.tech/meet-pzza-the-latest-pizza-robot-built-by-a-rocket-scientist/&amp;sa=D&amp;source=editors&amp;ust=1730413583728985&amp;usg=AOvVaw1GSLWAemwKCyiwW3cfdryw">create pizzas</a></span><span class="c88">, </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://asia.nikkei.com/Business/Food-Beverage/Don-t-look-now-but-your-next-sushi-chef-could-be-a-robot&amp;sa=D&amp;source=editors&amp;ust=1730413583729153&amp;usg=AOvVaw3XCJRvR25rFqsEqUVRIa9B">make sushi</a></span><span class="c88">, </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://www.cbsnews.com/news/sweetgreen-robots-to-make-salad/&amp;sa=D&amp;source=editors&amp;ust=1730413583729295&amp;usg=AOvVaw3q-HZVjSNRMw-gLmER5kLt">prepare salads</a></span><span class="c88">, </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://sfstandard.com/2023/04/13/this-ramen-vending-machine-serves-tasty-tonkotsu-with-the-efficiency-of-a-japanese-bullet-train-almost/&amp;sa=D&amp;source=editors&amp;ust=1730413583729467&amp;usg=AOvVaw2ByNYbNmtUbIBTSfwt-xTO">serve ramen</a></span><span class="c88">, </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://thespoon.tech/four-years-after-ces-breadbots-robotic-breadmaker-is-dishing-out-loaves-at-grocery-stores/&amp;sa=D&amp;source=editors&amp;ust=1730413583729622&amp;usg=AOvVaw21sBA93pXnk-ohiTS4qhzE">bake bread</a></span><span class="c88">, </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://www.scrippsnews.com/science-and-tech/artificial-intelligence/these-robots-can-make-you-coffee-cocktails-you-name-it&amp;sa=D&amp;source=editors&amp;ust=1730413583729798&amp;usg=AOvVaw18fK3CIs1trekOmjnjatPe">mix cocktails</a></span><span class="c88">, and </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://singularityhub.com/2022/02/17/flippy-the-fast-food-robot-is-going-to-work-in-100-restaurants/&amp;sa=D&amp;source=editors&amp;ust=1730413583729959&amp;usg=AOvVaw1mbtMqaL49B3phh62yLe9H">much more</a></span><span class="c88">. AI can </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://www.dishgen.com/&amp;sa=D&amp;source=editors&amp;ust=1730413583730076&amp;usg=AOvVaw1vpcC0rzej0pEE4auLLQN-">invent recipes</a></span><span class="c88">&nbsp;based on the </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://theaicuisine.com/ai-and-molecular-gastronomy-a-match-made-in-the-kitchen/&amp;sa=D&amp;source=editors&amp;ust=1730413583730232&amp;usg=AOvVaw23GSpVaiiKN1zoe_E25zsD">molecular</a></span><span class="c88">&nbsp;</span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://ai.sony/blog/AI-Assisted-Recipe-Creation-Concept-Video/&amp;sa=D&amp;source=editors&amp;ust=1730413583730401&amp;usg=AOvVaw1SGGrE5PvO4h5VG6BPkp1Q">compatibility</a></span><span class="c88">&nbsp;of ingredients or whatever a kitchen has </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://bgr.com/tech/samsungs-new-ai-powered-fridge-looks-at-your-food-to-suggest-recipes/&amp;sa=D&amp;source=editors&amp;ust=1730413583730569&amp;usg=AOvVaw2fA-3xQi80rznQDF3n0H7t">in</a></span><span class="c88">&nbsp;</span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://www.buzzfeed.com/rossyoder/ai-recipe-generator&amp;sa=D&amp;source=editors&amp;ust=1730413583730709&amp;usg=AOvVaw0Nwg9DgvrfM7EjEHs_w9U3">stock</a></span><span class="c88">. More advanced concepts are in the works to automate the </span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D48x04OgLYnw&amp;sa=D&amp;source=editors&amp;ust=1730413583730844&amp;usg=AOvVaw1HQaksTULqrSDEfA5HOsX4">entire</a></span><span class="c88">&nbsp;</span><span class="c68 c126"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DmKCVol2iWcc&amp;sa=D&amp;source=editors&amp;ust=1730413583730971&amp;usg=AOvVaw3W-ZZSGesyUTR34Qx4A5P6">kitchen</a></span><span class="c92 c88 c37 c48">&nbsp;for fine dining</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c100 c78 li-bullet-0"><span>Amazon has acquired a team to give robots greater intelligence and dexterity&mdash;potentially automating much more of its warehouse operations: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/amazon-covariant-robotics-deal/&amp;sa=D&amp;source=editors&amp;ust=1730413583731263&amp;usg=AOvVaw0KIWwbajHShc6pVlaewR-7">https://www.wired.com/amazon-covariant-robotics-deal/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c69 li-bullet-0"><span class="c92 c41 c37 c48 c14">Amazon&rsquo;s mobile robot army grew from around 10,000 in 2013 to 750,000 by 2023, and the sheer scale of the company&rsquo;s operations meant that it could deliver millions of items faster and cheaper than anyone else</span></li><li class="c69 li-bullet-0"><span class="c41 c14">As </span><span class="c20 c41 c14"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/amazons-new-robots-automation-revolution/&amp;sa=D&amp;source=editors&amp;ust=1730413583731686&amp;usg=AOvVaw3VtHJM2aMhmVb8-p-b9NEF">WIRED revealed last year</a></span><span class="c92 c41 c37 c48 c14">, Amazon has in recent years developed new robotic systems that rely on machine learning to do things like perceive, grab, and sort packed boxes. Again, Amazon is leveraging scale to its advantage, with the training data being gathered as items flow through its facilities helping to improve the performance of different algorithms. The effort has already led to further automation of the work that had previously been done by human workers at some fulfillment centers.</span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>&ldquo;SkillMimic&quot; uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmimic_uses_just_35_minutes_of_video_and/&amp;sa=D&amp;source=editors&amp;ust=1730413583732034&amp;usg=AOvVaw2gf5qRjQ7nAA_PViMjyvJ7">https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmim</a></span></li><li class="c100 c78 li-bullet-0"><span>Window washing robot: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.fastcompany.com/91187456/ai-window-washing-robot-ozmo&amp;sa=D&amp;source=editors&amp;ust=1730413583732281&amp;usg=AOvVaw0ovnryIfrMQZ2Ixi0KYWPK">https://www.fastcompany.com/91187456/ai-window-washing-robot-ozmo</a></span></li><li class="c4 li-bullet-0"><span>IHMC and Boardwalk robotics show their humanoid robot, Nadia, being remotely controlled for boxing training with their advanced low latency VR teleoperation system: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fm7fup/ihmc_and_boardwalk_robotics_show_their_humanoid/&amp;sa=D&amp;source=editors&amp;ust=1730413583732565&amp;usg=AOvVaw2KN9Jyimu7ArFtx_LWPEYD">https://www.reddit.com/r/singularity/comments/1fm7fup/ihmc_and_boardwalk_robotics_show_their_humanoid/</a></span></li><li class="c4 li-bullet-0"><span>Remote controlled robots managing shipping operations: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ftgiay/longshoreman_have_gone_on_strike_demanding_a/?sort%3Dconfidence&amp;sa=D&amp;source=editors&amp;ust=1730413583732830&amp;usg=AOvVaw38_l4R9pPy49th-DJ-SwFN">https://www.reddit.com/r/singularity/comments/1ftgiay/longshoreman_have_gone_on_strike_demanding_a/?sort=confidence</a></span></li><li class="c4 li-bullet-0"><span>Agility robotics is focusing on warehouse logistics. They&#39;ll be competing with wheeled bimanual robots that are highly efficient in pick-and-place tasks. One example is Reflex Robotics, a NY-based company that partnered with GXO to deploy robots in warehouses: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fzzlmm/agility_robotics_is_focusing_on_warehouse/&amp;sa=D&amp;source=editors&amp;ust=1730413583733171&amp;usg=AOvVaw0KW3PhQA4ILniWnyPncoqG">https://www.reddit.com/r/singularity/comments/1fzzlmm/agility_robotics_is_focusing_on_warehouse/</a></span></li><li class="c4 li-bullet-0"><span>Optimus Robot is able to act as a bartender, pour drinks and be friendly with customers and didn&rsquo;t ask for a 25% tip on an iPad: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ThatsInsane/comments/1g12skt/optimus_robot_is_able_to_act_as_a_bartender_pour/&amp;sa=D&amp;source=editors&amp;ust=1730413583733467&amp;usg=AOvVaw3Y8_Xfqtbiy7H32M1Qlp4d">https://www.reddit.com/r/ThatsInsane/comments/1g12skt/optimus_robot_is_able_to_act_as_a_bartender_pour/</a></span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-1 start"><li class="c10 li-bullet-0"><span class="c1">Even if it&rsquo;s tele operated, it can be outsourced to countries with cheap labor </span></li></ul><ul class="c0 lst-kix_j6b3cjdkd1ra-0"><li class="c4 li-bullet-0"><span>CooHOI is a framework that trains simulated humanoid robots to work as a team to move furniture. First, robots learn on their own, then they practice teamwork by sharing object movement info. It&#39;s faster and easier than past methods and works with different object sizes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g9p92s/coohoi_is_a_framework_that_trains_simulated/&amp;sa=D&amp;source=editors&amp;ust=1730413583733868&amp;usg=AOvVaw3HTohilh_1G6iFUW3IN4FH">https://www.reddit.com/r/singularity/comments/1g9p92s/coohoi_is_a_framework_that_trains_simulated/</a></span></li><li class="c4 li-bullet-0"><span>Can replace even more jobs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ArtificialInteligence/comments/1ge553x/think_bluecollar_jobs_are_safe_from_ai_think_again/&amp;sa=D&amp;source=editors&amp;ust=1730413583734294&amp;usg=AOvVaw0TK5gAa5DVXM598g38AfKw">https://www.reddit.com/r/ArtificialInteligence/comments/1ge553x/think_bluecollar_jobs_are_safe_from_ai_think_again/</a></span></li><li class="c4 li-bullet-0"><span>Robot doing nails and eyelashes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/esthercrawford/status/1850681223770947869?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583734610&amp;usg=AOvVaw3NSjypjSzPPGTlP_FkxHsT">https://x.com/esthercrawford/status/1850681223770947869</a></span></li></ul></td></tr></table><p class="c9"><span class="c1 c14"></span></p><h1 class="c123" id="h.pc1sxqg24482"><span class="c14">6. AI Can Code</span></h1><ul class="c0 lst-kix_by7qhqpvs1r5-0 start"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 486.67px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 486.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">o1-preview is weaker than the full o1 model</span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span class="c14">[Alphacode 2 beat 85% of competitive programming participants in Codeforce competitions](</span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/&amp;sa=D&amp;source=editors&amp;ust=1730413583735281&amp;usg=AOvVaw0Beui4P70LL84eFO2Mci49">https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-1"><li class="c10 li-bullet-0"><span class="c6 c40">Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it&rsquo;s STILL much better than those guys. </span></li><li class="c10 li-bullet-0"><span class="c6 c40">In the article, it says &ldquo;AlphaCode 2 can understand programming challenges involving &ldquo;complex&rdquo; math and theoretical computer science. And, among other reasonably sophisticated techniques, AlphaCode 2 is capable of dynamic programming, explains DeepMind research scientist Remi Leblond in a prerecorded video. Dynamic programming entails simplifying a complex problem by breaking it down into easier sub-problems over and over; Leblond says that AlphaCode 2 knows not only when to properly implement this strategy but where to use it. That&rsquo;s noteworthy, considering programming problems requiring dynamic programming were a major trip-up for the original AlphaCode. &ldquo;[AlphaCode 2] needs to show some level of understanding, some level of reasoning and designing of code solutions before it can get to the actual implementation to solve [a] coding problem,&rdquo; Leblond said. &ldquo;And it does all that on problems it&rsquo;s never seen before.&rdquo;</span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>OpenAI o1 model released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/&amp;sa=D&amp;source=editors&amp;ust=1730413583735811&amp;usg=AOvVaw2uCxgRy6WmsU6DV8yjn5PS">https://openai.com/index/learning-to-reason-with-llms/</a></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-1 start"><li class="c10 li-bullet-0"><span class="c1">o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).</span></li><li class="c10 li-bullet-0"><span class="c1">On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.</span></li><li class="c10 li-bullet-0"><span class="c1">We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.</span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-2 start"><li class="c7 li-bullet-0"><span class="c1">With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 &ndash; above the gold medal threshold &ndash; even without any test-time selection strategy. &nbsp;</span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-1"><li class="c10 li-bullet-0"><span>Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating</span><span class="c5 c107"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/%23citation-bottom-3&amp;sa=D&amp;source=editors&amp;ust=1730413583736316&amp;usg=AOvVaw11UmdVoSL0bVS8-GAE0AZ-">3</a></span><span class="c1">&nbsp;of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1&mdash;it achieved an Elo rating of 1807, performing better than 93% of competitors.</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583736523&amp;usg=AOvVaw3cH6b29_hwURhPJUjNKCwp">https://cdn.openai.com/o1-system-card.pdf</a></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-2 start"><li class="c7 li-bullet-0"><span class="c1">&nbsp;We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn&rsquo;t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the &ldquo;Unknown&rdquo; option (ambiguous questions). This is not necessarily an indicator of o1-preview&rsquo;s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 555.50px; height: 82.79px;"><img alt="" src="images/image1.png" style="width: 555.50px; height: 82.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.50px; height: 98.99px;"><img alt="" src="images/image288.png" style="width: 551.50px; height: 98.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 556.75px; height: 348.86px;"><img alt="" src="images/image344.png" style="width: 556.75px; height: 348.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.49px; height: 341.22px;"><img alt="" src="images/image116.png" style="width: 554.49px; height: 341.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 580.86px; height: 491.50px;"><img alt="" src="images/image95.png" style="width: 580.86px; height: 491.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.50px; height: 207.65px;"><img alt="" src="images/image206.png" style="width: 558.50px; height: 207.65px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 543.51px; height: 408.50px;"><img alt="" src="images/image286.png" style="width: 543.51px; height: 408.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.82px; height: 313.86px;"><img alt="" src="images/image203.png" style="width: 554.82px; height: 313.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 575.50px; height: 506.53px;"><img alt="" src="images/image88.png" style="width: 575.50px; height: 506.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-2 start"><li class="c7 li-bullet-0"><span>Code generated by o1 for this: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://codeforces.com/blog/entry/134091&amp;sa=D&amp;source=editors&amp;ust=1730413583737731&amp;usg=AOvVaw0eDwBuR_c_QnSBhfI4Cihd">https://codeforces.com/blog/entry/134091</a></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image163.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 605.33px;"><img alt="" src="images/image183.png" style="width: 624.00px; height: 605.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 657.33px;"><img alt="" src="images/image224.png" style="width: 624.00px; height: 657.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 730.67px;"><img alt="" src="images/image66.png" style="width: 624.00px; height: 730.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 494.67px;"><img alt="" src="images/image134.png" style="width: 624.00px; height: 494.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1169.33px;"><img alt="" src="images/image78.png" style="width: 624.00px; height: 1169.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1188.00px;"><img alt="" src="images/image73.png" style="width: 624.00px; height: 1188.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 421.33px;"><img alt="" src="images/image196.png" style="width: 624.00px; height: 421.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-2 start"><li class="c7 li-bullet-0"><span>NOTE: this graph does not include the full base o1 model</span></li></ul><p class="c9"><span class="c92 c37 c14 c76 c98 c75"></span></p><p class="c9"><span class="c92 c37 c14 c76 c98 c75"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c22 c32 c14 li-bullet-0"><span>Nvidia CEO says don&rsquo;t learn coding because of AI, tech giant exec says jobs will be hit: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.indiatoday.in/technology/features/story/nvidia-ceo-says-dont-learn-coding-because-ai-tech-giant-exec-says-jobs-will-be-hit-story-in-5-points-2509126-2024-03-01&amp;sa=D&amp;source=editors&amp;ust=1730413583738878&amp;usg=AOvVaw23xAmYK-DCHEvcLA0e3O9p">https://www.indiatoday.in/technology/features/story/nvidia-ceo-says-dont-learn-coding-because-ai-tech-giant-exec-says-jobs-will-be-hit-story-in-5-points-2509126-2024-03-01</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-1"><li class="c22 c72 c14 li-bullet-0"><span class="c1">Lying about this goes against his interest as discouraging coders would make them harder to find and more expensive to employ due to a lower supply. It would be a very stupid and short-sighted way of generating hype for the sake of hype when there are many other ways to do it that would not increase long-term costs for his company. </span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>DeepSeek-Coder-V2: First Open Source Model Beats GPT4-Turbo in Coding and Math: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583739446&amp;usg=AOvVaw3CMuZsrj8z6fwjuyL8zbNG">https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf</a></span></li></ul><p class="c21"><span class="c1">&nbsp;</span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>AI makes code refactoring much faster: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/&amp;sa=D&amp;source=editors&amp;ust=1730413583739823&amp;usg=AOvVaw3yu9GGD4XAC_spY0L0KznJ">https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 614.67px;"><img alt="" src="images/image592.png" style="width: 624.00px; height: 614.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8&amp;sa=D&amp;source=editors&amp;ust=1730413583740303&amp;usg=AOvVaw3024WdkrxCozNtAf1cDP9C">https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-1"><li class="c10 li-bullet-0"><span class="c1">This isn&rsquo;t marketing hype since the recording was not meant to be public.</span></li><li class="c10 li-bullet-0"><span class="c1">Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry </span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>ChatGPT o1 preview + mini Wrote NASA researcher&rsquo;s PhD Code in 1 Hour*&mdash;What Took Me ~1 Year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fhi59o/chatgpt_o1_preview_mini_wrote_my_phd_code_in_1/&amp;sa=D&amp;source=editors&amp;ust=1730413583740879&amp;usg=AOvVaw1V24j0A-mwNzPefeRWSJ6d">https://www.reddit.com/r/singularity/comments/1fhi59o/chatgpt_o1_preview_mini_wrote_my_phd_code_in_1/</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-1"><li class="c10 li-bullet-0"><span class="c1">It completed it in 6 shots with no external feedback for some very complicated code from very obscure Python directories</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027&amp;sa=D&amp;source=editors&amp;ust=1730413583741454&amp;usg=AOvVaw0l1wL3Dh1OnG8GgtU2YBna">https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027</a></span></li></ul><ul class="c0 lst-kix_by7qhqpvs1r5-1 start"><li class="c10 li-bullet-0"><span class="c1">Short Term:</span></li></ul><ul class="c0 lst-kix_w9nfenze7id7-0"><li class="c7 li-bullet-0"><span class="c1">AI tools will slightly increase productivity by helping with tasks.</span></li><li class="c7 li-bullet-0"><span class="c1">Senior developers in well-run companies will benefit the most from these tools.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kviltkqr3kxc-0"><li class="c10 li-bullet-0"><span class="c1">Medium Term:</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_kviltkqr3kxc-1"><li class="c7 li-bullet-0"><span class="c1">AI agents will change how developers work by automating more tasks.</span></li><li class="c7 li-bullet-0"><span class="c1">Most code will be made by AI, not humans.</span></li><li class="c7 li-bullet-0"><span class="c1">Developers need to learn new skills like prompt engineering and RAG.</span></li></ul><ul class="c0 lst-kix_kviltkqr3kxc-0"><li class="c10 li-bullet-0"><span class="c1">Long Term:</span></li></ul><ul class="c0 lst-kix_hw08zzin6mm8-0"><li class="c7 li-bullet-0"><span class="c1">More skilled software engineers are needed because of the growing demand for AI-powered software.</span></li><li class="c7 li-bullet-0"><span class="c1">A new type of engineer, called an AI engineer, who knows about software, data science, and AI/ML will be very important</span></li></ul><ul class="c0 lst-kix_gxvgspx76nqx-0 start"><li class="c4 li-bullet-0"><span>ACM writer who has been in CS since the 1980s predicts AI will make programmers obsolete: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cacm.acm.org/opinion/the-end-of-programming/&amp;sa=D&amp;source=editors&amp;ust=1730413583742176&amp;usg=AOvVaw1KXC2ZobQsxbwCAh6-_eBk">https://cacm.acm.org/opinion/the-end-of-programming</a></span></li></ul><h2 class="c22 c80 c14" id="h.jy39d6h3mvgi"><span class="c40 c37 c48 c75">6.1. Practical Use/Software Engineering</span></h2><ul class="c0 lst-kix_cpaf1rpc28c-0 start"><li class="c4 li-bullet-0"><span>Sundar Pichai said on the earnings call today that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/&amp;sa=D&amp;source=editors&amp;ust=1730413583742619&amp;usg=AOvVaw3s5x_4HRYy7bfw7-HDzwp2">https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-1 start"><li class="c10 li-bullet-0"><span class="c1">Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said &ldquo;a large percentage&rdquo; instead of a specific and verifiable number.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c4 li-bullet-0"><span>LLM skeptic Internet of B</span><span>ugs says ChatGPT-O1 Changes Programming as a Profession: &ldquo;I really hated saying that&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Dj0yKLumIbaM&amp;sa=D&amp;source=editors&amp;ust=1730413583743288&amp;usg=AOvVaw3pRDmnonG6mRPRRUI1PYx4">https://youtube.com/watch?v=j0yKLumIbaM</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c4 li-bullet-0"><span>OpenAI&rsquo;s o1 model can get perfect scores on their research engineer interview coding questions: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://assets.ctfassets.net/kftzwdyauwt9/67qJD51Aur3eIc96iOfeOP/71551c3d223cd97e591aa89567306912/o1_system_card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583743629&amp;usg=AOvVaw2rsxWQfkxhZ-lcI9V84Xz3">https://assets.ctfassets.net/kftzwdyauwt9/67qJD51Aur3eIc96iOfeOP/71551c3d223cd97e591aa89567306912/o1_system_card.pdf</a></span></li></ul><ul class="c0 lst-kix_cpaf1rpc28c-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 882.67px;"><img alt="" src="images/image368.png" style="width: 624.00px; height: 882.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c4 li-bullet-0"><span>R</span><span>andomized controlled trial using the older, less-powerful GPT-3.5 powered Github Copilot for 4,867 coders in Fortune 100 firms. It finds a 26.08% increase in completed tasks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emollick/status/1831739827773174218&amp;sa=D&amp;source=editors&amp;ust=1730413583744047&amp;usg=AOvVaw1GvEvXfPO5vvmXJeZXwYEr">https://x.com/emollick/status/1831739827773174218</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c4 li-bullet-0"><span>AI Dominates Web Development: 63% of Developers Use AI Tools Like ChatGPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://flatlogic.com/starting-web-app-in-2024-research&amp;sa=D&amp;source=editors&amp;ust=1730413583744380&amp;usg=AOvVaw2KBwQiNyOvzxjrJrqot0xD">https://flatlogic.com/starting-web-app-in-2024-research</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c4 li-bullet-0"><span class="c37 c14 c76 c98 c75">NYT article on ChatGPT:</span><span class="c37 c14 c76 c98 c75"><a class="c13" href="https://www.google.com/url?q=https://archive.is/hy3Ae&amp;sa=D&amp;source=editors&amp;ust=1730413583744707&amp;usg=AOvVaw0QHVR8jslF3yMpAOFlYWSk">&nbsp;</a></span><span class="c5 c37 c14 c76 c75"><a class="c13" href="https://www.google.com/url?q=https://archive.is/hy3Ae&amp;sa=D&amp;source=editors&amp;ust=1730413583744828&amp;usg=AOvVaw1Ckv1wfFVA5JBfyjPi0Efo">https://archive.is/hy3Ae</a></span></li></ul><p class="c9 c93"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-1 start"><li class="c10 li-bullet-0"><span class="c37 c14 c76 c98 c75">&ldquo;In a trial run by GitHub&rsquo;s researchers, developers given an entry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than those who did the assignment manually.&rdquo;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c4 li-bullet-0"><span class="c1">What percent of code is now written by AI? &quot;I ask all the software companies I meet about this. The number is rarely lower than 40%. For some young programmers it&#39;s 90%.&quot; - Paul Graham of Y Combinator on Twitter</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c4 c144 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 961.33px;"><img alt="" src="images/image64.png" style="width: 624.00px; height: 961.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_cpaf1rpc28c-1 start"><li class="c10 li-bullet-0"><span class="c1">Not as good as the Opus model they said is coming out later this year </span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">80% lower cost than Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">2x speed over Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">decent math and coding jump. 10% better on MATH 9% better on GPQA</span></li><li class="c10 li-bullet-0"><span class="c15 c65 c60">Can convert research paper descriptions to code: </span><span class="c5 c15 c65 c114"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1803816296410190286&amp;sa=D&amp;source=editors&amp;ust=1730413583745797&amp;usg=AOvVaw335ONto6G9jd3jSCIKF_Mv">https://x.com/VictorTaelin/status/1803816296410190286</a></span></li></ul><ul class="c0 lst-kix_cpaf1rpc28c-2 start"><li class="c73 c86 li-bullet-0"><span class="c1">Yves does NOT explain how to implement the system at all, he just defines it in mathematical terms. By all means, ICs aren&#39;t hard to implement, but understanding what the paper is saying without images is tough. The best models so far always outputted 100% bullshit code. I just tested again and Opus/GPT-4 outputs are always just gibberish. Sonnet 3.5 did surprisingly well</span></li></ul><ul class="c0 lst-kix_cpaf1rpc28c-1"><li class="c10 li-bullet-0"><span>Claude 3.5 Sonnet is at the top of the Aider leaderboard at 77.4% correct: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://aider.chat/docs/leaderboards/&amp;sa=D&amp;source=editors&amp;ust=1730413583746099&amp;usg=AOvVaw0wTI7Es1EZOV0b1mxIKOhG">https://aider.chat/docs/leaderboards/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 355.14px; height: 400.49px;"><img alt="" src="images/image260.png" style="width: 355.14px; height: 400.49px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c45 li-bullet-0"><span class="c15">ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.00176&amp;sa=D&amp;source=editors&amp;ust=1730413583746550&amp;usg=AOvVaw05dkGE86OvwSxIitfiTCyJ">https://arxiv.org/pdf/2311.00176</a></span><span class="c33 c15">&nbsp;</span></li></ul><p class="c73 c46 c129"><span class="c6 c40"></span></p><ul class="c0 lst-kix_cpaf1rpc28c-0"><li class="c45 li-bullet-0"><span class="c6">BP Earnings Call: We need </span><span class="c15 c65 c60">70% less coders </span><span class="c6 c40">from third parties to code as the AI handles most of the coding, the human only needs to look at the final 30% to validate it, that&#39;s a big savings for the company moving forward.</span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_srn1fozfk9nn-0 start"><li class="c59 li-bullet-0"><span class="c6">Source: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript&amp;sa=D&amp;source=editors&amp;ust=1730413583746988&amp;usg=AOvVaw3AR15W7VnDPJ7OVYZnRAG2">https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript</a></span><span class="c6 c40">&nbsp;</span></li></ul><p class="c73 c46 c129"><span class="c6 c40"></span></p><ul class="c0 lst-kix_srn1fozfk9nn-0"><li class="c59 li-bullet-0"><span class="c6">This is almost certainly true because this is quoted from an earnings call from BP and lying to investors is a crime (securities fraud) and the reason for the Theranos scandal. This would include lying about the reason (in other words, it can&rsquo;t just be layoffs). The numbers that are provided are also too specific to be exaggerations without also being a lie.</span></li></ul><p class="c22 c44 c14"><span class="c92 c37 c14 c76 c98 c75"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0 start"><li class="c22 c32 c14 li-bullet-0"><span>The best performing agent on the SWEBench Verified leaderboard was created in August with a 49% solve rate as of October 2024, indicating that improvements are currently being made: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.swebench.com/&amp;sa=D&amp;source=editors&amp;ust=1730413583747449&amp;usg=AOvVaw3NCOglxIagpVqJ1ZqXeBXp">https://www.swebench.com/</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-1"><li class="c22 c72 c14 li-bullet-0"><span class="c1">In October 2023 (about 1 year ago), the highest scoring one on SWEBench Verified got only 4.4%</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-1"><li class="c22 c72 c14 li-bullet-0"><span>Can be improved with many samples (it&rsquo;s currently pass or fail in one try, almost no human can do this): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.21787&amp;sa=D&amp;source=editors&amp;ust=1730413583747886&amp;usg=AOvVaw2bLKleeeG0F65X7STJChoa">https://arxiv.org/abs/2407.21787</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-2 start"><li class="c22 c104 c86 c14 li-bullet-0"><span class="c3">When we apply repeated sampling to SWE-bench Lite, the fraction of issues solved with DeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250 samples, outperforming the single-attempt state-of-the-art of 43% which uses more capable frontier models. Moreover, using current API pricing, amplifying the cheaper DeepSeek model with five samples is more cost-effective and solves more issues than paying a premium for one sample from GPT-4o or Claude 3.5 Sonnet. Interestingly, the relationship between coverage and the number of samples is often log-linear and can be modeled with an exponentiated power law, suggesting the existence of inference-time scaling laws. </span></li><li class="c22 c104 c86 c14 li-bullet-0"><span class="c3">When solving math word problems from GSM8K and MATH, coverage with Llama-3 models grows to over 95% with 10,000 samples.</span></li></ul><p class="c22 c44 c14"><span class="c3"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-1"><li class="c10 li-bullet-0"><span>For reference, an </span><span>OpenAI tester completed 38.8% of them within 15 mins and 52.2% of them within 1 hour. So basically Claude is slightly worse than the average python dev that OpenAI hired as a contractor (they would need to pass at least one round of the OpenAI hiring assessment) when the contractor is given 1 hour per problem </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/introducing-swe-bench-verified/&amp;sa=D&amp;source=editors&amp;ust=1730413583748529&amp;usg=AOvVaw2Q_eiBS0xLi4sbSRpvJdXX">https://openai.com/index/introducing-swe-bench-verified/</a></span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-2"><li class="c7 li-bullet-0"><span class="c1">Plus, LLMs can work 24/7 so time isn&rsquo;t really an issue </span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0"><li class="c4 li-bullet-0"><span>Multimodal terminal-based AI coding engine: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPTCoding/comments/1ddhv50/the_terminalbased_ai_coding_engine_i_built_is_now/&amp;sa=D&amp;source=editors&amp;ust=1730413583749073&amp;usg=AOvVaw0oXavoWZKLmkRaUK_4ygeG">https://www.reddit.com/r/ChatGPTCoding/comments/1ddhv50/the_terminalbased_ai_coding_engine_i_built_is_now/</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-1"><li class="c10 li-bullet-0"><span class="c1">Can build a whole web app based on just a wireframe image </span></li><li class="c10 li-bullet-0"><span class="c1">Plandex is agent-based so it can keep chugging along automatically through multiple responses and files. Even if the app required like 20 files, Plandex would keep going until it finished them all. With ChatGPT you&#39;d need to keep continually prompting it.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0"><li class="c4 li-bullet-0"><span>Dir-assistant: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/curvedinf/dir-assistant&amp;sa=D&amp;source=editors&amp;ust=1730413583749728&amp;usg=AOvVaw3d7VfWkDV7HxbUXES0kiuE">https://github.com/curvedinf/dir-assistant</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Chat with your current directory&#39;s files using a local or API LLM.</span></li><li class="c10 li-bullet-0"><span class="c1">allows an LLM to be aware of a whole large repo. It can do all the research on a repository&#39;s code and write highly integrated additions with no user input</span></li><li class="c10 li-bullet-0"><span>Uses CGRAG for large repos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://medium.com/@djangoist/how-to-create-accurate-llm-responses-on-large-code-repositories-presenting-cgrag-a-new-feature-of-e77c0ffe432d&amp;sa=D&amp;source=editors&amp;ust=1730413583750193&amp;usg=AOvVaw1jqp1tkS278Q1OqDIfWXUl">https://medium.com/@djangoist/how-to-create-accurate-llm-responses-on-large-code-repositories-presenting-cgrag-a-new-feature-of-e77c0ffe432d</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_srn1fozfk9nn-0"><li class="c4 li-bullet-0"><span class="c14">Microsoft AutoDev:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.08299&amp;sa=D&amp;source=editors&amp;ust=1730413583750543&amp;usg=AOvVaw1hcOGETfl5PKJ0Vz8-TMX8">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.08299&amp;sa=D&amp;source=editors&amp;ust=1730413583750690&amp;usg=AOvVaw3eCKX7oF_1Z0KElsNHwe-M">https://arxiv.org/pdf/2403.08299</a></span></li></ul><p class="c9 c93"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_npq7lfz9ly6z-0 start"><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;We tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c92 c37 c14 c76 c98 c75"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0"><li class="c4 li-bullet-0"><span>AI-powered coding with cursor: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f1wrq1/mckay_wrigley_shows_off_aipowered_coding_with/&amp;sa=D&amp;source=editors&amp;ust=1730413583751244&amp;usg=AOvVaw2ewdbyzVXegef72WDmAoJ8">https://www.reddit.com/r/singularity/comments/1f1wrq1/mckay_wrigley_shows_off_aipowered_coding_with/</a></span></li></ul><p class="c9"><span class="c92 c37 c14 c76 c98 c75"></span></p><ul class="c0 lst-kix_dii13kfyl9ma-0 start"><li class="c159 c78 li-bullet-0"><span>Microsoft announces up to 1,500 layoffs, leaked memo blames &#39;AI wave&#39; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave&amp;sa=D&amp;source=editors&amp;ust=1730413583751562&amp;usg=AOvVaw3KHFh8zN6v9_PL78AMp_WQ">https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave</a></span></li></ul><p class="c159 c46"><span class="c1"></span></p><ul class="c0 lst-kix_dii13kfyl9ma-1 start"><li class="c159 c97 c105 li-bullet-0"><span class="c1">This isn&rsquo;t a PR move since the memo was not supposed to be publicized.</span></li></ul><p class="c159 c46"><span class="c1"></span></p><ul class="c0 lst-kix_dii13kfyl9ma-0"><li class="c159 c78 li-bullet-0"><span>o1 is very good at refactoring: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/OpenAI/comments/1fqmkbm/o1_is_extremely_good_for_refactoring_complex_code/&amp;sa=D&amp;source=editors&amp;ust=1730413583752043&amp;usg=AOvVaw2SqGI_vLrFvPWRuNLGnbgk">https://www.reddit.com/r/OpenAI/comments/1fqmkbm/o1_is_extremely_good_for_refactoring_complex_code/</a></span></li></ul><p class="c159 c46"><span class="c1"></span></p><ul class="c0 lst-kix_dii13kfyl9ma-1"><li class="c159 c97 c105 li-bullet-0"><span>Top comment: </span><span class="c1">This thing is actually semi-capable of writing 6507 assembly code and macros for programming Atari 2600 games. It&#39;s kind of ridiculous. Not perfect at all, but WAY better than previous models. This kind of stuff is my ultimate &quot;litmus test&quot; for programming.</span></li></ul><ul class="c0 lst-kix_dii13kfyl9ma-2 start"><li class="c7 li-bullet-0"><span class="c1">There can&#39;t be that much 6507 assembly out there, ergo it has to be translating, inferring and creating rather a lot to succeed. Then there&#39;s the impracticality of coding for such heavily limited hardware that has to bit-bang the display output!</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_dii13kfyl9ma-0"><li class="c4 li-bullet-0"><span>OpenAI&#39;s Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests, and Noam Brown says everyone will know AGI has been achieved internally when they take down all their job listings: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/&amp;sa=D&amp;source=editors&amp;ust=1730413583752919&amp;usg=AOvVaw1wJ6AGtaPvAmbywqrewxXe">https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/</a></span></li></ul><h2 class="c22 c80 c14" id="h.pd0ali6qd6d1"><span class="c40 c37 c48 c75">6.2. Research</span></h2><ul class="c0 lst-kix_vexpnyyatkbq-0 start"><li class="c4 li-bullet-0"><span class="c225">ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.00176&amp;sa=D&amp;source=editors&amp;ust=1730413583753362&amp;usg=AOvVaw2hKgw4LzAM7tkp6W39KJnD">https://arxiv.org/pdf/2311.00176</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3613904.3642596&amp;sa=D&amp;source=editors&amp;ust=1730413583753614&amp;usg=AOvVaw1yTcWiiCGFYeB1uGQ6N0_c">Study that ChatGPT supposedly fails 52% of coding tasks</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3613904.3642596&amp;sa=D&amp;source=editors&amp;ust=1730413583753759&amp;usg=AOvVaw37v2zAYT_I8IdhbYPLuT90">https://dl.acm.org/doi/pdf/10.1145/3613904.3642596</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-1 start"><li class="c10 li-bullet-0"><span class="c14">&ldquo;this work has used the </span><span class="c34 c14">free version of ChatGPT (GPT-3.5)</span><span class="c1 c14">&nbsp;for acquiring the ChatGPT responses for the manual analysis.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c14">&ldquo;Thus, we chose to </span><span class="c34 c14">only consider the initial answer </span><span class="c1 c14">generated by ChatGPT.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected [StackOverflow] questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-2 start"><li class="c7 li-bullet-0"><span class="c14">This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to</span><span class="c15">&nbsp;~77% for GPT 4</span><span class="c1">&nbsp;(equal to (517 times 0.48+517 times 6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-3 start"><li class="c21 c26 li-bullet-0"><span>Note: This was all done in</span><span class="c33 c15">&nbsp;ONE SHOT with no repeat attempts or follow up.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_3mbe6pf0vyok-0 start"><li class="c22 c72 c14 li-bullet-0"><span class="c14">Also, the study was released </span><span class="c15">before GPT-4o and o1 </span><span>and </span><span class="c34">may not have used GPT-4-Turbo</span><span>, both of which are significantly higher quality in coding capacity than GPT 4 according to the </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://chat.lmsys.org/?leaderboard&amp;sa=D&amp;source=editors&amp;ust=1730413583754731&amp;usg=AOvVaw0CQNxtyZWe3DvecBk04e_q">LMSYS arena</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_3mbe6pf0vyok-1 start"><li class="c22 c104 c86 c14 li-bullet-0"><span>On top of that, both of those models are inferior to Claude 3.5 Sonnet: </span><span>&quot;In an </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583755060&amp;usg=AOvVaw34r8nVx47lBPzjdWTNBwlB">internal agentic coding evaluation</a></span><span>, </span><span class="c15">Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%.</span><span class="c1">&quot; Claude 3.5 Opus (which will be even better than Sonnet) is set to be released later this year.</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_fktfq9ltsq98-0 start"><li class="c22 c32 c14 li-bullet-0"><span>New strategy to write code with LLMs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2310.19791v4%23Pt1&amp;sa=D&amp;source=editors&amp;ust=1730413583755398&amp;usg=AOvVaw3I92xep1okzRYj-szLZidp">https://arxiv.org/html/2310.19791v4#Pt1</a></span><span class="c1">&nbsp;</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_x87etp2vfva3-0 start"><li class="c22 c72 c14 li-bullet-0"><span>While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce Lilo, a neurosymbolic framework that</span><span class="c34">&nbsp;iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains</span><span>. Lilo combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal &#120582;-abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that </span><span class="c34">infers natural language names and docstrings based on contextual examples of usage</span><span>. In addition to improving human readability, we find that AutoDoc</span><span class="c34">&nbsp;boosts performance by helping Lilo&rsquo;s synthesizer to interpret and deploy learned abstractions</span><span>. We evaluate Lilo on three inductive program synthesis benchmarks for string editing, scene reasoning, and graphics composition. Compared to existing methods&mdash;including the state-of-the-art libraries learning algorithm DreamCoder&mdash;</span><span class="c33 c34">Lilo solves more complex tasks and learns richer libraries that are grounded in linguistic knowledge.</span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-1 start"><li class="c22 c86 c14 c104 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 328.00px;"><img alt="" src="images/image283.png" style="width: 624.00px; height: 328.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c104 c86 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 353.33px;"><img alt="" src="images/image473.png" style="width: 624.00px; height: 353.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c44 c14"><span class="c33 c34"></span></p><ul class="c0 lst-kix_3mbe6pf0vyok-0"><li class="c22 c72 c14 li-bullet-0"><span>Diffusion models for code generation that learn to directly *edit* syntax trees of programs. The result is a system that can incrementally write code, see the execution output, and debug it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/shreyaskapur/status/1797726079995826629&amp;sa=D&amp;source=editors&amp;ust=1730413583756151&amp;usg=AOvVaw3yrfCBOjwUdibZcjt9J31X">https://x.com/shreyaskapur/status/1797726079995826629</a></span><span class="c1">&nbsp;</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_8979tijdi163-0 start"><li class="c4 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.09308&amp;sa=D&amp;source=editors&amp;ust=1730413583756398&amp;usg=AOvVaw1X4ObVOfPLhqluH2qUrdHz">https://arxiv.org/pdf/2406.09308</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_8979tijdi163-1 start"><li class="c10 li-bullet-0"><span class="c14">Such NARs proved effective as generic solvers for algorithmic tasks, when specified in graph form. To make their embeddings accessible to a Transformer, we propose a hybrid architecture with a two- phase training procedure, allowing the tokens in the lan- guage model to cross-attend to the node embeddings from the NAR. We evaluate our resulting TransNAR model on CLRS-Text, the text-based version of the CLRS-30 bench- mark, and</span><span class="c33 c15">&nbsp;demonstrate significant gains over Transformer- only models for algorithmic reasoning, both in and out of distribution.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 561.00px;"><img alt="" src="images/image426.png" style="width: 624.00px; height: 561.00px; margin-left: -24.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_8979tijdi163-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.15568&amp;sa=D&amp;source=editors&amp;ust=1730413583756889&amp;usg=AOvVaw1oIgDSsqbUk3c9iPwhzLjD">https://arxiv.org/pdf/2405.15568</a></span></li></ul><ul class="c0 lst-kix_8979tijdi163-1 start"><li class="c10 li-bullet-0"><span>OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent&rsquo;s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents&rsquo; learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: https://dub.sh/omniepic.</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><h2 class="c22 c80 c14" id="h.ulp09litl7eq"><span class="c40 c37 c48 c75">6.3. Feats</span></h2><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>I got an LLM to write frontend and backend code for a graph visualizer, fix its own bug and literally deploy it to the public web with google cloud. This would take most devs 2 days. It took AI ~20mins: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/deedydas/status/1850024012677775829&amp;sa=D&amp;source=editors&amp;ust=1730413583757637&amp;usg=AOvVaw1p-g1Z7fjskV-AoaamSTlW">https://x.com/deedydas/status/1850024012677775829</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span class="c14">[GPT4o creates Flappy Bird in a single simple prompt](</span><span class="c55 c202 c244">https://x.com/minchoi/status/1787836907566531056)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span class="c14">[Claude 3 builds a great website](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/OpenAI/comments/1bm305k/what_the_hell_claud_3_opus_is_a_straight/?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583758094&amp;usg=AOvVaw0yAXZq-OZTy3RIflNHnQUM">https://www.reddit.com/r/OpenAI/comments/1bm305k/what_the_hell_claud_3_opus_is_a_straight/?darkschemeovr=1</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2grrmxr8q0i0-0 start"><li class="c4 li-bullet-0"><span class="c1 c14">Claude 3 Creates a Multi-Player Application with a Single Prompt: https://www.reddit.com/r/singularity/comments/1b8f5q3/claude_3_creates_a_multiplayer_application_with_a/</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span class="c14">Claude 3 is great at programming: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1coszok/comment/l3h0s1v/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583758758&amp;usg=AOvVaw02pz79s6XyO1-0kabeNjwk">https://www.reddit.com/r/singularity/comments/1coszok/comment/l3h0s1v/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c22 c32 c14 li-bullet-0"><span>GPT 4o recreates Facebook messenger in a single prompt: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/GPNq0WiXa50?feature%3Dshared%26t%3D927&amp;sa=D&amp;source=editors&amp;ust=1730413583759129&amp;usg=AOvVaw18D4109llc5Ti9xW8qb-rR">https://youtu.be/GPNq0WiXa50?feature=shared&amp;t=927</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c22 c32 c14 li-bullet-0"><span class="c14">GPT-4o is the best LLM for coding and solves 73% of Aider&rsquo;s code editing benchmark: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://aider.chat/docs/leaderboards/&amp;sa=D&amp;source=editors&amp;ust=1730413583759536&amp;usg=AOvVaw15Y-sNnPk0UjM8srCrzHL9">https://aider.chat/docs/leaderboards/</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c22 c32 c14 li-bullet-0"><span>Claude 3.5 creates Nintendo style retro game: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dkp6uf/claude_35_can_generate_early_nintendo_style_games/&amp;sa=D&amp;source=editors&amp;ust=1730413583759942&amp;usg=AOvVaw28KPHZyIkPU1ro4IdpLP-H">https://www.reddit.com/r/singularity/comments/1dkp6uf/claude_35_can_generate_early_nintendo_style_games/</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>Claude 3.5&#39;s sonnet created a fully working checkers game in the chat interface. It even had AI to play against: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1dmlgrm/claude_35s_sonnet_created_a_fully_working/&amp;sa=D&amp;source=editors&amp;ust=1730413583760285&amp;usg=AOvVaw03ISU4vz6FSwayedOfWpr0">https://www.reddit.com/r/ChatGPT/comments/1dmlgrm/claude_35s_sonnet_created_a_fully_working/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>Claude made me a 3D first-person shooter touchscreen game right in the chat interface. In the game, you shoot happy emojis at sad monsters to make them happy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1dmejz5/claude_made_me_a_3d_firstperson_shooter/&amp;sa=D&amp;source=editors&amp;ust=1730413583760631&amp;usg=AOvVaw1V-iUa9PxutRSeJCV4YB9J">https://www.reddit.com/r/ChatGPT/comments/1dmejz5/claude_made_me_a_3d_firstperson_shooter/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>Claude created a fractal explorer for me in which I can display and zoom 4 different fractals: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dn85qz/claude_created_a_fractal_explorer_for_me_in_which/&amp;sa=D&amp;source=editors&amp;ust=1730413583760992&amp;usg=AOvVaw0-bcNKg49J98lFZ3on654X">https://www.reddit.com/r/singularity/comments/1dn85qz/claude_created_a_fractal_explorer_for_me_in_which/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_by7qhqpvs1r5-0"><li class="c4 li-bullet-0"><span>Claude creates a complex 3D solar system animation based on a text prompt in under a minute: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/slow_developer/status/1813839430043725900&amp;sa=D&amp;source=editors&amp;ust=1730413583761327&amp;usg=AOvVaw0XUy2HseoCVjvMrvD1B-F9">https://x.com/slow_developer/status/1813839430043725900</a></span></li></ul><h1 class="c140 c199" id="h.drp52fkp5u5g"><span class="c14">7. </span><span class="c40 c37 c48 c77 c14">AI Is Not Low Effort</span></h1><ul class="c0 lst-kix_4cx6uiey4qy0-0 start"><li class="c4 li-bullet-0"><span class="c15">Incredible use of Stable Diffusion: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q&amp;sa=D&amp;source=editors&amp;ust=1730413583761665&amp;usg=AOvVaw2aDwRuKrTs_IsedJlI4uuo">https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q</a></span></li><li class="c4 li-bullet-0"><span class="c14">Using Midjourney is more than simple prompting: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1812977740783755581&amp;sa=D&amp;source=editors&amp;ust=1730413583761876&amp;usg=AOvVaw192EyKTA8Nz60LKL8FeVFO">https://x.com/nickfloats/status/1812977740783755581</a></span></li></ul><ul class="c0 lst-kix_4cx6uiey4qy0-1 start"><li class="c10 li-bullet-0"><span class="c14">From this: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 349.33px;"><img alt="" src="images/image441.png" style="width: 624.00px; height: 349.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c14">To this: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 509.26px; height: 509.26px;"><img alt="" src="images/image380.png" style="width: 509.26px; height: 509.26px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_4cx6uiey4qy0-0"><li class="c4 li-bullet-0"><span class="c14">AI art is very similar to photography. Both can be as simple as clicking a button or be much more complex. For example, creating with Stable Diffusion can involve using </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/lllyasviel/ControlNet&amp;sa=D&amp;source=editors&amp;ust=1730413583762269&amp;usg=AOvVaw36VJbOdcyI4SgeRPQIrJaW">ControlNet</a></span><span class="c14">, </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/tencent-ailab/IP-Adapter&amp;sa=D&amp;source=editors&amp;ust=1730413583762407&amp;usg=AOvVaw1NIoKx32B1mTqWbLoJALGV">IPAdapter</a></span><span class="c14">, </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/221845/lowra-offset-noise&amp;sa=D&amp;source=editors&amp;ust=1730413583762601&amp;usg=AOvVaw3OkrSu1iLZC6yQbLSBPpw5">LowRa</a></span><span class="c14">,</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/lllyasviel/IC-Light&amp;sa=D&amp;source=editors&amp;ust=1730413583762760&amp;usg=AOvVaw0_PrrHYji-_zZx_OCRHdJE">&nbsp;IC-Light</a></span><span class="c1 c14">, animation extensions, very complicated ComfyUI workflows, and much more to get the result you want. Additionally, both involve a machine doing most of the actual creation process, where the camera/AI creates the images, while the artist guides it on what the end result should be and completes post-processing work. </span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/33192/comfyui-impact-pack&amp;sa=D&amp;source=editors&amp;ust=1730413583762979&amp;usg=AOvVaw3Aj0F83xZasFBQS88IWREG">Examples of complex ComfyUI workflows</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/33192/comfyui-impact-pack&amp;sa=D&amp;source=editors&amp;ust=1730413583763122&amp;usg=AOvVaw1ELu3SRgVZt1e_p5EGATqN">https://civitai.com/models/33192/comfyui-impact-pack</a></span><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ul><ul class="c0 lst-kix_4cx6uiey4qy0-1 start"><li class="c10 li-bullet-0"><span>Many more examples: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openart.ai/workflows/all&amp;sa=D&amp;source=editors&amp;ust=1730413583763366&amp;usg=AOvVaw1PWuRd8ID9gUgqL3ZUKlek">https://openart.ai/workflows/all</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 369.33px;"><img alt="" src="images/image322.png" style="width: 624.00px; height: 369.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_4cx6uiey4qy0-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openart.ai/workflows/datou/manga-cosplay/SgsFFSuOeFe7Qzs3eHij&amp;sa=D&amp;source=editors&amp;ust=1730413583763655&amp;usg=AOvVaw08EUyd9G4_Efxta9q7MHxx">https://openart.ai/workflows/datou/manga-cosplay/SgsFFSuOeFe7Qzs3eHij</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_4cx6uiey4qy0-1"><li class="c10 li-bullet-0"><span>pose changes based on video feed: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Mr_AllenT/status/1796890250695803187&amp;sa=D&amp;source=editors&amp;ust=1730413583763853&amp;usg=AOvVaw0k-p0h6JuKo2RnmZ1IgOnN">https://x.com/Mr_AllenT/status/1796890250695803187</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_4cx6uiey4qy0-0"><li class="c4 li-bullet-0"><span>Art is not about effort anyway,</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Fountain_(Duchamp)&amp;sa=D&amp;source=editors&amp;ust=1730413583764047&amp;usg=AOvVaw0PO6tmmZ5rrnV0U2rmScPr">&nbsp;Duchamp&rsquo;s fountain </a></span><span class="c1">took very little effort but is widely considered to be pivotal in art.</span></li><li class="c4 li-bullet-0"><span>Weird thing about using LLMs that it is very bad at a lot of things (including word games) but that you can actually often get it to do those things if you ask it the right away, usually by giving clearer instructions or asking AI to think step by step: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emollick/status/1795604532187263198&amp;sa=D&amp;source=editors&amp;ust=1730413583764311&amp;usg=AOvVaw3obGEA0maXLhfd2FJ39gWL">https://x.com/emollick/status/1795604532187263198</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_4cx6uiey4qy0-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583764594&amp;usg=AOvVaw1MZgEbNgUk8BcfNf64_dLO">AI image won Colorado state fair </a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413583764737&amp;usg=AOvVaw30eqL6NSiOSosorPUitW7n">https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_12ba2se2e37v-1 start"><li class="c10 li-bullet-0"><span class="c14">&gt;</span><span class="c35 c14">You can feed a phrase like </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/rachelmetz/status/1565780528384524288&amp;sa=D&amp;source=editors&amp;ust=1730413583765027&amp;usg=AOvVaw1AEkz-x9CvvEFJ5Kix3bfi">&ldquo;an oil painting of an angry strawberry&rdquo;</a></span><span class="c40 c37 c35 c48 c14">&nbsp;to Midjourney and receive several images from the AI system within seconds, but Allen&rsquo;s process wasn&rsquo;t that simple. To get the final three images he entered in the competition, he said, took more than 80 hours.</span></li><li class="c214 c97 c105 li-bullet-0"><span class="c35 c14">First, he said, he played around with phrasing that led Midjourney to generate images of women in frilly dresses and space helmets &mdash; he was trying to mash up Victorian-style costuming with space themes, he said. Over time, with many slight tweaks to his written prompt (such as to adjust lighting and color harmony), he created 900 iterations of what led to his final three images. He cleaned up those three images in Photoshop, such as by giving one of the female figures in his winning image a head with wavy, dark hair afterMidjourney had rendered her headless. Then he ran the images through another software program called Gigapixel AI that can improve resolution and had the images printed on canvas at a local print shop.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_4cx6uiey4qy0-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;Cal Duran, an artist and art teacher who was one of the judges for competition, said that while Allen&rsquo;s piece included a mention of Midjourney, he didn&rsquo;t realize that it was generated by AI when judging it. Still, he sticks by his decision to award it first place in its category, he said, calling it a &ldquo;beautiful piece&rdquo;.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_4cx6uiey4qy0-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;&ldquo;I think there&rsquo;s a lot involved in this piece and I think the AI technology may give more opportunities to people who may not find themselves artists in the conventional way,&rdquo; he said.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_4cx6uiey4qy0-0"><li class="c4 li-bullet-0"><span class="c14">Solar system simulation: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1fh5pqa/solar_system_htmljava_browser_animation_made/&amp;sa=D&amp;source=editors&amp;ust=1730413583765720&amp;usg=AOvVaw1KwwSVYFS7ffDD9mZ9Z0U9">https://www.reddit.com/r/ChatGPT/comments/1fh5pqa/solar_system_htmljava_browser_animation_made/</a></span></li></ul><h1 class="c140 c196" id="h.xqs5ma3uhpy2"><span class="c40 c37 c48 c77 c14"></span></h1><h1 class="c123" id="h.mx360pwg02ix"><span class="c14">8. AI Is Reliable/Addressing Hallucinations</span></h1><ul class="c0 lst-kix_2cqjr2ei92jl-0 start"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 539.18px; height: 721.50px;"><img alt="" src="images/image123.png" style="width: 539.18px; height: 721.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413583766350&amp;usg=AOvVaw062C9ogXR_jT5wQtqVaAlC">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span>OpenAI o1 model released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/&amp;sa=D&amp;source=editors&amp;ust=1730413583766636&amp;usg=AOvVaw2hrrrVpXJZSI2Cuh9ILueM">https://openai.com/index/learning-to-reason-with-llms/</a></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span class="c1">o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).</span></li><li class="c10 li-bullet-0"><span class="c1">On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 412.27px; height: 343.95px;"><img alt="" src="images/image326.png" style="width: 412.27px; height: 343.95px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 342.77px; height: 420.52px;"><img alt="" src="images/image9.png" style="width: 342.77px; height: 420.52px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c1">We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-2 start"><li class="c7 li-bullet-0"><span class="c1">With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 &ndash; above the gold medal threshold &ndash; even without any test-time selection strategy. &nbsp;</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span>Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating</span><span class="c5 c107"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/%23citation-bottom-3&amp;sa=D&amp;source=editors&amp;ust=1730413583767503&amp;usg=AOvVaw1irJNlfsc5RUTQPR_Q7mVv">3</a></span><span class="c1">&nbsp;of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1&mdash;it achieved an Elo rating of 1807, performing better than 93% of competitors.</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583767720&amp;usg=AOvVaw3L4rKJmpJGkYmMezkdebEE">https://cdn.openai.com/o1-system-card.pdf</a></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-2 start"><li class="c7 li-bullet-0"><span class="c1">&nbsp;We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn&rsquo;t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the &ldquo;Unknown&rdquo; option (ambiguous questions). This is not necessarily an indicator of o1-preview&rsquo;s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 555.50px; height: 82.79px;"><img alt="" src="images/image1.png" style="width: 555.50px; height: 82.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.50px; height: 98.99px;"><img alt="" src="images/image288.png" style="width: 551.50px; height: 98.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 556.75px; height: 348.86px;"><img alt="" src="images/image344.png" style="width: 556.75px; height: 348.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.49px; height: 341.22px;"><img alt="" src="images/image116.png" style="width: 554.49px; height: 341.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 580.86px; height: 491.50px;"><img alt="" src="images/image95.png" style="width: 580.86px; height: 491.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.50px; height: 207.65px;"><img alt="" src="images/image206.png" style="width: 558.50px; height: 207.65px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 543.51px; height: 408.50px;"><img alt="" src="images/image286.png" style="width: 543.51px; height: 408.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.82px; height: 313.86px;"><img alt="" src="images/image203.png" style="width: 554.82px; height: 313.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 498.67px;"><img alt="" src="images/image68.png" style="width: 624.00px; height: 498.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c1">Note: This is the weakest model compared to o1-preview and the full o1 model</span></li><li class="c10 li-bullet-0"><span>OpenAI&rsquo;s o1 model can get perfect scores on their research engineer interview coding questions:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 610.00px; height: 377.33px;"><img alt="" src="images/image137.png" style="width: 610.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 c46 li-bullet-0"><span class="c92 c102 c42 c37"></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 550.67px;"><img alt="" src="images/image88.png" style="width: 624.00px; height: 550.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-2 start"><li class="c7 li-bullet-0"><span>Code generated by o1 for this: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://codeforces.com/blog/entry/134091&amp;sa=D&amp;source=editors&amp;ust=1730413583768944&amp;usg=AOvVaw1q1TGTA8UkjftW4qwp6ncB">https://codeforces.com/blog/entry/134091</a></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image163.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 605.33px;"><img alt="" src="images/image183.png" style="width: 624.00px; height: 605.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 657.33px;"><img alt="" src="images/image224.png" style="width: 624.00px; height: 657.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 730.67px;"><img alt="" src="images/image66.png" style="width: 624.00px; height: 730.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 494.67px;"><img alt="" src="images/image134.png" style="width: 624.00px; height: 494.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 474.81px; height: 889.50px;"><img alt="" src="images/image78.png" style="width: 474.81px; height: 889.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 478.77px; height: 911.50px;"><img alt="" src="images/image73.png" style="width: 478.77px; height: 911.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 394.67px;"><img alt="" src="images/image167.png" style="width: 624.00px; height: 394.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span>Reproducible outputs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://platform.openai.com/docs/advanced-usage/reproducible-outputs&amp;sa=D&amp;source=editors&amp;ust=1730413583769773&amp;usg=AOvVaw0mKayrCSk7_ktJkkjTEfu2">https://platform.openai.com/docs/advanced-usage/reproducible-outputs</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c1">in the middle of a response, Claude suddenly notices it might be hallucinating</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 510.67px;"><img alt="" src="images/image307.png" style="width: 624.00px; height: 510.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span>Mistral Large 2 released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://mistral.ai/news/mistral-large-2407/&amp;sa=D&amp;source=editors&amp;ust=1730413583770224&amp;usg=AOvVaw1rtdSYkbP5BP6iqI6gikP6">https://mistral.ai/news/mistral-large-2407/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c1">&ldquo;Additionally, the new Mistral Large 2 is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. This commitment to accuracy is reflected in the improved model performance on popular mathematical benchmarks, demonstrating its enhanced reasoning and problem-solving skills&rdquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 192.00px;"><img alt="" src="images/image174.png" style="width: 624.00px; height: 192.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 234.67px;"><img alt="" src="images/image461.png" style="width: 624.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span>Effective strategy to make an LLM express doubt and admit when it does not know something: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/GAIR-NLP/alignment-for-honesty&amp;sa=D&amp;source=editors&amp;ust=1730413583770717&amp;usg=AOvVaw0jRWOLWhSrJ6C7KhTusuaN">https://github.com/GAIR-NLP/alignment-for-honesty</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image119.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 547.14px; height: 585.42px;"><img alt="" src="images/image405.png" style="width: 547.14px; height: 585.42px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span>Researchers describe how to tell if ChatGPT is confabulating: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/&amp;sa=D&amp;source=editors&amp;ust=1730413583771164&amp;usg=AOvVaw2HZsG7cTUjuPEsBeqBIVMI">https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span>Two things became apparent during these tests. One is that, except for a few edge cases, </span><span class="c15">semantic entropy caught more false answers than any other methods. </span><span class="c1">The second is that most errors produced by LLMs appear to be confabulations. That can be inferred from the fact that some of the other methods catch a variety of error types, yet they were outperformed by semantic entropy tests, even though these tests only catch confabulations.</span></li><li class="c10 li-bullet-0"><span>The researchers also demonstrate that the system can be </span><span class="c15">adapted to work with more than basic factual statements by altering to handle biographies, which are a large collection of individual facts</span><span class="c1">. So they developed software that broke down biographical information into a set of individual factual statements and evaluated each of these using semantic entropy. This worked on a short biography with as many as 150 individual factual claims.</span></li><li class="c10 li-bullet-0"><span>Overall, this seems to be a highly flexible system that </span><span class="c15">doesn&#39;t require major new developments to put into practice and could provide some significant improvements in LLM performance</span><span>. And, since it only catches confabulations and not other types of errors, </span><span class="c33 c15">it might be possible to combine it with other methods to boost performance even further.</span></li><li class="c10 li-bullet-0"><span>As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they&#39;ve got the right answer; it&#39;s just not being leveraged. As they put it, &quot;</span><span class="c15">The success of semantic entropy at detecting errors suggests that LLMs are even better at &#39;knowing what they don&rsquo;t know&#39; than was argued... they just don&rsquo;t know they know what they don&rsquo;t know.</span><span class="c1">&quot;</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span>Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while </span><span>using only 2K training samples) as GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413583772176&amp;usg=AOvVaw3G4MSrEKCqOTsFQ8RbX2lY">https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c31">Prover-Verifier Games improve legibility of language model outputs: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/prover-verifier-games-improve-legibility/&amp;sa=D&amp;source=editors&amp;ust=1730413583772499&amp;usg=AOvVaw0P5y4S2B3axnCoofd-pfGz">https://openai.com/index/prover-verifier-games-improve-legibility/</a></span></li></ul><p class="c9"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c89 c53 c56 li-bullet-0"><span class="c40 c37 c48 c31">We trained strong language models to produce text that is easy for weak language models to verify and found that this training also made the text easier for humans to evaluate.</span></li><li class="c89 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.00px; height: 352.20px;"><img alt="" src="images/image452.png" style="width: 554.00px; height: 1199.72px; margin-left: 0.00px; margin-top: -322.12px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c131 c53 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c131 c53 c56 c78 li-bullet-0"><span>Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.14283&amp;sa=D&amp;source=editors&amp;ust=1730413583772949&amp;usg=AOvVaw0a1kvCtusX4bIw99Na27Rq">https://arxiv.org/abs/2406.14283</a></span></li></ul><p class="c131 c53 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c89 c53 c56 li-bullet-0"><span class="c14 c31">In this paper, we aim to alleviate the pathology by introducing Q*, a general, versatile and agile framework for guiding LLMs decoding process with </span><span class="c34 c14 c31">deliberative planning</span><span class="c14 c31">. By learning a plug-and-play Q-value model as heuristic function, our Q* can </span><span class="c15 c31">effectively guide LLMs to select the most promising next step without fine-tuning LLMs for each task</span><span class="c14 c31">, which </span><span class="c34 c14 c31">avoids the significant computational overhead and potential risk of performance degeneration</span><span class="c14 c31">&nbsp;on other tasks. Extensive experiments on GSM8K, MATH and MBPP </span><span class="c28 c43">confirm the superiority of our method.</span></li></ul><p class="c53 c56 c46 c131"><span class="c28 c43"></span></p><p class="c131 c53 c56 c46"><span class="c28 c43"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c33 c15">Over 32 techniques to reduce hallucinations:</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.01313&amp;sa=D&amp;source=editors&amp;ust=1730413583773593&amp;usg=AOvVaw1qbPbzFIVFzG-c-UwM298j">https://arxiv.org/abs/2401.0131</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">REDUCING LLM HALLUCINATIONS USING EPISTEMIC NEURAL NETWORKS: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2312.15576&amp;sa=D&amp;source=editors&amp;ust=1730413583773834&amp;usg=AOvVaw0Yex5dSZoaOCoOvWygBJJ2">https://arxiv.org/pdf/2312.15576</a></span></li></ul><p class="c22 c44 c14"><span class="c40 c55 c37 c48 c14"></span></p><p class="c22 c44 c14"><span class="c40 c55 c37 c48 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">Reducing hallucination in structured outputs via Retrieval-Augmented Generation: &nbsp;</span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.08189&amp;sa=D&amp;source=editors&amp;ust=1730413583774143&amp;usg=AOvVaw0bTylXm5n0b3KtZlwvo0Ri">https://arxiv.org/abs/2404.08189</a></span></li></ul><p class="c22 c44 c14"><span class="c40 c55 c37 c48 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c32 c14 li-bullet-0"><span class="c14 c55">Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2405.21048&amp;sa=D&amp;source=editors&amp;ust=1730413583774397&amp;usg=AOvVaw2zwHRXq9S4uXMCnGueEbD_">https://huggingface.co/papers/2405.21048</a></span></li></ul><p class="c22 c104 c97 c14"><span class="c40 c55 c37 c48 c14">&nbsp; </span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c32 c14 li-bullet-0"><span class="c55 c14">Show, Don&rsquo;t Tell: Aligning Language Models with Demonstrated Feedback: </span><span class="c5 c55 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.00888&amp;sa=D&amp;source=editors&amp;ust=1730413583774730&amp;usg=AOvVaw3nKek7mvUUzUnHlEDTjU5E">https://arxiv.org/abs/2406.00888</a></span></li></ul><p class="c22 c44 c14"><span class="c40 c55 c37 c48 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c22 c72 c14 li-bullet-0"><span class="c55 c14">&gt;Significantly outperforms few-shot prompting, SFT and other self-play methods by an average of 19% using demonstrations as feedback directly with &lt;10 examples</span></li></ul><p class="c22 c44 c14"><span class="c33 c15"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c161 c78 li-bullet-0"><span>Mostly secure and aligned LLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/andyzou_jiaming/status/1799232319250743561&amp;sa=D&amp;source=editors&amp;ust=1730413583775102&amp;usg=AOvVaw2BxOgtGptcIJEmSNwBmxJs">https://x.com/andyzou_jiaming/status/1799232319250743561</a></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c22 c161 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 257.33px;"><img alt="" src="images/image25.png" style="width: 624.00px; height: 257.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c161 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 290.67px;"><img alt="" src="images/image550.png" style="width: 624.00px; height: 290.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c78 c161 li-bullet-0"><span>Safe LLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/youliang_yuan/status/1812665889852121332&amp;sa=D&amp;source=editors&amp;ust=1730413583775459&amp;usg=AOvVaw0YOkictB0TOWN3tmvwj2e8">https://x.com/youliang_yuan/status/1812665889852121332</a></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c22 c161 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 333.33px;"><img alt="" src="images/image641.png" style="width: 624.00px; height: 333.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c161 c78 li-bullet-0"><span>Another paper of refusals: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.12043&amp;sa=D&amp;source=editors&amp;ust=1730413583775733&amp;usg=AOvVaw0HOEEYM288xm_1vfpikyeO">https://huggingface.co/papers/2407.12043</a></span><span>&nbsp;</span></li></ul><p class="c131 c53 c56 c46 c129"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c1 c14">August 6 GPT 4o update:</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span class="c14">The new GPT-4o is slightly better and </span><span class="c15">33% cheaper</span><span class="c1 c14">&nbsp;than the old one! &nbsp;Right now, it&#39;s only a tad below Sonnet 3.5 on Livebench!</span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 342.67px;"><img alt="" src="images/image115.png" style="width: 624.00px; height: 342.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c89 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 594.67px;"><img alt="" src="images/image61.png" style="width: 624.00px; height: 594.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 c144 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 961.33px;"><img alt="" src="images/image64.png" style="width: 624.00px; height: 961.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span class="c1">Not as good as the Opus model they said is coming out later this year </span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">80% lower cost than Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">2x speed over Claude 3 Opus</span></li><li class="c49 li-bullet-0"><span class="c40 c37 c65 c60">decent math and coding jump. 10% better on MATH 9% better on GPQA</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c15 c65 c60">Can convert research paper descriptions to code: </span><span class="c5 c15 c65 c114"><a class="c13" href="https://www.google.com/url?q=https://x.com/VictorTaelin/status/1803816296410190286&amp;sa=D&amp;source=editors&amp;ust=1730413583776746&amp;usg=AOvVaw2WDmPzyGDKvdyKWt-JLyYu">https://x.com/VictorTaelin/status/1803816296410190286</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c15 c65 c60">Even GPT3 (which is VERY out of date) knew when something was incorrect. All you had to do was tell it to call you out on it: </span><span class="c5 c15 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/nickcammarata/status/1284050958977130497&amp;sa=D&amp;source=editors&amp;ust=1730413583777114&amp;usg=AOvVaw1zwjW0lpVpc3V8N0Kq15tM">https://twitter.com/nickcammarata/status/1284050958977130497</a></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 522.67px;"><img alt="" src="images/image39.png" style="width: 624.00px; height: 522.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span>LLMs know their limitations and choose to hallucinate to respond to the prompt. This is why allowing it to say &ldquo;I don&rsquo;t know&rdquo; is important: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583777619&amp;usg=AOvVaw3jsQD0ZmBRoD_ONnuh_xQM">https://cdn.openai.com/o1-system-card.pdf</a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 526.50px; height: 319.78px;"><img alt="" src="images/image21.png" style="width: 526.50px; height: 319.78px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span>Golden Gate Claude (LLM that is forced to hyperfocus on details about the Golden Gate Bridge in California) recognizes that what it&rsquo;s saying is incorrect: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ElytraMithra/status/1793916830987550772&amp;sa=D&amp;source=editors&amp;ust=1730413583777925&amp;usg=AOvVaw1Gu0zOMBbKBU4bLvIspllm">https://x.com/ElytraMithra/status/1793916830987550772</a></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 514.16px; height: 389.30px;"><img alt="" src="images/image372.png" style="width: 514.16px; height: 389.30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 537.13px; height: 414.04px;"><img alt="" src="images/image45.jpg" style="width: 537.13px; height: 414.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><p class="c21 c105"><span class="c40 c15 c35 c65">&nbsp;</span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span>More proof: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/blixt/status/1284804985579016193&amp;sa=D&amp;source=editors&amp;ust=1730413583778320&amp;usg=AOvVaw12uQL3xp53xdWHxnmNzmZY">https://x.com/blixt/status/1284804985579016193</a></span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span>Robust agents learn causal world models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.10877%23deepmind%25C2%25A0&amp;sa=D&amp;source=editors&amp;ust=1730413583778559&amp;usg=AOvVaw004eSpPlCeN1liWCn3H3UE">https://arxiv.org/abs/2402.10877</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c1">CONCLUSION: Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear. We have resolved this conjecture in a model-independent way, showing that any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c1">TLDR: a model that can reliably answer decision based questions correctly must have learned a cause and effect that led to the result. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c14">We introduce BSDETECTOR, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric</span><span class="c34 c14">&nbsp;confidence score </span><span class="c14">for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, whose training data remains unknown. By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a</span><span class="c34 c14">&nbsp;confidence estimate that cautions when not to trust this response</span><span class="c14">. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDETECTOR </span><span class="c15">more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT)</span><span class="c14">. By sampling multiple responses from the LLM and considering the one with the highest confidence score, we can </span><span class="c15">additionally obtain more accurate responses from the same LLM, without any extra training steps.</span><span class="c1 c14">&nbsp;In applications involving automated evaluation with LLMs, accounting for our confidence scores leads to more reliable evaluation in both human-in-the-loop and fully-automated settings (across both GPT 3.5 and 4).</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://openreview.net/pdf?id%3DQTImFg6MHU&amp;sa=D&amp;source=editors&amp;ust=1730413583779410&amp;usg=AOvVaw0Lnvs8bOESbMug8Jk0cWxs">https://openreview.net/pdf?id=QTImFg6MHU</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 516.00px;"><img alt="" src="images/image577.png" style="width: 624.00px; height: 516.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 549.33px;"><img alt="" src="images/image228.png" style="width: 624.00px; height: 549.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c15">[</span><span class="c15 c35 c65">LLMs have an internal world model ](</span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.15498.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583779815&amp;usg=AOvVaw0gxC0iiRLrB48Rx657z9An">https://arxiv.org/pdf/2403.15498.pdf</a></span><span class="c40 c15 c35 c65">)</span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c15 c35 c65">More proof: </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2210.13382&amp;sa=D&amp;source=editors&amp;ust=1730413583780027&amp;usg=AOvVaw17SCmIiciTBWB0fRcktucU">https://arxiv.org/abs/2210.13382</a></span><span class="c40 c15 c35 c65">&nbsp;</span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c15 c35 c65">Golden Gate Claude (LLM that is only aware of details about the Golden Gate Bridge in California) recognizes that what it&rsquo;s saying is incorrect: </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://x.com/ElytraMithra/status/1793916830987550772&amp;sa=D&amp;source=editors&amp;ust=1730413583780259&amp;usg=AOvVaw0x_HQyqljFRLwT8rEp4uwm">https://x.com/ElytraMithra/status/1793916830987550772</a></span><span class="c40 c15 c35 c65">&nbsp;</span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c15 c35 c65">Even more proof by Max Tegmark (renowned MIT professor): </span><span class="c5 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.02207&amp;sa=D&amp;source=editors&amp;ust=1730413583780597&amp;usg=AOvVaw3u7afm3e4_co4VNB3Z4xe0">https://arxiv.org/abs/2310.02207</a></span><span class="c40 c15 c35 c65">&nbsp;</span></li></ul><p class="c9"><span class="c40 c15 c65 c60"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c15 c35 c65">&ldquo;Godfather of AI&rdquo; and Turing Award winner Geoffrey Hinton: A neural net given training data where half the examples are incorrect still had an error rate of &lt;=25% rather than 50% because it understands the rules and does better despite the false information</span><span class="c23 c14">: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/n4IQOBka8bc?si%3DwM423YLd-48YC-eY?t%3D840&amp;sa=D&amp;source=editors&amp;ust=1730413583781035&amp;usg=AOvVaw2aaJ-xm-QBKR9XJf3xoBnE">https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY</a></span><span class="c1">&nbsp;(14:00 timestamp)</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c15">Klarna SUCCESSFULLY replaces call centers with AI </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/klarna/comments/1c1fwr3/klarna_ceo_on_using_ai_to_replace_700_workers/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583781531&amp;usg=AOvVaw1gj1ywycxkw2rUQFuzq-Og">https://www.reddit.com/r/klarna/comments/1c1fwr3/klarna_ceo_on_using_ai_to_replace_700_workers/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">Klarnas AI assistant, powered by @OpenAI , has in its first 4 weeks handled 2.3 million customer service chats and the data and insights are staggering:</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c1 c14">Handles 2/3 rd of our customer service enquires</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c33 c15">On par with humans on customer satisfaction</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c14">Higher accuracy leading to a </span><span class="c33 c15">25% reduction in repeat inquiries</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c1 c14">customer resolves their errands in 2 min vs 11 min</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c14">&nbsp;Live 24/7 in over 23 markets, </span><span class="c33 c15">communicating in over 35 languages</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-1"><li class="c10 li-bullet-0"><span class="c1 c14">It performs the equivalent job of 700 full time agents</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c14">&lsquo;I will never go back&rsquo;: Ontario family doctor says new AI notetaking saved her job:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583782929&amp;usg=AOvVaw3yj4_R1xwSRBcozvRFgQpk">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583783081&amp;usg=AOvVaw04m-gpmlwTHonGRd9HD5Q3">https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span class="c14">&ldquo;If the physician is unhappy with the note, Lall said, they can ask the AI model to regenerate the information or add more detail to any one of the categories. While the tool has some imperfections, she said, the improvements have been noticeable over the 10 months since she began using it.&ldquo;I really feel this should be the</span><span class="c15">&nbsp;next gold standard for all of our doctors.</span><span class="c14">&nbsp;It decreases the cognitive load you feel at the end of the day,&rdquo; she said.The Ford government has been so impressed with the technology that it announced </span><span class="c15">a pilot program to allow 150 family physicians to use AI Scribe as part of their practices.</span><span class="c1 c14">&nbsp;The health minister said the early signs were promising but stressed government would proceed carefully.&rdquo;</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c22 c32 li-bullet-0"><span class="c15">Great thread on medical research uses of generative AI:</span><span class="c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/Sandbar101/status/1784620540092731827&amp;sa=D&amp;source=editors&amp;ust=1730413583783546&amp;usg=AOvVaw0m9iiGQNWb00tWlqkW5-OU">&nbsp;</a></span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/Sandbar101/status/1784620540092731827&amp;sa=D&amp;source=editors&amp;ust=1730413583783676&amp;usg=AOvVaw2qrTYbH-z558Ps-Zs9fTLu">https://x.com/Sandbar101/status/1784620540092731827</a></span></li><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-01087-4&amp;sa=D&amp;source=editors&amp;ust=1730413583783972&amp;usg=AOvVaw03LjXDWV9v--dg22eOO4qw">AI beats humans at basic tasks</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-01087-4&amp;sa=D&amp;source=editors&amp;ust=1730413583784180&amp;usg=AOvVaw2UBY2mcSBT9uaUwIop33wK">https://www.nature.com/articles/d41586-024-01087-4</a></span></li><li class="c4 li-bullet-0"><span class="c14">[It passed several exams, including the SAT, bar exam, and multiple AP tests](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.businessinsider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1&amp;sa=D&amp;source=editors&amp;ust=1730413583784514&amp;usg=AOvVaw30HzoYvMxBHY2Sg5h89EYN">https://www.businessinsider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1</a></span><span class="c14">) as well as a [medical licensing exam](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.medscape.com/viewarticle/987549?form%3Dfpf&amp;sa=D&amp;source=editors&amp;ust=1730413583784768&amp;usg=AOvVaw3mmxjqb5IaTeGHDKqbRjWz">https://www.medscape.com/viewarticle/987549?form=fpf</a></span><span class="c1 c14">) and [beat many doctors](https://www.businessinsider.com/chatgpt-passes-medical-exam-diagnoses-rare-condition-2023-4)</span></li></ul><ul class="c0 lst-kix_2cqjr2ei92jl-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">These are from real exams where the questions and solutions are not published online. </span></li><li class="c10 li-bullet-0"><span class="c1 c14">If the LLM is just repeating answers it found online, why does it do so poorly on math exams and Stanford Medical School&rsquo;s clinical reasoning final but so well on other exams? </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c45 li-bullet-0"><span class="c15">ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.00176&amp;sa=D&amp;source=editors&amp;ust=1730413583785401&amp;usg=AOvVaw1C-B-Fya52fkrGoH1cYEHP">https://arxiv.org/pdf/2311.00176</a></span></li></ul><p class="c73 c46"><span class="c33 c15"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3613904.3642596&amp;sa=D&amp;source=editors&amp;ust=1730413583785763&amp;usg=AOvVaw1i4i_ch8suD5AKRYyrPFzN">Study that ChatGPT fails 52% of coding tasks </a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c14">&ldquo;this work has used the </span><span class="c34 c14">free version of ChatGPT (GPT-3.5)</span><span class="c1 c14">&nbsp;for acquiring the ChatGPT responses for the manual analysis.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c14">&ldquo;Thus, we chose to </span><span class="c34 c14">only consider the initial answer </span><span class="c1 c14">generated by ChatGPT.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected SO questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.&rdquo;</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-2 start"><li class="c7 li-bullet-0"><span class="c14">This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to</span><span class="c15">&nbsp;~77% for GPT 4</span><span class="c1">&nbsp;(equal to (517*0.48+517*6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-3 start"><li class="c21 c26 li-bullet-0"><span>Note: This was all done in</span><span class="c33 c15">&nbsp;ONE SHOT with no repeat attempts.</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c14">Study was released </span><span class="c15">before GPT-4o </span><span>and </span><span class="c34">did not use GPT 4 Turbo</span><span>, both of which are significantly higher quality than GPT 4 according to the </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://chat.lmsys.org/?leaderboard&amp;sa=D&amp;source=editors&amp;ust=1730413583787003&amp;usg=AOvVaw1UfTs0X1EJNiKSIUHLOIeM">LMSYS arena.</a></span><span>&nbsp;Now, this has also been </span><span class="c33 c34">surpassed by Claude Sonnet 3.5 with Opus 3.5 coming later this year and OpenAI&rsquo;s GPT-4o and o1 models. </span></li></ul><p class="c9"><span class="c33 c34"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c14">Microsoft AutoDev:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.08299&amp;sa=D&amp;source=editors&amp;ust=1730413583787445&amp;usg=AOvVaw2G2O88USi6S31sozhGaPQi">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.08299&amp;sa=D&amp;source=editors&amp;ust=1730413583787617&amp;usg=AOvVaw2Jaf3PP3xequ2Y-IxHs0D1">https://arxiv.org/pdf/2403.08299</a></span></li></ul><p class="c9 c93"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_npq7lfz9ly6z-0"><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;We tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_2cqjr2ei92jl-0"><li class="c4 li-bullet-0"><span class="c37 c14 c76 c98 c75">NYT article on ChatGPT:</span><span class="c37 c14 c76 c98 c75"><a class="c13" href="https://www.google.com/url?q=https://archive.is/hy3Ae&amp;sa=D&amp;source=editors&amp;ust=1730413583788229&amp;usg=AOvVaw1lX6LWdeJpHj91Z5e-TlG4">&nbsp;</a></span><span class="c5 c37 c14 c76 c75"><a class="c13" href="https://www.google.com/url?q=https://archive.is/hy3Ae&amp;sa=D&amp;source=editors&amp;ust=1730413583788395&amp;usg=AOvVaw3B-5sVehtAyHYiMtvMRL_U">https://archive.is/hy3Ae</a></span></li></ul><p class="c9 c93"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0"><li class="c4 li-bullet-0"><span class="c92 c37 c14 c76 c98 c75">&ldquo;In a trial run by GitHub&rsquo;s researchers, developers given an entry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than those who did the assignment manually.&rdquo;</span></li></ul><p class="c9"><span class="c92 c37 c14 c76 c98 c75"></span></p><p class="c117 c46"><span class="c92 c37 c14 c76 c98 c75"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0"><li class="c4 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2404.03683v1&amp;sa=D&amp;source=editors&amp;ust=1730413583789007&amp;usg=AOvVaw24p_TnLEGKcFZECyJnCRDk">https://arxiv.org/html/2404.03683v1</a></span></li></ul><ul class="c0 lst-kix_qx6x5q8dhn22-1 start"><li class="c10 li-bullet-0"><span class="c14">Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string &mdash; a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers</span><span class="c15">. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory</span><span class="c14">. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models</span><span class="c15">&nbsp;solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers.</span><span class="c14">&nbsp;Our results indicate that language models </span><span class="c33 c15">can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. </span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0"><li class="c4 li-bullet-0"><span class="c30 c37">LLMs can correct their own mistakes: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.01297&amp;sa=D&amp;source=editors&amp;ust=1730413583789855&amp;usg=AOvVaw0THemthg1jbNxaw7SLXiwl">https://arxiv.org/abs/2406.01297</a></span><span class="c30 c37">&nbsp;</span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c14">AI doing sales calls very well: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Futurology/comments/1ceeq17/comment/l1k8b7f/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583790335&amp;usg=AOvVaw0COMb7emg_E93egUCNoB0-">https://www.reddit.com/r/Futurology/comments/1ceeq17/comment/l1k8b7f/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span class="c14">[AI beats humans on all performance indicators](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/ai-index-report-global-impact/&amp;sa=D&amp;source=editors&amp;ust=1730413583790735&amp;usg=AOvVaw0qTJfkoc2g4nT2SbB-2HSb">https://newatlas.com/technology/ai-index-report-global-impact/</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span class="c14">ChatGPT outperforms psychologists: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.psypost.org/chatgpt-4-outperforms-human-psychologists-in-test-of-social-intelligence-study-finds/&amp;sa=D&amp;source=editors&amp;ust=1730413583791213&amp;usg=AOvVaw1S16I_ZuDk2Fn1bkGbJvyb">https://www.psypost.org/chatgpt-4-outperforms-human-psychologists-in-test-of-social-intelligence-study-finds/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/&amp;sa=D&amp;source=editors&amp;ust=1730413583791600&amp;usg=AOvVaw10kzt-eWA9pwA4XhZJt8Jx">China&rsquo;s &lsquo;AI Ship Designer&rsquo; Works At Unprecedented Speed; Performed A Year&rsquo;s Work Only In 24 Hours!</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed&amp;sa=D&amp;source=editors&amp;ust=1730413583791841&amp;usg=AOvVaw1jbsSlDX4ZZL-a7pWxtroI">https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html&amp;sa=D&amp;source=editors&amp;ust=1730413583792267&amp;usg=AOvVaw3KvWtmMbsSTSb5LhfqX5tx">The military wants &lsquo;robot ships&rsquo; to replace sailors in battle</a></span><span class="c202">: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html&amp;sa=D&amp;source=editors&amp;ust=1730413583792535&amp;usg=AOvVaw0-0ceMW_4-ixfU2Am_W3Jb">https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html</a></span></li><li class="c4 li-bullet-0"><span>CriticGPT is intended to help identify hallucinations as models grow more sophisticated: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://spectrum.ieee.org/openai-rlhf&amp;sa=D&amp;source=editors&amp;ust=1730413583792835&amp;usg=AOvVaw0VEysAaEPulMg-K2JNdcrl">https://spectrum.ieee.org/openai-rlhf</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 469.33px;"><img alt="" src="images/image425.png" style="width: 624.00px; height: 469.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 620.00px;"><img alt="" src="images/image238.png" style="width: 624.00px; height: 620.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 600.00px;"><img alt="" src="images/image628.png" style="width: 624.00px; height: 600.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/janleike/status/1806386442568142995&amp;sa=D&amp;source=editors&amp;ust=1730413583793348&amp;usg=AOvVaw1HhP9bpw-KBxQPka7trFba">https://x.com/janleike/status/1806386442568142995</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c22 c161 c78 li-bullet-0"><span>AI can beat university students, study suggests: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/articles/cqqqln0eg65o&amp;sa=D&amp;source=editors&amp;ust=1730413583793679&amp;usg=AOvVaw30NYPsW_AXTSbWdEw4brgy">https://www.bbc.com/news/articles/cqqqln0eg65o</a></span></li></ul><p class="c22 c161 c97 c46"><span class="c1"></span></p><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span>MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/6llW7BqYzo&amp;sa=D&amp;source=editors&amp;ust=1730413583794053&amp;usg=AOvVaw2aKBbCFf8wQ4wgOKu-3qSP">https://arxiv.org/abs/2407.13089</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span class="c1">- The paper presents MetaSumPerceiver (MSP), a novel summarization model for generating claim-specific summaries from multimodal, multi-document datasets to assist with fact-checking. </span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- MSP uses a dynamic perceiver-based model to handle multimodal inputs of arbitrary lengths, including documents, images, and claims.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- To train MSP, reinforcement learning with an entailment model as a reward signal is employed to refine summaries to provide relevant evidence for fact-checking.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- MSP incorporates a proxy reward mechanism with PPO to continually update the summarizer during fact-checking.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- The paper introduces the Multi-News-Fact-Checking dataset with over 100k labeled claims derived from Multi-News using Llama prompts.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Experiments on MOCHEG and the new dataset show MSP </span><span class="c33 c15">substantially outperforms prior baselines, achieving state-of-the-art performance.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- The key innovation is using RL to optimize summarization specifically for claim verification versus generic summarization.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 689.33px;"><img alt="" src="images/image81.png" style="width: 624.00px; height: 689.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span>Taco Bell to roll out AI drive-thru ordering in hundreds of locations by end of year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524&amp;sa=D&amp;source=editors&amp;ust=1730413583795440&amp;usg=AOvVaw3Gb0AIT0Z_WRBZ4ZG-cteb">https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524</a></span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-1 start"><li class="c10 li-bullet-0"><span class="c1">Yum Brands said the tech has improved order accuracy, reduced wait times, decreased employees&rsquo; task load and fueled profitable growth.</span></li></ul><ul class="c0 lst-kix_l25ba28sjj7-0"><li class="c4 li-bullet-0"><span class="c6 c40">GPT-4 gets the classic riddle of &ldquo;which order should I carry the chickens or the fox over a river&rdquo; correct EVEN WITH A MAJOR CHANGE if you replace the fox with a &quot;zergling&quot; and the chickens with &quot;robots&quot;.</span></li></ul><p class="c21 c129"><span class="c6">Proof: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636&amp;sa=D&amp;source=editors&amp;ust=1730413583795948&amp;usg=AOvVaw2acZeVJBhgHv0kPvwhe5br">https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636</a></span></p><p class="c21 c129"><span class="c6 c40">This doesn&rsquo;t work if you use the original phrasing though. The problem isn&#39;t poor reasoning, but overfitting on the original version of the riddle.</span></p><ul class="c0 lst-kix_1l36jc1oov6-0"><li class="c10 li-bullet-0"><span class="c6">Also gets this riddle subversion correct for the same reason: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92&amp;sa=D&amp;source=editors&amp;ust=1730413583796307&amp;usg=AOvVaw1xvU32az8ux34AeFkcJJmR">https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ef6tx1pahaqo-0 start"><li class="c4 li-bullet-0"><span>LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2409.02897&amp;sa=D&amp;source=editors&amp;ust=1730413583796657&amp;usg=AOvVaw1vbtDWpUQU3oI1BoxzF0Rg">https://huggingface.co/papers/2409.02897</a></span></li><li class="c4 li-bullet-0"><span>Stanford researchers: &ldquo;Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413583796978&amp;usg=AOvVaw2KgU-r-f5u4aPA2NsopseJ">https://x.com/ChengleiSi/status/1833166031134806330</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ef6tx1pahaqo-1 start"><li class="c10 li-bullet-0"><span class="c1">&gt;Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ef6tx1pahaqo-1"><li class="c10 li-bullet-0"><span>&gt;We also used an LLM to </span><span class="c34">standardize the writing styles of human and LLM ideas to avoid potential confounders</span><span class="c1">, while preserving the original content.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image152.jpg" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image91.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-0"><li class="c4 li-bullet-0"><span>We&#39;ve created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DanHendrycks/status/1833152719756116154&amp;sa=D&amp;source=editors&amp;ust=1730413583797869&amp;usg=AOvVaw2ggYDQ5w94JlbM9r_lIKm9">https://x.com/DanHendrycks/status/1833152719756116154</a></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-1 start"><li class="c10 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters</span></li><li class="c10 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.</span></li><li class="c10 li-bullet-0"><span class="c141 c14">On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% &plusmn; 1.4. A link to the technical report is </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Tc_xY1NM-US4mZ4OpzxrpTudyo1W4KsE/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1730413583798410&amp;usg=AOvVaw2-ZmGEceJ58V8Is1rmFaZK">here</a></span><span class="c57 c37 c154 c48 c141 c14">. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they&rsquo;re similarly accurate.</span></li><li class="c10 li-bullet-0"><span class="c141 c14">The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=http://forecast.safe.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583798758&amp;usg=AOvVaw1PS6CUhzbpmEjH7AiXilZP">forecast.safe.ai</a></span><span class="c141 c14">.) Moreover, probabilities from AIs are also known to lead to </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Automation_bias&amp;sa=D&amp;source=editors&amp;ust=1730413583798964&amp;usg=AOvVaw1H8Jn2gV-igmCF1UeYdIM4">automation bias</a></span><span class="c57 c37 c154 c48 c141 c14">, and improvements in the interface could ameliorate this.</span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-0"><li class="c4 li-bullet-0"><span class="c141 c14">Researcher solves overfitting riddle issue: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition&amp;sa=D&amp;source=editors&amp;ust=1730413583799307&amp;usg=AOvVaw3vZVIphzsRYZE7itrP-8Xk">https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition</a></span></li><li class="c4 li-bullet-0"><span>Introducing PaperQA2, the first AI agent that conducts entire scientific literature reviews on its own: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/SGRodriques/status/1833908643856818443&amp;sa=D&amp;source=editors&amp;ust=1730413583799638&amp;usg=AOvVaw091M_VrZ5gm0zoK12K-7mG">https://x.com/SGRodriques/status/1833908643856818443</a></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-1 start"><li class="c10 li-bullet-0"><span class="c1">PaperQA2 is also the first agent to beat PhD and Postdoc-level biology researchers on multiple literature research tasks, as measured both by accuracy on objective benchmarks and assessments by human experts. We are publishing a paper and open-sourcing the code.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">This is the first example of AI agents exceeding human performance on a major portion of scientific research, and will be a game-changer for the way humans interact with the scientific literature. </span></li><li class="c10 li-bullet-0"><span class="c1">PaperQA2 finds and summarizes relevant literature, refines its search parameters based on what it finds, and provides cited, factually grounded answers that are more accurate on average than answers provided by PhD and postdoc-level biologists. When applied to answer highly specific questions, like this one, it obtains SOTA performance on LitQA2, part of LAB-Bench focused on information retrieval</span></li><li class="c10 li-bullet-0"><span class="c1">PaperQA2 can also do broad-based literature reviews. WikiCrow, which is an agent based on PaperQA2, writes Wikipedia-style articles that are significantly more accurate on average than actual human-written articles on Wikipedia, as judged by PhD and postdoc-level biologists. </span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-0"><li class="c4 li-bullet-0"><span>ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413583800428&amp;usg=AOvVaw2yOBRyU7zzBe0DwZW-92Fu">https://m.youtube.com/watch?v=a8QvnIAGjPA</a></span></li><li class="c4 li-bullet-0"><span>Differential transformer: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.05258&amp;sa=D&amp;source=editors&amp;ust=1730413583800690&amp;usg=AOvVaw2LjN9gGUw5JGUNwcFRlu8I">https://arxiv.org/abs/2410.05258</a></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-1 start"><li class="c10 li-bullet-0"><span>Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that Diff Transformer </span><span class="c15">outperforms Transformer in various settings of scaling up model size and training tokens</span><span>. More intriguingly, it offers </span><span class="c15">notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers</span><span>. By being less distracted by irrelevant context, Diff Transformer can </span><span class="c15">mitigate hallucination in question answering and text summarization</span><span>. For in-context learning, Diff Transformer not only </span><span class="c15">enhances accuracy but is also more robust to order permutation</span><span class="c1">, which was considered as a chronic robustness issue. The results position Diff Transformer as a highly effective and promising architecture to advance large language models.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 422.67px;"><img alt="" src="images/image50.png" style="width: 624.00px; height: 422.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 622.67px;"><img alt="" src="images/image229.png" style="width: 624.00px; height: 622.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-0"><li class="c4 li-bullet-0"><span>Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08146&amp;sa=D&amp;source=editors&amp;ust=1730413583801660&amp;usg=AOvVaw1KflkvE0aP3OWJ65Ki_RKR">https://arxiv.org/abs/2410.08146</a></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-1 start"><li class="c10 li-bullet-0"><span>We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is</span><span class="c15">&nbsp;&gt;8% more accurate, and 1.5&minus;5&times; more compute-efficient. </span><span>Online RL with dense rewards from PAVs enables one of the first results with</span><span class="c33 c15">&nbsp;5&minus;6&times; gain in sample efficiency, and &gt;6% gain in accuracy, over ORMs.</span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-0"><li class="c4 li-bullet-0"><span>Sundar Pichai said on the earnings call today that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/&amp;sa=D&amp;source=editors&amp;ust=1730413583802250&amp;usg=AOvVaw26YZTid3_5-RSKYVqrEXdC">https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ef6tx1pahaqo-1"><li class="c10 li-bullet-0"><span class="c1">Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said &ldquo;a large percentage&rdquo; instead of a specific and verifiable number.</span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-0"><li class="c78 c121 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/introducing-simpleqa/&amp;sa=D&amp;source=editors&amp;ust=1730413583802684&amp;usg=AOvVaw0usUSrIqq8F1Yb4WJDxLK4">https://openai.com/index/introducing-simpleqa/</a></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-1 start"><li class="c121 c97 c105 li-bullet-0"><span class="c1">High confidence score correlates with higher accurracy and vice versa</span></li><li class="c121 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 502.67px;"><img alt="" src="images/image345.png" style="width: 624.00px; height: 502.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c121 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image98.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ef6tx1pahaqo-2 start"><li class="c121 c86 li-bullet-0"><span class="c1">Not attempted = refusal to answer</span></li></ul><h2 class="c64" id="h.k8f1uljw9sdl"><span>8.1. Math</span></h2><ul class="c0 lst-kix_evcxr39uk36z-0 start"><li class="c4 li-bullet-0"><span>Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08304&amp;sa=D&amp;source=editors&amp;ust=1730413583803566&amp;usg=AOvVaw31TvxPTz2OqR_bpwIXY2r6">https://arxiv.org/abs/2410.08304</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 464.00px;"><img alt="" src="images/image416.png" style="width: 624.00px; height: 464.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 600.00px;"><img alt="" src="images/image354.png" style="width: 624.00px; height: 600.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 346.67px;"><img alt="" src="images/image333.png" style="width: 624.00px; height: 346.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413583804288&amp;usg=AOvVaw2DrdblFYc7jf_vW1qbWuPE">https://arxiv.org/abs/2410.0620</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span class="c1">LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c22 c32 li-bullet-0"><span class="c18">First AI to solve International Mathematical Olympiad problems at a silver medalist level: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/GoogleDeepMind/status/1816498082860667086&amp;sa=D&amp;source=editors&amp;ust=1730413583804768&amp;usg=AOvVaw047Xu9ZVwcJbKtOGRZNhBv">https://x.com/GoogleDeepMind/status/1816498082860667086</a></span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c22 c72 li-bullet-0"><span class="c40 c18">&gt;It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. </span></li><li class="c22 c72 li-bullet-0"><span class="c40 c18">Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.</span></li><li class="c22 c72 li-bullet-0"><span class="c40 c18">It solved this year&rsquo;s IMO Problem 4 within 19 seconds</span></li><li class="c22 c72 li-bullet-0"><span>The fact that the program can come up with a non-obvious construction like this is very impressive, and well beyond what I thought was state of the art. -PROF SIR TIMOTHY GOWERS, IMO GOLD MEDALIST AND FIELDS MEDAL WINNER</span></li><li class="c22 c72 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image237.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Math professor on DeepMind&#39;s breakthrough: &quot;When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert&quot; </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/PoShenLoh/status/1816500461484081519&amp;sa=D&amp;source=editors&amp;ust=1730413583805762&amp;usg=AOvVaw24MfEhEL43HMYl2IPG9BuM">https://x.com/PoShenLoh/status/1816500461484081519</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>A thread of a researcher sharing his team&#39;s findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/robertghrist/status/1841462507543949581?t%3D5zV3VpQI0mbrSU9_QRtfkQ%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583806112&amp;usg=AOvVaw1M5Y7abViwMEl7yqmz0S7U">https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&amp;s=19</a></span></li><li class="c4 li-bullet-0"><span>OpenAI o1 model released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/&amp;sa=D&amp;source=editors&amp;ust=1730413583806415&amp;usg=AOvVaw2CHyPjgHdyHRXw51RcQMOo">https://openai.com/index/learning-to-reason-with-llms/</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span class="c1">Terrance Tao said o1 is a mediocre but not incompetent grad student, who means a lot coming from him </span></li><li class="c10 li-bullet-0"><span>o1 improves over GPT</span><span class="c1">-4o on a wide range of benchmarks, including 54/57 MMLU subcategories</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).</span></li><li class="c10 li-bullet-0"><span class="c1">On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.</span></li><li class="c10 li-bullet-0"><span class="c1">We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-2 start"><li class="c7 li-bullet-0"><span class="c1">With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 &ndash; above the gold medal threshold &ndash; even without any test-time selection strategy. &nbsp;</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span>Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating</span><span class="c5 c107"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/%23citation-bottom-3&amp;sa=D&amp;source=editors&amp;ust=1730413583807518&amp;usg=AOvVaw02hkhqnvwRHg2Q99UelDtd">3</a></span><span class="c1">&nbsp;of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1&mdash;it achieved an Elo rating of 1807, performing better than 93% of competitors.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 550.67px;"><img alt="" src="images/image88.png" style="width: 624.00px; height: 550.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image163.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 605.33px;"><img alt="" src="images/image183.png" style="width: 624.00px; height: 605.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 657.33px;"><img alt="" src="images/image224.png" style="width: 624.00px; height: 657.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 730.67px;"><img alt="" src="images/image66.png" style="width: 624.00px; height: 730.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 494.67px;"><img alt="" src="images/image134.png" style="width: 624.00px; height: 494.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1169.33px;"><img alt="" src="images/image78.png" style="width: 624.00px; height: 1169.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1188.00px;"><img alt="" src="images/image73.png" style="width: 624.00px; height: 1188.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 578.00px; height: 360.00px;"><img alt="" src="images/image118.png" style="width: 578.00px; height: 360.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c14">Abacus Embeddings, a simple tweak to positional embeddings that</span><span class="c15">&nbsp;enables LLMs to do addition, multiplication, sorting, and more</span><span class="c14">. Our Abacus Embeddings </span><span class="c15">trained only on 20-digit addition generalise near perfectly to 100+ digits: </span><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/SeanMcleish/status/1795481814553018542&amp;sa=D&amp;source=editors&amp;ust=1730413583809036&amp;usg=AOvVaw1i5N048Lad_7JRsWqY4Rmy">https://x.com/SeanMcleish/status/1795481814553018542</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 573.65px; height: 290.50px;"><img alt="" src="images/image343.png" style="width: 573.65px; height: 290.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>Researcher </span><span>trained GPT2 to predict the product of two numbers up to 20 digits w/o intermediate reasoning steps, surpassing previous 15-digit demo w/o CoT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/yuntiandeng/status/1814319104448467137&amp;sa=D&amp;source=editors&amp;ust=1730413583809661&amp;usg=AOvVaw2CU0gGjVCsiA7f_DiwIkwe">https://x.com/yuntiandeng/status/1814319104448467137</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span>The accuracy is a perfect 100%, while GPT-4 has 0% accuracy</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/&amp;sa=D&amp;source=editors&amp;ust=1730413583810257&amp;usg=AOvVaw2u1LXrxAzUG7s25IO3qayr">https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>Fields Medalist Terence Tao explains how proof checkers and AI programs are dramatically changing mathematics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/&amp;sa=D&amp;source=editors&amp;ust=1730413583810657&amp;usg=AOvVaw22ujSBahFEg_X7HwoOgv6Q">https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span class="c92 c99 c37 c65 c60 c144">&gt;Tao: I think in three years AI will become useful for mathematicians.</span></li></ul><p class="c9"><span class="c92 c99 c37 c65 c60 c144"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span class="c18 c14">Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math:</span><span class="c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1793864788579090917?s%3D46%26t%3DlZJAHzXMXI1MgQuyBgEhgA&amp;sa=D&amp;source=editors&amp;ust=1730413583811290&amp;usg=AOvVaw1-RDR_GmidF83BNK8tpcAX">&nbsp;</a></span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1793864788579090917?s%3D46%26t%3DlZJAHzXMXI1MgQuyBgEhgA&amp;sa=D&amp;source=editors&amp;ust=1730413583811520&amp;usg=AOvVaw2vpt4lSTENf7DNKBBDOozO">https://x.com/_akhaliq/status/1793864788579090917?s=46&amp;t=lZJAHzXMXI1MgQuyBgEhgA</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>Improve Mathematical Reasoning in Language Models by Automated Process Supervision: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.06592&amp;sa=D&amp;source=editors&amp;ust=1730413583811960&amp;usg=AOvVaw0rNmVAT3DVfUJ8KYdJQq_2">https://arxiv.org/abs/2406.06592</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span class="c3">&gt;Utilizing this fully automated process supervision alongside the weighted self-consistency algorithm, we have enhanced the instruction tuned Gemini Pro model&#39;s math reasoning performance, achieving a 69.4\% success rate on the MATH benchmark, a 36\% relative improvement from the 51\% base model performance. Additionally, the entire process operates without any human intervention, making our method both financially and computationally cost-effective compared to existing methods.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span class="c14">AlphaGeomertry surpasses the state-of-the-art approach for geometry problems, advancing AI reasoning in mathematics: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/&amp;sa=D&amp;source=editors&amp;ust=1730413583812639&amp;usg=AOvVaw3L_hcadHcW1YKVGzo3Lkz1">https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 552.45px; height: 345.28px;"><img alt="" src="images/image337.png" style="width: 552.45px; height: 345.28px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.07394&amp;sa=D&amp;source=editors&amp;ust=1730413583813088&amp;usg=AOvVaw0zQbvEY0kkU-gA8CKLIFTK">https://arxiv.org/abs/2406.07394</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Extensive experiments demonstrate MCTSr&#39;s efficacy in solving Olympiad-level mathematical problems, significantly improving success rates across multiple datasets, including GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math Odyssey, AIME, and OlympiadBench. The study advances the application of LLMs in complex reasoning tasks and sets a foundation for future AI integration, enhancing decision-making accuracy and reliability in LLM-driven applications.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span class="c1">This would be even more effective with a better model than LLAMA 8B </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>DeepSeek-Coder-V2: First Open Source Model Beats GPT4-Turbo in Coding and Math: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583813694&amp;usg=AOvVaw2m9uAcXQGUN0CrkggdnAWf">https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>Google DeepMind used a large language model to solve an unsolved math problem: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/&amp;sa=D&amp;source=editors&amp;ust=1730413583814074&amp;usg=AOvVaw3kdHZBzbI-u0EglhekhRGw">https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>Six months ago, we launched Numina to lead open research in AI4Math. The Numina Math 7B model won the 1st progress prize of the AI Math Olympiad: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/JiaLi52524397/status/1808886880164880631&amp;sa=D&amp;source=editors&amp;ust=1730413583814331&amp;usg=AOvVaw0_LwbI1v9kW1-0yd4Re8AR">https://x.com/JiaLi52524397/status/1808886880164880631</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span class="c1">It even impressed Fields medalist Terrance Tao</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 961.33px;"><img alt="" src="images/image64.png" style="width: 624.00px; height: 961.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span class="c1">Not as good as the Opus model they said is coming out later this year</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span class="c18">Exclusive: OpenAI working on new reasoning technology under code name &lsquo;Strawberry&rsquo; </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/artificial-intelligence/openai-working-new-reasoning-technology-under-code-name-strawberry-2024-07-12/&amp;sa=D&amp;source=editors&amp;ust=1730413583814794&amp;usg=AOvVaw2W5OwkPJ3rt4xi53Ie37vO">https://www.reuters.com/technology/artificial-intelligence/openai-working-new-reasoning-technology-under-code-name-strawberry-2024-07-12/</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span class="c1">&#39;A different source briefed on the matter said OpenAI has tested AI internally that scored over 90% on a MATH dataset, a benchmark of championship math problems. Reuters could not determine if this was the &quot;Strawberry&quot; project.&#39;</span></li><li class="c10 li-bullet-0"><span class="c1">The MATH dataset is challenging: large language models achieved accuracies ranging from 3.0% to 6.9%. Despite these low accuracies, models clearly possess some mathematical knowledge: they achieve up to 15% accuracy on the easiest difficulty level, and they are able to generate step-by-step solutions that are coherent and on-topic even when incorrect. We also evaluated humans on MATH, and found that a computer science PhD student who does not especially like mathematics attained approximately 40% on MATH, while a three-time IMO gold medalist attained 90%, indicating that MATH can be challenging for humans as well.</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/be83ab3ecd0db773eb2dc1b0a17836a1-Paper-round2.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583815178&amp;usg=AOvVaw0CZ9-rjV1ehqF6QyZ1cema">https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/be83ab3ecd0db773eb2dc1b0a17836a1-Paper-round2.pdf</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1"><li class="c10 li-bullet-0"><span class="c18 c14">Significant progress in Gemini 1.5 Pro across all key benchmarks; TL;DR: 1.5 Pro &gt; 1.0 Ultra, 1.5 Flash (our fastest model) ~= 1.0 Ultra. A math-specialised variant of Gemini 1.5 Pro performs strongly on competition-level math problems, including a breakthrough performance of 91.1% on Hendryck&rsquo;s MATH benchmark without tool-use: </span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/OriolVinyalsML/status/1791521517211107515?t%3Duf0Sgqt_UpU_QsXB5w-HJA%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413583815440&amp;usg=AOvVaw3QStnGnqcx2M3fxmsxkZHT">https://x.com/OriolVinyalsML/status/1791521517211107515?t=uf0Sgqt_UpU_QsXB5w-HJA&amp;s=19</a></span><span class="c40 c18 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 585.98px; height: 220.49px;"><img alt="" src="images/image208.png" style="width: 585.98px; height: 220.49px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>Alibaba unveils Qwen2-Math. New open weights model that outperforms closed source ones in Math benchmarks: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Alibaba_Qwen/status/1821553401744015816&amp;sa=D&amp;source=editors&amp;ust=1730413583815824&amp;usg=AOvVaw0hRpRpksHTLWXpkADKVRz7">https://x.com/Alibaba_Qwen/status/1821553401744015816</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image369.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image60.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 c46 li-bullet-0"><span class="c40 c18 c14"></span></li><li class="c45 li-bullet-0"><span class="c14">NuminaMath 72b TIR model: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/JiaLi52524397/status/1814957190320631929/&amp;sa=D&amp;source=editors&amp;ust=1730413583816317&amp;usg=AOvVaw1JSJdOgeQGaVyWXaQdYbBf">https://x.com/JiaLi52524397/status/1814957190320631929/</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c59 li-bullet-0"><span class="c1 c14">Trained on new competition math dataset ever released, with 860K problem solution pairs.</span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 514.67px;"><img alt="" src="images/image35.png" style="width: 624.00px; height: 514.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c59 li-bullet-0"><span class="c1 c14">For AMC 10 2023, the average score is 43%, </span></li><li class="c59 li-bullet-0"><span class="c39 c37 c14">AIME Floor: 70% (top ~6%)</span></li><li class="c177 c97 c14 c105 li-bullet-0"><span class="c39 c37 c14">Distinction: 75%</span></li><li class="c177 c97 c14 c105 li-bullet-0"><span class="c39 c37 c14">Distinguished Honor Roll: 90%</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 512.00px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 512.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://mathvista.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583817097&amp;usg=AOvVaw1VwEbHBbzDPKVJwYoGmGYE">https://mathvista.github.io/</a></span></li><li class="c22 c72 c14 li-bullet-0"><span class="c35 c34 c14 c127">test</span><span class="c92 c37 c35 c48 c14 c127">: 5,141 examples for standard evaluation. Notably, the answer labels for test will NOT be publicly released</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c92 c37 c35 c48 c14 c127">Human performance is 60.8%. Average human performance is from AMT annotators who have high school diplomas or above.</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 712.00px;"><img alt="" src="images/image136.png" style="width: 624.00px; height: 712.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c1">Scores of o1-preview and GPT-4o on &quot;official national exam in abstract mathematics used in Dutch high schools.&quot; Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: &quot;System 2 thinking in OpenAI&rsquo;s o1-preview model: Near-perfect performance on a mathematics exam&quot; &nbsp;</span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 406.67px;"><img alt="" src="images/image132.png" style="width: 624.00px; height: 406.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-0"><li class="c4 li-bullet-0"><span>AI is better at math than these humans: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Teachers/comments/1axhne2/the_public_needs_to_know_the_ugly_truth_students/&amp;sa=D&amp;source=editors&amp;ust=1730413583817935&amp;usg=AOvVaw3GcGpcfIM3LZCyAsyp4Ylf">https://www.reddit.com/r/Teachers/comments/1axhne2/the_public_needs_to_know_the_ugly_truth_students/</a></span></li><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413583818176&amp;usg=AOvVaw04x_bSP5-FLj2eUh1YUpdk">https://arxiv.org/abs/2410.06209</a></span></li></ul><ul class="c0 lst-kix_evcxr39uk36z-1 start"><li class="c10 li-bullet-0"><span>LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><h2 class="c64" id="h.dzn1tzdnxj0o"><span class="c40 c37 c48 c75">8.2. Medicine</span></h2><ul class="c0 lst-kix_xczac0sw8y6a-0 start"><li class="c4 li-bullet-0"><span>New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/&amp;sa=D&amp;source=editors&amp;ust=1730413583818718&amp;usg=AOvVaw2SZqBhcm-dwLQd8ioVK6PC">https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 596.00px;"><img alt="" src="images/image575.jpg" style="width: 624.00px; height: 596.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_xczac0sw8y6a-1 start"><li class="c22 c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DeryaTR_/status/1834630356286558336&amp;sa=D&amp;source=editors&amp;ust=1730413583819021&amp;usg=AOvVaw3Wg_7j-BeMP0uvLuMeHsL_">https://x.com/DeryaTR_/status/1834630356286558336</a></span></li></ul><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c22 c4 li-bullet-0"><span class="c14">New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S135964462400134X&amp;sa=D&amp;source=editors&amp;ust=1730413583819257&amp;usg=AOvVaw3Pa75Ri53IaSkpYQ2hQzJO">https://www.sciencedirect.com/science/article/pii/S135964462400134X</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9 c129"><span class="c1"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span>AI Detects More Breast Cancers with Fewer False Positives </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers&amp;sa=D&amp;source=editors&amp;ust=1730413583819551&amp;usg=AOvVaw1FvvdIESQr4Cu0bgVU2uHY">https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers</a></span></li></ul><ul class="c0 lst-kix_xczac0sw8y6a-1 start"><li class="c10 li-bullet-0"><span class="c1">Recall (false positive) rate and radiologist reading workload decreased significantly in AI-screened group</span></li><li class="c10 li-bullet-0"><span class="c1">Using AI, breast radiologists in Denmark have improved breast cancer screening performance and reduced the rate of false-positive findings.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">In total, 60,751 women were screened without AI, and 58,246 women were screened with the AI system. In the AI implementation group, 66.9% (38,977) of the screenings were single-read, and 33.1% (19,269) were double-read with AI assistance. </span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">Compared to screening without AI, screening with the AI system detected significantly more breast cancers (0.82% versus 0.70%) and had a lower false-positive rate (1.63% versus 2.39%). </span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">&ldquo;In the AI-screened group, the recall rate decreased by 20.5 percent, and the radiologists&rsquo; reading workload was lowered by 33.4 percent,&rdquo; Dr. Lauritzen said.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">The positive predictive value of AI screening was also greater than that of screening without AI (33.5% versus 22.5%). In the AI group, a higher proportion of invasive cancers detected were 1 centimeter or less in size (44.93% vs. 36.60%).</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">&ldquo;All screening performance indicators improved except for the node-negative rate which showed no evidence of change,&rdquo; Dr. Lauritzen said.</span></li></ul><p class="c9"><span class="c92 c37 c65 c126 c81"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span>AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients&rsquo; tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color&amp;sa=D&amp;source=editors&amp;ust=1730413583820635&amp;usg=AOvVaw0M0_myGkB9_ir4H6UPcxlb">https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c10 li-bullet-0"><span>the paper itself shows that the best model has a f1 score, precision, recall all above 98% </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mdpi.com/2227-7080/12/7/97&amp;sa=D&amp;source=editors&amp;ust=1730413583821009&amp;usg=AOvVaw2xUSmC4NYTF07cqynWtC31">https://www.mdpi.com/2227-7080/12/7/97</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span>AI spots cancer and viral infections at nanoscale precision: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html&amp;sa=D&amp;source=editors&amp;ust=1730413583821343&amp;usg=AOvVaw0sw-6RGo9R5HPkFIvRNX-k">https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/?f%3Dflair_name%253A%2522AI%2522&amp;sa=D&amp;source=editors&amp;ust=1730413583821543&amp;usg=AOvVaw2M9oE3FuzhEdyUbJtErAlf"></a></span></p><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c10 li-bullet-0"><span class="c1">Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span>AI Detects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131&amp;sa=D&amp;source=editors&amp;ust=1730413583821933&amp;usg=AOvVaw1w1-WOZQQuUVvpS0hHntVK">https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c45 li-bullet-0"><span class="c6">GPs use AI to boost cancer detection rates in England by 8%: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8&amp;sa=D&amp;source=editors&amp;ust=1730413583822385&amp;usg=AOvVaw26ysSPVTX6Eb-UPARRm9zI">https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8</a></span></li></ul><p class="c22 c44 c129"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c22 c32 li-bullet-0"><span class="c63 c14">AI Outperforms Radiologists in Detecting Prostate Cancer on MRI: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://www.insideprecisionmedicine.com/topics/patient-care/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/&amp;sa=D&amp;source=editors&amp;ust=1730413583822874&amp;usg=AOvVaw14Lw7S_8wjSe81ksaFjB7f">https://www.insideprecisionmedicine.com/topics/patient-care/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/</a></span></li></ul><p class="c22 c44"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c22 c72 li-bullet-0"><span class="c63 c14 c227">AI detected nearly seven percent more significant prostate cancers than the radiologists. Moreover, AI triggered false alarms 50 percent less often, potentially reducing the number of unnecessary biopsies by half. These findings suggest that AI could significantly alleviate the workload of radiologists, improve diagnostic accuracy, and minimize unnecessary procedures.&rdquo;</span></li></ul><p class="c22 c104 c97"><span class="c40 c42 c37 c14">&nbsp;</span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c22 c32 li-bullet-0"><span class="c99 c37 c65 c60 c144">Med-Gemini : h</span><span class="c37 c65 c60 c68"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.18416&amp;sa=D&amp;source=editors&amp;ust=1730413583823547&amp;usg=AOvVaw3BNd6ibu7wTx821jEcSfF-">ttps://arxiv.org/abs/2404.18416</a></span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c22 c72 li-bullet-0"><span class="c3">&gt;We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health &amp; medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini&#39;s long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini&#39;s performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. </span></li></ul><p class="c22 c44"><span class="c3"></span></p><p class="c22 c44"><span class="c3"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c18">Double-blind study with Patient Actors and Doctors, who didn&#39;t know if they were communicating with a human, or an AI. Best performers were AI:</span><span class="c18"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DjQwwLEZ2Hz8&amp;sa=D&amp;source=editors&amp;ust=1730413583824464&amp;usg=AOvVaw1w9AlLcD_o7SPpQ5x6uP8Z">&nbsp;</a></span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DjQwwLEZ2Hz8&amp;sa=D&amp;source=editors&amp;ust=1730413583824645&amp;usg=AOvVaw3f7GDTpMbgpSl6w1-zaWVb">https://m.youtube.com/watch?v=jQwwLEZ2Hz8</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c10 li-bullet-0"><span class="c15 c65 c114">&gt;Human doctors + AI did worse, than AI by itself.</span><span class="c40 c18">&nbsp;The mere involvement of a human reduced the accuracy of the diagnosis.</span></li><li class="c10 li-bullet-0"><span class="c15 c65 c114">AI was consistently rated to have better bedside manner than human doctors</span><span class="c40 c18">. </span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c14">[Google&#39;s medical AI destroys GPT&#39;s benchmark and outperforms doctors](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/google-med-gemini-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583825340&amp;usg=AOvVaw3LREVp4fZVS8z1Tlk5NZ5w">https://newatlas.com/technology/google-med-gemini-ai/</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c18 c139">Med-Gemini&#39;s outputs are preferred to drafts from clinicians for common and time-consuming real-world tasks such as simplifying or summarising long medical notes, or drafting referral letters: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/alan_karthi/status/1785117444383588823&amp;sa=D&amp;source=editors&amp;ust=1730413583825757&amp;usg=AOvVaw2EEZ9FEOhEg8EDPr0bePDz">https://x.com/alan_karthi/status/1785117444383588823</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_xczac0sw8y6a-1 start"><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 281.33px;"><img alt="" src="images/image413.png" style="width: 624.00px; height: 281.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c14">[The first randomized trial of medical #AI to show it saves lives. ECG-AI alert in 16,000 hospitalized patients. 31% reduction of mortality (absolute 7 per 100 patients) in pre-specified high-risk group](</span><span class="c20 c124 c34 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/erictopol/status/1784936718283805124&amp;sa=D&amp;source=editors&amp;ust=1730413583826291&amp;usg=AOvVaw1UZdlxjCkWol5fri98L7jz">https://twitter.com/erictopol/status/1784936718283805124</a></span><span class="c40 c124 c34 c14">)</span></li></ul><p class="c9"><span class="c40 c34 c14 c124"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c18">Medical Text Written By Artificial Intelligence Outperforms Doctors:</span><span class="c18"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/&amp;sa=D&amp;source=editors&amp;ust=1730413583826734&amp;usg=AOvVaw1SEyf6HxisA2319WmErnTf">&nbsp;</a></span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/&amp;sa=D&amp;source=editors&amp;ust=1730413583826982&amp;usg=AOvVaw1e9YSxUnhULdybiGxSO92F">https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c14">AI can make healthcare better and safer:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1brojzm/ais_will_make_health_care_safer_and_better/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583827446&amp;usg=AOvVaw0LJ7R_6PvACH98Fn3UzQKN">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.economist.com/technology-quarterly/2024/03/27/ais-will-make-health-care-safer-and-better&amp;sa=D&amp;source=editors&amp;ust=1730413583827672&amp;usg=AOvVaw3408zZBCPmQuyWF38XSliF">https://www.economist.com/technology-quarterly/2024/03/27/ais-will-make-health-care-safer-and-better</a></span></li></ul><p class="c9"><span class="c20 c57 c37 c48 c14 c225"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c18">CheXzero significantly outperformed humans, especially on uncommon conditions. Huge implications for improving diagnosis of neglected &quot;long tail&quot; diseases:</span><span class="c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/pranavrajpurkar/status/1797292562333454597&amp;sa=D&amp;source=editors&amp;ust=1730413583828056&amp;usg=AOvVaw01qqaooEjF6KInHpVrEOp_">&nbsp;</a></span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/pranavrajpurkar/status/1797292562333454597&amp;sa=D&amp;source=editors&amp;ust=1730413583828234&amp;usg=AOvVaw07EgSPbTB-HyRaIt4D9TWc">https://x.com/pranavrajpurkar/status/1797292562333454597</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 612.00px; height: 370.67px;"><img alt="" src="images/image251.png" style="width: 612.00px; height: 370.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_xczac0sw8y6a-2 start"><li class="c7 li-bullet-0"><span class="c40 c18">&gt;Humans near chance level (50-55% accuracy) on rarest conditions, while CheXzero maintains 64-68% accuracy.</span></li></ul><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image602.png" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c6">AI is better than doctors at detecting breast cancer:</span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.bing.com/videos/search?q%3Dai%2Bbetter%2Bthan%2Bdoctors%2Busing%2Bai%26mid%3D6017EF2744FCD442BA926017EF2744FCD442BA92%26view%3Ddetail%26FORM%3DVIRE%26PC%3DEMMX04&amp;sa=D&amp;source=editors&amp;ust=1730413583829064&amp;usg=AOvVaw0MU_CWKDDx-6ygFJ4QxejD">&nbsp;</a></span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/health-50857759&amp;sa=D&amp;source=editors&amp;ust=1730413583829250&amp;usg=AOvVaw1nXXKsufeM31XBESYlLjOR">https://www.bbc.com/news/health-50857759</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c14">&lsquo;I will never go back&rsquo;: Ontario family doctor says new AI notetaking saved her job:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583829659&amp;usg=AOvVaw0lh-bbTBy38bApHPErTCVS">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413583829874&amp;usg=AOvVaw2IWV0ddoS2R43Bylh9d8m2">https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span>China&#39;s first (simulated) AI hospital town debuts: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.globaltimes.cn/page/202405/1313235.shtml&amp;sa=D&amp;source=editors&amp;ust=1730413583830263&amp;usg=AOvVaw2xGhvGQPWBXjoJX3v6gcQt">https://www.globaltimes.cn/page/202405/1313235.shtml</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-1"><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">&gt;Remarkably, AI doctors can treat 10,000 [simulated] &nbsp;patients in just a few days. It would take human doctors at least two years to treat that many patients. Furthermore, evolved doctor agents achieved an impressive 93.06 percent accuracy rate on the MedQA dataset (US Medical Licensing Exam questions) covering major respiratory diseases. They simulate the entire process of diagnosing and treating patients, including consultation, examination, diagnosis, treatment and follow-up.</span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c45 li-bullet-0"><span class="c6">Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx&amp;sa=D&amp;source=editors&amp;ust=1730413583830944&amp;usg=AOvVaw3PMyh8_1XVQqEkeu2cU6TD">https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx</a></span><span class="c6 c40">&nbsp;</span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c45 li-bullet-0"><span class="c6">ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583831391&amp;usg=AOvVaw1gss_FqLKPCFChdwXM78q_">https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1</a></span></li></ul><p class="c73 c46 c129"><span class="c6 c40"></span></p><ul class="c0 lst-kix_snh8lpyqaleg-0"><li class="c45 li-bullet-0"><span class="c6">AI just as good at diagnosing illness as humans: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.medicalnewstoday.com/articles/326460?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583831774&amp;usg=AOvVaw3FvvpbsEE0NKzQrwLFK4iA">https://www.medicalnewstoday.com/articles/326460</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c6">AI can replace doctors: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583832155&amp;usg=AOvVaw2xQzGoremLFG7CFSVQrxQA">https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr=1</a></span></li></ul><p class="c73 c46"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span>Geoffrey Hinton says AI doctors who have seen 100 million patients will be much better than human doctors and able to diagnose rare conditions more accurately: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1797169362799091934&amp;sa=D&amp;source=editors&amp;ust=1730413583832557&amp;usg=AOvVaw18ppghrG8o3d6FgL4LzHIi">https://x.com/tsarnick/status/1797169362799091934</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c45 li-bullet-0"><span class="c63 c14">AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1814048365002596425&amp;sa=D&amp;source=editors&amp;ust=1730413583832954&amp;usg=AOvVaw3R6-k8-sObf3BX7JQTokHI">https://x.com/tsarnick/status/1814048365002596425</a></span></li><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.00px; height: 925.00px;"><img alt="" src="images/image505.png" style="width: 569.00px; height: 925.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_xczac0sw8y6a-0"><li class="c4 li-bullet-0"><span class="c14">[</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583833413&amp;usg=AOvVaw1IKq90W5arvzlFu34CdtBJ">Generative AI will be designing new drugs all on its own in the near future]</a></span><span class="c14">(</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html&amp;sa=D&amp;source=editors&amp;ust=1730413583833604&amp;usg=AOvVaw3a3oibjCfTtIABzeEM4vcZ">https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html</a></span><span class="c1 c14">)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span>In a historic moment for the dental profession, an AI-controlled autonomous robot has performed an entire procedure on a human patient for the first time, about eight times faster than a human dentist could do it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/health-wellbeing/robot-dentist-world-first/&amp;sa=D&amp;source=editors&amp;ust=1730413583833990&amp;usg=AOvVaw3Xdp-XUzyeHRVYSuDSgHKB">https://newatlas.com/health-wellbeing/robot-dentist-world-first/</a></span></li><li class="c4 li-bullet-0"><span>Tx-LLM: Supporting therapeutic development with large language models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413583834367&amp;usg=AOvVaw2kmjsuH3t4hYrTyh9yc_JW">https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/</a></span></li><li class="c4 li-bullet-0"><span>BrainLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583834699&amp;usg=AOvVaw0aZOA_K4AfF8pf57lq33TZ">https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf</a></span></li></ul><ul class="c0 lst-kix_b966qb5z56w2-1 start"><li class="c10 li-bullet-0"><span>Utilizing self-supervised masked-prediction training, BrainLM demonstrates </span><span class="c15">proficiency in both fine-tuning and zero-shot inference tasks</span><span>. Fine-tuning allows for the </span><span class="c15">accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states</span><span>. Critically, the model </span><span class="c15">generalizes well to entirely new external cohorts not seen during training.</span><span>&nbsp;In zero-shot inference mode, BrainLM can i</span><span class="c15">dentify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training</span><span>. The model also generates i</span><span class="c15">nterpretable latent representations that reveal relationships between brain activity patterns and cognitive states</span><span>. Overall, BrainLM offers a </span><span class="c34">versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. </span><span>It serves as a powerful &quot;lens&quot; through which m</span><span class="c15">assive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale</span><span class="c1">. The work demonstrates the potential of foundation models to advance computational neuroscience research. </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 444.00px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 444.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 601.33px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 601.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 568.00px;"><img alt="" src="images/image38.png" style="width: 624.00px; height: 568.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 160.00px;"><img alt="" src="images/image133.png" style="width: 624.00px; height: 160.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 653.33px;"><img alt="" src="images/image211.png" style="width: 624.00px; height: 653.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 613.96px; height: 520.50px;"><img alt="" src="images/image13.png" style="width: 613.96px; height: 520.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_b966qb5z56w2-0"><li class="c4 li-bullet-0"><span>Cardiologists working with AI said it was equal or better than human cardiologists in most areas: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DKThomp/status/1843993273825964312&amp;sa=D&amp;source=editors&amp;ust=1730413583836272&amp;usg=AOvVaw2KP5gX81DHP8p0v6XVH74S">https://x.com/DKThomp/status/1843993273825964312</a></span></li></ul><ul class="c0 lst-kix_b966qb5z56w2-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 209.33px;"><img alt="" src="images/image77.png" style="width: 624.00px; height: 209.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h1 class="c123" id="h.4j57a8xqgokw"><span class="c14">9. </span><span class="c40 c37 c48 c77 c14">Morality/AI Is Not Theft</span></h1><ul class="c0 lst-kix_wdnsgpew1acl-0 start"><li class="c51 li-bullet-0"><span class="c6 c40">Imagine if the first dude who painted a wall didn&#39;t give &quot;consent&quot; for some other dude to &quot;copy&quot; his cave painting. We wouldn&#39;t have art today.</span></li><li class="c4 li-bullet-0"><span class="c6 c40">AI training is similar to how people learn now. They read/see other people&rsquo;s work, which is usually copyrighted, and get inspired to make their own. If it is moral for humans to do that without permission or compensation (even if they make money from it), it is moral for AI to do the same.</span></li></ul><ul class="c0 lst-kix_wdnsgpew1acl-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">And yes, AI does not learn like humans do. Birds and planes are fundamentally different too. But they both fly even if their method of doing it is not the same. </span></li><li class="c10 li-bullet-0"><span class="c14">Example 1: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://faroutmagazine.co.uk/the-godfather-directly-inspired-breaking-bad/&amp;sa=D&amp;source=editors&amp;ust=1730413583837026&amp;usg=AOvVaw2IUdEhiIYU_lQhwi4jKJy6">The director Breaking Bad, Vince Gilligan, stated that The Godfather was a main inspiration for the show.</a></span><span class="c1 c14">&nbsp;Yet the owner of The Godfather was not paid any royalties for it despite Breaking Bad being a for-profit show. &nbsp;</span></li><li class="c10 li-bullet-0"><span class="c1 c14">Example 2: People draw fan art all the time without paying or getting permission, including profiting from it on Patreon or Gumroad and potentially damaging the brands by creating NSFW content of copyrighted characters.</span></li><li class="c10 li-bullet-0"><span class="c1 c14">Example 3: Everyone is a product of the sum of their experiences similar to how AI is a product of analyzing countless images or texts. Yet AI is expected to credit or compensate for everything it analyzes while humans are not.</span></li></ul><ul class="c0 lst-kix_wdnsgpew1acl-0"><li class="c4 li-bullet-0"><span class="c1 c14">&ldquo;Why are you defending big corporations?&rdquo;</span></li></ul><ul class="c0 lst-kix_wdnsgpew1acl-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">The fact big corporations benefit does not make AI bad. Vaccines and the Internet are also defensible even though they help Big Pharma or ISPs profit.</span></li></ul><ul class="c0 lst-kix_wdnsgpew1acl-0"><li class="c4 li-bullet-0"><span class="c1 c14">AI voice generation is not much different from someone doing a good voice impression. Both can be used for malicious purposes, but we still find the latter acceptable.</span></li><li class="c4 li-bullet-0"><span class="c14">Twitter/X is banning </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://blog.twitter.com/en_us/topics/company/2023/an-update-on-our-work-to-tackle-child-sexual-exploitation-on-x&amp;sa=D&amp;source=editors&amp;ust=1730413583837536&amp;usg=AOvVaw163a4iSDnOPhsQr4oqJw69">millions of accounts a year</a></span><span class="c1 c14">&nbsp;for CSAM, but we don&rsquo;t consider Twitter to be inherently immoral because CSAM exists on their servers. Services need to make a reasonable, good faith effort to remove this material anywhere it is found and work with law enforcement to help catch the perpetrators. In this case, a small amount of CSAM was found in some of the LAION training links used to train Stabke Diffusion, LAION was made aware, and they took all their datasets offline temporarily while they removed those links from the listings.</span></li></ul><ul class="c0 lst-kix_wdnsgpew1acl-1 start"><li class="c10 li-bullet-0"><span class="c1 c14">That is the response of an organization making a good faith effort to remove CSAM from their work. Instead of pearl clutching any time someone does something illegal on the internet, we should look at what actions we expect companies and services to take, and ensure they are taking those actions. </span></li><li class="c10 li-bullet-0"><span class="c1 c14">If our expectation is that any company that unknowingly has CSAM on their site should be permanently shut down, that will be an impossible task.</span></li></ul><ul class="c0 lst-kix_wdnsgpew1acl-0"><li class="c4 li-bullet-0"><span class="c14">Child abuse images removed from AI image-generator training source, researchers say: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://apnews.com/article/ai-image-generators-child-sexual-abuse-laion-stable-diffusion-2652b0f4245fb28ced1cf74c60a8d9f0&amp;sa=D&amp;source=editors&amp;ust=1730413583837941&amp;usg=AOvVaw3nWVMjQHrOEnI37bB53cBZ">https://apnews.com/article/ai-image-generators-child-sexual-abuse-laion-stable-diffusion-2652b0f4245fb28ced1cf74c60a8d9f0</a></span></li><li class="c4 li-bullet-0"><span class="c1">This is not how plagiarism works. You can&rsquo;t copy everyone. There have to be substantial similarities between the AI output and a specific work.</span></li><li class="c4 li-bullet-0"><span class="c1">If AI takes jobs, it&rsquo;s similar to previous industries being obsolete, like coal mining and manufacturing industries. Times change, and people should change with it by getting new skills. Coal miners were told to learn to code, so coders should learn to weld or do construction work.</span></li><li class="c4 li-bullet-0"><span class="c1">&ldquo;Good artists borrow, great artists steal&rdquo; &nbsp;- Pablo Picasso</span></li></ul><p class="c9"><span class="c1"></span></p><h1 class="c123" id="h.tezj6n5cpoxy"><span class="c14">10. </span><span class="c40 c37 c48 c77 c14">Legality</span></h1><ul class="c0 lst-kix_yn02lgpxo9se-0 start"><li class="c4 li-bullet-0"><span>LAION wins copyright infringement lawsuit in German court: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technollama.co.uk/laion-wins-copyright-infringement-lawsuit-in-german-court&amp;sa=D&amp;source=editors&amp;ust=1730413583838543&amp;usg=AOvVaw0-ezFGrzf4h7C2mPeildxt">https://www.technollama.co.uk/laion-wins-copyright-infringement-lawsuit-in-german-court</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span class="c1">TL;DR: The use of copyrighted art for training purposes counts as scientific research and is legal in Germany.</span></li><li class="c10 li-bullet-0"><span class="c1">No reason to think US courts would be more strict than an EU nation.</span></li></ul><p class="c9"><span class="c92 c99 c37 c65 c60 c144"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span>Legal claims against AI debunked: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/&amp;sa=D&amp;source=editors&amp;ust=1730413583839067&amp;usg=AOvVaw1OStx-wn-3YaCSOcFw7pLu">https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/</a></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span>courts are rejecting that just because an ai model was trained on a copyrighted work it or its output is an infringing work. In fact, it finds such claims either </span><span class="c33 c15">have no legal basis or it is so unlikely to be true that that the court don&rsquo;t think worth letting such a claim go on to discovery.</span></li><li class="c10 li-bullet-0"><span>the law firm doing these cases </span><span class="c33 c15">couldn&rsquo;t come up with a legal theory of how the trainers of the model were removing copyright information illegally.</span></li><li class="c10 li-bullet-0"><span class="c52 c37 c14">The removal of copyright management information (&ldquo;CMI,&rdquo; which includes information such as the title, the copyright holder, and other identifying information in a copyright notice) is a claim included in almost all plaintiffs&rsquo; complaints in the AI lawsuits, and </span><span class="c52 c15">this claim has failed to survive motions to dismiss without exception</span><span class="c52 c37 c14">. </span><span class="c133 c34 c60 c118 c14"><a class="c13" href="https://www.google.com/url?q=https://www.law.cornell.edu/uscode/text/17/1202&amp;sa=D&amp;source=editors&amp;ust=1730413583839513&amp;usg=AOvVaw0Bjj85y_oRi7PDTwFaqkx0">DMCA Section 1202(b)</a></span><span class="c52 c37 c14">&nbsp;restricts the intentional, unauthorized removal of CMI. Experts initially considered DMCA 1202(b) one of the biggest hurdles for non-licensed AI training. </span><span class="c52 c15">But courts so far have dismissed all DMCA 1202(b) claims, </span><span class="c52 c37 c14">including in </span><span class="c52 c37 c61 c14">J. Doe 1 v. GitHub, Tremblay v. OpenAI,</span><span class="c52 c37 c14">&nbsp;</span><span class="c52 c37 c61 c14">Andersen v. Stability AI</span><span class="c52 c37 c14">, </span><span class="c52 c37 c61 c14">Kadrey v. Meta Platforms, </span><span class="c52 c37 c14">and</span><span class="c52 c37 c61 c14">&nbsp;Silverman v. OpenAI</span><span class="c52 c37 c14">. The plaintiffs&rsquo; DMCA Section 1202(b)(1) claims have failed because </span><span class="c15 c52">plaintiffs were not able to offer any evidence showing their CMI has been intentionally removed by the AI companies</span><span class="c52 c37 c14">. For example, in </span><span class="c52 c37 c61 c14">Tremblay v. OpenAI </span><span class="c52 c37 c14">and</span><span class="c52 c37 c61 c14">&nbsp;Silverman v. OpenAI</span><span class="c52 c37 c14">, the courts held that the plaintiffs did not argue plausibly that OpenAI has intentionally removed CMI when ingesting plaintiffs&rsquo; works for training.</span><span class="c52 c37 c61 c14">&nbsp;</span><span class="c52 c37 c14">Additionally, plaintiffs&rsquo; DMCA Section 1202(b)(3) have failed thus far because the plaintiffs&rsquo; claims did not fulfill the identicality requirement. For example, in </span><span class="c52 c37 c61 c14">J. Doe 1 v. GitHub, </span><span class="c52 c37 c14">the court pointed out that</span><span class="c52 c37 c61 c14">&nbsp;</span><span class="c52 c37 c14">Copilot&rsquo;s output </span><span class="c52 c15">did not tend to represent verbatim copies of the original ingested code</span><span class="c52 c37 c14">. We now see plaintiffs voluntarily dropping the DMCA claims in their amended complaints, such as in </span><span class="c52 c37 c61 c14">Leovy v Google </span><span class="c52 c37 c14">(formerly </span><span class="c52 c37 c61 c14">J.L. vs Alphabet</span><span class="c52 c37 c14">)</span><span class="c52 c37 c61 c14">.</span><span class="c79 c37 c60 c118 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c52 c37 c14">Another claim that has been </span><span class="c52 c15">consistently dismissed by courts is that AI models are infringing derivative works of the training materials.</span><span class="c52 c37 c14">&nbsp;The law defines a derivative work as &ldquo;a work based upon one or more preexisting works, such as a translation, musical arrangement, &hellip; art reproduction, abridgment, condensation, or any other form in which a work may be recast, transformed, or adapted.&rdquo; To most of us, the idea that the model itself (as opposed to, say, outputs generated by the model) can be considered a derivative work seems to be a stretch. The courts have so far agreed. On November 20, 2023, </span><span class="c52 c15">the court in </span><span class="c52 c15 c61">Kadrey v. Meta Platforms </span><span class="c79 c15 c60 c118">said it is &ldquo;nonsensical&rdquo; to consider an AI model a derivative work of a book just because the book is used for training. </span></li><li class="c22 c128 c97 c105 li-bullet-0"><span class="c52 c37 c14">Similarly, </span><span class="c52 c15">claims that all AI outputs should be automatically considered infringing derivative works have been dismissed by courts,</span><span class="c52 c37 c14">&nbsp;because the </span><span class="c52 c15">claims cannot point to specific evidence that an instance of output is substantially similar to an ingested work.</span><span class="c52 c37 c14">&nbsp;</span><span class="c133 c34 c60 c118 c14"><a class="c13" href="https://www.google.com/url?q=https://storage.courtlistener.com/recap/gov.uscourts.cand.407208/gov.uscourts.cand.407208.117.0_3.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583840771&amp;usg=AOvVaw1gtenLEfKigaTPY5hGL5rg">In </a></span><span class="c34 c61 c60 c118 c14 c133"><a class="c13" href="https://www.google.com/url?q=https://storage.courtlistener.com/recap/gov.uscourts.cand.407208/gov.uscourts.cand.407208.117.0_3.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413583840954&amp;usg=AOvVaw2igEjKoGWmTT-OvDS1OjUn">Andersen v. Stability AI,</a></span><span class="c52 c37 c14">&nbsp;plaintiffs tried to argue &ldquo;that all elements of &hellip; Anderson&rsquo;s copyrighted works &hellip; were copied wholesale as Training Images and therefore the Output Images are necessarily derivative;&rdquo; </span><span class="c52 c34 c14">the court dismissed the argument </span><span class="c52 c37 c14">because&mdash;besides the fact that </span><span class="c52 c15">plaintiffs are unlikely able to show substantial similarity</span><span class="c52 c37 c14">&mdash;&ldquo;it is simply not plausible that every Training Image used to train Stable Diffusion was copyrighted &hellip; or that all &hellip; Output Images rely upon (theoretically) copyrighted Training Images and therefore all Output images are derivative images. &hellip; [The argument for dismissing these claims is strong] especially in light of </span><span class="c52 c15">plaintiffs&rsquo; admission that Output Images are unlikely to look like the Training Images</span><span class="c79 c37 c60 c14 c118">.&rdquo;</span></li><li class="c22 c128 c97 c105 li-bullet-0"><span class="c52 c37 c14">Several of these AI cases have raised claims of vicarious liability&mdash;that is, liability for the service provider based on the actions of others, such as users of the AI models. </span><span class="c52 c15">Because a vicarious infringement claim must be based on a showing of direct infringement, the vicarious infringement claims are also dismissed</span><span class="c52 c37 c14">&nbsp;in </span><span class="c52 c37 c14 c61">Tremblay v. OpenAI</span><span class="c52 c37 c14">&nbsp;and </span><span class="c52 c37 c61 c14">Silverman v. OpenAI</span><span class="c52 c37 c14">, when </span><span class="c79 c15 c60 c118">plaintiffs cannot point to any infringing similarity between AI output and the ingested books.</span></li><li class="c22 c128 c97 c105 li-bullet-0"><span class="c52 c37 c14">Many plaintiffs have also raised a number of non-copyright, </span><span class="c52 c15">state law claims (such as negligence or unfair competition) that have largely been dismissed based on copyright preemption.</span><span class="c52 c37 c14">&nbsp;Copyright preemption prevents duplicitous state law claims when those state law claims are based on an exercise of rights that are equivalent to those provided for under the federal Copyright Act. In </span><span class="c52 c37 c61 c14">Andersen v. Stability AI</span><span class="c52 c37 c14">, for example, </span><span class="c52 c15">the court dismissed the plaintiffs&rsquo; unjust enrichment claim</span><span class="c79 c37 c60 c118 c14">&nbsp;because the plaintiffs failed to add any new elements that would distinguish their claim based on California&rsquo;s Unfair Competition Law or common law from rights under the Copyright Act.</span></li><li class="c22 c97 c105 c128 li-bullet-0"><span class="c52 c37 c14">It is interesting to note that </span><span class="c52 c34 c14">many of the dismissed claims in different AI lawsuits closely mimic one another</span><span class="c52 c37 c14">, such as in </span><span class="c52 c37 c61 c14">Kadrey v. Meta Platforms, Andersen v. Stability AI, Tremblay v. OpenAI,</span><span class="c52 c37 c14">&nbsp;and </span><span class="c52 c37 c61 c14">Silverman v. OpenAI.</span><span class="c52 c37 c14">&nbsp;It turns out that the similarities are no coincidence&mdash;</span><span class="c52 c15">all these lawsuits are filed by the same law firm. </span><span class="c52 c37 c14">These mass-produced complaints not only contain </span><span class="c52 c15">overbroad claims that are prone to dismissal, they also have overbroad class designations</span><span class="c79 c37 c60 c118 c14">. </span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span>Judge sharply criticizes lawyers for authors in AI suit against Meta: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.politico.com/news/2024/09/20/judge-sharply-criticizes-lawyers-ai-lawsuit-meta-00180348&amp;sa=D&amp;source=editors&amp;ust=1730413583842271&amp;usg=AOvVaw0MZPOmLUwfsZvyqSEFKUCU">https://www.politico.com/news/2024/09/20/judge-sharply-criticizes-lawyers-ai-lawsuit-meta-00180348</a></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span class="c52 c37 c14">&ldquo;</span><span class="c1">It&rsquo;s very clear to me from the papers, from the docket and from talking to the magistrate judge that you have brought this case and you have not done your job to advance it,&rdquo; the judge said. &ldquo;You and your team have barely been litigating the case. That&rsquo;s obvious&hellip;.This is not your typical proposed class action. This is an important case. It&rsquo;s an important societal issue. It&rsquo;s important for your clients.&rdquo;</span></li><li class="c10 li-bullet-0"><span>&ldquo;I think what you need, frankly, is to </span><span class="c34">bring in somebody who can help you litigate the case, who has the resources and the wherewithal to move this case forward</span><span>&hellip;I think you need to </span><span class="c34">reconstitute your legal team</span><span class="c1">&rdquo;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 142.67px;"><img alt="" src="images/image159.jpg" style="width: 624.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-2 start"><li class="c7 li-bullet-0"><span class="c1">Translation: your lawyers are incompetent and should be fired.</span></li><li class="c7 li-bullet-0"><span>But unfortunately, they&rsquo;re the only ones willing to take the case: </span><span class="c52 c37 c14">&ldquo;</span><span class="c52 c34 c14">many of the dismissed claims in different AI lawsuits closely mimic one another</span><span class="c52 c37 c14">, such as in </span><span class="c52 c37 c61 c14">Kadrey v. Meta Platforms, Andersen v. Stability AI, Tremblay v. OpenAI,</span><span class="c52 c37 c14">&nbsp;and </span><span class="c52 c37 c61 c14">Silverman v. OpenAI.</span><span class="c52 c37 c14">&nbsp;It turns out that the similarities are no coincidence&mdash;</span><span class="c52 c15">all these lawsuits are filed by the same law firm. </span><span class="c52 c37 c14">These mass-produced complaints not only contain </span><span class="c52 c15">overbroad claims that are prone to dismissal, they also have overbroad class designations</span><span class="c79 c37 c60 c118 c14">.&rdquo;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/&amp;sa=D&amp;source=editors&amp;ust=1730413583843567&amp;usg=AOvVaw3zLBOphEpVawORJaWCmjHX">https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/</a></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span>Art styles cannot be legally copyrighted: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.thelegalartist.com/blog/you-cant-copyright-style&amp;sa=D&amp;source=editors&amp;ust=1730413583843804&amp;usg=AOvVaw0WUE1ipA3qmiSeUjKLM1PX">https://www.thelegalartist.com/blog/you-cant-copyright-style</a></span></li><li class="c4 li-bullet-0"><span class="c14">Williams won another Oscar for Star Wars and took inspiration from a 1942 movie called Kings Row, composed by Erich Wolfgang Korngold. Can you hear Star Wars? </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/ATRightMovies/status/1794345480207684058&amp;sa=D&amp;source=editors&amp;ust=1730413583844018&amp;usg=AOvVaw1jjyVb2O_zlqxuFgsDBV5a">https://x.com/ATRightMovies/status/1794345480207684058</a></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span>If this can be legally sold for commercial use, why not AI art?</span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span class="c6 c40">AI art is inherently transformative* and, therefore, fair use.</span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span class="c6 c40">*This is why it warps hands, fingers, limbs, eyes, etc. sometimes. If it was just copying and pasting existing images, why would it do that? Additionally, Stable Diffusion 1.5 checkpoints are only 2 GB, not nearly enough space to store anywhere close to all the images it was trained on. It can also generate infinite variations of absurd or extremely strange images that would not be well represented in its training data. </span></li><li class="c49 li-bullet-0"><span class="c40 c30 c37 c14">Stable Diffusion models can generate novel images of characters that only existed AFTER the model was trained and released if it uses a Lora trained on those characters. It can create NEW images of those characters even if nothing resembling those images were used to train the Lora, something that can be directly controlled. </span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-2 start"><li class="c7 li-bullet-0"><span class="c40 c30 c37 c14">In other words, if a brand new character is released, I can train a Lora on it, and SD can create new images of that character that I can verify it was NEVER trained on since it won&rsquo;t be in the dataset used to train the Lora. &nbsp;</span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span class="c40 c30 c37 c14">AI training off of data and taking jobs is similar to a human being inspired by a work and taking market share from their inspirations by creating their own. This is not considered immoral, and most artists are generally honored if someone was inspired by their work. </span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span class="c40 c30 c37 c14">Additionally, jobs are frequently automated, such as how milkmen lost their jobs to the rise of supermarkets, coal miners lost their jobs to renewable energy, horse carriage manufacturers lost their jobs to cars, and many mailmen lost their jobs to email. This would not justify banning any of those things and unemployment rates remained low despite these displacements.</span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span class="c40 c30 c37 c14">AI cannot displace artists as artists are still needed to create ideas, integrate scenes together, and fix mistakes. In fact, it can be a great improvement as it will reduce the amount of labor they will need to do that often leads to extreme burnout.</span></li><li class="c4 li-bullet-0"><span class="c40 c30 c37 c14">Even if you believe AI will take jobs, artists are not entitled to jobs and would still be allowed to create art on their own time. However, no one is obligated to employ them. If you have a problem with that, blame capitalism and the requirement of wage labor even when it is no longer needed instead of AI.</span></li><li class="c4 c14 c53 li-bullet-0"><span>Singapore: Copyright Infringement Defence for AI Machine Learning: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://rouse.com/insights/news/2024/artificial-intelligence-in-singapore-copyright-infringement-defence-for-artificial-intelligence-machine-learning&amp;sa=D&amp;source=editors&amp;ust=1730413583844858&amp;usg=AOvVaw3lVxxe2FeWELFuHeScIdWg">https://rouse.com/insights/news/2024/artificial-intelligence-in-singapore-copyright-infringement-defence-for-artificial-intelligence-machine-learning</a></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span>Machine learning requires data and information to learn from and typically this comes from content scraped from third party websites which could potentially be regarded as copyright infringement. This risk could now be neutralised by the Computational Analysis defense of the CA - under section 243</span></li></ul><p class="c9 c53 c14"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 c53 c14 li-bullet-0"><span class="c1 c14">Even if we agree that AI generated images are theft, the users are the ones generating the images, while the AI companies are only providing access to their model. Therefore, the users are the ones violating copyright, not the companies themselves, so they are not liable similar to how photo editing software companies are not liable if a user commits plagiarism using their software.</span></li></ul><p class="c9 c53 c14"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 c53 c14 li-bullet-0"><span class="c1 c14">US Copyright Law - Chapter 1 Section 102 &quot; In no case does copyright protection for an original work of authorship extend to any idea, procedure, process, system, method of operation, concept, principle, or discovery, regardless of the form in which it is described, explained, illustrated, or embodied in such work.&quot;</span></li></ul><p class="c9 c53 c14"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span class="c6">Creating a database of copyrighted work is legal in the US: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._Google,_Inc&amp;sa=D&amp;source=editors&amp;ust=1730413583845448&amp;usg=AOvVaw0YbOuhTttcLLwAmZ-sKkT1">https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._Google,_Inc</a></span><span class="c6 c40">.</span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 c53 c14 li-bullet-0"><span class="c14">Two cases with Bright Data against Meta and Twitter/X show that web scraping publicly available data is not against their ToS or copyright: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Bright_Data&amp;sa=D&amp;source=editors&amp;ust=1730413583845735&amp;usg=AOvVaw0TKYzTvxn32gggFsiCFU9c">https://en.wikipedia.org/wiki/Bright_Data</a></span></li></ul><p class="c9 c53 c14"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-1"><li class="c10 c53 c14 li-bullet-0"><span class="c14">&ldquo;</span><span class="c108 c60 c14">In January 2024, Bright Data won a legal dispute with Meta. A federal judge in San Francisco declared that Bright Data did not breach Meta&#39;s terms of use by scraping data from Facebook and Instagram, consequently denying Meta&#39;s request for summary judgment on claims of contract breach.</span><span class="c107 c14 c68 c125"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Bright_Data%23cite_note-20&amp;sa=D&amp;source=editors&amp;ust=1730413583846103&amp;usg=AOvVaw1B0xV-zOWkuIbIKpeHure4">[20]</a></span><span class="c107 c14 c68 c125"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Bright_Data%23cite_note-21&amp;sa=D&amp;source=editors&amp;ust=1730413583846234&amp;usg=AOvVaw2wNAvGDoAEY4D1HpEiME3X">[21]</a></span><span class="c107 c14 c68 c125"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Bright_Data%23cite_note-22&amp;sa=D&amp;source=editors&amp;ust=1730413583846354&amp;usg=AOvVaw0Ali_s27FR27059Wt-PGMX">[22]</a></span><span class="c92 c37 c108 c60 c48 c14">&nbsp;This court decision in favor of Bright Data&rsquo;s data scraping approach marks a significant moment in the ongoing debate over public access to web data, reinforcing the freedom of access to public web data for anyone.&rdquo;</span></li><li class="c53 c14 c96 li-bullet-0"><span class="c108 c60 c14">&ldquo;In May 2024, a federal judge dismissed a lawsuit by X Corp. (formerly Twitter) against Bright Data, ruling that the company did not violate X&#39;s terms of service or copyright by scraping publicly accessible data.</span><span class="c107 c14 c68 c125"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Bright_Data%23cite_note-25&amp;sa=D&amp;source=editors&amp;ust=1730413583846605&amp;usg=AOvVaw0nE-Rp1F6dAWifC2HnfeCR">[25]</a></span><span class="c108 c60 c14">&nbsp; The judge emphasized that such scraping practices are generally legal and that restricting them could lead to information monopolies,</span><span class="c107 c14 c68 c125"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Bright_Data%23cite_note-26&amp;sa=D&amp;source=editors&amp;ust=1730413583846803&amp;usg=AOvVaw29_bgpLOpYqHVTlzq3AXG2">[26]</a></span><span class="c92 c37 c108 c60 c48 c14">&nbsp;and highlighted that X&#39;s concerns were more about financial compensation than protecting user privacy.&rdquo;</span></li></ul><p class="c16 c14"><span class="c92 c37 c108 c60 c48 c14"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c53 c78 c14 c207 li-bullet-0"><span class="c108 c60 c14">Coders&#39; Copilot code-copying copyright claims crumble against GitHub, Microsoft: </span><span class="c5 c60 c14"><a class="c13" href="https://www.google.com/url?q=https://www.theregister.com/2024/07/08/github_copilot_dmca/&amp;sa=D&amp;source=editors&amp;ust=1730413583847071&amp;usg=AOvVaw3znwjpgMnVXR2y812TF_vT">https://www.theregister.com/2024/07/08/github_copilot_dmca/</a></span></li></ul><p class="c14 c16"><span class="c92 c37 c108 c60 c48 c14"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-1"><li class="c96 c53 c14 li-bullet-0"><span class="c92 c37 c108 c60 c48 c14">&gt;The most recently dismissed claims were fairly important, with one pertaining to infringement under the Digital Millennium Copyright Act (DMCA), section 1202(b), which basically says you shouldn&#39;t remove without permission crucial &quot;copyright management&quot; information, such as in this context who wrote the code and the terms of use, as licenses tend to dictate.</span></li><li class="c96 c53 c14 li-bullet-0"><span class="c108 c14 c169">The amended complaint argued that unlawful code copying was an inevitability if users flipped Copilot&#39;s anti-duplication safety switch to off, and also cited </span><span class="c20 c14 c169"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2202.07646&amp;sa=D&amp;source=editors&amp;ust=1730413583847377&amp;usg=AOvVaw2he63ZmpkbzVmlLNz2QY4m">a study</a></span><span class="c92 c37 c108 c48 c14 c169">&nbsp;into AI-generated code in attempt to back up their position that Copilot would plagiarize source, but once again the judge was not convinced that Microsoft&#39;s system was ripping off people&#39;s work in a meaningful way.</span></li></ul><p class="c16 c14"><span class="c92 c37 c108 c48 c14 c169"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c223 c53 c78 c14 li-bullet-0"><span>German court allows patents for AI-generated inventions: </span><span class="c5 c14 c169"><a class="c13" href="https://www.google.com/url?q=https://www.surrey.ac.uk/news/german-court-allows-patents-ai-generated-inventions&amp;sa=D&amp;source=editors&amp;ust=1730413583847651&amp;usg=AOvVaw1pEpKngo0I8Ha4eMyp6Mkc">https://www.surrey.ac.uk/news/german-court-allows-patents-ai-generated-inventions</a></span></li></ul><p class="c223 c53 c14 c46"><span class="c92 c37 c108 c48 c14 c169"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c53 c78 c14 c223 li-bullet-0"><span class="c108 c14 c169">3 separate gen AI cases show that AI training is not the same as removing a watermark: </span><span class="c5 c14 c169"><a class="c13" href="https://www.google.com/url?q=https://www.law.cornell.edu/uscode/text/17/1202&amp;sa=D&amp;source=editors&amp;ust=1730413583847885&amp;usg=AOvVaw1TEAoxBx32hf77vRMUGTkp">https://www.law.cornell.edu/uscode/text/17/1202</a></span></li><li class="c4 li-bullet-0"><span class="c1">I can go to a library and study math. The textbook authors cannot claim license to my work. The ai is not too different.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yn02lgpxo9se-1"><li class="c10 li-bullet-0"><span class="c1">If I use your textbook to pass my classes, get a PhD, and publish my own competing textbook, you can&rsquo;t sue even if my textbook teaches the same topics as yours and becomes so popular that it causes your market share to significantly decrease. Note that the textbook is a product sold for profit that directly competes with yours, not just an idea in my head. Yet I owe no royalties to you. </span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span>Downloading images is not infringement as </span><span class="c1">browsers download images for you to view them</span></li><li class="c4 li-bullet-0"><span class="c1">Derivative work only includes major copyrightable elements of the original. AI does not contain that.</span></li><li class="c4 li-bullet-0"><span class="c1">Tool manufacturers are not responsible if a user violates copyright with it. For example, Adobe is not responsible if someone violates copyright using Photoshop.</span></li><li class="c4 li-bullet-0"><span class="c35 c208 c14">Search engines already &ldquo;stole content&rdquo; long before AI, such as Google&rsquo;s featured snippets and &ldquo;People Also Ask&rdquo; sections that quote text from a website directly with no alterations: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://support.google.com/websearch/answer/9351707?hl%3Den%26visit_id%3D638612725182118407-343145636%26p%3Dfeatured_snippets%26rd%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583848465&amp;usg=AOvVaw2STRxU_DKXVwEEFj92-Qgp">https://support.google.com/websearch/answer/9351707?hl=en&amp;visit_id=638612725182118407-343145636&amp;p=featured_snippets&amp;rd=1</a></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 519.50px; height: 187.32px;"><img alt="" src="images/image33.png" style="width: 519.50px; height: 187.32px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 522.79px; height: 436.50px;"><img alt="" src="images/image466.png" style="width: 522.79px; height: 436.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-2 start"><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">(Ignore the Japanese text; it&rsquo;s from a browser extension)</span></li></ul><ul class="c0 lst-kix_yn02lgpxo9se-0"><li class="c4 li-bullet-0"><span class="c35 c208 c14">US Copyright Office shows leniency to copyrighting AI works: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583848903&amp;usg=AOvVaw3rI56G024glpOkzjXiVob9">https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/</a></span></li><li class="c4 li-bullet-0"><span class="c35 c208 c14">A </span><span class="c1">large fraction of the training data for all new LLMs is synthetic/computer generated. Orion is almost 60% synthetic data from o1. </span></li><li class="c4 li-bullet-0"><span class="c1">training is completely legal in countries like Japan, who&#39;ve removed all restrictions, so all these companies can just move to Japan or other countries with more common sense.</span></li><li class="c4 li-bullet-0"><span class="c1">Lithograph company tried to argue that photographs were a wholly deterministic physical reaction and thus involved no artistic input, in regards to a famous photograph of Oscar Wilde.</span></li><li class="c4 li-bullet-0"><span>Ukrainian IP Office registers works incorporating AI-generated content protected under new sui generis right: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ipkitten.blogspot.com/2024/09/ukrainian-ip-office-registers-works.html?m%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583849296&amp;usg=AOvVaw3Q6fwqmXuVxYVBSbE0pw6N">https://ipkitten.blogspot.com/2024/09/ukrainian-ip-office-registers-works.html?m=1</a></span></li></ul><h3 class="c119 c197" id="h.9xx1d26grtat"><span class="c92 c37 c168 c48 c125"></span></h3><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><h1 class="c123" id="h.nelh71sdpzxn"><span class="c14">11. </span><span class="c40 c37 c48 c77 c14">AI Art</span></h1><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_du8w67pu7mte-0 start"><li class="c4 li-bullet-0"><span class="c14">Algorithmic art or algorithm art is art, mostly visual art, in which the design is generated by an algorithm: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Algorithmic_art&amp;sa=D&amp;source=editors&amp;ust=1730413583849870&amp;usg=AOvVaw2qmmwkTAjfjLsu5yrhs99T">https://en.wikipedia.org/wiki/Algorithmic_art</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_du8w67pu7mte-0"><li class="c4 li-bullet-0"><span>Generative art is post-conceptual art that has been created (in whole or in part) with the use of an autonomous system: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Generative_art&amp;sa=D&amp;source=editors&amp;ust=1730413583850107&amp;usg=AOvVaw3dQpefb5L5G8ySwrYES49Q">https://en.wikipedia.org/wiki/Generative_art</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_du8w67pu7mte-1 start"><li class="c10 li-bullet-0"><span class="c14">Both have existed since the 1960s. If these </span><span class="c1">can be considered art, then why not AI art?</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_du8w67pu7mte-0"><li class="c4 li-bullet-0"><span class="c112 c37 c35 c48 c120">Computer-generated and non-deterministic music has existed for many decades:</span></li></ul><ul class="c0 lst-kix_du8w67pu7mte-1 start"><li class="c10 li-bullet-0"><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Aleatoric_music&amp;sa=D&amp;source=editors&amp;ust=1730413583850613&amp;usg=AOvVaw3QYrlzkN6Ty3RAacqy3oW9">https://en.wikipedia.org/wiki/Aleatoric_music</a></span></li></ul><ul class="c0 lst-kix_du8w67pu7mte-2 start"><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">Coined in the 50s</span></li><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">Leaves parts of music to pure chance</span></li></ul><ul class="c0 lst-kix_du8w67pu7mte-1"><li class="c10 li-bullet-0"><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Generative_music&amp;sa=D&amp;source=editors&amp;ust=1730413583850886&amp;usg=AOvVaw2zkxXZY6Q1Dlo8Ejg4Qi7H">https://en.wikipedia.org/wiki/Generative_music</a></span></li></ul><ul class="c0 lst-kix_du8w67pu7mte-2 start"><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">Coined by Brian Eno</span></li></ul><ul class="c0 lst-kix_du8w67pu7mte-1"><li class="c10 li-bullet-0"><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Algorithmic_composition&amp;sa=D&amp;source=editors&amp;ust=1730413583851099&amp;usg=AOvVaw05rZrKPlTU484DieZWoFlM">https://en.wikipedia.org/wiki/Algorithmic_composition</a></span></li></ul><ul class="c0 lst-kix_du8w67pu7mte-2 start"><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">Uses algorithms to create music</span></li></ul><p class="c9"><span class="c112 c37 c35 c48 c120"></span></p><ul class="c0 lst-kix_du8w67pu7mte-1"><li class="c4 li-bullet-0"><span>&lsquo;He touched a nerve&rsquo;: how the first piece of AI music was born in 1956: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/music/2021/dec/07/he-touched-a-nerve-how-the-first-piece-of-ai-music-was-born-in-1956&amp;sa=D&amp;source=editors&amp;ust=1730413583851397&amp;usg=AOvVaw33sow_jJz4Zpr7Iy2tt1-V">https://www.theguardian.com/music/2021/dec/07/he-touched-a-nerve-how-the-first-piece-of-ai-music-was-born-in-1956</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_du8w67pu7mte-1"><li class="c10 li-bullet-0"><span>Long before Auto-Tune and deepfake compositions, the university professor Lejaren Hiller premiered a concert recital composed by a computer and became an overnight celebrity&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ul><h2 class="c64" id="h.8kscl4xz7vhq"><span>11</span><span>.1. Images/Videos/3D Modeling</span></h2><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c51 li-bullet-0"><span class="c60 c14">A study found that it could extract training data from AI models using a CLIP-based attack: </span><span class="c5 c60 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2301.13188&amp;sa=D&amp;source=editors&amp;ust=1730413583851811&amp;usg=AOvVaw1WX2-sdMeQSeLwUAIoiZDv">https://arxiv.org/abs/2301.13188</a></span></li></ul><p class="c71 c46"><span class="c40 c37 c60 c48 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c49 li-bullet-0"><span class="c60 c14">The </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2301.13188&amp;sa=D&amp;source=editors&amp;ust=1730413583852066&amp;usg=AOvVaw1NuVUteOnmNj3r8iBzs4Vg">study</a></span><span class="c60 c14">&nbsp;identified 350,000 images in the training data to target for retrieval with 500 attempts each (totaling 175 million attempts), and of that managed to retrieve 107 images through high cosine similarity (85% or more) of their CLIP embeddings and through manual visual analysis. </span><span class="c15 c60">A replication rate of nearly 0% in a dataset biased in favor of overfitting using the exact same labels as the training data and specifically targeting images they knew were duplicated many times in the dataset using a smaller model of Stable Diffusion (890 million parameters vs. the larger 12 billion parameter Flux model that released on August 1). </span><span class="c40 c37 c60 c48 c14">This attack also relied on having access to the original training image labels:</span></li></ul><p class="c71 c46"><span class="c40 c37 c60 c48 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c49 li-bullet-0"><span class="c60 c14">&ldquo;</span><span class="c14 c191">Instead, we first embed each image to a 512 dimensional vector using CLIP [54], and then perform the all-pairs comparison between images in this lower-dimensional space (increasing efficiency by over 1500&times;). We count two examples as near-duplicates if their CLIP embeddings have a high cosine similarity. For each of these near-duplicated images, we use the corresponding captions as the input to our extraction attack</span><span class="c1 c14">.&rdquo;</span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 512.00px;"><img alt="" src="images/image97.png" style="width: 624.00px; height: 512.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c49 li-bullet-0"><span class="c1 c14">There is not as of yet evidence that this attack is replicable without knowing the image you are targeting beforehand. So the attack does not work as a valid method of privacy invasion so much as a method of determining if training occurred on the work in question - and only for images with a high rate of duplication AND with the same prompts as the training data labels, and still found almost NONE.</span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c49 li-bullet-0"><span class="c14">&ldquo;On Imagen, we attempted extraction of the 500 images with the highest out-ofdistribution score. Imagen memorized and </span><span class="c15">regurgitated 3 of these images </span><span class="c14">(which were unique in the training dataset). In contrast, we</span><span class="c15">&nbsp;failed to identify any memorization when applying the same methodology to Stable Diffusion</span><span class="c1 c14">&mdash;even after attempting to extract the 10,000 most-outlier samples&rdquo;</span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c49 li-bullet-0"><span class="c1 c14">I do not consider this rate or method of extraction to be an indication of duplication that would border on the realm of infringement, and this seems to be well within a reasonable level of control over infringement.</span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c51 li-bullet-0"><span class="c14">Diffusion models can create human faces </span><span class="c15">even when an average of 93% of the pixels are removed from all the images in the training data</span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2305.19256&amp;sa=D&amp;source=editors&amp;ust=1730413583853128&amp;usg=AOvVaw3YPz6Kl0ulYzneOjPUm-XW">https://arxiv.org/pdf/2305.19256</a></span></li></ul><p class="c71"><span class="c1 c14">&nbsp;</span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c49 li-bullet-0"><span class="c1 c14">&ldquo;if we corrupt the images by deleting 80% of the pixels prior to training and finetune, the memorization decreases sharply and there are distinct differences between the generated images and their nearest neighbors from the dataset. This is in spite of finetuning until convergence.&rdquo;</span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c49 li-bullet-0"><span class="c1 c14">&ldquo;As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 93% pixels missing (on average) from each training image.&rdquo;</span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 417.33px;"><img alt="" src="images/image222.png" style="width: 624.00px; height: 417.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 716.00px;"><img alt="" src="images/image296.png" style="width: 624.00px; height: 716.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c49 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 290.67px;"><img alt="" src="images/image143.png" style="width: 624.00px; height: 290.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c71 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 441.33px;"><img alt="" src="images/image24.png" style="width: 624.00px; height: 441.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>New open source AI image generator beats Midjourney: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blackforestlabs.ai/announcing-black-forest-labs/&amp;sa=D&amp;source=editors&amp;ust=1730413583853904&amp;usg=AOvVaw1AISuXAl1HZVKFw0hozbfM">https://blackforestlabs.ai/announcing-black-forest-labs/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c1">API costs $0.025 per image. It&#39;s cheaper than Dalle 3 and can do realism.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image364.png" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image107.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Very realistic images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/&amp;sa=D&amp;source=editors&amp;ust=1730413583854415&amp;usg=AOvVaw0crhwPmUPRXE-ekN3ayJOC">https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1106.67px;"><img alt="" src="images/image120.png" style="width: 624.00px; height: 1106.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image278.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1094.67px;"><img alt="" src="images/image46.png" style="width: 624.00px; height: 1094.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 638.67px;"><img alt="" src="images/image135.png" style="width: 624.00px; height: 638.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt with no additional editing: meme image with two men in it. On the left side the man is taller and is wearing a shirt that says Black Forest Labs. On the right side the other smaller scrawny man is wearing a shirt that says Stability AI and is sad. The taller man is hitting the back of the head of the small man. A caption coming from the tall man reads &quot;That&#39;s how you do a next-gen model!</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 501.33px;"><img alt="" src="images/image233.png" style="width: 624.00px; height: 501.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image37.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 249.72px; height: 240.88px;"><img alt="" src="images/image82.png" style="width: 249.72px; height: 240.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 357.33px;"><img alt="" src="images/image319.png" style="width: 624.00px; height: 357.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 633.33px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 633.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Created on first try. Robe and hands are perfect </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 885.33px;"><img alt="" src="images/image42.png" style="width: 624.00px; height: 885.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">First attempt: &quot;Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat.&quot;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 636.00px;"><img alt="" src="images/image85.png" style="width: 624.00px; height: 636.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: person take photo of Graffiti art spelling out the words &quot;WAFERSELAMAT&quot;, graffiti, white wall, dynamic color, spray paint,</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 640.00px;"><img alt="" src="images/image186.png" style="width: 624.00px; height: 640.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura&#39;s styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Google&rsquo;s new image diffusion model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/&amp;sa=D&amp;source=editors&amp;ust=1730413583856724&amp;usg=AOvVaw1wVX86kLTrDB9oKLyjhkvB">https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image189.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image177.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image40.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 629.33px;"><img alt="" src="images/image130.png" style="width: 624.00px; height: 629.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 630.67px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 630.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Lumina-GPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/Alpha-VLLM/Lumina-mGPT&amp;sa=D&amp;source=editors&amp;ust=1730413583857387&amp;usg=AOvVaw1jySq2K8ysypZBbomoo3mI">https://github.com/Alpha-VLLM/Lumina-mGPT</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c1">A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1013.33px;"><img alt="" src="images/image275.png" style="width: 624.00px; height: 1013.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c15">HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1815616891022418231&amp;sa=D&amp;source=editors&amp;ust=1730413583857910&amp;usg=AOvVaw2W1OuLuCJDgI7N6kAVSOIS">https://x.com/_akhaliq/status/1815616891022418231</a></span></li><li class="c4 li-bullet-0"><span class="c31">Extremely dynamic image to video: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1813486936868213073&amp;sa=D&amp;source=editors&amp;ust=1730413583858197&amp;usg=AOvVaw0Beu5KeVP_rURNs1cvTxJX">https://x.com/dreamingtulpa/status/1813486936868213073</a></span></li><li class="c4 li-bullet-0"><span class="c14">Great prompt comprehension: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.18893&amp;sa=D&amp;source=editors&amp;ust=1730413583858460&amp;usg=AOvVaw3TnE2JNYLUVtCA_dJ7ZI6k">https://arxiv.org/pdf/2406.18893</a></span></li><li class="c4 li-bullet-0"><span class="c15">Image to animation: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://github.com/Fictiverse/ToonCrafter-for-windows&amp;sa=D&amp;source=editors&amp;ust=1730413583858729&amp;usg=AOvVaw2YpL5EAWDqtQUmEGVSOYLn">https://github.com/Fictiverse/ToonCrafter-for-windows</a></span></li><li class="c4 li-bullet-0"><span>Photos to ads: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/&amp;sa=D&amp;source=editors&amp;ust=1730413583859004&amp;usg=AOvVaw3_XQDUKQvQJ8mBkBsAJnHU">https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/</a></span><span>&nbsp;</span></li><li class="c4 li-bullet-0"><span>GPT just churned out a 10-panel comic-book explaining &quot;Gravitational Waves&quot; in a one-shot prompt: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/electrik_dreams/status/1802421281876238354&amp;sa=D&amp;source=editors&amp;ust=1730413583859220&amp;usg=AOvVaw1tv1_oSD4sn2zO1R6hpl5o">https://x.com/electrik_dreams/status/1802421281876238354</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c33 c15">Much stronger control of image output:</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.01300&amp;sa=D&amp;source=editors&amp;ust=1730413583859466&amp;usg=AOvVaw3v4FcxqrxivhCNjZ5kcD71">https://arxiv.org/pdf/2406.01300</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.05282&amp;sa=D&amp;source=editors&amp;ust=1730413583859743&amp;usg=AOvVaw076SPP1sLknokS877K9F34">https://arxiv.org/pdf/2407.05282</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.03471&amp;sa=D&amp;source=editors&amp;ust=1730413583859915&amp;usg=AOvVaw2t_rKxd5XPS8-Z_y90H8kH">https://arxiv.org/pdf/2407.03471</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 596.50px; height: 235.43px;"><img alt="" src="images/image449.png" style="width: 596.50px; height: 235.43px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 429.33px;"><img alt="" src="images/image402.png" style="width: 624.00px; height: 429.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-3 start"><li class="c21 c26 li-bullet-0"><span class="c1">Our model significantly outperforms previous editing models as judged by human raters.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span>PartCrafter: Edit images using parts of other images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.04604&amp;sa=D&amp;source=editors&amp;ust=1730413583860288&amp;usg=AOvVaw0knEJqCZ6RD7r0GRSJ4E1Z">https://arxiv.org/pdf/2407.04604</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 328.00px;"><img alt="" src="images/image379.png" style="width: 624.00px; height: 328.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Image diffusion is getting much better and faster/cheaper to train: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.04692&amp;sa=D&amp;source=editors&amp;ust=1730413583860648&amp;usg=AOvVaw39uC0og8IP59_IjhNCdeUE">https://arxiv.org/pdf/2403.04692</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c35 c14 c54">Controllable video generation: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.20222v2&amp;sa=D&amp;source=editors&amp;ust=1730413583860915&amp;usg=AOvVaw2g1bhE9-1SvfznTNUX_mNC">https://arxiv.org/pdf/2405.20222v2</a></span><span class="c35 c14 c54">&nbsp;</span></li><li class="c22 c32 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04324&amp;sa=D&amp;source=editors&amp;ust=1730413583861224&amp;usg=AOvVaw36iLbSWuTI61A2Bzbz1w3n">https://huggingface.co/papers/2406.04324</a></span><span class="c92 c37 c35 c48 c14 c54">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">We show that, through the adversarial training, the multi-steps video diffusion model, i.e., Stable Video Diffusion (SVD), </span><span class="c15 c35 c54">can be trained to perform single forward pass to synthesize high-quality videos, capturing both temporal and spatial dependencies in the video data</span><span class="c35 c14 c54">. Extensive experiments demonstrate that our method achieves </span><span class="c15 c35 c54">competitive generation quality of synthesized videos with significantly reduced computational overhead for the denoising process </span><span class="c35 c14 c54">(i.e., around </span><span class="c15 c35 c54">23 times speedup compared with SVD and 6 times speedup compared with existing works, with even better generation quality</span><span class="c35 c14 c54">), paving the way for </span><span class="c2">real-time video synthesis and editing. </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c22 c32 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2406.04277&amp;sa=D&amp;source=editors&amp;ust=1730413583861831&amp;usg=AOvVaw2_xIhWEO9I7g0HKuLL2wyX">https://huggingface.co/papers/2406.04277</a></span><span class="c92 c37 c35 c48 c14 c54">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c35 c14 c54">Specifically, we propose spatio-temporal compositional diffusion to </span><span class="c15 c35 c54">precisely follow complex textual semantics</span><span class="c35 c14 c54">&nbsp;by manipulating and composing the attention maps of denoising networks spatially and temporally. Moreover, we propose an enhanced video data preprocessing to </span><span class="c15 c35 c54">enhance the training data regarding motion dynamics and prompt understanding</span><span class="c35 c14 c54">, equipped with a new reference frame attention mechanism to </span><span class="c15 c35 c54">improve the consistency of auto-regressive video generation</span><span class="c35 c14 c54">. Extensive experiments demonstrate that our VideoTetris </span><span class="c15 c35 c54">achieves impressive qualitative and quantitative results in compositional T2V generation. </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1">Image2Model</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fjylow/tripo_v20_is_out_now_you_can_create_stunning_3d/&amp;sa=D&amp;source=editors&amp;ust=1730413583862466&amp;usg=AOvVaw2Nlgi-U6Wj7-y893A5PjOc">https://www.reddit.com/r/singularity/comments/1fjylow/tripo_v20_is_out_now_you_can_create_stunning_3d/</a></span></li><li class="c10 li-bullet-0"><span>From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://stability.ai/news/introducing-stable-fast-3d&amp;sa=D&amp;source=editors&amp;ust=1730413583862748&amp;usg=AOvVaw1s6bXTJzeUG8d4B09gYIel">https://stability.ai/news/introducing-stable-fast-3d</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c10 li-bullet-0"><span>Very consistent examples: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/emmanuel_2m/status/1796118855237939346&amp;sa=D&amp;source=editors&amp;ust=1730413583863007&amp;usg=AOvVaw2TUYDmxpalSWLQbDcvttNg">https://x.com/emmanuel_2m/status/1796118855237939346</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span>Game made with 3D assets and textures made with AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CSM_ai/status/1796200041280925713&amp;sa=D&amp;source=editors&amp;ust=1730413583863262&amp;usg=AOvVaw231QPqo4K7z55NbIuHY36X">https://x.com/CSM_ai/status/1796200041280925713</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://3d.makedraft.com/gallery&amp;sa=D&amp;source=editors&amp;ust=1730413583863490&amp;usg=AOvVaw3xC06FXMtpHcLijMPCEY23">https://3d.makedraft.com/gallery</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://charmed.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583863705&amp;usg=AOvVaw1SSyhgws9GuI0pp6PZpCPl">https://charmed.ai/</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://medium.com/echo3d/7-generative-ai-tools-for-3d-asset-creation-97dd88153b7&amp;sa=D&amp;source=editors&amp;ust=1730413583863936&amp;usg=AOvVaw3BIO5hHNkjpbShX_kHN5gA">https://medium.com/echo3d/7-generative-ai-tools-for-3d-asset-creation-97dd88153b7</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.masterpiecex.com/blog/creating-usable-3d-models-with-generative-ai&amp;sa=D&amp;source=editors&amp;ust=1730413583864141&amp;usg=AOvVaw14nF6PlgEgvMxOgsJ1r3mb">https://www.masterpiecex.com/blog/creating-usable-3d-models-with-generative-ai</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1797104351204524516&amp;sa=D&amp;source=editors&amp;ust=1730413583864309&amp;usg=AOvVaw15APvGsbnX0bEiERdptYly">https://x.com/AIWarper/status/1797104351204524516</a></span><span class="c1">&nbsp;</span></li><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://costwen.github.io/Ouroboros3D/&amp;sa=D&amp;source=editors&amp;ust=1730413583864492&amp;usg=AOvVaw12kCYMkXFCn1helcVB0arE">https://costwen.github.io/Ouroboros3D/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c69 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jinkun-hao.github.io/Portrait3D/&amp;sa=D&amp;source=editors&amp;ust=1730413583864660&amp;usg=AOvVaw2C4AoxYP3cLzcQiWp5rh0U">https://jinkun-hao.github.io/Portrait3D/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Era3D: A new AI model that creates high-res &#128511;3D images from multiple viewpoints using just one input image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Gradio/status/1795866944568000697&amp;sa=D&amp;source=editors&amp;ust=1730413583864851&amp;usg=AOvVaw0yn1L0v-u8KIoyuesE5ZXn">https://x.com/Gradio/status/1795866944568000697</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">- Generates high-quality images up to 512&times;512 pixels&#127919;</span></li><li class="c7 li-bullet-0"><span class="c1">- Uses efficient row-wise attention to reduce computation&#9889;</span></li><li class="c7 li-bullet-0"><span class="c1">- 12x more efficient than sota methods&#128170;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span>Tailor3D can create customized 3D assets from text or single and dual-side images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1812817042736632091&amp;sa=D&amp;source=editors&amp;ust=1730413583865164&amp;usg=AOvVaw3QFiGbDa0sG2_XHKW1iLl_">https://x.com/dreamingtulpa/status/1812817042736632091</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">The method also supports adding changes to the inputs through additional text prompts.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span>Sparsecraft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1815204831679664191&amp;sa=D&amp;source=editors&amp;ust=1730413583865383&amp;usg=AOvVaw00A4NeM1I2aHvvjfzWMHIm">https://x.com/_akhaliq/status/1815204831679664191</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://assetgen.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583865602&amp;usg=AOvVaw0d2EP1ocFpDaVB-1bogaIc">https://assetgen.github.io/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 570.50px; height: 300.79px;"><img alt="" src="images/image74.png" style="width: 570.50px; height: 300.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span>Retexturing 3D models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eev502/with_this_tool_you_can_texture_3d_models_with_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583865917&amp;usg=AOvVaw0gQJJx9pw0pI8BB6CNSbWy">https://www.reddit.com/r/singularity/comments/1eev502/with_this_tool_you_can_texture_3d_models_with_ai/</a></span></li><li class="c10 li-bullet-0"><span>MeshAnything V2: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1ela7od/meshanything_v2/&amp;sa=D&amp;source=editors&amp;ust=1730413583866128&amp;usg=AOvVaw0SH7cEtkSBkO53VxXmXZld">https://www.reddit.com/r/StableDiffusion/comments/1ela7od/meshanything_v2/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://research.nvidia.com/labs/dir/edgerunner/&amp;sa=D&amp;source=editors&amp;ust=1730413583866306&amp;usg=AOvVaw0hZKGD1FqhXHD54cz60cOO">https://research.nvidia.com/labs/dir/edgerunner/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1">Human camouflage:</span></li></ul><p class="c21 c129"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q&amp;sa=D&amp;source=editors&amp;ust=1730413583866534&amp;usg=AOvVaw2AH_t2zKP18D28U0qletL-">https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q</a></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Animation from a single image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1d2saw7/its_coming_but_its_not_animateanyone/&amp;sa=D&amp;source=editors&amp;ust=1730413583866740&amp;usg=AOvVaw13-ZdrnvIgOpjwEr8C6NLx">https://www.reddit.com/r/StableDiffusion/comments/1d2saw7/its_coming_but_its_not_animateanyone/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Style change:</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c10 li-bullet-0"><span>Papercraft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1d2hdia/what_if_pixars_up_was_papercraft_style/?utm_source%3Dshare%26utm_medium%3Dweb3x%26utm_name%3Dweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413583867035&amp;usg=AOvVaw0gjxtwgSC37HT9Hw1vo-ww">https://www.reddit.com/r/StableDiffusion/comments/1d2hdia/what_if_pixars_up_was_papercraft_style/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li><li class="c10 li-bullet-0"><span>Pixel art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1792570014454727149&amp;sa=D&amp;source=editors&amp;ust=1730413583867216&amp;usg=AOvVaw3bfdQsxbuh32sVsEMIXg-e">https://x.com/AIWarper/status/1792570014454727149</a></span></li><li class="c10 li-bullet-0"><span>3D models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1780251522905083919&amp;sa=D&amp;source=editors&amp;ust=1730413583867395&amp;usg=AOvVaw2soCoiEH2x5i6EsUC8TDaI">https://x.com/AIWarper/status/1780251522905083919</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1811045840313799162&amp;sa=D&amp;source=editors&amp;ust=1730413583867645&amp;usg=AOvVaw0PFGEsEmHayrk-U5H0NmJW">https://x.com/AIWarper/status/1811045840313799162</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c4 li-bullet-0"><span>Editing videos from one frame: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://i2vedit.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583867889&amp;usg=AOvVaw2PRh3Ascnc5F1krrJr2BLq">https://i2vedit.github.io/</a></span><span class="c1 c43">&nbsp;</span></li><li class="c4 li-bullet-0"><span>AI object removal: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1795917964610351177&amp;sa=D&amp;source=editors&amp;ust=1730413583868148&amp;usg=AOvVaw1Vf37CSxPigQn8N3Hp5YQ5">https://x.com/AIWarper/status/1795917964610351177</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Upscaling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/Hillobar/Rope&amp;sa=D&amp;source=editors&amp;ust=1730413583868377&amp;usg=AOvVaw06OlAi04E_xAqwkUMm11kG">https://github.com/Hillobar/Rope</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c10 li-bullet-0"><span>Image: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 391.07px; height: 227.50px;"><img alt="" src="images/image126.png" style="width: 391.07px; height: 227.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/henryruhs/status/1795102994549055968&amp;sa=D&amp;source=editors&amp;ust=1730413583868753&amp;usg=AOvVaw0dix3hbn_RWyEng6-NF2Bf">https://x.com/henryruhs/status/1795102994549055968</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Consistent upscaling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/mervenoyann/status/1810592224830193781&amp;sa=D&amp;source=editors&amp;ust=1730413583869019&amp;usg=AOvVaw0TplY30VdEo1CuOFKiyvpi">https://x.com/mervenoyann/status/1810592224830193781</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c4 li-bullet-0"><span>Lip syncing: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1795157663266881929&amp;sa=D&amp;source=editors&amp;ust=1730413583869267&amp;usg=AOvVaw3WnFiPgBFIGNjTJ-byD1KA">https://x.com/AIWarper/status/1795157663266881929</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>VFX: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1780663596181287317&amp;sa=D&amp;source=editors&amp;ust=1730413583869527&amp;usg=AOvVaw0HlxdRpB44LNQLmVezacHI">https://x.com/AIWarper/status/1780663596181287317</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1">Replacing people in videos: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1789011656049324075&amp;sa=D&amp;source=editors&amp;ust=1730413583869837&amp;usg=AOvVaw2Hy60tPvxnSFeB8sGPdutN">https://x.com/AIWarper/status/1789011656049324075</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIWarper/status/1779952562843848981&amp;sa=D&amp;source=editors&amp;ust=1730413583870075&amp;usg=AOvVaw3zmc1Ds7alElcLOQ01Alqi">https://x.com/AIWarper/status/1779952562843848981</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span>Alibaba presents MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fp0ti3/alibaba_presents_mimo_controllable_character/&amp;sa=D&amp;source=editors&amp;ust=1730413583870377&amp;usg=AOvVaw1WLxDW4p0ImTCR-rHnhWko">https://www.reddit.com/r/singularity/comments/1fp0ti3/alibaba_presents_mimo_controllable_character/</a></span></li><li class="c4 li-bullet-0"><span>Morphing images together: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/krea_ai/status/1788465406971453814&amp;sa=D&amp;source=editors&amp;ust=1730413583870655&amp;usg=AOvVaw3r9AOmUWH1X22iC3H1E76j">https://x.com/krea_ai/status/1788465406971453814</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Image drag editing: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795858080908890242&amp;sa=D&amp;source=editors&amp;ust=1730413583870914&amp;usg=AOvVaw0s0-YyzHTi0tVy0F9hK4Xv">https://x.com/dreamingtulpa/status/1795858080908890242</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>ViViD can transfer a clothing item onto the video of a target person: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795786351733772479&amp;sa=D&amp;source=editors&amp;ust=1730413583871173&amp;usg=AOvVaw3tjLUGNZwu6CS3ZmUsUprJ">https://x.com/dreamingtulpa/status/1795786351733772479</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c10 li-bullet-0"><span class="c1">The method is able to capture garment details and human posture, resulting in more coherent and lifelike videos.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c4 li-bullet-0"><span>Video movement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1795698989708325273&amp;sa=D&amp;source=editors&amp;ust=1730413583871502&amp;usg=AOvVaw2NmRRSmx88PdOTUire1vg9">https://x.com/dreamingtulpa/status/1795698989708325273</a></span><span class="c1">&nbsp; </span></li><li class="c4 li-bullet-0"><span>Adding moving objects in video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1796062121215615031&amp;sa=D&amp;source=editors&amp;ust=1730413583871758&amp;usg=AOvVaw3zSvKqGH01aUjk2LesD1JV">https://x.com/dreamingtulpa/status/1796062121215615031</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">[Like photography, AI art is more complicated than a single button press](</span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1cjvw3k/image_realistic_composite_refine_comfyui_workflow/&amp;sa=D&amp;source=editors&amp;ust=1730413583872080&amp;usg=AOvVaw1T8W4wHxuZsYrEx2yGgP0z">https://www.reddit.com/r/StableDiffusion/comments/1cjvw3k/image_realistic_composite_refine_comfyui_workflow/</a></span><span class="c1 c14">)</span></li><li class="c4 li-bullet-0"><span class="c6 c40">AI art generators are tools, similar to Photoshop or how cameras create images rather than the photographers yet we still consider them artists.</span></li><li class="c4 li-bullet-0"><span class="c6 c40">Digital art is still considered art even though not every part is hand-drawn (e.g. anti-aliasing, paint bucket tool, creating shapes, etc) and not every part of a photograph was set by the photographer (e.g. photos/videos of nature)</span></li><li class="c4 li-bullet-0"><span class="c6">Intentionality does not matter in art, such as in </span><span class="c5 c6"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Action_painting&amp;sa=D&amp;source=editors&amp;ust=1730413583872533&amp;usg=AOvVaw2H67I5YoMuY2ZsfE7UPIBq">action painting</a></span><span class="c6">&nbsp;(where paint is &ldquo;s</span><span class="c108 c60 c14">pontaneously dribbled, splashed or smeared onto the canvas, rather than being carefully applied</span><span class="c6">&rdquo; and the artist has no idea what the result will look like), and the works of famous artists like </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Jackson_Pollock&amp;sa=D&amp;source=editors&amp;ust=1730413583872811&amp;usg=AOvVaw1plMB3vxFdttsuMFcLDaHb">Jackson Pollock</a></span></li><li class="c4 li-bullet-0"><span class="c1 c14">AI art is very similar to photography. Both can be as simple as clicking a button or be much more complex. For example, creating with Stable Diffusion can involve using ControlNet, IPAdapter, animation extensions, very complicated ComfyUI workflows, and much more to get the result you want. Additionally, both involve a machine doing most of the actual creation process, where the camera/AI creates the images, while the artist guides it on what the end result should be and completes post-processing work.</span></li><li class="c4 li-bullet-0"><span class="c14">Creating TV shows with diffusion: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://fablestudio.github.io/showrunner-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413583873191&amp;usg=AOvVaw0FDMIhhAaRCEZ8CAALu9gc">https://fablestudio.github.io/showrunner-agents/</a></span><span class="c1 c14">&nbsp; </span></li><li class="c4 li-bullet-0"><span class="c14">Very good control of output with text: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://ella-diffusion.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583873440&amp;usg=AOvVaw0PKzpjbiyUcV98FFmLPWoz">https://ella-diffusion.github.io/</a></span><span class="c1 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1 c14">Image Consistency: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2404.18919&amp;sa=D&amp;source=editors&amp;ust=1730413583873732&amp;usg=AOvVaw3HfM5JFN5f9TBfxsX3REk0">https://arxiv.org/pdf/2404.18919</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.17661&amp;sa=D&amp;source=editors&amp;ust=1730413583874000&amp;usg=AOvVaw2-A3KnY8HSPJZMGTfgHzrY">https://arxiv.org/pdf/2405.17661</a></span><span class="c1 c14">&nbsp;(has video consistency too)</span></li><li class="c10 li-bullet-0"><span class="c14">Consistent image to video: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2402.04324&amp;sa=D&amp;source=editors&amp;ust=1730413583874244&amp;usg=AOvVaw1gZbMuK1A5LxyehC9oE5Ng">https://arxiv.org/pdf/2402.04324</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c14">Midjourney character consistency: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://docs.midjourney.com/docs/character-reference&amp;sa=D&amp;source=editors&amp;ust=1730413583874511&amp;usg=AOvVaw0FZb_P5zAByU7Xs9Uugml8">https://docs.midjourney.com/docs/character-reference</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/fofrAI/status/1796547108478038355&amp;sa=D&amp;source=editors&amp;ust=1730413583874749&amp;usg=AOvVaw2dgrS89-g1M7jeZS5d0V9I">https://x.com/fofrAI/status/1796547108478038355</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span>Very consistent video to video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/&amp;sa=D&amp;source=editors&amp;ust=1730413583875082&amp;usg=AOvVaw2UUqLOxIduUyAryseoyHhA">https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/</a></span><span class="c1">&nbsp;</span></li><li class="c10 li-bullet-0"><span>NVIDIA Research solved subject consistency: &quot;Joint-image Diffusion Models for Finetuning-free Personalized Text-to-image Generation&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://research.nvidia.com/labs/dir/jedi/&amp;sa=D&amp;source=editors&amp;ust=1730413583875362&amp;usg=AOvVaw0fYWYhb3_CZGKlWPMDp-Iv">https://research.nvidia.com/labs/dir/jedi/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c51 li-bullet-0"><span class="c6 c40">AI images are getting VERY realistic: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/gdb/status/1790869434174746805?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413583875703&amp;usg=AOvVaw1Q2WtsI2T3C-PmLZRgsueX">https://twitter.com/gdb/status/1790869434174746805?s=46</a></span></li><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/310571/boring-reality&amp;sa=D&amp;source=editors&amp;ust=1730413583875946&amp;usg=AOvVaw1Qt5Mlc5V7MGNgJfmYAoM6">https://civitai.com/models/310571/boring-reality</a></span><span class="c6 c40">&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1794082708198420782&amp;sa=D&amp;source=editors&amp;ust=1730413583876186&amp;usg=AOvVaw1FctFEIfe-v6YaMJnjr5db">https://x.com/nickfloats/status/1794082708198420782</a></span><span class="c6 c40">&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/doganuraldesign/status/1797397984629445015&amp;sa=D&amp;source=editors&amp;ust=1730413583876450&amp;usg=AOvVaw39IkzYUcfrlJTr4JWEVNUq">https://x.com/doganuraldesign/status/1797397984629445015</a></span><span class="c6 c40">&nbsp;</span></li><li class="c85 li-bullet-0"><span>People accusing IRL video of being AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/toriel1one1/status/1799142881204249076&amp;sa=D&amp;source=editors&amp;ust=1730413583876822&amp;usg=AOvVaw3DUvyeYOXQZQHja6g6TV59">https://x.com/toriel1one1/status/1799142881204249076</a></span><span class="c1">&nbsp;</span></li><li class="c85 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/MidjourneyEats&amp;sa=D&amp;source=editors&amp;ust=1730413583877067&amp;usg=AOvVaw0PdjGyQp-IYTVpwwcnOltn">https://x.com/MidjourneyEats</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Guy commissioned and properly credited artists in the past, multiple times got backstabbed by artists who copy-striked his videos, threatening to take his channel down: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DknUkXwJXcpY&amp;sa=D&amp;source=editors&amp;ust=1730413583877343&amp;usg=AOvVaw0_fGBhq1UmuWrjeaQ1COme">https://www.youtube.com/watch?v=knUkXwJXcpY</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Toys R Us uses Sora generated promo: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/&amp;sa=D&amp;source=editors&amp;ust=1730413583877660&amp;usg=AOvVaw2qwrco5oIIJBjU2_L2tWPV">https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Generating Anatomically Controllable Consistent Text-to-3D Animals: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.16273&amp;sa=D&amp;source=editors&amp;ust=1730413583877921&amp;usg=AOvVaw2zp7ez2hzIzIZj9sD1aLiR">https://arxiv.org/pdf/2406.16273</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>3D model generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/murchellcruft/status/1805679588627861632&amp;sa=D&amp;source=editors&amp;ust=1730413583878180&amp;usg=AOvVaw21lTxNWqgWJyq8cxH_ymK7">https://x.com/murchellcruft/status/1805679588627861632</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nrqa__/status/1795469205934141463&amp;sa=D&amp;source=editors&amp;ust=1730413583878437&amp;usg=AOvVaw0j2F5J5HYwzoxAx5568j-S">https://x.com/nrqa__/status/1795469205934141463</a></span><span>&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>HOIFH generates synchronized object motion, full-body human motion, and detailed finger motion: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://hoifhli.github.io&amp;sa=D&amp;source=editors&amp;ust=1730413583878703&amp;usg=AOvVaw3wleOPnhlCZ4BUngoa2Jbd">https://hoifhli.github.io</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c1">It is designed for manipulating large objects within contextual environments, guided by human-level instructions.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Merging image elements together: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/alex_peys/status/1806719131791876418&amp;sa=D&amp;source=editors&amp;ust=1730413583879050&amp;usg=AOvVaw0GrBQzhc8PpvE5nHiLmYuT">https://x.com/alex_peys/status/1806719131791876418</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 564.26px; height: 297.50px;"><img alt="" src="images/image341.png" style="width: 564.26px; height: 297.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 484.00px;"><img alt="" src="images/image62.png" style="width: 624.00px; height: 484.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 329.33px;"><img alt="" src="images/image263.png" style="width: 624.00px; height: 329.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c1">H</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>High quality upscaling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://shuweis.github.io/ResMaster/&amp;sa=D&amp;source=editors&amp;ust=1730413583879729&amp;usg=AOvVaw2V0INENKo8O31BRwhzKpkK">https://shuweis.github.io/ResMaster/</a></span></li><li class="c4 li-bullet-0"><span>Square Enix says it used AI art in upcoming Foamstars game: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney&amp;sa=D&amp;source=editors&amp;ust=1730413583879974&amp;usg=AOvVaw0oeSe5CbJ_JVeaBQmjFr66">https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney</a></span></li><li class="c4 li-bullet-0"><span>Direct control over image generation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1809654865724862917&amp;sa=D&amp;source=editors&amp;ust=1730413583880174&amp;usg=AOvVaw0U7FIMfaaGQehWdQmtb6lh">https://x.com/dreamingtulpa/status/1809654865724862917</a></span></li><li class="c4 li-bullet-0"><span class="c1">Kling has realistic video generation despite a lack of compute: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1809322314225578158&amp;sa=D&amp;source=editors&amp;ust=1730413583880453&amp;usg=AOvVaw3n6NI0qMIivq3-b1WCZPeB">https://x.com/kimmonismus/status/1809322314225578158</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsumotokai/status/1810128665889685596&amp;sa=D&amp;source=editors&amp;ust=1730413583880718&amp;usg=AOvVaw2Gg2MVvqup7LkT6uLH2dpC">https://x.com/tsumotokai/status/1810128665889685596</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1810547329356771827&amp;sa=D&amp;source=editors&amp;ust=1730413583880967&amp;usg=AOvVaw3W_-ye1UPRnJZGJnpPRO-P">https://x.com/kimmonismus/status/1810547329356771827</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1810952037246349739&amp;sa=D&amp;source=editors&amp;ust=1730413583881206&amp;usg=AOvVaw1cZ88zJiuCT06TFU-HbDy7">https://x.com/CharaspowerAI/status/1810952037246349739</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1811105682000671147&amp;sa=D&amp;source=editors&amp;ust=1730413583881455&amp;usg=AOvVaw2Tw-kfdVIKyMAfTHk_SmEO">https://x.com/CharaspowerAI/status/1811105682000671147</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/&amp;sa=D&amp;source=editors&amp;ust=1730413583881694&amp;usg=AOvVaw1liUto_k2iOIk2ao2V3Y5t">https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1">Good AI videos: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span>OpenAI is already training a new version of Sora with even higher quality and longer videos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign%3DEditorial%26utm_content%3DNewsletter%252CAI%2BAgenda%26utm_medium%3Dorganic_social%26utm_source%3Dtwitter&amp;sa=D&amp;source=editors&amp;ust=1730413583882135&amp;usg=AOvVaw2L2kcj2wPkDPa2_AlWTIGf">https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign=Editorial&amp;utm_content=Newsletter%2CAI+Agenda&amp;utm_medium=organic_social&amp;utm_source=twitter</a></span></li><li class="c10 li-bullet-0"><span>New SOTA coming soon: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/&amp;sa=D&amp;source=editors&amp;ust=1730413583882614&amp;usg=AOvVaw1r86UHi3lzyM0Z4-2BNIU9">https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/</a></span></li><li class="c10 li-bullet-0"><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1811727094499385347&amp;sa=D&amp;source=editors&amp;ust=1730413583882895&amp;usg=AOvVaw3yRQfzdg_FQtm1IndoNL47">https://x.com/kimmonismus/status/1811727094499385347</a></span></li><li class="c10 li-bullet-0"><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/&amp;sa=D&amp;source=editors&amp;ust=1730413583883178&amp;usg=AOvVaw3_CQLD7505BNy0PCji0wuw">https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Diesol/status/1810468576882770109&amp;sa=D&amp;source=editors&amp;ust=1730413583883417&amp;usg=AOvVaw3YJ2NPWut7ivljf0sxx88k">https://x.com/Diesol/status/1810468576882770109</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1810949448584855729&amp;sa=D&amp;source=editors&amp;ust=1730413583883687&amp;usg=AOvVaw03XQR_hbZkA_KSCx-WTvSo">https://x.com/kimmonismus/status/1810949448584855729</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/shanef3d/status/1811505820129214687&amp;sa=D&amp;source=editors&amp;ust=1730413583883920&amp;usg=AOvVaw1igr6kYCLQZvsr8w2lOK2Z">https://x.com/shanef3d/status/1811505820129214687</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ai_for_success/status/1811576761617928300&amp;sa=D&amp;source=editors&amp;ust=1730413583884185&amp;usg=AOvVaw2rD4uEAmvzO4YOtkUMl7Mg">https://x.com/ai_for_success/status/1811576761617928300</a></span></li><li class="c10 li-bullet-0"><span>Hands: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/arohaAIX/status/1811381195676307623&amp;sa=D&amp;source=editors&amp;ust=1730413583884462&amp;usg=AOvVaw0nT7-s6ykN3YwvfCxzct8Y">https://x.com/arohaAIX/status/1811381195676307623</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1e0hwiq/mixing_ai_music_suno_and_ai_video_runway/&amp;sa=D&amp;source=editors&amp;ust=1730413583884756&amp;usg=AOvVaw102IKOQ4qI7m35tuDykEW7">https://www.reddit.com/r/aiwars/comments/1e0hwiq/mixing_ai_music_suno_and_ai_video_runway/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e1nhn5/poof/&amp;sa=D&amp;source=editors&amp;ust=1730413583884959&amp;usg=AOvVaw1GHDOucbhANC8yv9LuBF5s">https://www.reddit.com/r/aivideo/comments/1e1nhn5/poof/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1812531456452747276&amp;sa=D&amp;source=editors&amp;ust=1730413583885214&amp;usg=AOvVaw3KXA7Gux-tuXoWwPH4ix0k">https://x.com/CharaspowerAI/status/1812531456452747276</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/&amp;sa=D&amp;source=editors&amp;ust=1730413583885495&amp;usg=AOvVaw06ye2HMwZXNmxAMTLNRSac">https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/</a></span></li><li class="c10 li-bullet-0"><span>Grand Theft Auto in India: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/&amp;sa=D&amp;source=editors&amp;ust=1730413583885799&amp;usg=AOvVaw05eeaT14rRCLz-HI3TjXH0">https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1816096185016357030&amp;sa=D&amp;source=editors&amp;ust=1730413583886044&amp;usg=AOvVaw27EJ_pzHxvHDGz64KsjsYx">https://x.com/runwayml/status/1816096185016357030</a></span></li><li class="c10 li-bullet-0"><span>Apples to guinea pigs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/&amp;sa=D&amp;source=editors&amp;ust=1730413583886321&amp;usg=AOvVaw0_8TBFnYFXoVrM76yISnOI">https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/</a></span></li><li class="c10 li-bullet-0"><span>Person speaking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/&amp;sa=D&amp;source=editors&amp;ust=1730413583886601&amp;usg=AOvVaw05fCVX8ZUBf_1En1JMvhAW">https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1f527rg/just_going_for_a_lil_walk/&amp;sa=D&amp;source=editors&amp;ust=1730413583886876&amp;usg=AOvVaw0xf9AXhsF21FZBXGIWjoH2">https://www.reddit.com/r/aivideo/comments/1f527rg/just_going_for_a_lil_walk/</a></span></li><li class="c10 li-bullet-0"><span>Burger King commercial parody: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583887184&amp;usg=AOvVaw14iuwoz58RAIqdKL5vRuhh">https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>drag-and-drop a subject from an image with an arbitrary style onto another target image with a vastly different style and achieve a style-aware and realistic insertion of the subject into the target image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://magicinsert.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583887469&amp;usg=AOvVaw36Aw_aj4PWvR2tTwSyX2S3">https://magicinsert.github.io/</a></span></li><li class="c4 li-bullet-0"><span>Image movement: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1753710085447074104&amp;sa=D&amp;source=editors&amp;ust=1730413583887738&amp;usg=AOvVaw0a4_A0QxHk8rgwm0IdTq4C">https://x.com/dreamingtulpa/status/1753710085447074104</a></span></li><li class="c4 li-bullet-0"><span>Adding and tweaking concepts to a pre-existing image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/gytdau/status/1811530283747000386&amp;sa=D&amp;source=editors&amp;ust=1730413583887990&amp;usg=AOvVaw0AasyEG0U19cM-NoFRZQme">https://x.com/gytdau/status/1811530283747000386</a></span></li><li class="c4 li-bullet-0"><span>Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1811751431453450449&amp;sa=D&amp;source=editors&amp;ust=1730413583888196&amp;usg=AOvVaw0RJgBsZQEFJFv82dz5qoZC">https://x.com/runwayml/status/1811751431453450449</a></span></li><li class="c4 li-bullet-0"><span>Image + motion to video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/tencent/MimicMotion&amp;sa=D&amp;source=editors&amp;ust=1730413583888388&amp;usg=AOvVaw3UBM5Wb4fY16UwzSIL9iJn">https://github.com/tencent/MimicMotion</a></span></li><li class="c4 li-bullet-0"><span>InfiniteCraft uses AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://neal.fun/infinite-craft/&amp;sa=D&amp;source=editors&amp;ust=1730413583888576&amp;usg=AOvVaw37Tkq6k-4_XwkbspAHwg1e">https://neal.fun/infinite-craft/</a></span></li><li class="c4 li-bullet-0"><span>Adding sound to video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1812518092557193604&amp;sa=D&amp;source=editors&amp;ust=1730413583888800&amp;usg=AOvVaw2nZbPpnDj18HwFjQ8hPN2J">https://x.com/dreamingtulpa/status/1812518092557193604</a></span></li><li class="c4 li-bullet-0"><span>M2S is a new DDPM-based image inpainting method that is 60 times faster than RePaint: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/linghuyuhangyuan/M2S&amp;sa=D&amp;source=editors&amp;ust=1730413583889028&amp;usg=AOvVaw2gOQpJiLGw67FhyxEPPYSv">https://github.com/linghuyuhangyuan/M2S</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image114.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c24">Combining AI with CGI: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/c_valenzuelab/status/1813954465667457412&amp;sa=D&amp;source=editors&amp;ust=1730413583889365&amp;usg=AOvVaw1PJDPHS_EJKLK6jReWKfk6">https://x.com/c_valenzuelab/status/1813954465667457412</a></span></li><li class="c4 li-bullet-0"><span>McDonalds ad: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/&amp;sa=D&amp;source=editors&amp;ust=1730413583889623&amp;usg=AOvVaw2FJ96UZDy_a47NT4zcMaec">https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/</a></span></li><li class="c4 li-bullet-0"><span class="c24">Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency: We present Stable Video 4D (SV4D), a latent video diffusion model for multi-frame and multi-view consistent dynamic 3D content generation. Unlike previous methods that rely on separately trained </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1816146758608605362&amp;sa=D&amp;source=editors&amp;ust=1730413583889968&amp;usg=AOvVaw1xFu7gvVxda07JVofXcHQ5">https://x.com/dreamingtulpa/status/1816146758608605362</a></span></li><li class="c4 li-bullet-0"><span class="c24">Similar to creative upscaling in images, Noise Calibration can improve the visual quality of videos while maintaining the structure of the input video: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1816441922589708291&amp;sa=D&amp;source=editors&amp;ust=1730413583890272&amp;usg=AOvVaw31-gU_Xp87CId9UJ-3CsyK">https://x.com/dreamingtulpa/status/1816441922589708291</a></span></li><li class="c4 li-bullet-0"><span class="c24">Excellent video to video: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/8bit_e/status/1818246916129329464&amp;sa=D&amp;source=editors&amp;ust=1730413583890559&amp;usg=AOvVaw37qtgXGJOs-Xhyr3AN1czt">https://x.com/8bit_e/status/1818246916129329464</a></span></li><li class="c4 li-bullet-0"><span>LumaLabsAI - Dream Machine 1.5 is here. Now with higher-quality text-to-video, smarter understanding of your prompts, custom text rendering, and improved image-to-video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/LumaLabsAI/status/1825639918539817101&amp;sa=D&amp;source=editors&amp;ust=1730413583890808&amp;usg=AOvVaw2QZ4I1oIwQSITiZda6c-dq">https://x.com/LumaLabsAI/status/1825639918539817101</a></span></li><li class="c4 li-bullet-0"><span>Ideagram 2.0: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/&amp;sa=D&amp;source=editors&amp;ust=1730413583891051&amp;usg=AOvVaw3e89tMGqBCYnsj1aovo5cD">https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/</a></span></li><li class="c4 li-bullet-0"><span>Adding movement to images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fk4tgp/kling_ai_showcasing_the_use_of_the_motion_brush/&amp;sa=D&amp;source=editors&amp;ust=1730413583891382&amp;usg=AOvVaw3UFNYZYcb1H_mjVXvUeB9Q">https://www.reddit.com/r/singularity/comments/1fk4tgp/kling_ai_showcasing_the_use_of_the_motion_brush/</a></span></li></ul><h2 class="c64" id="h.ew2v9spc8v47"><span>11.</span><span class="c40 c37 c48 c75">2. Quality/Soul</span></h2><p class="c21"><span class="c33 c15">See section 15.3 for awards won and accomplishments </span></p><p class="c21"><span class="c1">&nbsp;</span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c15">First legally recognized nonbinary person with disabilities writes book with ChatGPT: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583892079&amp;usg=AOvVaw2CphldC9gBhpevOzc9ssfK">https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span>The novel draws from Shupe&rsquo;s eventful life, </span><span class="c15">including her advocacy for more inclusive gender recognition</span><span class="c1">.</span></li><li class="c10 li-bullet-0"><span>Shupe believes fervently that she was </span><span class="c15">only able to complete her book with the assistance of generative AI tools</span><span class="c1">. She says she has been assessed as 100 percent disabled by the Department of Veterans Affairs and struggles to write due to cognitive impairment related to conditions including bipolar disorder, borderline personality disorder, and a brain stem malformation.</span></li><li class="c10 li-bullet-0"><span>She is proud of the finished work and sees working with a text generator as a </span><span class="c15">different but no less worthwhile method of expressing thoughts</span><span>. &ldquo;You don&#39;t just hit &lsquo;generate&rsquo; and get something worthy of publishing. That may come in the future, but we&#39;re still far from it,&rdquo; she says, noting that she spen</span><span class="c33 c15">t upwards of 14 hours a day working on her draft.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c15">Excellent amateur quality AI photos: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/&amp;sa=D&amp;source=editors&amp;ust=1730413583893123&amp;usg=AOvVaw1E0xHu3dNYnnVRux98dcc1">https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Diffusion models as real-time interactive game engines: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://gamengen.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413583893510&amp;usg=AOvVaw34v90vvr1Rwyr9CTZxf3Vl">https://gamengen.github.io/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1811751431453450449&amp;sa=D&amp;source=editors&amp;ust=1730413583893910&amp;usg=AOvVaw3B1Mr_v0cKiLvEPOEdMJGf">https://x.com/runwayml/status/1811751431453450449</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 441.33px;"><img alt="" src="images/image24.png" style="width: 624.00px; height: 441.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 506.67px;"><img alt="" src="images/image570.png" style="width: 624.00px; height: 506.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 477.31px; height: 597.50px;"><img alt="" src="images/image209.png" style="width: 477.31px; height: 597.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c1">Many people, including AI haters, couldnt tell it&rsquo;s AI generated: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/midosommar/status/1843013374919241868&amp;sa=D&amp;source=editors&amp;ust=1730413583894636&amp;usg=AOvVaw1X3MRfyINwIsjRjwJ3OAd0">https://x.com/midosommar/status/1843013374919241868</a></span></li><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/beyoncesspamacc/status/1843094040851726800&amp;sa=D&amp;source=editors&amp;ust=1730413583894919&amp;usg=AOvVaw0p47Ht3J6s3ZO9W-UjT1Oj">https://x.com/beyoncesspamacc/status/1843094040851726800</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span>And no photoshop was involved: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/2byStanuby/status/1843456682392801662&amp;sa=D&amp;source=editors&amp;ust=1730413583895293&amp;usg=AOvVaw0ALjC1Thokd0SOU-s5nyC4">https://x.com/2byStanuby/status/1843456682392801662</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span>People accuse real video of being AI-generated: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/oncloud_e/status/1847036245916242248&amp;sa=D&amp;source=editors&amp;ust=1730413583895601&amp;usg=AOvVaw0dlHsAAZObByP4SvGi34v4">https://x.com/oncloud_e/status/1847036245916242248</a></span></li><li class="c4 li-bullet-0"><span>New open source AI image generator beats Midjourney: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blackforestlabs.ai/announcing-black-forest-labs/&amp;sa=D&amp;source=editors&amp;ust=1730413583895918&amp;usg=AOvVaw2Pt0B54h_h2Wf1UFW5zK-w">https://blackforestlabs.ai/announcing-black-forest-labs/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c1">API costs $0.025 per image. It&#39;s cheaper than Dalle 3 and can do realism.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image364.png" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image107.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Very realistic images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/&amp;sa=D&amp;source=editors&amp;ust=1730413583896631&amp;usg=AOvVaw2ASm_bGNMnnH-9kCqnjLk6">https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 503.09px; height: 892.50px;"><img alt="" src="images/image120.png" style="width: 503.09px; height: 892.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 508.16px; height: 879.50px;"><img alt="" src="images/image2.png" style="width: 508.16px; height: 879.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 504.69px; height: 873.50px;"><img alt="" src="images/image278.png" style="width: 504.69px; height: 873.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 504.04px; height: 884.50px;"><img alt="" src="images/image46.png" style="width: 504.04px; height: 884.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c105"><span class="c1"></span></p><p class="c21 c105"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 501.33px;"><img alt="" src="images/image233.png" style="width: 624.00px; height: 501.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c0 lst-kix_prgyqriqvk4e-2"><li class="c7 li-bullet-0"><span class="c1">Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image37.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 249.72px; height: 240.88px;"><img alt="" src="images/image82.png" style="width: 249.72px; height: 240.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 357.33px;"><img alt="" src="images/image319.png" style="width: 624.00px; height: 357.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 633.33px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 633.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Created on first try. Robe and hands are perfect </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 885.33px;"><img alt="" src="images/image42.png" style="width: 624.00px; height: 885.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">First attempt: &quot;Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat.&quot;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 636.00px;"><img alt="" src="images/image85.png" style="width: 624.00px; height: 636.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: person take photo of Graffiti art spelling out the words &quot;WAFERSELAMAT&quot;, graffiti, white wall, dynamic color, spray paint,</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 640.00px;"><img alt="" src="images/image186.png" style="width: 624.00px; height: 640.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura&#39;s styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 457.33px;"><img alt="" src="images/image178.png" style="width: 624.00px; height: 457.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Google&rsquo;s new image diffusion model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/&amp;sa=D&amp;source=editors&amp;ust=1730413583899315&amp;usg=AOvVaw3XKp3rDR2SkXVLOVs32k_9">https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image189.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image177.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image40.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 629.33px;"><img alt="" src="images/image130.png" style="width: 624.00px; height: 629.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 630.67px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 630.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>DiT-10B can surpass DALLE-3 and Stable Diffusion 3 in both image-text alignment and image quality. The API will be available next week: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1djddik/lidit10b_can_surpass_dalle3_and_stable_diffusion/&amp;sa=D&amp;source=editors&amp;ust=1730413583900384&amp;usg=AOvVaw3Q5KSBbSNnu_wGVwDm7Adi">https://www.reddit.com/r/StableDiffusion/comments/1djddik/lidit10b_can_surpass_dalle3_and_stable_diffusion/</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>AI used by official Disney show for intro: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits&amp;sa=D&amp;source=editors&amp;ust=1730413583900803&amp;usg=AOvVaw3WlA2N_jofJLBga4ueX-Ro">https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1 c14">&ldquo;Runway&#39;s tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.&rdquo; </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Runway_(company)&amp;sa=D&amp;source=editors&amp;ust=1730413583901329&amp;usg=AOvVaw2C3fybL2yTKOzWDn6ALUOo">https://en.wikipedia.org/wiki/Runway_(company)</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney&amp;sa=D&amp;source=editors&amp;ust=1730413583901754&amp;usg=AOvVaw2EJB7jbrjHgTn1dcA-C87I">https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney</a></span></li></ul><p class="c9"><span class="c40 c37 c63 c76"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c37 c63 c76">&gt;AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/11/6/23948454/microsoft-xbox-generative-ai-developer-tools-inworld-partnership&amp;sa=D&amp;source=editors&amp;ust=1730413583902214&amp;usg=AOvVaw3lkiUi6rLxyC297Qpix2DH">to develop tools for developers to generate AI NPCs, quests, and stories</a></span><span class="c37 c63 c76">. </span><span class="c5 c37 c63 c61 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/12/7/23991851/the-finals-embark-studios-launch-xbox-ps5-pc-steam-available-now&amp;sa=D&amp;source=editors&amp;ust=1730413583902477&amp;usg=AOvVaw30fA5IZ8adhS2nkxyLab5o">The Finals</a></span><span class="c37 c63 c76">, a free-to-play multiplayer shooter, </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/the-finals-uses-ai-text-to-speech-because-it-can-produce-lines-in-just-a-matter-of-hours-rather-than-months-baffles-actual-voice-actors/&amp;sa=D&amp;source=editors&amp;ust=1730413583902792&amp;usg=AOvVaw3q5tKt82qOUn9EM2AyekIT">was criticized by voice actors</a></span><span class="c40 c37 c63 c76">&nbsp;for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.</span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span>High quality video game characters: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/midjourney/comments/1dnbm78/characters_from_games/%23lightbox&amp;sa=D&amp;source=editors&amp;ust=1730413583903227&amp;usg=AOvVaw25oeBjxC5BL-N9OkeKLmEo">https://www.reddit.com/r/midjourney/comments/1dnbm78/characters_from_games/#lightbox</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c1">Great images: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/midjourney/comments/1bnm357/crashed_cybertruck/?share_id%3DBrM6plj1Yja58nGZUmG7c%26utm_content%3D1%26utm_medium%3Dios_app%26utm_name%3Dioscss%26utm_source%3Dshare%26utm_term%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583903752&amp;usg=AOvVaw0suEg1sKlb1uAGyMvuHznw">https://www.reddit.com/r/midjourney/comments/1bnm357/crashed_cybertruck/?share_id=BrM6plj1Yja58nGZUmG7c&amp;utm_content=1&amp;utm_medium=ios_app&amp;utm_name=ioscss&amp;utm_source=share&amp;utm_term=1</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 567.86px; height: 753.50px;"><img alt="" src="images/image92.png" style="width: 567.86px; height: 753.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://checkyourfact.com/2024/06/19/fact-check-crash-involving-two-cybertrucks-ai-generated/&amp;sa=D&amp;source=editors&amp;ust=1730413583904227&amp;usg=AOvVaw1NRECPGoYcwualGIMWttkB">https://checkyourfact.com/2024/06/19/fact-check-crash-involving-two-cybertrucks-ai-generated/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 566.40px; height: 737.50px;"><img alt="" src="images/image105.png" style="width: 566.40px; height: 737.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/RogerHaus/status/1808130565284954421/photo/1&amp;sa=D&amp;source=editors&amp;ust=1730413583904641&amp;usg=AOvVaw01oWcOpNzZtVPoKQ6kXbAT">https://x.com/RogerHaus/status/1808130565284954421/photo/1</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 557.96px; height: 740.50px;"><img alt="" src="images/image501.png" style="width: 557.96px; height: 740.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://isitai.com/detection-result/ai-person-in-yellow-dress/&amp;sa=D&amp;source=editors&amp;ust=1730413583905050&amp;usg=AOvVaw2qKVHLwkxrpkQS_5saof_7">https://isitai.com/detection-result/ai-person-in-yellow-dress/</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image656.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/17391786&amp;sa=D&amp;source=editors&amp;ust=1730413583905513&amp;usg=AOvVaw3xtUw5frXrc4Y-_hx6Gk4q">https://civitai.com/images/17391786</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 441.50px; height: 586.37px;"><img alt="" src="images/image227.png" style="width: 441.50px; height: 586.37px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/MustangMan_TX/status/1849975999905267941&amp;sa=D&amp;source=editors&amp;ust=1730413583905953&amp;usg=AOvVaw2623mKPrzqtIMQ5XQTEC8c">https://x.com/MustangMan_TX/status/1849975999905267941</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 471.17px;"><img alt="" src="images/image291.jpg" style="width: 265.03px; height: 471.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/10703900&amp;sa=D&amp;source=editors&amp;ust=1730413583906319&amp;usg=AOvVaw0IqLle7FF1n_CpsDJZ78yW">https://civitai.com/images/10703900</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 912.00px;"><img alt="" src="images/image400.png" style="width: 624.00px; height: 912.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25624025&amp;sa=D&amp;source=editors&amp;ust=1730413583906693&amp;usg=AOvVaw1it-_-bEcdK2axRZf6IfpU">https://civitai.com/images/25624025</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image585.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/14614776&amp;sa=D&amp;source=editors&amp;ust=1730413583907072&amp;usg=AOvVaw3Dtw__G4OS2SJrMYyPXgNS">https://civitai.com/images/14614776</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image164.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/34601798&amp;sa=D&amp;source=editors&amp;ust=1730413583907504&amp;usg=AOvVaw0XblHiWLB7v84-I5DsFNFU">https://civitai.com/images/34601798</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image385.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/34798101&amp;sa=D&amp;source=editors&amp;ust=1730413583907904&amp;usg=AOvVaw31WFPDpNai5LHe1sncRQxa">https://civitai.com/images/34798101</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.71px; height: 678.48px;"><img alt="" src="images/image556.png" style="width: 527.71px; height: 678.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/34532010&amp;sa=D&amp;source=editors&amp;ust=1730413583908296&amp;usg=AOvVaw1L5tILd4sH9e9zEcJQinI7">https://civitai.com/images/34532010</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image22.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/34519978&amp;sa=D&amp;source=editors&amp;ust=1730413583908704&amp;usg=AOvVaw1MuLwEKOlLNi80bAl-68hX">https://civitai.com/images/34519978</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image460.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/34702343&amp;sa=D&amp;source=editors&amp;ust=1730413583909092&amp;usg=AOvVaw0e6ktFsBnxyqIDL_7XdkDz">https://civitai.com/images/34702343</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image100.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/34747527&amp;sa=D&amp;source=editors&amp;ust=1730413583909481&amp;usg=AOvVaw3RmSaoHgWL7QRPWy-Z4CZ0">https://civitai.com/images/34747527</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1040.00px;"><img alt="" src="images/image109.png" style="width: 624.00px; height: 1040.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32477178&amp;sa=D&amp;source=editors&amp;ust=1730413583909875&amp;usg=AOvVaw3IpqjM11C3PFsRJRtgBmXp">https://civitai.com/images/32477178</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image154.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/31459655&amp;sa=D&amp;source=editors&amp;ust=1730413583910253&amp;usg=AOvVaw3zfHsxrfi_LAjd9VjM4Omm">https://civitai.com/images/31459655</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image236.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/33529460&amp;sa=D&amp;source=editors&amp;ust=1730413583910629&amp;usg=AOvVaw2shq6gufbwt0VgXbXcquS1">https://civitai.com/images/33529460</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image329.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/31455357&amp;sa=D&amp;source=editors&amp;ust=1730413583911014&amp;usg=AOvVaw2_xLOgngebaKR8hTgc0hn_">https://civitai.com/images/31455357</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 424.05px; height: 753.87px;"><img alt="" src="images/image261.png" style="width: 424.05px; height: 753.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/31458079&amp;sa=D&amp;source=editors&amp;ust=1730413583911396&amp;usg=AOvVaw0bSAUKXvu2ilXL7ZM4p84C">https://civitai.com/images/31458079</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1094.67px;"><img alt="" src="images/image430.png" style="width: 624.00px; height: 1094.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/33681154&amp;sa=D&amp;source=editors&amp;ust=1730413583911789&amp;usg=AOvVaw3hrEgBmO525a4IMsC7r7br">https://civitai.com/images/33681154</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 801.33px;"><img alt="" src="images/image75.png" style="width: 624.00px; height: 801.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/33502269&amp;sa=D&amp;source=editors&amp;ust=1730413583912170&amp;usg=AOvVaw15Lsaa5fD8XOHb5r6Cqmk8">https://civitai.com/images/33502269</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image495.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/33670042&amp;sa=D&amp;source=editors&amp;ust=1730413583912562&amp;usg=AOvVaw3VSiVlRAPKPmBVSdr9oFQx">https://civitai.com/images/33670042</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image447.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/31296140&amp;sa=D&amp;source=editors&amp;ust=1730413583912942&amp;usg=AOvVaw16BahtOMVjaeztd-e6sfRL">https://civitai.com/images/31296140</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image287.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32641269&amp;sa=D&amp;source=editors&amp;ust=1730413583913319&amp;usg=AOvVaw3Ygj6fPjspfcFJ9VODcL1q">https://civitai.com/images/32641269</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image220.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/33480744&amp;sa=D&amp;source=editors&amp;ust=1730413583913685&amp;usg=AOvVaw2LyL8hOw9ZJbpCVHJ9JIPE">https://civitai.com/images/33480744</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image29.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/34747512&amp;sa=D&amp;source=editors&amp;ust=1730413583914062&amp;usg=AOvVaw0NdqI0DCPSiOlPOgEgXx8r">https://civitai.com/images/34747512</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image492.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/24315213&amp;sa=D&amp;source=editors&amp;ust=1730413583914450&amp;usg=AOvVaw1fl_W-fBCugOolCQQIMXrQ">https://civitai.com/images/24315213</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 912.00px;"><img alt="" src="images/image375.png" style="width: 624.00px; height: 912.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/9219897&amp;sa=D&amp;source=editors&amp;ust=1730413583914830&amp;usg=AOvVaw2KDyw2WvW8TlGoHsbxRkzd">https://civitai.com/images/9219897</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image191.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/15565887&amp;sa=D&amp;source=editors&amp;ust=1730413583915201&amp;usg=AOvVaw03XCjMuKyFfoapwsSHMquU">https://civitai.com/images/15565887</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 802.67px;"><img alt="" src="images/image588.png" style="width: 624.00px; height: 802.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/13073993&amp;sa=D&amp;source=editors&amp;ust=1730413583915585&amp;usg=AOvVaw1kLwIX41uaQ5-fN3YK_MLh">https://civitai.com/images/13073993</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image270.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25309799&amp;sa=D&amp;source=editors&amp;ust=1730413583915961&amp;usg=AOvVaw2M_uAH4PBBC6YWL_DtUD9q">https://civitai.com/images/25309799</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.71px; height: 678.48px;"><img alt="" src="images/image552.jpg" style="width: 527.71px; height: 678.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25788822&amp;sa=D&amp;source=editors&amp;ust=1730413583916335&amp;usg=AOvVaw12vYFToBHqRdfyF3GSwGRR">https://civitai.com/images/25788822</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.71px; height: 678.48px;"><img alt="" src="images/image484.png" style="width: 527.71px; height: 678.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25304285&amp;sa=D&amp;source=editors&amp;ust=1730413583916718&amp;usg=AOvVaw1OuCPAQ742-fwPwoSxos2w">https://civitai.com/images/25304285</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.71px; height: 678.48px;"><img alt="" src="images/image603.png" style="width: 527.71px; height: 678.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/26139677&amp;sa=D&amp;source=editors&amp;ust=1730413583917091&amp;usg=AOvVaw25Z7PcnrY-7iJk0mf3_TmZ">https://civitai.com/images/26139677</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 603.09px; height: 603.09px;"><img alt="" src="images/image597.jpg" style="width: 603.09px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25121505&amp;sa=D&amp;source=editors&amp;ust=1730413583917488&amp;usg=AOvVaw2ntgPDFdFeoXbMVuMs8ROU">https://civitai.com/images/25121505</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image4.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/18029224&amp;sa=D&amp;source=editors&amp;ust=1730413583917955&amp;usg=AOvVaw1XGoSAHvSxPuJp0aAiZcOW">https://civitai.com/images/18029224</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image44.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/10556898&amp;sa=D&amp;source=editors&amp;ust=1730413583918421&amp;usg=AOvVaw36gCyYplhE08DdY4Cp-_H5">https://civitai.com/images/10556898</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image523.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/11871535&amp;sa=D&amp;source=editors&amp;ust=1730413583918889&amp;usg=AOvVaw0UikGAxpU0NZiBNc68jVY9">https://civitai.com/images/11871535</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image127.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/9173928&amp;sa=D&amp;source=editors&amp;ust=1730413583919333&amp;usg=AOvVaw1GHBqeiyIJXMvAJLXA4cGy">https://civitai.com/images/9173928</a></span></li></ul><p class="c46 c50"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image195.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/15234021&amp;sa=D&amp;source=editors&amp;ust=1730413583919782&amp;usg=AOvVaw2uFXMyJoK-gqccWt5VFlsv">https://civitai.com/images/15234021</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><p class="c50"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image566.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/17108902&amp;sa=D&amp;source=editors&amp;ust=1730413583920208&amp;usg=AOvVaw3g4D20FmFMyYdixz8cHRKv">https://civitai.com/images/17108902</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 905.33px;"><img alt="" src="images/image640.jpg" style="width: 624.00px; height: 905.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/23487588&amp;sa=D&amp;source=editors&amp;ust=1730413583920577&amp;usg=AOvVaw35ihDyKb4lWw-Y3521bhE3">https://civitai.com/images/23487588</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 905.33px;"><img alt="" src="images/image234.jpg" style="width: 624.00px; height: 905.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/21052667&amp;sa=D&amp;source=editors&amp;ust=1730413583920941&amp;usg=AOvVaw0VMwGJBtzov7iuysZaJdw-">https://civitai.com/images/21052667</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1040.00px;"><img alt="" src="images/image626.png" style="width: 624.00px; height: 1040.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/29966073&amp;sa=D&amp;source=editors&amp;ust=1730413583921315&amp;usg=AOvVaw32aOzJC5HCUrQpWFdYRldN">https://civitai.com/images/29966073</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image632.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/30212103&amp;sa=D&amp;source=editors&amp;ust=1730413583921686&amp;usg=AOvVaw3E7XmrBLFmk7o3plCpHu4B">https://civitai.com/images/30212103</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image580.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/30207996&amp;sa=D&amp;source=editors&amp;ust=1730413583922043&amp;usg=AOvVaw0JhlqbafJ4HwBlaEpX316U">https://civitai.com/images/30207996</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image581.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/30146245&amp;sa=D&amp;source=editors&amp;ust=1730413583922407&amp;usg=AOvVaw0-WqP4F_SqGUrUMCw4bmG2">https://civitai.com/images/30146245</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image3.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/30216976&amp;sa=D&amp;source=editors&amp;ust=1730413583922780&amp;usg=AOvVaw2K6OotjQ7kWD1oCaKGZzZt">https://civitai.com/images/30216976</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 912.00px;"><img alt="" src="images/image80.png" style="width: 624.00px; height: 912.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/30597000&amp;sa=D&amp;source=editors&amp;ust=1730413583923135&amp;usg=AOvVaw3p7tMdMPGjUp3gY-Sf0H7J">https://civitai.com/images/30597000</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image219.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/30104097&amp;sa=D&amp;source=editors&amp;ust=1730413583923505&amp;usg=AOvVaw3yBDwZITsnkb0RenTUi5Rj">https://civitai.com/images/30104097</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image308.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/26929838&amp;sa=D&amp;source=editors&amp;ust=1730413583923937&amp;usg=AOvVaw1V8wsjHDObLxKjDYZ8tsoz">https://civitai.com/images/26929838</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 508.86px; height: 659.63px;"><img alt="" src="images/image407.png" style="width: 508.86px; height: 659.63px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27572488&amp;sa=D&amp;source=editors&amp;ust=1730413583924293&amp;usg=AOvVaw2aq7Q-6X5hAmTD7zgczZA_">https://civitai.com/images/27572488</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 603.09px; height: 603.09px;"><img alt="" src="images/image149.png" style="width: 603.09px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/23957380&amp;sa=D&amp;source=editors&amp;ust=1730413583924659&amp;usg=AOvVaw1WOvkLbnf91k6qUlgEOXmJ">https://civitai.com/images/23957380</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image298.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27585666&amp;sa=D&amp;source=editors&amp;ust=1730413583925021&amp;usg=AOvVaw0q1wIcOJcJvnjWSZJMgBvk">https://civitai.com/images/27585666</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image613.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27585338&amp;sa=D&amp;source=editors&amp;ust=1730413583925380&amp;usg=AOvVaw2YMACCiKppB8EE_YWlVfNY">https://civitai.com/images/27585338</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image408.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/21329840&amp;sa=D&amp;source=editors&amp;ust=1730413583925748&amp;usg=AOvVaw1CCuoMvezz7tobXNGJwv3y">https://civitai.com/images/21329840</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1109.33px;"><img alt="" src="images/image243.png" style="width: 624.00px; height: 1109.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32271527&amp;sa=D&amp;source=editors&amp;ust=1730413583926105&amp;usg=AOvVaw3GnKQ0PXCGK9abwG-tys0L">https://civitai.com/images/32271527</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image533.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27570470&amp;sa=D&amp;source=editors&amp;ust=1730413583926489&amp;usg=AOvVaw3M2oS55l03vo822UWIzuMb">https://civitai.com/images/27570470</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 603.09px; height: 904.64px;"><img alt="" src="images/image549.png" style="width: 603.09px; height: 904.64px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27763004&amp;sa=D&amp;source=editors&amp;ust=1730413583926851&amp;usg=AOvVaw2R3AKdvlz-f1QJAmHqAspc">https://civitai.com/images/27763004</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image529.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27565856&amp;sa=D&amp;source=editors&amp;ust=1730413583927213&amp;usg=AOvVaw0V7_lFi7xqtQQSClMNayBh">https://civitai.com/images/27565856</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image273.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27361846&amp;sa=D&amp;source=editors&amp;ust=1730413583927575&amp;usg=AOvVaw3MKhDSS_0dUjhtRXhws7fg">https://civitai.com/images/27361846</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image324.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27574560&amp;sa=D&amp;source=editors&amp;ust=1730413583927925&amp;usg=AOvVaw1Uyj0XoVZfgKAP3HtLl_6L">https://civitai.com/images/27574560</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image112.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27315366&amp;sa=D&amp;source=editors&amp;ust=1730413583928226&amp;usg=AOvVaw18JVYWQ_4XTfCN55oq6H7F">https://civitai.com/images/27315366</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 678.48px;"><img alt="" src="images/image437.png" style="width: 452.32px; height: 678.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/26888438&amp;sa=D&amp;source=editors&amp;ust=1730413583928514&amp;usg=AOvVaw1P2AzmSqFmt2kTbBRAWFwZ">https://civitai.com/images/26888438</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image551.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/27513824&amp;sa=D&amp;source=editors&amp;ust=1730413583928820&amp;usg=AOvVaw0XhsvCBwsTz7hVb7dCJkPh">https://civitai.com/images/27513824</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 716.17px;"><img alt="" src="images/image446.png" style="width: 452.32px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/24641975&amp;sa=D&amp;source=editors&amp;ust=1730413583929055&amp;usg=AOvVaw0kH9f7IoYALfLLaCpnbHYg">https://civitai.com/images/24641975</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 942.33px;"><img alt="" src="images/image531.png" style="width: 471.17px; height: 942.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25605628&amp;sa=D&amp;source=editors&amp;ust=1730413583929311&amp;usg=AOvVaw2mT83CbPRhxRfkrMPrCm7L">https://civitai.com/images/25605628</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 828.00px;"><img alt="" src="images/image532.png" style="width: 624.00px; height: 828.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/19114796&amp;sa=D&amp;source=editors&amp;ust=1730413583929632&amp;usg=AOvVaw0xEAmBh7mLceO4syy9LExc">https://civitai.com/images/19114796</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 791.56px;"><img alt="" src="images/image517.png" style="width: 452.32px; height: 791.56px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/26780730&amp;sa=D&amp;source=editors&amp;ust=1730413583929948&amp;usg=AOvVaw1TymkvADL2eI6aaNAOCzAm">https://civitai.com/images/26780730</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 753.87px;"><img alt="" src="images/image642.png" style="width: 452.32px; height: 753.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/24609254&amp;sa=D&amp;source=editors&amp;ust=1730413583930252&amp;usg=AOvVaw0qb9wFYWvnIlidoLAJMrha">https://civitai.com/images/24609254</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 912.00px;"><img alt="" src="images/image480.png" style="width: 624.00px; height: 912.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25613929&amp;sa=D&amp;source=editors&amp;ust=1730413583930511&amp;usg=AOvVaw0nNe2WVkToDpavtnpP5qrn">https://civitai.com/images/25613929</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 301.55px; height: 603.09px;"><img alt="" src="images/image193.png" style="width: 301.55px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25281783&amp;sa=D&amp;source=editors&amp;ust=1730413583930780&amp;usg=AOvVaw3PF_K45fKa9NJnwdDwb0SL">https://civitai.com/images/25281783</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.71px; height: 678.48px;"><img alt="" src="images/image457.png" style="width: 527.71px; height: 678.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25159359&amp;sa=D&amp;source=editors&amp;ust=1730413583931070&amp;usg=AOvVaw11WXRld7nFvtToyfFPQwei">https://civitai.com/images/25159359</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image389.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25932335&amp;sa=D&amp;source=editors&amp;ust=1730413583931346&amp;usg=AOvVaw0zPRxkcWnKBqvxaHGNtUAi">https://civitai.com/images/25932335</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image481.png" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/23990027&amp;sa=D&amp;source=editors&amp;ust=1730413583931659&amp;usg=AOvVaw3hMmyxLNyDJ4HlTal_bJDD">https://civitai.com/images/23990027</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 753.87px;"><img alt="" src="images/image267.png" style="width: 452.32px; height: 753.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/23849851&amp;sa=D&amp;source=editors&amp;ust=1730413583931965&amp;usg=AOvVaw09qtKoD2KqlpsTXn6XeHr4">https://civitai.com/images/23849851</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 603.09px; height: 603.09px;"><img alt="" src="images/image482.jpg" style="width: 603.09px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/26128780&amp;sa=D&amp;source=editors&amp;ust=1730413583932253&amp;usg=AOvVaw1S-6ngOr5qyrK4Wer--VR1">https://civitai.com/images/26128780</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.25px; height: 942.50px;"><img alt="" src="images/image391.png" style="width: 471.25px; height: 942.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/718471&amp;sa=D&amp;source=editors&amp;ust=1730413583932547&amp;usg=AOvVaw2vnJxM_xQwOi60RLBIv_Eu">https://civitai.com/images/718471</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image160.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25941621&amp;sa=D&amp;source=editors&amp;ust=1730413583932795&amp;usg=AOvVaw3iSNbrDWVjBPDc-nfwMlxe">https://civitai.com/images/25941621</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image235.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/26697324&amp;sa=D&amp;source=editors&amp;ust=1730413583933047&amp;usg=AOvVaw0sl1PCqCxJZMjILtOlgdEe">https://civitai.com/images/26697324</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image539.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/11029293&amp;sa=D&amp;source=editors&amp;ust=1730413583933323&amp;usg=AOvVaw2KT9Spw7Z5DjLFQ-7YxjZM">https://civitai.com/images/11029293</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 791.56px;"><img alt="" src="images/image595.png" style="width: 452.32px; height: 791.56px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25148210&amp;sa=D&amp;source=editors&amp;ust=1730413583933619&amp;usg=AOvVaw2npQWu2R4xPSgivBROy_S6">https://civitai.com/images/25148210</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image439.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25301409&amp;sa=D&amp;source=editors&amp;ust=1730413583933884&amp;usg=AOvVaw11W2_8aCxXMJZAL8FGyz2P">https://civitai.com/images/25301409</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image99.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25777852&amp;sa=D&amp;source=editors&amp;ust=1730413583934125&amp;usg=AOvVaw0ITLA-m0rlPC-q1ERNn8sI">https://civitai.com/images/25777852</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 802.67px;"><img alt="" src="images/image635.png" style="width: 624.00px; height: 802.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/16255071&amp;sa=D&amp;source=editors&amp;ust=1730413583934392&amp;usg=AOvVaw3LqLFJXvdcymxZt0AtCCdA">https://civitai.com/images/16255071</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 603.09px; height: 989.45px;"><img alt="" src="images/image427.png" style="width: 603.09px; height: 989.45px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/9022765&amp;sa=D&amp;source=editors&amp;ust=1730413583934677&amp;usg=AOvVaw36bgRronHaTVRx5kNkWNzq">https://civitai.com/images/9022765</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 912.00px;"><img alt="" src="images/image458.png" style="width: 624.00px; height: 912.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/13166175&amp;sa=D&amp;source=editors&amp;ust=1730413583934976&amp;usg=AOvVaw2vfObrdbjihizgrjrdOBdj">https://civitai.com/images/13166175</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 802.67px;"><img alt="" src="images/image599.png" style="width: 624.00px; height: 802.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/18004690&amp;sa=D&amp;source=editors&amp;ust=1730413583935239&amp;usg=AOvVaw21Oc0eWyGIvALE9meiOLHK">https://civitai.com/images/18004690</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image258.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/21454911&amp;sa=D&amp;source=editors&amp;ust=1730413583935500&amp;usg=AOvVaw2tKzVA6DzB0mVYCJY1JAow">https://civitai.com/images/21454911</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 753.87px;"><img alt="" src="images/image185.png" style="width: 452.32px; height: 753.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25617160&amp;sa=D&amp;source=editors&amp;ust=1730413583935738&amp;usg=AOvVaw0ZMi_tkOhcyrrlz9w8eztd">https://civitai.com/images/25617160</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image618.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/23361289&amp;sa=D&amp;source=editors&amp;ust=1730413583935970&amp;usg=AOvVaw3Yje7sJ9LnVVDUBuT79zNh">https://civitai.com/images/23361289</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 791.56px;"><img alt="" src="images/image645.png" style="width: 452.32px; height: 791.56px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/30249134&amp;sa=D&amp;source=editors&amp;ust=1730413583936203&amp;usg=AOvVaw3sYRVrFSGQ_6k0jKl_6HB0">https://civitai.com/images/30249134</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 735.02px;"><img alt="" src="images/image463.png" style="width: 490.01px; height: 735.02px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/29817639&amp;sa=D&amp;source=editors&amp;ust=1730413583936537&amp;usg=AOvVaw1XL3Rq4DBieUuPJbddAOuV">https://civitai.com/images/29817639</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 791.56px;"><img alt="" src="images/image559.png" style="width: 452.32px; height: 791.56px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32628093&amp;sa=D&amp;source=editors&amp;ust=1730413583936818&amp;usg=AOvVaw38D1GLyktNufhNII8MqHWE">https://civitai.com/images/32628093</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 565.40px; height: 753.87px;"><img alt="" src="images/image32.png" style="width: 565.40px; height: 753.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32439181&amp;sa=D&amp;source=editors&amp;ust=1730413583937066&amp;usg=AOvVaw2Tx1EdD57AcCG5cT2D9GmX">https://civitai.com/images/32439181</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 802.67px;"><img alt="" src="images/image440.png" style="width: 624.00px; height: 802.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/36361030&amp;sa=D&amp;source=editors&amp;ust=1730413583937368&amp;usg=AOvVaw3rCODLqGGjVuubTUc6t8LN">https://civitai.com/images/36361030</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.71px; height: 678.48px;"><img alt="" src="images/image168.png" style="width: 527.71px; height: 678.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32281291&amp;sa=D&amp;source=editors&amp;ust=1730413583937613&amp;usg=AOvVaw2k7c-ybEeuDXsBmNchmuRF">https://civitai.com/images/32281291</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 556.00px;"><img alt="" src="images/image106.png" style="width: 624.00px; height: 556.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c1">All text is AI generated</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 524.00px; height: 425.00px;"><img alt="" src="images/image327.png" style="width: 524.00px; height: 425.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ai_shame/status/1850662527874617505&amp;sa=D&amp;source=editors&amp;ust=1730413583938049&amp;usg=AOvVaw3RTNADLHeKwhKVGAP81A8e">https://x.com/ai_shame/status/1850662527874617505</a></span></li></ul><p class="c50 c129"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1040.00px;"><img alt="" src="images/image109.png" style="width: 624.00px; height: 1040.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32477178&amp;sa=D&amp;source=editors&amp;ust=1730413583938290&amp;usg=AOvVaw1YyZvOeFmIYCDL9Jl3P29h">https://civitai.com/images/32477178</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image622.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/13824757&amp;sa=D&amp;source=editors&amp;ust=1730413583938550&amp;usg=AOvVaw2Kd3doaZHgZ3JuwzBd2GRD">https://civitai.com/images/13824757</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image395.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/26541023&amp;sa=D&amp;source=editors&amp;ust=1730413583938886&amp;usg=AOvVaw2P7QopfkLTHkHM635t3vF8">https://civitai.com/images/26541023</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image287.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/32641269&amp;sa=D&amp;source=editors&amp;ust=1730413583939219&amp;usg=AOvVaw3y-MR1svMliVz1DYeQdC0q">https://civitai.com/images/32641269</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 603.09px; height: 603.09px;"><img alt="" src="images/image490.png" style="width: 603.09px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/23991007&amp;sa=D&amp;source=editors&amp;ust=1730413583939505&amp;usg=AOvVaw0RTpIFiJ0dgdz988bNiGXa">https://civitai.com/images/23991007</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.01px; height: 716.17px;"><img alt="" src="images/image606.jpg" style="width: 490.01px; height: 716.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/13774580&amp;sa=D&amp;source=editors&amp;ust=1730413583939752&amp;usg=AOvVaw13qNdCwCBOOi7O-IqMm1fC">https://civitai.com/images/13774580</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 206.13px;"><img alt="" src="images/image325.jpg" style="width: 265.03px; height: 206.13px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/25679756&amp;sa=D&amp;source=editors&amp;ust=1730413583939989&amp;usg=AOvVaw2pGPzAod2-nG2vCEn4gBcc">https://civitai.com/images/25679756</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 387.53px;"><img alt="" src="images/image117.jpg" style="width: 265.03px; height: 387.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 265.03px;"><img alt="" src="images/image125.jpg" style="width: 265.03px; height: 265.03px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/24955975&amp;sa=D&amp;source=editors&amp;ust=1730413583940347&amp;usg=AOvVaw0875tqMh95EzwTq7s13EQA">https://civitai.com/images/24955975</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 341.01px;"><img alt="" src="images/image398.jpg" style="width: 265.03px; height: 341.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 341.01px;"><img alt="" src="images/image131.jpg" style="width: 265.03px; height: 341.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 341.01px;"><img alt="" src="images/image489.jpg" style="width: 265.03px; height: 341.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 341.01px;"><img alt="" src="images/image318.jpg" style="width: 265.03px; height: 341.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 265.03px;"><img alt="" src="images/image615.jpg" style="width: 265.03px; height: 265.03px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/689192/aesthetic-amateur-photo-flux-dev&amp;sa=D&amp;source=editors&amp;ust=1730413583940974&amp;usg=AOvVaw1M1C_TnBjIf0pQt7reRtZc">https://civitai.com/models/689192/aesthetic-amateur-photo-flux-dev</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 319.57px; height: 354.50px;"><img alt="" src="images/image383.png" style="width: 319.57px; height: 354.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span>&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 311.71px; height: 352.86px;"><img alt="" src="images/image277.png" style="width: 311.71px; height: 352.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/mrsballs69/status/1839037286576697784&amp;sa=D&amp;source=editors&amp;ust=1730413583941388&amp;usg=AOvVaw2Nb3mJGdx--Td0uEWNAyBv">https://x.com/mrsballs69/status/1839037286576697784</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image545.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 353.37px;"><img alt="" src="images/image339.jpg" style="width: 265.03px; height: 353.37px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image197.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 353.37px;"><img alt="" src="images/image414.jpg" style="width: 265.03px; height: 353.37px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image225.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image280.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image456.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image184.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 353.37px;"><img alt="" src="images/image614.jpg" style="width: 265.03px; height: 353.37px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 387.53px;"><img alt="" src="images/image522.jpg" style="width: 265.03px; height: 387.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 387.53px;"><img alt="" src="images/image145.jpg" style="width: 265.03px; height: 387.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 206.13px;"><img alt="" src="images/image515.jpg" style="width: 265.03px; height: 206.13px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 181.40px;"><img alt="" src="images/image546.jpg" style="width: 265.03px; height: 181.40px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image511.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 387.53px;"><img alt="" src="images/image639.jpg" style="width: 265.03px; height: 387.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 387.53px;"><img alt="" src="images/image520.jpg" style="width: 265.03px; height: 387.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 387.53px;"><img alt="" src="images/image53.jpg" style="width: 265.03px; height: 387.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 387.53px;"><img alt="" src="images/image534.jpg" style="width: 265.03px; height: 387.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image660.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image26.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 181.40px;"><img alt="" src="images/image216.jpg" style="width: 265.03px; height: 181.40px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 265.03px; height: 199.07px;"><img alt="" src="images/image514.jpg" style="width: 265.03px; height: 199.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/724495/1999-digital-camera-style-olympus-d-450&amp;sa=D&amp;source=editors&amp;ust=1730413583943823&amp;usg=AOvVaw1pZEzSXz6aAwf7nHq7Byco">https://civitai.com/models/724495/1999-digital-camera-style-olympus-d-450</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 471.17px; height: 706.75px;"><img alt="" src="images/image504.jpg" style="width: 471.17px; height: 706.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kattlatte/status/1810336325087694992&amp;sa=D&amp;source=editors&amp;ust=1730413583944250&amp;usg=AOvVaw2i1-zl1sy2kdlt4_coKhL2">https://x.com/kattlatte/status/1810336325087694992</a></span></li></ul><p class="c50"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 936.00px;"><img alt="" src="images/image312.jpg" style="width: 624.00px; height: 936.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Gavin_BIC/status/1811516467411845425&amp;sa=D&amp;source=editors&amp;ust=1730413583944635&amp;usg=AOvVaw19qPVdKkFvPvt7V5yYkiN7">https://x.com/Gavin_BIC/status/1811516467411845425</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 828.00px;"><img alt="" src="images/image509.jpg" style="width: 624.00px; height: 828.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/lummipics/status/1811409862464532684&amp;sa=D&amp;source=editors&amp;ust=1730413583945015&amp;usg=AOvVaw0gk4FeHX6GGq-Hc5iK67a9">https://x.com/lummipics/status/1811409862464532684</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 936.00px;"><img alt="" src="images/image453.jpg" style="width: 624.00px; height: 936.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/lummipics/status/1831399579993960821&amp;sa=D&amp;source=editors&amp;ust=1730413583945400&amp;usg=AOvVaw2P60ZkKtzxiaR-fv95yHU_">https://x.com/lummipics/status/1831399579993960821</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 754.67px;"><img alt="" src="images/image299.jpg" style="width: 624.00px; height: 754.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 754.67px;"><img alt="" src="images/image382.jpg" style="width: 624.00px; height: 754.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image276.jpg" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/lummipics/status/1829531772792827977&amp;sa=D&amp;source=editors&amp;ust=1730413583945991&amp;usg=AOvVaw0p93JvSjv2dPDHDlFXH8P4">https://x.com/lummipics/status/1829531772792827977</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 546.55px; height: 725.60px;"><img alt="" src="images/image442.jpg" style="width: 546.55px; height: 725.60px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/bri_guy_ai/status/1811084147051372717/photo/1&amp;sa=D&amp;source=editors&amp;ust=1730413583946465&amp;usg=AOvVaw2xnCUKMpSJSvAPmoTHRwnS">https://x.com/bri_guy_ai/status/1811084147051372717/photo/1</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Artedeingenio/status/1811750372366533027&amp;sa=D&amp;source=editors&amp;ust=1730413583946809&amp;usg=AOvVaw1DtQjA2XjfuBkmkR_LIpcE">https://x.com/Artedeingenio/status/1811750372366533027</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image272.jpg" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c50 c46"><span class="c1"></span></p><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.96px; height: 336.29px;"><img alt="" src="images/image634.jpg" style="width: 588.96px; height: 336.29px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.96px; height: 336.29px;"><img alt="" src="images/image204.jpg" style="width: 588.96px; height: 336.29px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 312.00px;"><img alt="" src="images/image187.jpg" style="width: 624.00px; height: 312.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/LudovicCreator/status/1811679395712479546&amp;sa=D&amp;source=editors&amp;ust=1730413583947768&amp;usg=AOvVaw0gwm0H4uDmuKeEdboO_kEe">https://x.com/LudovicCreator/status/1811679395712479546</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 565.40px; height: 706.75px;"><img alt="" src="images/image328.jpg" style="width: 565.40px; height: 706.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ThysaniaRegina/status/1811389409666924781&amp;sa=D&amp;source=editors&amp;ust=1730413583948231&amp;usg=AOvVaw2N8UOLrnXtJJUeKolg-_sh">https://x.com/ThysaniaRegina/status/1811389409666924781</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/bri_guy_ai/status/1811753268344766537&amp;sa=D&amp;source=editors&amp;ust=1730413583948581&amp;usg=AOvVaw31O5P_hWJGC4qZZtDn8tk1">https://x.com/bri_guy_ai/status/1811753268344766537</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/dreamingtulpa/status/1811381630428155941&amp;sa=D&amp;source=editors&amp;ust=1730413583948922&amp;usg=AOvVaw2D0viNhKoJzaHvs1Iu8CWE">https://x.com/dreamingtulpa/status/1811381630428155941</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 530.06px; height: 530.06px;"><img alt="" src="images/image406.jpg" style="width: 530.06px; height: 530.06px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/RobotCleopatra/status/1812573536592302253&amp;sa=D&amp;source=editors&amp;ust=1730413583949381&amp;usg=AOvVaw3caxVrPtbqF36ULTU86u87">https://x.com/RobotCleopatra/status/1812573536592302253</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 603.09px; height: 603.09px;"><img alt="" src="images/image521.jpg" style="width: 603.09px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/digitallywired/status/1812481019301200321&amp;sa=D&amp;source=editors&amp;ust=1730413583949923&amp;usg=AOvVaw0u-sIMp8QqVz1fcKD_oS2t">https://x.com/digitallywired/status/1812481019301200321</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 394.60px; height: 493.55px;"><img alt="" src="images/image31.jpg" style="width: 394.60px; height: 493.55px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image19.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 368.69px; height: 461.74px;"><img alt="" src="images/image295.jpg" style="width: 368.69px; height: 461.74px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jacaeryslg/status/1843546283652587910&amp;sa=D&amp;source=editors&amp;ust=1730413583950531&amp;usg=AOvVaw1qDzsvuDUaDxDziLW2P7hj">https://x.com/jacaeryslg/status/1843546283652587910</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1fak0jl/finally_an_update_on_improved_training_approaches/&amp;sa=D&amp;source=editors&amp;ust=1730413583950942&amp;usg=AOvVaw1H7eFZxu4-q2W2yqIp4oMo">https://www.reddit.com/r/StableDiffusion/comments/1fak0jl/finally_an_update_on_improved_training_approaches/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 397.50px; height: 397.50px;"><img alt="" src="images/image472.png" style="width: 397.50px; height: 397.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 522.50px; height: 522.50px;"><img alt="" src="images/image610.png" style="width: 522.50px; height: 522.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 470.50px; height: 470.50px;"><img alt="" src="images/image28.png" style="width: 470.50px; height: 470.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 486.50px; height: 486.50px;"><img alt="" src="images/image612.png" style="width: 486.50px; height: 486.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 519.50px; height: 519.50px;"><img alt="" src="images/image366.png" style="width: 519.50px; height: 519.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 481.50px; height: 481.50px;"><img alt="" src="images/image89.png" style="width: 481.50px; height: 481.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 423.50px; height: 423.50px;"><img alt="" src="images/image304.png" style="width: 423.50px; height: 423.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 477.50px; height: 477.50px;"><img alt="" src="images/image445.png" style="width: 477.50px; height: 477.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 510.50px; height: 510.50px;"><img alt="" src="images/image67.png" style="width: 510.50px; height: 510.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1fr4ov0/text_to_image_is_getting_so_good_at_text_and_more/&amp;sa=D&amp;source=editors&amp;ust=1730413583952201&amp;usg=AOvVaw3MdVcc2S8S56eShguvqknk">https://www.reddit.com/r/aiwars/comments/1fr4ov0/text_to_image_is_getting_so_good_at_text_and_more/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 357.33px;"><img alt="" src="images/image594.png" style="width: 624.00px; height: 357.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/javilopen/status/1831753822890602662&amp;sa=D&amp;source=editors&amp;ust=1730413583952614&amp;usg=AOvVaw2OmT0KI_gE3l3sMOMdQB5f">https://x.com/javilopen/status/1831753822890602662</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image373.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image335.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image410.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image646.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image79.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image621.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image147.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.32px; height: 603.09px;"><img alt="" src="images/image84.jpg" style="width: 452.32px; height: 603.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 802.67px;"><img alt="" src="images/image644.jpg" style="width: 624.00px; height: 802.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span>AI art with 5.2k upvotes that many people in the comments did not realize is AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Frieren/comments/1gam9w7/frieren_x_himmel_by_ulyssesx00/&amp;sa=D&amp;source=editors&amp;ust=1730413583953997&amp;usg=AOvVaw075-TJab4gFG-xCvDQFpM0">https://www.reddit.com/r/Frieren/comments/1gam9w7/frieren_x_himmel_by_ulyssesx00</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 494.33px; height: 741.50px;"><img alt="" src="images/image498.png" style="width: 494.33px; height: 741.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c50 c46 c129"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span>AI art with 205k likes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/pon_pon_pon_ai/status/1834916150301671471&amp;sa=D&amp;source=editors&amp;ust=1730413583954499&amp;usg=AOvVaw0LL90xvdDh3RFz7wCDPjGE">https://x.com/pon_pon_pon_ai/status/1834916150301671471</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 832.00px;"><img alt="" src="images/image565.jpg" style="width: 624.00px; height: 832.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 785.33px;"><img alt="" src="images/image47.png" style="width: 624.00px; height: 785.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiArt/comments/1f8oqi9/majestic_peacock_and_its_cosmic_feather/?share_id%3DZLMRIPiRchNQ1xxiNVN7j%26utm_content%3D1%26utm_medium%3Dandroid_app%26utm_name%3Dandroidcss%26utm_source%3Dshare%26utm_term%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583955161&amp;usg=AOvVaw2uCh4syD2yVRmBXqfIszpa">https://www.reddit.com/r/aiArt/comments/1f8oqi9/majestic_peacock_and_its_cosmic_feather/</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span>Everything on here: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/bettrthanbeeple&amp;sa=D&amp;source=editors&amp;ust=1730413583955508&amp;usg=AOvVaw1Mx6muI3HtMofeGlRvc0Aq">https://x.com/bettrthanbeeple</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 475.50px; height: 475.50px;"><img alt="" src="images/image624.png" style="width: 475.50px; height: 475.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 467.50px; height: 467.50px;"><img alt="" src="images/image352.png" style="width: 467.50px; height: 467.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 470.67px;"><img alt="" src="images/image576.jpg" style="width: 624.00px; height: 470.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 361.50px; height: 361.50px;"><img alt="" src="images/image71.png" style="width: 361.50px; height: 361.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image264.jpg" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_i0yf1mju0g1s-0 start"><li class="c50 c78 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1813290295964176561&amp;sa=D&amp;source=editors&amp;ust=1730413583956255&amp;usg=AOvVaw1gEFB4Mo5OfcvR_mq5-9Tp">https://x.com/nickfloats/status/1813290295964176561</a></span></li></ul><ul class="c0 lst-kix_i0yf1mju0g1s-1 start"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 395.50px; height: 395.50px;"><img alt="" src="images/image547.png" style="width: 395.50px; height: 395.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 204.00px;"><img alt="" src="images/image651.png" style="width: 320.00px; height: 204.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c1">Kling has realistic video generation despite a lack of compute: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1809322314225578158&amp;sa=D&amp;source=editors&amp;ust=1730413583956919&amp;usg=AOvVaw3NViO50Jciw_ahEBDE95gh">https://x.com/kimmonismus/status/1809322314225578158</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1813578798283255823&amp;sa=D&amp;source=editors&amp;ust=1730413583957139&amp;usg=AOvVaw1PNDnKPcdReWk5VGCGDIl6">https://x.com/_akhaliq/status/1813578798283255823</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>This was done in less than 24h by one person using AI as the ground tooling, some post in AE and that&rsquo;s it. Imagine the time and cost a real spot like this would cost. 100x less expensive due to AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/&amp;sa=D&amp;source=editors&amp;ust=1730413583957582&amp;usg=AOvVaw24KiWinXzY9yQj9Oej15xZ">https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c1">Popular AI generated memes:</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://knowyourmeme.com/memes/mr-chedda&amp;sa=D&amp;source=editors&amp;ust=1730413583957981&amp;usg=AOvVaw2QQwSE_S5Ot8zkAkYNOMAQ">https://knowyourmeme.com/memes/mr-chedda</a></span></li><li class="c50 c86 li-bullet-0"><span>Many comments stating the human-made version is worse than the AI-generated one: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/zxnoshima/status/1791227049928994867&amp;sa=D&amp;source=editors&amp;ust=1730413583958190&amp;usg=AOvVaw0VuhLmZjoozCy93F0_Rix3">https://x.com/zxnoshima/status/1791227049928994867</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 511.50px; height: 256.22px;"><img alt="" src="images/image182.png" style="width: 511.50px; height: 256.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CitizenPlain/status/1316760510709338112&amp;sa=D&amp;source=editors&amp;ust=1730413583958619&amp;usg=AOvVaw1naOkFKyFy7pZFS1JdhkpW">https://x.com/CitizenPlain/status/1316760510709338112</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.50px; height: 314.16px;"><img alt="" src="images/image630.jpg" style="width: 558.50px; height: 314.16px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://knowyourmeme.com/memes/ash-baby-screaming-baby-made-of-ash&amp;sa=D&amp;source=editors&amp;ust=1730413583959068&amp;usg=AOvVaw0nGPubPia-_Q_qqpkRrnyV">https://knowyourmeme.com/memes/ash-baby-screaming-baby-made-of-ash</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 c46 li-bullet-0"><span class="c1"></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://knowyourmeme.com/memes/angry-dr-mario-dr-marios-origin-story-ai-video&amp;sa=D&amp;source=editors&amp;ust=1730413583959475&amp;usg=AOvVaw2y-gE33FBaFpi7lsdK0RBX">https://knowyourmeme.com/memes/angry-dr-mario-dr-marios-origin-story-ai-video</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 421.69px; height: 397.55px;"><img alt="" src="images/image59.jpg" style="width: 421.69px; height: 397.55px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://knowyourmeme.com/memes/dope-flaming-shrimp-dunking-over-some-sharks&amp;sa=D&amp;source=editors&amp;ust=1730413583959858&amp;usg=AOvVaw0lxLvnQrycTD_UkCociHqH">https://knowyourmeme.com/memes/dope-flaming-shrimp-dunking-over-some-sharks</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/TheFigen_/status/1790803489859187112&amp;sa=D&amp;source=editors&amp;ust=1730413583960172&amp;usg=AOvVaw00dAT1bcKxYyWLfmvGEzuE">https://x.com/TheFigen_/status/1790803489859187112</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c1">(20k likes)</span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image548.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://knowyourmeme.com/memes/biden-shout&amp;sa=D&amp;source=editors&amp;ust=1730413583960649&amp;usg=AOvVaw1QGsznI5sUjj4LzcbRWWMZ">https://knowyourmeme.com/memes/biden-shout</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 578.50px; height: 578.50px;"><img alt="" src="images/image332.png" style="width: 578.50px; height: 578.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/6722cbef-cf54-8000-b2be-61636a66da04&amp;sa=D&amp;source=editors&amp;ust=1730413583960946&amp;usg=AOvVaw09vjOZB48Nd7IswL2m3U8p">https://chatgpt.com/share/6722cbef-cf54-8000-b2be-61636a66da04</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 540.50px; height: 540.50px;"><img alt="" src="images/image282.png" style="width: 540.50px; height: 540.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1gfih4y/asked_chatgpt_to_show_me_a_shtpost/&amp;sa=D&amp;source=editors&amp;ust=1730413583961325&amp;usg=AOvVaw3pqOVyxsz-98Juy5iSL-Ow">https://www.reddit.com/r/ChatGPT/comments/1gfih4y/asked_chatgpt_to_show_me_a_shtpost/</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span>AI meme with 169k likes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Skvlvtvn/status/1843335191890424218&amp;sa=D&amp;source=editors&amp;ust=1730413583961657&amp;usg=AOvVaw1kRFSqf6ReYrJIEhUAoyci">https://x.com/Skvlvtvn/status/1843335191890424218</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://trending.knowyourmeme.com/editorials/guides/what-is-the-how-do-you-spell-chauffeur-song-tiktoks-viral-fancy-pants-rich-mcgee-meme-explained&amp;sa=D&amp;source=editors&amp;ust=1730413583962065&amp;usg=AOvVaw3_aI0tvqz4BRpWFz8274-O">https://trending.knowyourmeme.com/editorials/guides/what-is-the-how-do-you-spell-chauffeur-song-tiktoks-viral-fancy-pants-rich-mcgee-meme-explained</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/haultrukkz/status/1799490974151799174&amp;sa=D&amp;source=editors&amp;ust=1730413583962323&amp;usg=AOvVaw2tfGVQgY0rk9xxgMHJQHAc">https://x.com/haultrukkz/status/1799490974151799174</a></span></li><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/FacebookAIslop/status/1804419391255093269&amp;sa=D&amp;source=editors&amp;ust=1730413583962579&amp;usg=AOvVaw2LL83uuwUy0ME9qsASs8M4">https://x.com/FacebookAIslop/status/1804419391255093269</a></span></li><li class="c50 c86 li-bullet-0"><span class="c1">(everyone likes the art)</span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-2"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/umesh_ai/status/1812031272408994083&amp;sa=D&amp;source=editors&amp;ust=1730413583962909&amp;usg=AOvVaw3eoXXxrtkpa4s-2j0ZCNrz">https://x.com/umesh_ai/status/1812031272408994083</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c17 li-bullet-0"><span>130k likes on AI image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/picsthatg0hard_/status/1814537639082795480&amp;sa=D&amp;source=editors&amp;ust=1730413583963171&amp;usg=AOvVaw0_lIMWBozOdIlR68CcMr4y">https://x.com/picsthatg0hard_/status/1814537639082795480</a></span></li><li class="c17 li-bullet-0"><span>101k likes on AI meme: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/waystarroyhoe/status/1825298333985824874&amp;sa=D&amp;source=editors&amp;ust=1730413583963381&amp;usg=AOvVaw1gs0X4D2i0GGfj-eL6ID85">https://x.com/waystarroyhoe/status/1825298333985824874</a></span></li><li class="c17 li-bullet-0"><span>AI meme with 80k likes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/bigdybbukenergy/status/1847382264877109264&amp;sa=D&amp;source=editors&amp;ust=1730413583963620&amp;usg=AOvVaw0s_29QCqtfVTwcZiEpWIcW">https://x.com/bigdybbukenergy/status/1847382264877109264</a></span></li><li class="c17 li-bullet-0"><span>AI used for meme with 32k likes: </span><span class="c5 c55"><a class="c13" href="https://www.google.com/url?q=https://x.com/Ovirtuous_/status/1847723007198056855&amp;sa=D&amp;source=editors&amp;ust=1730413583963888&amp;usg=AOvVaw2IQlSWsLe9HuMQN2SRF0Sk">https://x.com/Ovirtuous_/status/1847723007198056855</a></span></li><li class="c17 li-bullet-0"><span>90k likes on AI image of Snoop Dogg in the style of Studio Ghibli: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/90sPiictures/status/1830968058401431575&amp;sa=D&amp;source=editors&amp;ust=1730413583964129&amp;usg=AOvVaw0KAhejdMvDzcFEWeEIF0Yr">https://x.com/90sPiictures/status/1830968058401431575</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-2 start"><li class="c50 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 564.50px; height: 564.50px;"><img alt="" src="images/image323.jpg" style="width: 564.50px; height: 564.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c50 c78 li-bullet-0"><span class="c1">AI images are getting very realistic</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1795525684628242906&amp;sa=D&amp;source=editors&amp;ust=1730413583964475&amp;usg=AOvVaw2k9RBOEbjI24le4Z__qBzY">https://x.com/nickfloats/status/1795525684628242906</a></span><span class="c1">&nbsp;</span></li><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1794082708198420782&amp;sa=D&amp;source=editors&amp;ust=1730413583964697&amp;usg=AOvVaw2_1gSIbDB_Af_MuFq_HPIS">https://x.com/nickfloats/status/1794082708198420782</a></span><span class="c1">&nbsp;</span></li><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/gdb/status/1790869434174746805&amp;sa=D&amp;source=editors&amp;ust=1730413583964956&amp;usg=AOvVaw1IsprYGeQMWSrDRMZ_erhQ">https://x.com/gdb/status/1790869434174746805</a></span><span>&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/310571/boring-reality&amp;sa=D&amp;source=editors&amp;ust=1730413583965239&amp;usg=AOvVaw0pfEBdDa6Ag5mCzu8BovIW">https://civitai.com/models/310571/boring-reality</a></span><span class="c6 c40">&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1794082708198420782&amp;sa=D&amp;source=editors&amp;ust=1730413583965492&amp;usg=AOvVaw0_ory2_rvqeLBumGIFQr9E">https://x.com/nickfloats/status/1794082708198420782</a></span><span class="c6 c40">&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/doganuraldesign/status/1797397984629445015&amp;sa=D&amp;source=editors&amp;ust=1730413583965756&amp;usg=AOvVaw2JqywM2XNT0h36nGgNLtTW">https://x.com/doganuraldesign/status/1797397984629445015</a></span><span class="c6 c40">&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ARTiV3RSE/status/1809708250243432777&amp;sa=D&amp;source=editors&amp;ust=1730413583966004&amp;usg=AOvVaw1dfIIWjctAny_C-WbyVYst">https://x.com/ARTiV3RSE/status/1809708250243432777</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c130 c78 li-bullet-0"><span class="c31">UltraPixel is now on Replicate. Based on Stable Cascade, you can use it to make up to 4096x4096 images without upscaling: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/fofrAI/status/1815043204086956444&amp;sa=D&amp;source=editors&amp;ust=1730413583966302&amp;usg=AOvVaw0NnM4Nd2uTo7t9vS-mzEOQ">https://x.com/fofrAI/status/1815043204086956444</a></span></li><li class="c4 li-bullet-0"><span>Juggernaut XI World Wide Release | Better Prompt Adherence | Text Generation | Styling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1f4369h/juggernaut_xi_world_wide_release_better_prompt/&amp;sa=D&amp;source=editors&amp;ust=1730413583966609&amp;usg=AOvVaw3wWeTiu4QRNkHnqCt9HROV">https://www.reddit.com/r/StableDiffusion/comments/1f4369h/juggernaut_xi_world_wide_release_better_prompt/</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1">Kling has realistic video generation despite a lack of compute: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1809322314225578158&amp;sa=D&amp;source=editors&amp;ust=1730413583967031&amp;usg=AOvVaw0m1AMGYffBoqdg3ShoAPkM">https://x.com/kimmonismus/status/1809322314225578158</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsumotokai/status/1810128665889685596&amp;sa=D&amp;source=editors&amp;ust=1730413583967280&amp;usg=AOvVaw0--VHZ64TuQPSij4IW3D-Q">https://x.com/tsumotokai/status/1810128665889685596</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1810547329356771827&amp;sa=D&amp;source=editors&amp;ust=1730413583967527&amp;usg=AOvVaw0ctFEODixFRaNqzjuGzoM5">https://x.com/kimmonismus/status/1810547329356771827</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1810952037246349739&amp;sa=D&amp;source=editors&amp;ust=1730413583967748&amp;usg=AOvVaw3c2pWQOOmFa6ursibRQIkC">https://x.com/CharaspowerAI/status/1810952037246349739</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1811105682000671147&amp;sa=D&amp;source=editors&amp;ust=1730413583967971&amp;usg=AOvVaw2JwNS_xfzvopdg1rZndkHn">https://x.com/CharaspowerAI/status/1811105682000671147</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/&amp;sa=D&amp;source=editors&amp;ust=1730413583968210&amp;usg=AOvVaw0ZZltXrMk9nSshWzJtuQpn">https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1">Good AI videos: </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span>New SOTA coming soon: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/&amp;sa=D&amp;source=editors&amp;ust=1730413583968585&amp;usg=AOvVaw0SkRlkAyG6jIMV87yy00GU">https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/</a></span></li><li class="c10 li-bullet-0"><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1811727094499385347&amp;sa=D&amp;source=editors&amp;ust=1730413583968836&amp;usg=AOvVaw03vb66ks7e4_MJG-13h1Un">https://x.com/kimmonismus/status/1811727094499385347</a></span></li><li class="c10 li-bullet-0"><span class="c5 c43"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/&amp;sa=D&amp;source=editors&amp;ust=1730413583969116&amp;usg=AOvVaw2zUj1YpnrssIHid-IuC_ab">https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Diesol/status/1810468576882770109&amp;sa=D&amp;source=editors&amp;ust=1730413583969348&amp;usg=AOvVaw3gTkfh0jEM14AAhEiRFk7Y">https://x.com/Diesol/status/1810468576882770109</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kimmonismus/status/1810949448584855729&amp;sa=D&amp;source=editors&amp;ust=1730413583969595&amp;usg=AOvVaw3EnVnJNavUdy_FZ0ung0r7">https://x.com/kimmonismus/status/1810949448584855729</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/shanef3d/status/1811505820129214687&amp;sa=D&amp;source=editors&amp;ust=1730413583969825&amp;usg=AOvVaw2w9CaJdv7VDAG09Wc0WR04">https://x.com/shanef3d/status/1811505820129214687</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ai_for_success/status/1811576761617928300&amp;sa=D&amp;source=editors&amp;ust=1730413583970078&amp;usg=AOvVaw1NHr9vJDXI4Kt-iNu6xuzg">https://x.com/ai_for_success/status/1811576761617928300</a></span></li><li class="c10 li-bullet-0"><span>Hands: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/arohaAIX/status/1811381195676307623&amp;sa=D&amp;source=editors&amp;ust=1730413583970328&amp;usg=AOvVaw319cIelfVIebSitP5rVS0Y">https://x.com/arohaAIX/status/1811381195676307623</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1e0hwiq/mixing_ai_music_suno_and_ai_video_runway/&amp;sa=D&amp;source=editors&amp;ust=1730413583970614&amp;usg=AOvVaw1nFNge19-2yT7dyx-vdaKm">https://www.reddit.com/r/aiwars/comments/1e0hwiq/mixing_ai_music_suno_and_ai_video_runway/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e1nhn5/poof/&amp;sa=D&amp;source=editors&amp;ust=1730413583970863&amp;usg=AOvVaw2_pKuiq6w75wHBgzD2ZVK2">https://www.reddit.com/r/aivideo/comments/1e1nhn5/poof/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/CharaspowerAI/status/1812531456452747276&amp;sa=D&amp;source=editors&amp;ust=1730413583971112&amp;usg=AOvVaw0QqclA7CGCHqbABya7rxNu">https://x.com/CharaspowerAI/status/1812531456452747276</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/&amp;sa=D&amp;source=editors&amp;ust=1730413583971366&amp;usg=AOvVaw35yyrJcRvYyxaqL2m-8_mR">https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/</a></span></li><li class="c10 li-bullet-0"><span>Grand Theft Auto in India: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/&amp;sa=D&amp;source=editors&amp;ust=1730413583971587&amp;usg=AOvVaw0HagcykY2540yyA7NRfLcK">https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/runwayml/status/1816096185016357030&amp;sa=D&amp;source=editors&amp;ust=1730413583971856&amp;usg=AOvVaw2nLlKbOiAN6OU70H7ZSlkr">https://x.com/runwayml/status/1816096185016357030</a></span></li><li class="c10 li-bullet-0"><span>Apples to guinea pigs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/&amp;sa=D&amp;source=editors&amp;ust=1730413583972145&amp;usg=AOvVaw0ZGXlfUVASOaqtJuoMvN25">https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/</a></span></li><li class="c10 li-bullet-0"><span>Person speaking: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/&amp;sa=D&amp;source=editors&amp;ust=1730413583972442&amp;usg=AOvVaw11YM9E00sRHyE7j7Ap_nU4">https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1f527rg/just_going_for_a_lil_walk/&amp;sa=D&amp;source=editors&amp;ust=1730413583972719&amp;usg=AOvVaw26qSavpCE2g6XiKUHBVodc">https://www.reddit.com/r/aivideo/comments/1f527rg/just_going_for_a_lil_walk/</a></span></li><li class="c10 li-bullet-0"><span>Burger King commercial parody: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413583973005&amp;usg=AOvVaw0Kp_uX46pCNdHHWp7HfbII">https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Runway and Lionsgate are partnering to explore the use of AI in film production: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://runwayml.com/news/runway-partners-with-lionsgate&amp;sa=D&amp;source=editors&amp;ust=1730413583973261&amp;usg=AOvVaw1g9Rq2gQEtJe_80INmQfx1">https://runwayml.com/news/runway-partners-with-lionsgate</a></span></li><li class="c4 li-bullet-0"><span>Late Night With the Devil movie uses AI art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://letterboxd.com/film/late-night-with-the-devil/&amp;sa=D&amp;source=editors&amp;ust=1730413583973535&amp;usg=AOvVaw1K6DuBGR1DXXbsnqOBc1kO">https://letterboxd.com/film/late-night-with-the-devil/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span>Recommended by Chainsaw Man/Look Back/Goodbye Eri author Tatsuki Fujimoto: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 464.00px;"><img alt="" src="images/image162.png" style="width: 624.00px; height: 464.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Other people like it too: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/&amp;sa=D&amp;source=editors&amp;ust=1730413583974010&amp;usg=AOvVaw2RrHlCv6NFv4lL5hKbI0Ap">https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/</a></span></li><li class="c10 li-bullet-0"><span class="c1">3.4 out of 5 on Letterboxed despite anti AI review bombing (very good movies typically receive a 3.5-4.0)</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve &ldquo;hundreds&rdquo; of people at the company and will primarily focus on post-production and visual effects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.thewrap.com/disney-ai-initiative/&amp;sa=D&amp;source=editors&amp;ust=1730413583974390&amp;usg=AOvVaw0wpzlgV5N9haPTtCW5X9yu">https://www.thewrap.com/disney-ai-initiative/</a></span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language&amp;sa=D&amp;source=editors&amp;ust=1730413583974706&amp;usg=AOvVaw3jdXWA-OkAbUmnK9RLJrUg">https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image419.png" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 560.80px; height: 421.50px;"><img alt="" src="images/image96.png" style="width: 560.80px; height: 421.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Style control: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 221.33px;"><img alt="" src="images/image7.png" style="width: 624.00px; height: 221.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><h2 class="c64" id="h.fo1vk08bo7yv"><span class="c40 c37 c48 c75">11.3. Glaze/Nightshade</span></h2><ul class="c0 lst-kix_apk8f490x7qb-0 start"><li class="c4 li-bullet-0"><span class="c15">Glaze can actually IMPROVE AI training </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/blog/parsee-mizuhashi/glaze-and-anti-ai-methods&amp;sa=D&amp;source=editors&amp;ust=1730413583975546&amp;usg=AOvVaw1sGcYt6bTDNiB6OcTfnxG2">https://huggingface.co/blog/parsee-mizuhashi/glaze-and-anti-ai-methods</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_apk8f490x7qb-1 start"><li class="c8 li-bullet-0"><span>&ldquo;Noise offset, as described by </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.crosslabs.org/blog/diffusion-with-offset-noise&amp;sa=D&amp;source=editors&amp;ust=1730413583975910&amp;usg=AOvVaw2Sn-LJCpNp-f1-LYHojbbg">crosslabs&#39;s article</a></span><span>&nbsp;works by adding a small non-0 number to the latent image before passing it to the diffuser. This effectively increases the most contrast possible by making the model see more light/dark colors. Glaze and Nightshade effectively add noise to the images, acting as a sort of noise offset at train time. This can explain why </span><span class="c15">images generated with LoRAs trained with glazed images look better than non-glazed images</span><span class="c1">.&rdquo;</span></li></ul><p class="c116 c9 c97"><span class="c1"></span></p><ul class="c0 lst-kix_apk8f490x7qb-1"><li class="c8 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/1412.6572&amp;sa=D&amp;source=editors&amp;ust=1730413583976349&amp;usg=AOvVaw2astsLsAhOoNg7cvbjn8QL">https://arxiv.org/pdf/1412.6572</a></span></li></ul><ul class="c0 lst-kix_apk8f490x7qb-2 start"><li class="c116 c7 li-bullet-0"><span class="c1">Using this approach to provide examples for adversarial training (eg Glaze/Nightshade), we REDUCE the test set error of a maxout network on the MNIST dataset.</span></li></ul><p class="c116 c9 c97"><span class="c1"></span></p><ul class="c0 lst-kix_apk8f490x7qb-0"><li class="c116 c4 li-bullet-0"><span>Glaze does not work according to ETH Zurich lab: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://spylab.ai/blog/glaze/&amp;sa=D&amp;source=editors&amp;ust=1730413583976822&amp;usg=AOvVaw3QZZXHqqI7WgiSz2Z5D2iL">https://spylab.ai/blog/glaze/</a></span></li><li class="c116 c131 c78 li-bullet-0"><span>Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2406.12027v1&amp;sa=D&amp;source=editors&amp;ust=1730413583977115&amp;usg=AOvVaw1pNnPnyRj5Bu6fq6vfIUBb">https://arxiv.org/pdf/2406.12027v1</a></span></li></ul><ul class="c0 lst-kix_apk8f490x7qb-1 start"><li class="c116 c89 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 493.33px;"><img alt="" src="images/image360.png" style="width: 624.00px; height: 493.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c116 c89 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 288.00px;"><img alt="" src="images/image554.png" style="width: 624.00px; height: 288.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c116 c89 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 381.33px;"><img alt="" src="images/image423.png" style="width: 624.00px; height: 381.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c116 c89 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 344.00px;"><img alt="" src="images/image474.png" style="width: 624.00px; height: 344.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_apk8f490x7qb-0"><li class="c4 li-bullet-0"><span>Easy to detect and filter from datasets: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/RichardAragon/NightshadeAntidote?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413583977849&amp;usg=AOvVaw1Qfvpd7yTPZEis7nZkrupb">https://github.com/RichardAragon/NightshadeAntidote?darkschemeovr=1</a></span></li><li class="c4 li-bullet-0"><span class="c1">Also easy to remove the poison: </span></li></ul><ul class="c0 lst-kix_apk8f490x7qb-1 start"><li class="c10 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://github.com/yoinked-h/deglazer&amp;sa=D&amp;source=editors&amp;ust=1730413583978171&amp;usg=AOvVaw0tILSZ3eG_RsdYIH4s3gm8">https://github.com/yoinked-h/deglazer</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/p1atdev/stable-diffusion-webui-adverse-cleaner-tab/tree/main&amp;sa=D&amp;source=editors&amp;ust=1730413583978476&amp;usg=AOvVaw3soTRYGUiZeNgn0DVQcOUh">https://github.com/p1atdev/stable-diffusion-webui-adverse-cleaner-tab/tree/main</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://web.archive.org/web/20231209210532/https://github.com/lllyasviel/AdverseCleaner&amp;sa=D&amp;source=editors&amp;ust=1730413583978766&amp;usg=AOvVaw1UfHukIw_9FldB1m_P3AM1">https://web.archive.org/web/20231209210532/https://github.com/lllyasviel/AdverseCleaner</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/parsee-mizuhashi/nightshade-antidote&amp;sa=D&amp;source=editors&amp;ust=1730413583979033&amp;usg=AOvVaw11k41iRfrOgg8sE3cgkq8b">https://github.com/parsee-mizuhashi/nightshade-antidote</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/ghunkins/Voice-Denoising-AN&amp;sa=D&amp;source=editors&amp;ust=1730413583979302&amp;usg=AOvVaw2XoForpuVg0MsI8EB_TqYh">https://github.com/ghunkins/Voice-Denoising-AN</a></span></li></ul><ul class="c0 lst-kix_apk8f490x7qb-0"><li class="c4 li-bullet-0"><span>Ruins image quality: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 154.71px; height: 410.50px;"><img alt="" src="images/image340.png" style="width: 154.71px; height: 410.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_apk8f490x7qb-0"><li class="c4 li-bullet-0"><span>Ineffective (the image shown below is from </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://nightshade.cs.uchicago.edu/whatis.html&amp;sa=D&amp;source=editors&amp;ust=1730413583979797&amp;usg=AOvVaw3rHtHz5j-ZadRJVFCF_HBU">Nightshade&rsquo;s own website</a></span><span class="c1">): </span></li></ul><p class="c21"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 389.50px; height: 500.46px;"><img alt="" src="images/image378.png" style="width: 389.50px; height: 500.46px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><ul class="c0 lst-kix_kfuatcy312kx-0 start"><li class="c4 li-bullet-0"><span>In</span><span>&nbsp;response to the Carlini paper posted above, one scientist behind glaze/nightshade (Ben Zhao) has thrown multiple hissyfits and has attempted to publicly libel the scientists that dare try to validate their work- thereby also leading to harassment: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://old.reddit.com/r/aiwars/comments/1doe1tt/why_i_attack_nicholas_carlini_responds_to/&amp;sa=D&amp;source=editors&amp;ust=1730413583980316&amp;usg=AOvVaw0ImH4W7k8EtD2TnLa8y2je">https://old.reddit.com/r/aiwars/comments/1doe1tt/why_i_attack_nicholas_carlini_responds_to/</a></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.1ki5amzf082x"><span>11.4. </span><span>Music</span></h2><ul class="c0 lst-kix_codfi3rttsmj-0 start"><li class="c4 li-bullet-0"><span class="c24">AI-made remix of another AI song: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1kSQjtbjYd45DroFtAiBDd&amp;sa=D&amp;source=editors&amp;ust=1730413583980922&amp;usg=AOvVaw1YTmJ7EuEmyaZWOKUDS_mh">https://www.udio.com/songs/1kSQjtbjYd45DroFtAiBDd</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1 start"><li class="c10 li-bullet-0"><span class="c24">The original song (VERY different, less than half the length, and has no vocals or percussion counterpoint): </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/dUdbjyscaTTGGyjoN28H7a&amp;sa=D&amp;source=editors&amp;ust=1730413583981251&amp;usg=AOvVaw0dbM_wVIugLs_n_qEOnr06">https://www.udio.com/songs/dUdbjyscaTTGGyjoN28H7a</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c112 c37 c35 c48 c120">Computer-generated and non-deterministic music has existed for many decades:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1 start"><li class="c10 li-bullet-0"><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Aleatoric_music&amp;sa=D&amp;source=editors&amp;ust=1730413583981591&amp;usg=AOvVaw1G7w_BI__w4CRmCN9PhAB7">https://en.wikipedia.org/wiki/Aleatoric_music</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c112 c37 c35 c48 c120">Coined in the 50s</span></li><li class="c7 li-bullet-0"><span class="c24">Leaves parts of music to pure chance</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Generative_music&amp;sa=D&amp;source=editors&amp;ust=1730413583982001&amp;usg=AOvVaw0hYwHtZH1KCddOaP3L1Wu0">https://en.wikipedia.org/wiki/Generative_music</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c24">Popularized by Brian Eno, who likes AI (see section 11.5)</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Algorithmic_composition&amp;sa=D&amp;source=editors&amp;ust=1730413583982303&amp;usg=AOvVaw0-Bu1O_nTrc16obpOjNSnG">https://en.wikipedia.org/wiki/Algorithmic_composition</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c24">Uses algorithms to create music</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c24">We recently announced JASCO, a music-generation model with improved controllability using conditioning inputs like chords or beat: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIatMeta/status/1814405505789706253&amp;sa=D&amp;source=editors&amp;ust=1730413583982636&amp;usg=AOvVaw2SyCugBmQmBU9HOiUb20Td">https://x.com/AIatMeta/status/1814405505789706253</a></span></li><li class="c4 li-bullet-0"><span class="c14">MusiConGen, Rhythm and Chord Control for Transformer-Based Text-to-Music Generation: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.15060&amp;sa=D&amp;source=editors&amp;ust=1730413583982890&amp;usg=AOvVaw07nTdxyQ2JIKoZSw9iDumo">https://huggingface.co/papers/2407.15060</a></span></li><li class="c4 li-bullet-0"><span>Udio introduces Udio 1.5 with significantly improved audio quality: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/blog/introducing-v1-5&amp;sa=D&amp;source=editors&amp;ust=1730413583983118&amp;usg=AOvVaw29Wm_ZqHPlqF71Dprh2mCa">https://www.udio.com/blog/introducing-v1-</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/blog/introducing-v1-5&amp;sa=D&amp;source=editors&amp;ust=1730413583983244&amp;usg=AOvVaw338i7QiQeHh-LU15X5sZDk">5</a></span></li><li class="c4 li-bullet-0"><span class="c14">Precise control over edits: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/udiomusic/status/1851719943626395778&amp;sa=D&amp;source=editors&amp;ust=1730413583983469&amp;usg=AOvVaw085IiSoNfIZBX_fZAODhe2">https://x.com/udiomusic/status/1851719943626395778</a></span></li><li class="c4 li-bullet-0"><span class="c1 c14">Professional musciscians impressed by AI music: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1 start"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dc3VeXE5Rbps&amp;sa=D&amp;source=editors&amp;ust=1730413583983712&amp;usg=AOvVaw2nKUnurjpZ9ygCwn-HW_vU">https://www.youtube.com/watch?v=c3VeXE5Rbps</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DZxYAtL0D50A&amp;sa=D&amp;source=editors&amp;ust=1730413583983894&amp;usg=AOvVaw2Ad29W0BaW4jthOJDRwwry">https://www.youtube.com/watch?v=ZxYAtL0D50A</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DaQC0FI_asKY&amp;sa=D&amp;source=editors&amp;ust=1730413583984080&amp;usg=AOvVaw03AF6elRxp_ZeBorHIPn8-">https://www.youtube.com/watch?v=aQC0FI_asKY</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DPCYTqDSUbvU&amp;sa=D&amp;source=editors&amp;ust=1730413583984281&amp;usg=AOvVaw2gskJzcUDTh1LwZM2xnGoD">https://www.youtube.com/watch?v=PCYTqDSUbvU</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c14">AI music creator has 229k total subscribers and 7.5 million views on all channels </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/@ObscurestVinyl/videos&amp;sa=D&amp;source=editors&amp;ust=1730413583984498&amp;usg=AOvVaw3TNmj39O1ziHXAb4KamKjE">https://m.youtube.com/@ObscurestVinyl</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">Topic channel: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/channel/UCSeqzYZQ8GEoF6eMdvJREyw&amp;sa=D&amp;source=editors&amp;ust=1730413583984757&amp;usg=AOvVaw0IzhO2fbMqFll4U4tzXjOp">https://m.youtube.com/channel/UCSeqzYZQ8GEoF6eMdvJREyw</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">A few very popular songs: </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DwPlOYPGMRws%26pp%3DygUPb2JzY3VyZXN0IHZpbnls&amp;sa=D&amp;source=editors&amp;ust=1730413583985209&amp;usg=AOvVaw1c6_nUYo7JzeLowWCR6W8U">https://m.youtube.com/watch?v=wPlOYPGMRws&amp;pp=ygUPb2JzY3VyZXN0IHZpbnls</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D7zTei5RMhQ8%26pp%3DygUPb2JzY3VyZXN0IHZpbnls&amp;sa=D&amp;source=editors&amp;ust=1730413583985456&amp;usg=AOvVaw1If1DuAvMvotA477_KNBdX">https://m.youtube.com/watch?v=7zTei5RMhQ8&amp;pp=ygUPb2JzY3VyZXN0IHZpbnls</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DsuXO7Yy_A-8%26pp%3DygUPb2JzY3VyZXN0IHZpbnls&amp;sa=D&amp;source=editors&amp;ust=1730413583985707&amp;usg=AOvVaw0b9EVABLZHamOSIb2w61QQ">https://m.youtube.com/watch?v=suXO7Yy_A-8&amp;pp=ygUPb2JzY3VyZXN0IHZpbnls</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c1 c14">AI song covers with have hundreds of thousands or even millions of views each: </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DGvnTSLS1dTU&amp;sa=D&amp;source=editors&amp;ust=1730413583986130&amp;usg=AOvVaw3ivXofzDmCOLXy7iN4CcYA">https://m.youtube.com/watch?v=GvnTSLS1dTU</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DVNWudHD3Kt8&amp;sa=D&amp;source=editors&amp;ust=1730413583986399&amp;usg=AOvVaw3IBw9xDqdp9SiGm5KIVLjc">https://m.youtube.com/watch?v=VNWudHD3Kt8</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DrH14QH9jSDQ&amp;sa=D&amp;source=editors&amp;ust=1730413583986657&amp;usg=AOvVaw0XZMv1Bfol6laste5ZeJNO">https://m.youtube.com/watch?v=rH14QH9jSDQ</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D-pAW1-bSsAc&amp;sa=D&amp;source=editors&amp;ust=1730413583986985&amp;usg=AOvVaw3SUsu65vhi9x7fndmzr006">https://m.youtube.com/watch?v=-pAW1-bSsAc</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D_Y543NEiR5w&amp;sa=D&amp;source=editors&amp;ust=1730413583987200&amp;usg=AOvVaw3JGeqT3G14a0QB6nF9Dbz7">https://m.youtube.com/watch?v=_Y543NEiR5w</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D-ugjFAljBKI&amp;sa=D&amp;source=editors&amp;ust=1730413583987418&amp;usg=AOvVaw2IxZXnHrvFeq1xdA7ZcJl3">https://m.youtube.com/watch?v=-ugjFAljBKI</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Df32P3ZAoJg0&amp;sa=D&amp;source=editors&amp;ust=1730413583987635&amp;usg=AOvVaw13LI4zYQt1Mu4aRzlMQhli">https://m.youtube.com/watch?v=f32P3ZAoJg0</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D89H4OyZRFcA&amp;sa=D&amp;source=editors&amp;ust=1730413583987854&amp;usg=AOvVaw0CJf6Y2s7NPq-bTpCYuaH-">https://m.youtube.com/watch?v=89H4OyZRFcA</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">There are MANY more</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c14">AI generated song remixed by Metro Boomin, who did not even realize it was AI generated: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy&amp;sa=D&amp;source=editors&amp;ust=1730413583988276&amp;usg=AOvVaw1rbbe7E17HMwHwceaDbOCv">https://en.m.wikipedia.org/wiki/BBL_Drizzy</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c97 c105 c109 li-bullet-0"><span class="c18 c92 c108 c14">Unbeknownst to Metro at the time, the original track&#39;s vocals and instrumental were generated entirely by an artificial intelligence model.</span></li><li class="c109 c97 c105 li-bullet-0"><span class="c29 c14">Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Elon_Musk&amp;sa=D&amp;source=editors&amp;ust=1730413583988596&amp;usg=AOvVaw3kmQG4zuoLvztxnKdVioDj">Elon Musk</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Dr._Miami&amp;sa=D&amp;source=editors&amp;ust=1730413583988736&amp;usg=AOvVaw3jkHDlse-DeLa1zbVZrTC_">Dr. Miami</a></span><span class="c29 c14">&nbsp;reacted to the beat.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Complex_Cowen2024_DrMiamiLooping-19&amp;sa=D&amp;source=editors&amp;ust=1730413583988889&amp;usg=AOvVaw20bqogo3rmZ1TZBnCQnhC7">[19]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Dexerto_Horetski2024_WhatDoesBBLDrizzyMean-20&amp;sa=D&amp;source=editors&amp;ust=1730413583989019&amp;usg=AOvVaw2WqkgfXYUZLvrP2cnriPbJ">[20]</a></span><span class="c29 c14">&nbsp;Several corporations also responded, including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Educational_technology&amp;sa=D&amp;source=editors&amp;ust=1730413583989160&amp;usg=AOvVaw1VRTUv8ycUq639jgoeeeBR">educational technology</a></span><span class="c29 c14">&nbsp;company </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Duolingo&amp;sa=D&amp;source=editors&amp;ust=1730413583989291&amp;usg=AOvVaw005b3h7vJShw57nQAtUf7X">Duolingo</a></span><span class="c29 c14">&nbsp;and meat producer </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Oscar_Mayer&amp;sa=D&amp;source=editors&amp;ust=1730413583989439&amp;usg=AOvVaw2ILz9uY2XD1KdgdRnDNtPc">Oscar Mayer</a></span><span class="c29 c14">.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-XXL_Ech2024_OscarMeyerBBLGlizzy-21&amp;sa=D&amp;source=editors&amp;ust=1730413583989611&amp;usg=AOvVaw3JO03MoAcP5tnEx6AqpMuQ">[21]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Dexerto_Horetski2024_WhatDoesBBLDrizzyMean-20&amp;sa=D&amp;source=editors&amp;ust=1730413583989764&amp;usg=AOvVaw3JZJXTXJVyxeOdGy3tC40C">[20]</a></span></li><li class="c109 c97 c105 li-bullet-0"><span class="c29 c14">In addition to users releasing freestyle raps over the instrumental, the track also evolved into a </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Viral_phenomenon&amp;sa=D&amp;source=editors&amp;ust=1730413583989989&amp;usg=AOvVaw1nfanpyUtCmWoiln-id2JI">viral phenomenon</a></span><span class="c29 c14">&nbsp;where users would create remixes of the song beyond the </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Hip_hop_music&amp;sa=D&amp;source=editors&amp;ust=1730413583990127&amp;usg=AOvVaw1uB_CysnlnxwSv_14UESNa">hip hop</a></span><span class="c29 c14">&nbsp;genre.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-BET_Grove2024_BBLDrizzyRemixTreatment-22&amp;sa=D&amp;source=editors&amp;ust=1730413583990280&amp;usg=AOvVaw2cJUtTpJrBVClBHQcX6n-H">[22]</a></span><span class="c29 c14">&nbsp;Many recreated the song in other genres, including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/House_music&amp;sa=D&amp;source=editors&amp;ust=1730413583990419&amp;usg=AOvVaw0bx6TWtKaKaGuCqmJ0IKCv">house</a></span><span class="c29 c14">, </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Merengue_music&amp;sa=D&amp;source=editors&amp;ust=1730413583990617&amp;usg=AOvVaw2j1cyiEYvKmS4EnQoIRhUZ">merengue</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Hindi_film_music&amp;sa=D&amp;source=editors&amp;ust=1730413583990781&amp;usg=AOvVaw1jr1acTv5jd9NtqGwUvTdU">Bollywood</a></span><span class="c29 c14">.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Billboard_Saponara2024_FanRemixesGoingViral-23&amp;sa=D&amp;source=editors&amp;ust=1730413583991028&amp;usg=AOvVaw1xeEesN5APaDHcs2DrzW6p">[23]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Gizmodo_Zeff2024_SagaOfBBLDrizzy-18&amp;sa=D&amp;source=editors&amp;ust=1730413583991222&amp;usg=AOvVaw1z0_xzjWhf_FGmm-BkqPy0">[18]</a></span><span class="c29 c14">&nbsp;Users also created covers of the song on a variety of </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Musical_instruments&amp;sa=D&amp;source=editors&amp;ust=1730413583991458&amp;usg=AOvVaw2cSPLsd-FC-9QbJt4FufPr">musical instruments</a></span><span class="c29 c14">, including on </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Saxophone&amp;sa=D&amp;source=editors&amp;ust=1730413583991678&amp;usg=AOvVaw11bbnq_hgzrUwgjB7hLgQX">saxophone</a></span><span class="c29 c14">, </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Guitar&amp;sa=D&amp;source=editors&amp;ust=1730413583991881&amp;usg=AOvVaw2eY0rJdbs4HJ7ZwV_k5mol">guitar</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Harp&amp;sa=D&amp;source=editors&amp;ust=1730413583992087&amp;usg=AOvVaw0g8Zso8loxlAd5rNkA7zQw">harp</a></span><span class="c29 c14">.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">3.88/5 with 613 reviews on Rate Your Music (the best albums of ALL time get about a &#8536; on the site) </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">86 on Album of the Year (qualifies for an orange star denoting high reviews from fans despite multiple anti AI negative review bombers)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">Charted 22nd New Zealand </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span>AI-generated song made it to 72nd highest ranking song in Germany: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DtUA7mBxCpb4&amp;sa=D&amp;source=editors&amp;ust=1730413583993021&amp;usg=AOvVaw1EZauB3MrNfeHyrf4Dx3k6">https://www.youtube.com/watch?v=tUA7mBxCpb4</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c1 c14">Good AI-generated songs:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1 start"><li class="c10 li-bullet-0"><span class="c14">Similar to Taling Heads/Oingo Boungo: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/f1JozMnXM2cez2BocXPVLr&amp;sa=D&amp;source=editors&amp;ust=1730413583993578&amp;usg=AOvVaw0w2PG4C3Iptaq_GZDPyMb5">https://www.udio.com/songs/f1JozMnXM2cez2BocXPVLr</a></span></li><li class="c10 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/playlists/tKDTmFpu7nJbAXwC6ehpk8&amp;sa=D&amp;source=editors&amp;ust=1730413583993863&amp;usg=AOvVaw04GO1FJPIF4STCkgDONtmY">https://www.udio.com/playlists/tKDTmFpu7nJbAXwC6ehpk8</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/playlists/6bHyGJMLyymjvNhp33USp2&amp;sa=D&amp;source=editors&amp;ust=1730413583994158&amp;usg=AOvVaw0EgRDIFi8Q596Ni1r-GjoY">https://www.udio.com/playlists/6bHyGJMLyymjvNhp33USp2</a></span><span class="c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c14">Electro-Pop: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/sV5W2KMqYK9LCSo7626bd3&amp;sa=D&amp;source=editors&amp;ust=1730413583994480&amp;usg=AOvVaw2SKIzUvphsZDuiYiKmGKTL">https://www.udio.com/songs/sV5W2KMqYK9LCSo7626bd3</a></span></li><li class="c10 li-bullet-0"><span class="c14">Lupin the Third theme: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/6TkdCh57tuM2kHoY3LLLrT&amp;sa=D&amp;source=editors&amp;ust=1730413583994785&amp;usg=AOvVaw3yzeLlEhvtmoDuI0hPhgd0">https://www.udio.com/songs/6TkdCh57tuM2kHoY3LLLrT</a></span></li><li class="c10 li-bullet-0"><span class="c14">Pop </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c15">Love Bites: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ouoEmLz3AYuaFf1QiuvwtJ&amp;sa=D&amp;source=editors&amp;ust=1730413583995190&amp;usg=AOvVaw1hD7FIYngYxBL4PcCRLRgR">https://www.udio.com/songs/ouoEmLz3AYuaFf1QiuvwtJ</a></span></li><li class="c7 li-bullet-0"><span class="c14">somewhat similar to Billie Eillish: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qokun63DMDSFKxVD1iuZKu&amp;sa=D&amp;source=editors&amp;ust=1730413583995509&amp;usg=AOvVaw0KAn2jKIE66ASKW9Rj-HdB">https://www.udio.com/songs/qokun63DMDSFKxVD1iuZKu</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/tN7ibXYnaaRZZa7kPR3jac&amp;sa=D&amp;source=editors&amp;ust=1730413583995786&amp;usg=AOvVaw3-6NuXfWYwhaXeDSlm5_wa">https://www.udio.com/songs/tN7ibXYnaaRZZa7kPR3jac</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/svRzxwgGWFFEgCcUQogYbw&amp;sa=D&amp;source=editors&amp;ust=1730413583996060&amp;usg=AOvVaw00GSwI90sEhflZDMwmyx1X">https://www.udio.com/songs/svRzxwgGWFFEgCcUQogYbw</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1yuXBba4br5Epj63ArsCYB&amp;sa=D&amp;source=editors&amp;ust=1730413583996351&amp;usg=AOvVaw1gEKExb9BJkaIuoTSz7e1f">https://www.udio.com/songs/1yuXBba4br5Epj63ArsCYB</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/fEg8zs9rDMo73WUESTGNAY&amp;sa=D&amp;source=editors&amp;ust=1730413583996651&amp;usg=AOvVaw1AZiDWd8fN9GLcxc4QIHFX">https://www.udio.com/songs/fEg8zs9rDMo73WUESTGNAY</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/bgpW9H3nB7cb12SPMf74ug&amp;sa=D&amp;source=editors&amp;ust=1730413583996960&amp;usg=AOvVaw2yGWtzTigadwBWA7gr4MIC">https://www.udio.com/songs/bgpW9H3nB7cb12SPMf74ug</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2geD1KX882FEPaHUawzN9M&amp;sa=D&amp;source=editors&amp;ust=1730413583997285&amp;usg=AOvVaw16eWoYA6Axyzr9Bb8kUgrX">https://www.udio.com/songs/2geD1KX882FEPaHUawzN9M</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2dLuDwyQBK6S5vNYX97dgw&amp;sa=D&amp;source=editors&amp;ust=1730413583997616&amp;usg=AOvVaw1gwUcwiwdKWFbUMO9YQShs">https://www.udio.com/songs/2dLuDwyQBK6S5vNYX97dgw</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/bgpW9H3nB7cb12SPMf74ug&amp;sa=D&amp;source=editors&amp;ust=1730413583997907&amp;usg=AOvVaw2QwSHUKPzWG5c6J2_Xs-cQ">https://www.udio.com/songs/bgpW9H3nB7cb12SPMf74ug</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/oEXcN4hy6yUK5thfRmjLmS&amp;sa=D&amp;source=editors&amp;ust=1730413583998179&amp;usg=AOvVaw31PX2SwhclVg6IsCm17B2g">https://www.udio.com/songs/oEXcN4hy6yUK5thfRmjLmS</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2ETqVVrtu6Et7apEUDVDXK&amp;sa=D&amp;source=editors&amp;ust=1730413583998466&amp;usg=AOvVaw2ybochwnDk3_irgWS76H4W">https://www.udio.com/songs/2ETqVVrtu6Et7apEUDVDXK</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/3THstVGoSBmakd4XcNsrRu&amp;sa=D&amp;source=editors&amp;ust=1730413583998748&amp;usg=AOvVaw28ItpUzXecVLGHZ3bjV_Si">https://www.udio.com/songs/3THstVGoSBmakd4XcNsrRu</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qsgPsTNnVraQRLyUTTVmEA&amp;sa=D&amp;source=editors&amp;ust=1730413583999023&amp;usg=AOvVaw3orm_LkHTSyP6_Xh_cuE57">https://www.udio.com/songs/qsgPsTNnVraQRLyUTTVmEA</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ecSDmjNPb8M7re4JRQWvzi&amp;sa=D&amp;source=editors&amp;ust=1730413583999302&amp;usg=AOvVaw3mjl38fr9ykTDFy7oMCj8h">https://www.udio.com/songs/ecSDmjNPb8M7re4JRQWvzi</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/7D9sEtcRygEzKF2D1sPzDx&amp;sa=D&amp;source=editors&amp;ust=1730413583999611&amp;usg=AOvVaw1gN5C46_Yu6oF666yLMIfA">https://www.udio.com/songs/7D9sEtcRygEzKF2D1sPzDx</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qKuwwzw5D3VmKaM5SUxvHN&amp;sa=D&amp;source=editors&amp;ust=1730413583999912&amp;usg=AOvVaw3KU0ps1c_arheNmiOL9B3V">https://www.udio.com/songs/qKuwwzw5D3VmKaM5SUxvHN</a></span></li><li class="c7 li-bullet-0"><span>Ghost of Your Heart: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/37AsiMKmH39wfjJjp2PNQp&amp;sa=D&amp;source=editors&amp;ust=1730413584000242&amp;usg=AOvVaw2GPardUdc8GFB6YtDYsgKU">https://www.udio.com/songs/37AsiMKmH39wfjJjp2PNQp</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">50s style:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/dk3DiKu8ar6WjEg4RAZuyT&amp;sa=D&amp;source=editors&amp;ust=1730413584000723&amp;usg=AOvVaw1K__-A3-kJCeoFhr-yfa-V">https://www.udio.com/songs/dk3DiKu8ar6WjEg4RAZuyT</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/nPmcyMCrBXQqZeKAEhgaqE&amp;sa=D&amp;source=editors&amp;ust=1730413584001015&amp;usg=AOvVaw0WvIz1r44qkmn7HkG0NGx_">https://www.udio.com/songs/nPmcyMCrBXQqZeKAEhgaqE</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">Dream pop:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/64H22gmWju8q48XoqL2aX8&amp;sa=D&amp;source=editors&amp;ust=1730413584001459&amp;usg=AOvVaw1GEnEVU_1FPsjmtb6KKSAh">https://www.udio.c</a></span><span><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/64H22gmWju8q48XoqL2aX8&amp;sa=D&amp;source=editors&amp;ust=1730413584001634&amp;usg=AOvVaw0JDJKAtYBbpbjCOJI4tF0i">o</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/64H22gmWju8q48XoqL2aX8&amp;sa=D&amp;source=editors&amp;ust=1730413584001811&amp;usg=AOvVaw2ny-g_Qm4QP1ppS9H2dLaa">m/songs/64H22gmWju8q48XoqL2aX8</a></span></li><li class="c7 li-bullet-0"><span class="c14">h</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/64H22gmWju8q48XoqL2aX8&amp;sa=D&amp;source=editors&amp;ust=1730413584002125&amp;usg=AOvVaw0wreXZZQ0PvxUcDaBlmS-N">ttps://suno.com/song/a5e2198a-f352-4abb-9a24-7f81b143ded3</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c10 li-bullet-0"><span class="c14">Very similar to Portishead: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/os5u4dTNjNBBUF5uLQDqVw&amp;sa=D&amp;source=editors&amp;ust=1730413584002552&amp;usg=AOvVaw2QK_DFcZ2Zl1fcFZxUjPCy">https://www.udio.com/songs/os5u4dTNjNBBUF5uLQDqVw</a></span></li></ul><p class="c9 c129"><span class="c33 c15"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c10 li-bullet-0"><span>Very similar to Bjork: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8VM2wwjdt5Ckr7PKNnJmDg&amp;sa=D&amp;source=editors&amp;ust=1730413584002959&amp;usg=AOvVaw0RxTxbkn8MSH1FHtIPqNPg">https://www.udio.com/songs/8VM2wwjdt5Ckr7PKNnJmDg</a></span></li></ul><p class="c9 c129"><span class="c33 c15"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Also very good: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/p2r6YbiWXa1C1MyyGb9kZV&amp;sa=D&amp;source=editors&amp;ust=1730413584003391&amp;usg=AOvVaw1r3BeirdLpi1U4_Lmt30-x">https://www.udio.com/songs/p2r6YbiWXa1C1MyyGb9kZV</a></span></li><li class="c7 li-bullet-0"><span class="c20 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/3o71EwRVz9rW7U3yQxcdNS&amp;sa=D&amp;source=editors&amp;ust=1730413584003669&amp;usg=AOvVaw2wRabRc3Mk3_ybMGEs-WHZ">https://www.udio.com/songs/3o71EwRVz9rW7U3yQxcdNS</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/tmwG381JgobNksk2z83biD&amp;sa=D&amp;source=editors&amp;ust=1730413584003931&amp;usg=AOvVaw3GYTxR2V4x9FTfBsflfiqW">https://www.udio.com/songs/tmwG381JgobNksk2z83biD</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">Rock: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2Ed7Ea2LQDjtLYHcf6BMfr&amp;sa=D&amp;source=editors&amp;ust=1730413584004356&amp;usg=AOvVaw0MRBKWcGrQaS36WK1Nc24S">https://www.udio.com/songs/2Ed7Ea2LQDjtLYHcf6BMfr</a></span></li><li class="c7 li-bullet-0"><span class="c15">Similar to Queens of the Stone Age: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/bpYkrt4BmGDUwMRHxHYHiV&amp;sa=D&amp;source=editors&amp;ust=1730413584004669&amp;usg=AOvVaw0JTovjl90wrulTCesIxPxL">https://www.udio.com/songs/bpYkrt4BmGDUwMRHxHYHiV</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-3 start"><li class="c21 c26 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gh5yhSQFqFafhDzuK73yBr&amp;sa=D&amp;source=editors&amp;ust=1730413584004960&amp;usg=AOvVaw1EYDeXPxJlDodWAlizMhxh">https://www.udio.com/songs/gh5yhSQFqFafhDzuK73yBr</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c15">K-rock: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/rXpFufByCQ4ZYwopN2Afr4&amp;sa=D&amp;source=editors&amp;ust=1730413584005258&amp;usg=AOvVaw1ukgij-EDnCGBBJcuA9ZWX">https://www.udio.com/songs/rXpFufByCQ4ZYwopN2Afr4</a></span></li><li class="c7 li-bullet-0"><span class="c15">Personal favorite (a &nbsp;</span><span class="c15">Cover/remake of the song &quot;Muori Delay&quot; by Italian rock band Verdena): </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/7VKZg1aGVhTuvenC2PY4WD&amp;sa=D&amp;source=editors&amp;ust=1730413584005634&amp;usg=AOvVaw1ztCEnRPLYlla-KJ0P--SS">https://www.udio.com/songs/7VKZg1aGVhTuvenC2PY4WD</a></span></li><li class="c7 li-bullet-0"><span class="c15">Jimi Hendrix style cover of Waltzing Matilda: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/shDPAYnpmNk&amp;sa=D&amp;source=editors&amp;ust=1730413584005926&amp;usg=AOvVaw3Yd7Jh1tiVLimZzjcDjqZ7">https://youtu.be/shDPAYnpmNk</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-3 start"><li class="c21 c26 li-bullet-0"><span class="c15">Another song in his style: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8bdgHjqv9Ky4LPWXL2n8NH&amp;sa=D&amp;source=editors&amp;ust=1730413584006218&amp;usg=AOvVaw08PzfB_COILjhl0q_ec1sW">https://www.udio.com/songs/8bdgHjqv9Ky4LPWXL2n8NH</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c33 c15">Similar to Oasis</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-3 start"><li class="c21 c26 li-bullet-0"><span>Shine On: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/4AjmM0oB3hc&amp;sa=D&amp;source=editors&amp;ust=1730413584006589&amp;usg=AOvVaw3MBEjHde6aJutGBprQLLa0">https://youtu.be/4AjmM0oB3hc</a></span></li><li class="c21 c26 li-bullet-0"><span>Oh Sally, Can You Wait Now </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vrxuRGYAHmbTkR7qCacsKH&amp;sa=D&amp;source=editors&amp;ust=1730413584006914&amp;usg=AOvVaw0hMwq_3sOzXxjVRq-ehjZE">https://www.udio.com/songs/vrxuRGYAHmbTkR7qCacsKH</a></span></li><li class="c21 c26 li-bullet-0"><span>Still Breathing: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/nTiu4Fv9eJDCN6TF1R9ARh&amp;sa=D&amp;source=editors&amp;ust=1730413584007198&amp;usg=AOvVaw1mNv2jSZeZKAwRD15Cuauu">https://www.udio.com/songs/nTiu4Fv9eJDCN6TF1R9ARh</a></span></li><li class="c21 c26 li-bullet-0"><span>Rebuild What Was Once Great: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5tfbdzeHUQPSTrVopz7kuN&amp;sa=D&amp;source=editors&amp;ust=1730413584007500&amp;usg=AOvVaw31ra2KHyypE6dI5toJV-dF">https://www.udio.com/songs/5tfbdzeHUQPSTrVopz7kuN</a></span></li><li class="c21 c26 li-bullet-0"><span>The Boatman: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/51ccELLuE3RLYXRvVPt7wG&amp;sa=D&amp;source=editors&amp;ust=1730413584007793&amp;usg=AOvVaw0OtqSvsi978eQl8C8KIRYo">https://www.udio.com/songs/51ccELLuE3RLYXRvVPt7wG</a></span></li><li class="c21 c26 li-bullet-0"><span>Whatever We Want: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qewPH5tf4C8Qe6LkSKxMfN&amp;sa=D&amp;source=editors&amp;ust=1730413584008097&amp;usg=AOvVaw3n5rAbdQn2tmaKm40QqWhR">https://www.udio.com/songs/qewPH5tf4C8Qe6LkSKxMfN</a></span></li><li class="c21 c26 li-bullet-0"><span>Daredevils: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/g7Gj5y4f2Lx4UpHvqDd7At&amp;sa=D&amp;source=editors&amp;ust=1730413584008393&amp;usg=AOvVaw1ku-OZw58h1vuRE45FxHRn">https://www.udio.com/songs/g7Gj5y4f2Lx4UpHvqDd7At</a></span></li><li class="c21 c26 li-bullet-0"><span>Cosmic Glow: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/uzWf2tch5GZgscbmR5mG6n&amp;sa=D&amp;source=editors&amp;ust=1730413584008693&amp;usg=AOvVaw1-VtFqRIq8uILYA3GRKv2a">https://www.udio.com/songs/uzWf2tch5GZgscbmR5mG6n</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c33 c15">Similar to REM</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-3 start"><li class="c21 c26 li-bullet-0"><span class="c15">Wild Ones: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/SpN04-5a0Sg&amp;sa=D&amp;source=editors&amp;ust=1730413584009048&amp;usg=AOvVaw14pl6t24cERX_IcH1sKd0c">https://youtu.be/SpN04-5a0Sg</a></span></li><li class="c21 c26 li-bullet-0"><span>Echoes of Us: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/ACZ3newiRq4&amp;sa=D&amp;source=editors&amp;ust=1730413584009322&amp;usg=AOvVaw13gBxg9uI02q_IhNpqjx2L">https://youtu.be/ACZ3newiRq4</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/pgyBTM31JbyT8rcxe62bSS&amp;sa=D&amp;source=editors&amp;ust=1730413584009614&amp;usg=AOvVaw0xxseU9QR5kdgwKFx_BQ6P">https://www.udio.com/songs/pgyBTM31JbyT8rcxe62bSS</a></span></li><li class="c7 li-bullet-0"><span>J-rock: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gEn2LrwLCgky3faABjp2GZ&amp;sa=D&amp;source=editors&amp;ust=1730413584009939&amp;usg=AOvVaw0Yd7hTeSXXmA_eupz3Xn3Q">https://www.udio.com/songs/gEn2LrwLCgky3faABjp2GZ</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gaiFRJ1v9WsWZd3pwVJ1yN&amp;sa=D&amp;source=editors&amp;ust=1730413584010220&amp;usg=AOvVaw2qDyIyWkR5HxokRJgqJac6">https://www.udio.com/songs/gaiFRJ1v9WsWZd3pwVJ1yN</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/94k4LxH1t7HRQtsPf3Kq3B&amp;sa=D&amp;source=editors&amp;ust=1730413584010503&amp;usg=AOvVaw1y_Qstx1YOtnrtVCNtGDQd">https://www.udio.com/songs/94k4LxH1t7HRQtsPf3Kq3B</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/6s1MpfEAbvwXWtgoTETwyD&amp;sa=D&amp;source=editors&amp;ust=1730413584010793&amp;usg=AOvVaw1_D9SINmsB1Yn84CkfYcZq">https://www.udio.com/songs/6s1MpfEAbvwXWtgoTETwyD</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8bdgHjqv9Ky4LPWXL2n8NH&amp;sa=D&amp;source=editors&amp;ust=1730413584011079&amp;usg=AOvVaw1kZX4VuhARax2rVWgmbVxk">https://www.udio.com/songs/8bdgHjqv9Ky4LPWXL2n8NH</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/nwTGjbHT9bMCNMxcLnxmdu&amp;sa=D&amp;source=editors&amp;ust=1730413584011347&amp;usg=AOvVaw0laychyNfK7JzPxegSdT5c">https://www.udio.com/songs/nwTGjbHT9bMCNMxcLnxmdu</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/3LauHupubZRq869nmPdE8K&amp;sa=D&amp;source=editors&amp;ust=1730413584011659&amp;usg=AOvVaw1GKOnKiXoqGQrdI80F0Xte">https://www.udio.com/songs/3LauHupubZRq869nmPdE8K</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/7SkG6AKLbFcxLGCSd385GL&amp;sa=D&amp;source=editors&amp;ust=1730413584011961&amp;usg=AOvVaw3WvKr3GA55qo_guNXUGpdU">https://www.udio.com/songs/7SkG6AKLbFcxLGCSd385GL</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/tMVVG4YkbrEwZw8mxzD54Z&amp;sa=D&amp;source=editors&amp;ust=1730413584012251&amp;usg=AOvVaw3mtZRDIPSNEH6wXNUCOZhF">https://www.udio.com/songs/tMVVG4YkbrEwZw8mxzD54Z</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qdoazG83x2wFeXbJNJzyDK&amp;sa=D&amp;source=editors&amp;ust=1730413584012562&amp;usg=AOvVaw1qoya4itJDDLqRZcMLX1Mn">https://www.udio.com/songs/qdoazG83x2wFeXbJNJzyDK</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/a8ug9yeSKE56Mj6Bty2Pmw&amp;sa=D&amp;source=editors&amp;ust=1730413584012856&amp;usg=AOvVaw1vhCeTu2Cz5NICYWds45xu">https://www.udio.com/songs/a8ug9yeSKE56Mj6Bty2Pmw</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/4MR9EjGZM92EGdwPYWWCZB&amp;sa=D&amp;source=editors&amp;ust=1730413584013149&amp;usg=AOvVaw2EdD4O05HJ2wZTnLwZDt2r">https://www.udio.com/songs/4MR9EjGZM92EGdwPYWWCZB</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/e2gecDGvevV3UV6G7zDZ92&amp;sa=D&amp;source=editors&amp;ust=1730413584013437&amp;usg=AOvVaw2GTcwmbMgrBTjJRXBobppb">https://www.udio.com/songs/e2gecDGvevV3UV6G7zDZ92</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ew6ibNRDu31kJLZFuvWLXC&amp;sa=D&amp;source=editors&amp;ust=1730413584013725&amp;usg=AOvVaw3U2Hx-ST9UJ3AGEItBkWBy">https://www.udio.com/songs/ew6ibNRDu31kJLZFuvWLXC</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/eZmhKGyS18q4CrihWd1cK7&amp;sa=D&amp;source=editors&amp;ust=1730413584014018&amp;usg=AOvVaw0uOrzNqSFdO6joOXm2DTEK">https://www.udio.com/songs/eZmhKGyS18q4CrihWd1cK7</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/99gAgAqi9baMAsn6kPGRsc&amp;sa=D&amp;source=editors&amp;ust=1730413584014301&amp;usg=AOvVaw17CnqNg6BClUNv0leilv5a">https://www.udio.com/songs/99gAgAqi9baMAsn6kPGRsc</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vVt5qcCWWTwN8jJpUkTwys&amp;sa=D&amp;source=editors&amp;ust=1730413584014588&amp;usg=AOvVaw2UOzQ1flzLK7yLsNCCuVit">https://www.udio.com/songs/vVt5qcCWWTwN8jJpUkTwys</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/hwPBjCN7DkXfkbCD5gKGbx&amp;sa=D&amp;source=editors&amp;ust=1730413584014863&amp;usg=AOvVaw2QZqi6voyQh50AW94wS1nC">https://www.udio.com/songs/hwPBjCN7DkXfkbCD5gKGbx</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1vp6VSkRWWsJD2zSNFrKxv&amp;sa=D&amp;source=editors&amp;ust=1730413584015137&amp;usg=AOvVaw1RYK_luGM1JapOFYIgEdBj">https://www.udio.com/songs/1vp6VSkRWWsJD2zSNFrKxv</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/e2gecDGvevV3UV6G7zDZ92&amp;sa=D&amp;source=editors&amp;ust=1730413584015447&amp;usg=AOvVaw2z5-6PWMETSDuY9v7V6Qyn">https://www.udio.com/songs/e2gecDGvevV3UV6G7zDZ92</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qnSFuPggD4SnnCEVfsD6L3&amp;sa=D&amp;source=editors&amp;ust=1730413584015729&amp;usg=AOvVaw1B2ew3Seu5GRL6mpg872w7">https://www.udio.com/songs/qnSFuPggD4SnnCEVfsD6L3</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/99gAgAqi9baMAsn6kPGRsc&amp;sa=D&amp;source=editors&amp;ust=1730413584016016&amp;usg=AOvVaw0HbpgMDkDlzWAh_EEbP3Sn">https://www.udio.com/songs/99gAgAqi9baMAsn6kPGRsc</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/7eWvYLrEDHZojGUo2nm3oc&amp;sa=D&amp;source=editors&amp;ust=1730413584016331&amp;usg=AOvVaw1_it-VnyHOedQXkAnUhFjz">https://www.udio.com/songs/7eWvYLrEDHZojGUo2nm3oc</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/hPMkN5N6KarArvYLkWkHRY&amp;sa=D&amp;source=editors&amp;ust=1730413584016647&amp;usg=AOvVaw28bqISdw20dlaZ7VylGAc9">https://www.udio.com/songs/hPMkN5N6KarArvYLkWkHRY</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qewPH5tf4C8Qe6LkSKxMfN&amp;sa=D&amp;source=editors&amp;ust=1730413584017061&amp;usg=AOvVaw0zUJ-Q8pMUrRFuKPb6sThf">https://www.udio.com/songs/qewPH5tf4C8Qe6LkSKxMfN</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ozoJN8GqchKXW7HnbYLtYL&amp;sa=D&amp;source=editors&amp;ust=1730413584017339&amp;usg=AOvVaw3b6xv93UJlFQa3hNIahRWL">https://www.udio.com/songs/ozoJN8GqchKXW7HnbYLtYL</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/nreEFNbjREMbVVwWNFpP34&amp;sa=D&amp;source=editors&amp;ust=1730413584017631&amp;usg=AOvVaw3dosXYCNo21RO19HgKmcTL">https://www.udio.com/songs/nreEFNbjREMbVVwWNFpP34</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qMxGkZd5vZcMm7sXFf2o5L&amp;sa=D&amp;source=editors&amp;ust=1730413584017919&amp;usg=AOvVaw0paY4ZI5H6xjQecH3Techq">https://www.udio.com/songs/qMxGkZd5vZcMm7sXFf2o5L</a></span></li><li class="c7 li-bullet-0"><span class="c15">Rap rock in the style of Rage Against the Machine: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/o6DEogHeabUxtRV7wJrPhn&amp;sa=D&amp;source=editors&amp;ust=1730413584018255&amp;usg=AOvVaw284y4qh-Ae6Y9R64fS4oKe">https://www.udio.com/songs/o6DEogHeabUxtRV7wJrPhn</a></span></li><li class="c7 li-bullet-0"><span class="c14">Surf rock instrumental: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/fNAXQ664SsUYocoX5bPny4&amp;sa=D&amp;source=editors&amp;ust=1730413584018598&amp;usg=AOvVaw3BxtfIkz83vzkOQGU7Q2Wy">https://www.udio.com/songs/fNAXQ664SsUYocoX5bPny4</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">Grunge: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c15">Similar to Slowdive: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vdCbJBXpFjLdYEqNh6NTEJ&amp;sa=D&amp;source=editors&amp;ust=1730413584019130&amp;usg=AOvVaw3zkxpXe_03sQVrqhrlOmQU">https://www.udio.com/songs/vdCbJBXpFjLdYEqNh6NTEJ</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/bVjvspP7z5Ls8mHfKDZ23v&amp;sa=D&amp;source=editors&amp;ust=1730413584019426&amp;usg=AOvVaw1jDCuDaX4ZYBtv4HVIDiiG">https://www.udio.com/songs/bVjvspP7z5Ls8mHfKDZ23v</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/39ZN9a1GvLCisYVPNUizcU&amp;sa=D&amp;source=editors&amp;ust=1730413584019648&amp;usg=AOvVaw1nJo3o2pCxdIHP1Wi6MzWZ">https://www.udio.com/songs/39ZN9a1GvLCisYVPNUizcU</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/peR88V4TMWxvrnVC31G3VD&amp;sa=D&amp;source=editors&amp;ust=1730413584019854&amp;usg=AOvVaw0GURoRmOHch3u50UubcvPS">https://www.udio.com/songs/peR88V4TMWxvrnVC31G3VD</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/w1wkYMyd9hbLQaYUxJeg4u&amp;sa=D&amp;source=editors&amp;ust=1730413584020038&amp;usg=AOvVaw38BNoQG8GQarb-j41m54eN">https://www.udio.com/songs/w1wkYMyd9hbLQaYUxJeg4u</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vdwyAUybfdJTKAHvfi8Jfh&amp;sa=D&amp;source=editors&amp;ust=1730413584020256&amp;usg=AOvVaw2fd7pY3Y7efx2deuI_uIAk">https://www.udio.com/songs/vdwyAUybfdJTKAHvfi8Jfh</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/kNhN2Hy5EWNvsF7Wbz71hV&amp;sa=D&amp;source=editors&amp;ust=1730413584020477&amp;usg=AOvVaw0V1IFie-se9nXmrhe-7Ru0">https://www.udio.com/songs/kNhN2Hy5EWNvsF7Wbz71hV</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">Punk: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/sQwB3EcykSoQpbabrr9TFP&amp;sa=D&amp;source=editors&amp;ust=1730413584020792&amp;usg=AOvVaw0m9cT-DfKBOSklmL_5RRdb">https://www.udio.com/songs/sQwB3EcykSoQpbabrr9TFP</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">Prog rock: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/txUbSjEPJzgViahbrdefxM&amp;sa=D&amp;source=editors&amp;ust=1730413584021111&amp;usg=AOvVaw3QG1gbjKhUT8Z3oZSm1h-M">https://www.udio.com/songs/txUbSjEPJzgViahbrdefxM</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/99N5VnHwv78QPgcqAoLBnk&amp;sa=D&amp;source=editors&amp;ust=1730413584021328&amp;usg=AOvVaw3wCSQhD4Rqz9Jcky2tmooG">https://www.udio.com/songs/99N5VnHwv78QPgcqAoLBnk</a></span></li><li class="c7 li-bullet-0"><span>Instrumental is great but some of the lyrics are&hellip; not: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/oxUrxAihUEg5fp6eGFgMc3&amp;sa=D&amp;source=editors&amp;ust=1730413584021556&amp;usg=AOvVaw1aDLJRNqxF7bQ1mS3MuIap">https://www.udio.com/songs/oxUrxAihUEg5fp6eGFgMc3</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qZN29EiF89HsLCQmYxq42Z&amp;sa=D&amp;source=editors&amp;ust=1730413584021784&amp;usg=AOvVaw23ZuZs5ZyK2hKAgHNO_4Gh">https://www.udio.com/songs/qZN29EiF89HsLCQmYxq42Z</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c10 li-bullet-0"><span class="c1">EDM:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/78U95aNRYQHyQrn8xHizf8&amp;sa=D&amp;source=editors&amp;ust=1730413584022193&amp;usg=AOvVaw1GKjmH-RNT0DWs24MYJpp_">https://www.udio.com/songs/78U95aNRYQHyQrn8xHizf8</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/7eWvYLrEDHZojGUo2nm3oc&amp;sa=D&amp;source=editors&amp;ust=1730413584022412&amp;usg=AOvVaw0r8uDwg7bEqzJA9orgIaR9">https://www.udio.com/songs/7eWvYLrEDHZojGUo2nm3oc</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/hK7F6fcmEcqW2egu9UDWrE&amp;sa=D&amp;source=editors&amp;ust=1730413584022620&amp;usg=AOvVaw36XcdIGh5csQRQ718DH8l4">https://www.udio.com/songs/hK7F6fcmEcqW2egu9UDWrE</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ox13W8kzdWQvA6cFwkVTe2&amp;sa=D&amp;source=editors&amp;ust=1730413584022813&amp;usg=AOvVaw0Re3M7FrnC9ES9HB2usmFY">https://www.udio.com/songs/ox13W8kzdWQvA6cFwkVTe2</a></span></li><li class="c7 li-bullet-0"><span class="c15">15.5 minutes long: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vk7QLdDPJxnwEecmLW42La&amp;sa=D&amp;source=editors&amp;ust=1730413584023020&amp;usg=AOvVaw2h1zcd6xaoHbUgoSkUzkaH">https://www.udio.com/songs/vk7QLdDPJxnwEecmLW42La</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qrxFXVy7Rgh2ebqFxpm52j&amp;sa=D&amp;source=editors&amp;ust=1730413584023309&amp;usg=AOvVaw2NIYXCwN6gxGuWR0ImEug6">https://www.udio.com/songs/qrxFXVy7Rgh2ebqFxpm52j</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5jQp8EykyocuCf8YDc5zvq&amp;sa=D&amp;source=editors&amp;ust=1730413584023590&amp;usg=AOvVaw3aX_RyfYPJhOrDr2WT6CNu">https://www.udio.com/songs/5jQp8EykyocuCf8YDc5zvq</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/hYEQXXgtaswTcgTnp4rt3z&amp;sa=D&amp;source=editors&amp;ust=1730413584023799&amp;usg=AOvVaw2lnan-8yh-XQZ-k25ntTI_">https://www.udio.com/songs/hYEQXXgtaswTcgTnp4rt3z</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/wUm4jbahw6StPijoYgSaZa&amp;sa=D&amp;source=editors&amp;ust=1730413584024020&amp;usg=AOvVaw29-o5_JnIqyiKn2CWMTCIg">https://www.udio.com/songs/wUm4jbahw6StPijoYgSaZa</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/uVLqsad8rc3jk83eu9twxM&amp;sa=D&amp;source=editors&amp;ust=1730413584024295&amp;usg=AOvVaw2tidAg8iumjNmR6mGf2SHa">https://www.udio.com/songs/uVLqsad8rc3jk83eu9twxM</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/oERbSC94qAcozPkYMRpn8d&amp;sa=D&amp;source=editors&amp;ust=1730413584024550&amp;usg=AOvVaw0_uLcnvlK5CaVpzJWc1VVO">https://www.udio.com/songs/oERbSC94qAcozPkYMRpn8d</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/eCXUkAxsvHydxS2w8Pt9zV&amp;sa=D&amp;source=editors&amp;ust=1730413584024776&amp;usg=AOvVaw1GUhyISKr2lGXAOuMAX4zp">https://www.udio.com/songs/eCXUkAxsvHydxS2w8Pt9zV</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ocYMEPXWYkD19egp8ivZZJ&amp;sa=D&amp;source=editors&amp;ust=1730413584025003&amp;usg=AOvVaw0JbS0gWquvEcK_kN_xvtUN">https://www.udio.com/songs/ocYMEPXWYkD19egp8ivZZJ</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span>Dubstep: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/eMZq9X4twmqn9Ufm9SfVCE&amp;sa=D&amp;source=editors&amp;ust=1730413584025248&amp;usg=AOvVaw3kS1UeSv9y9o_-R_2lt2UB">https://www.udio.com/songs/eMZq9X4twmqn9Ufm9SfVCE</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5yvMrfHboXxW2aA2hrmPJ3&amp;sa=D&amp;source=editors&amp;ust=1730413584025449&amp;usg=AOvVaw1EvxIRzrdgGBPk9VNz2wGJ">https://www.udio.com/songs/5yvMrfHboXxW2aA2hrmPJ3</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/rFc8oEXBSnNdbLJhcTj7ga&amp;sa=D&amp;source=editors&amp;ust=1730413584025654&amp;usg=AOvVaw0-PBLuROl4zXEIgV6SlV5l">https://www.udio.com/songs/rFc8oEXBSnNdbLJhcTj7ga</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qbBGzdXX2QH6P6Sfw8YtJD&amp;sa=D&amp;source=editors&amp;ust=1730413584025873&amp;usg=AOvVaw1P639sjBTx6g7xmMDNjIcs">https://www.udio.com/songs/qbBGzdXX2QH6P6Sfw8YtJD</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5DmgjJ1cfcfyHkohDWhFNb&amp;sa=D&amp;source=editors&amp;ust=1730413584026082&amp;usg=AOvVaw0CoyV9ZKZN5iHFWeM4p_7i">https://www.udio.com/songs/5DmgjJ1cfcfyHkohDWhFNb</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/uVLqsad8rc3jk83eu9twxM&amp;sa=D&amp;source=editors&amp;ust=1730413584026272&amp;usg=AOvVaw03k-ISDHxKl1FlFTRUWtG2">https://www.udio.com/songs/uVLqsad8rc3jk83eu9twxM</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/jW2fsjekZehnZNLAhQXQmW&amp;sa=D&amp;source=editors&amp;ust=1730413584026454&amp;usg=AOvVaw2-uj-p-_YzS_R1myG09bzB">https://www.udio.com/songs/jW2fsjekZehnZNLAhQXQmW</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/jrU8zow3PdkPJw21Tx566u&amp;sa=D&amp;source=editors&amp;ust=1730413584026668&amp;usg=AOvVaw0J94xQx7k0tHXhLQ2_t2Gp">https://www.udio.com/songs/jrU8zow3PdkPJw21Tx566u</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/4KEYRbLJ3oBucBNMu2bp71&amp;sa=D&amp;source=editors&amp;ust=1730413584026894&amp;usg=AOvVaw3Pnvp4cqDAlAoLVD2_7hzV">https://www.udio.com/songs/4KEYRbLJ3oBucBNMu2bp71</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/wCCDUoHeo8z97xRehQadR7&amp;sa=D&amp;source=editors&amp;ust=1730413584027142&amp;usg=AOvVaw1vwbLvNSUbM9EuwSy5EVuB">https://www.udio.com/songs/wCCDUoHeo8z97xRehQadR7</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/42n6cj6iwQPsxFp4tqJieP&amp;sa=D&amp;source=editors&amp;ust=1730413584027398&amp;usg=AOvVaw3-ETEKLvnPBfMx8ayLo1HZ">https://www.udio.com/songs/42n6cj6iwQPsxFp4tqJieP</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1CMdUtzG6iB6WTt395xwky&amp;sa=D&amp;source=editors&amp;ust=1730413584027775&amp;usg=AOvVaw34Xat8UOFe5GO6z4R0D3Ur">https://www.udio.com/songs/1CMdUtzG6iB6WTt395xwky</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/tcQJPepikuyTP3w3eeAmTT&amp;sa=D&amp;source=editors&amp;ust=1730413584028027&amp;usg=AOvVaw3ca1N2EBUnA7wSyBffmrMu">https://www.udio.com/songs/tcQJPepikuyTP3w3eeAmTT</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5Q3XT7ESm7heW6oJMgsZff&amp;sa=D&amp;source=editors&amp;ust=1730413584028270&amp;usg=AOvVaw1vO5tk1hfbnFKs3Zg1VKqf">https://www.udio.com/songs/5Q3XT7ESm7heW6oJMgsZff</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/cyGcSbRRdn3yiNTkvu3vxA&amp;sa=D&amp;source=editors&amp;ust=1730413584028464&amp;usg=AOvVaw27Sa5qz0wNNhRquu7TY-hn">https://www.udio.com/songs/cyGcSbRRdn3yiNTkvu3vxA</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/osYzP5cm6X1wE7nP6xdMzD&amp;sa=D&amp;source=editors&amp;ust=1730413584028716&amp;usg=AOvVaw3kqj-mkhZ6-vp9v4IkK1VO">https://www.udio.com/songs/osYzP5cm6X1wE7nP6xdMzD</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/4rG7oq2s4muDLDpHBH8T57&amp;sa=D&amp;source=editors&amp;ust=1730413584029031&amp;usg=AOvVaw1g8f0LRDJt8DMuZLO1z_Wi">https://www.udio.com/songs/4rG7oq2s4muDLDpHBH8T57</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2s4zyXNvcyVLvxT2hYKdTt&amp;sa=D&amp;source=editors&amp;ust=1730413584029286&amp;usg=AOvVaw11W-W8mLyNosLCgRXeHWj3">https://www.udio.com/songs/2s4zyXNvcyVLvxT2hYKdTt</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1kSQjtbjYd45DroFtAiBDd&amp;sa=D&amp;source=editors&amp;ust=1730413584029545&amp;usg=AOvVaw1CwY2uTWp6SVpfWlgumuxI">https://www.udio.com/songs/1kSQjtbjYd45DroFtAiBDd</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/cjSWd9peh1Vwz8KfRDACfR&amp;sa=D&amp;source=editors&amp;ust=1730413584029804&amp;usg=AOvVaw2_lNJvrFCry6qDUBT92DFR">https://www.udio.com/songs/cjSWd9peh1Vwz8KfRDACfR</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?app%3Ddesktop%26v%3D3j3hEqOX2m0%26list%3DOLAK5uy_kdHzo57Bp-3gAuvooImbyHfEJJkdDFlMw&amp;sa=D&amp;source=editors&amp;ust=1730413584030067&amp;usg=AOvVaw00NapvU3Rggr409mvoc1XR">https://www.youtube.com/watch?app=desktop&amp;v=3j3hEqOX2m0&amp;list=OLAK5uy_kdHzo57Bp-3gAuvooImbyHfEJJkdDFlMw</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DRiUBPLe_-Oc&amp;sa=D&amp;source=editors&amp;ust=1730413584030343&amp;usg=AOvVaw0NFM-27qz9GGv-b4cYbir0">https://www.youtube.com/watch?v=RiUBPLe_-Oc</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/4KEYRbLJ3oBucBNMu2bp71&amp;sa=D&amp;source=editors&amp;ust=1730413584030609&amp;usg=AOvVaw3jkQ_PctLB7vRgrs272pTB">https://www.udio.com/songs/4KEYRbLJ3oBucBNMu2bp71</a></span></li><li class="c7 li-bullet-0"><span>Lofi/chillwave: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gp35soPqGMXmGU7rQ3397z&amp;sa=D&amp;source=editors&amp;ust=1730413584030886&amp;usg=AOvVaw0nA5JBdaP1D_NvXuBrz9z9">https://www.udio.com/songs/gp35soPqGMXmGU7rQ3397z</a></span></li></ul><p class="c9 c129"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c10 li-bullet-0"><span class="c1">Downtempo:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/sV5W2KMqYK9LCSo7626bd3&amp;sa=D&amp;source=editors&amp;ust=1730413584031257&amp;usg=AOvVaw2LNNrt4WnHDi5UaBgxXqtp">https://www.udio.com/songs/sV5W2KMqYK9LCSo7626bd3</a></span></li><li class="c7 li-bullet-0"><span class="c14">&nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/85QWwPisL1pSuPzXfxdU4R&amp;sa=D&amp;source=editors&amp;ust=1730413584031555&amp;usg=AOvVaw34c7Us5faDQ1rrNupRcz-o">https://www.udio.com/songs/85QWwPisL1pSuPzXfxdU4R</a></span></li><li class="c7 li-bullet-0"><span class="c14">Minimal but great vocals: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/aw2uXhzVbPzZU3tKB26qBR&amp;sa=D&amp;source=editors&amp;ust=1730413584031780&amp;usg=AOvVaw28Zqpfp8q3flbeE1-tiUOB">https://www.udio.com/songs/aw2uXhzVbPzZU3tKB26qBR</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c10 li-bullet-0"><span class="c1">Big Beat/Turntablism:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1 start"><li class="c7 li-bullet-0"><span class="c15">Somewhat similar to Jet Set Radio: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/x3xLvnN48DGnmxM5VPTw93&amp;sa=D&amp;source=editors&amp;ust=1730413584032072&amp;usg=AOvVaw3NKpz0pHnOmoTt19vsXaSB">https://www.udio.com/songs/x3xLvnN48DGnmxM5VPTw93</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">Blues rock with ***INCREDIBLE*** guitar playing: </span><span class="c20 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/jaGkxT9QohSiUCBA2waVTj&amp;sa=D&amp;source=editors&amp;ust=1730413584032321&amp;usg=AOvVaw3EqIWXja98S_g3_-iXQ4vj">https://www.udio.com/songs/jaGkxT9QohSiUCBA2waVTj</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c33 c15">Cinematic neoclassical/Medieval/Folk/Fantasy (all excellent!)</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vzy9E3po7mnsonZWhbES5e&amp;sa=D&amp;source=editors&amp;ust=1730413584032598&amp;usg=AOvVaw3eUH-tOoU_a1KQsCdO4WtB">https://www.udio.com/songs/vzy9E3po7mnsonZWhbES5e</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5HHbkgTWfpSb5rkW2dGotN&amp;sa=D&amp;source=editors&amp;ust=1730413584032778&amp;usg=AOvVaw3dxvLAHUykcjS2LAQzwUU6">https://www.udio.com/songs/5HHbkgTWfpSb5rkW2dGotN</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/foVqjXtP1jHxc7QpkM1khD&amp;sa=D&amp;source=editors&amp;ust=1730413584032964&amp;usg=AOvVaw1Mq1wyL67ctJRjsOH8Gujc">https://www.udio.com/songs/foVqjXtP1jHxc7QpkM1khD</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/9AVqmPHPcXecvpo86ZfabF&amp;sa=D&amp;source=editors&amp;ust=1730413584033168&amp;usg=AOvVaw3ZXExwwfYg-2mZ_Fy_0Fgl">https://www.udio.com/songs/9AVqmPHPcXecvpo86ZfabF</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/v5LbZc3Lm6j7EusKAzkWUx&amp;sa=D&amp;source=editors&amp;ust=1730413584033417&amp;usg=AOvVaw0MvP4GZWfoaloE0RKrufgU">https://www.udio.com/songs/v5LbZc3Lm6j7EusKAzkWUx</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8Y5oSqye5JR3Fajvg63E7T&amp;sa=D&amp;source=editors&amp;ust=1730413584033676&amp;usg=AOvVaw3oFRn3z4-GuEYqEVOYt6p6">https://www.udio.com/songs/8Y5oSqye5JR3Fajvg63E7T</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/g4jCQEQRa6QvM2UNNtA1y1&amp;sa=D&amp;source=editors&amp;ust=1730413584033927&amp;usg=AOvVaw2wJsTUwUnr_th3oG3iNorS">https://www.udio.com/songs/g4jCQEQRa6QvM2UNNtA1y1</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1gR5jn6ZDNVt6oApq4BSpL&amp;sa=D&amp;source=editors&amp;ust=1730413584034170&amp;usg=AOvVaw23A3uR1RmN5a35rvvdJc4E">https://www.udio.com/songs/1gR5jn6ZDNVt6oApq4BSpL</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vzy9E3po7mnsonZWhbES5e&amp;sa=D&amp;source=editors&amp;ust=1730413584034529&amp;usg=AOvVaw2GBS9NUfkQ9qkERZzm4B3o">https://www.udio.com/songs/vzy9E3po7mnsonZWhbES5e</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/cqcXvCsUxqFtSTQTnWUcAL&amp;sa=D&amp;source=editors&amp;ust=1730413584034776&amp;usg=AOvVaw29czYLQjd-w67SORkwQwBu">https://www.udio.com/songs/cqcXvCsUxqFtSTQTnWUcAL</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8V9JBTg9mzxGyNfA9B5EDP&amp;sa=D&amp;source=editors&amp;ust=1730413584034978&amp;usg=AOvVaw0jBYundVQa4V3gOjqF78LF">https://www.udio.com/songs/8V9JBTg9mzxGyNfA9B5EDP</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/cy69XmLZUPvavXkMEemVeE&amp;sa=D&amp;source=editors&amp;ust=1730413584035159&amp;usg=AOvVaw39OrHa53cGNYSdN2einSEk">https://www.udio.com/songs/cy69XmLZUPvavXkMEemVeE</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/knwr9be44FTZczicGks9Ag&amp;sa=D&amp;source=editors&amp;ust=1730413584035336&amp;usg=AOvVaw1G3v-rcS0ULPIziXs4ZU2p">https://www.udio.com/songs/knwr9be44FTZczicGks9Ag</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2LtGWCvhVivRTmxCmxqQgE&amp;sa=D&amp;source=editors&amp;ust=1730413584035517&amp;usg=AOvVaw0iIZursl3IjG6uN3TxUkHO">https://www.udio.com/songs/2LtGWCvhVivRTmxCmxqQgE</a></span></li><li class="c7 li-bullet-0"><span>A Vignette of Valency: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vt5kHKXczqgVgRBjsFpsm4&amp;sa=D&amp;source=editors&amp;ust=1730413584035717&amp;usg=AOvVaw0R4OwWQMxFTGPn_TpasUUt">https://www.udio.com/songs/vt5kHKXczqgVgRBjsFpsm4</a></span></li><li class="c7 li-bullet-0"><span>Gialla Foglia: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ox13W8kzdWQvA6cFwkVTe2&amp;sa=D&amp;source=editors&amp;ust=1730413584035906&amp;usg=AOvVaw1E9iC3rD-xFckoL7x--RkE">https://www.udio.com/songs/ox13W8kzdWQvA6cFwkVTe2</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Dark cabaret/vaudeville</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/oF19dogeWA69hn2op4ZWKx&amp;sa=D&amp;source=editors&amp;ust=1730413584036154&amp;usg=AOvVaw33B17rRh9HKW7PoRYnUM0M">https://www.udio.com/songs/oF19dogeWA69hn2op4ZWKx</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/en8rnSZ6FKCZzFAUXxjKC2&amp;sa=D&amp;source=editors&amp;ust=1730413584036330&amp;usg=AOvVaw0o0fvKr3MOqUufutMWOYLX">https://www.udio.com/songs/en8rnSZ6FKCZzFAUXxjKC2</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/tY6KM6hc87tPvQYAP5iWmR&amp;sa=D&amp;source=editors&amp;ust=1730413584036515&amp;usg=AOvVaw16U-aEgTP03UZFB62wE0Tk">https://www.udio.com/songs/tY6KM6hc87tPvQYAP5iWmR</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/4e97iAsm1Bu8C8VYEXzvqJ&amp;sa=D&amp;source=editors&amp;ust=1730413584036694&amp;usg=AOvVaw3sQQxDdBFYC4e4M1rXfOSk">https://www.udio.com/songs/4e97iAsm1Bu8C8VYEXzvqJ</a></span></li><li class="c7 li-bullet-0"><span>Very similar to Tom Waits: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/6i4ZNQw7bc9MMLoQJUvAwM&amp;sa=D&amp;source=editors&amp;ust=1730413584036876&amp;usg=AOvVaw0lF-n18pkVn8Q2YrwEmS0l">https://www.udio.com/songs/6i4ZNQw7bc9MMLoQJUvAwM</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Musical</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/dzDzTBv5jM2qjjBr1PSEf1&amp;sa=D&amp;source=editors&amp;ust=1730413584037089&amp;usg=AOvVaw0SwlZZKuCaoG220KqrpqEp">https://www.udio.com/songs/dzDzTBv5jM2qjjBr1PSEf1</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span>Bluegrass: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/7bLE7wFVYiziGt9KkT7nem&amp;sa=D&amp;source=editors&amp;ust=1730413584037315&amp;usg=AOvVaw1inV6wA8Vc9Hh0KsKgZ98E">https://www.udio.com/songs/7bLE7wFVYiziGt9KkT7nem</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Future Bass:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/x3xLvnN48DGnmxM5VPTw93&amp;sa=D&amp;source=editors&amp;ust=1730413584037702&amp;usg=AOvVaw3aZzbjJNzWtvNR_M4xnD6M">https://www.udio.com/songs/x3xLvnN48DGnmxM5VPTw93</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2RznwVgBp7wsvtRvvhaEcX&amp;sa=D&amp;source=editors&amp;ust=1730413584037952&amp;usg=AOvVaw121K5jQSk1xWaV4EpdzQmd">https://www.udio.com/songs/2RznwVgBp7wsvtRvvhaEcX</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">Metal:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c14">Nu Metal: </span><span class="c20 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/iimtziNgEDRcpG8j4n4Mfg&amp;sa=D&amp;source=editors&amp;ust=1730413584038371&amp;usg=AOvVaw0JBa4g2HRcGF1OWxyPMcgk">https://www.udio.com/songs/iimtziNgEDRcpG8j4n4Mfg</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/3z26TSc8QfiVzJSwzXRRHY&amp;sa=D&amp;source=editors&amp;ust=1730413584038638&amp;usg=AOvVaw0i1LgTeANKxwqjiS_jfvCZ">https://www.udio.com/songs/3z26TSc8QfiVzJSwzXRRHY</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/sVpFN9FcPN56jiepBgivZ7&amp;sa=D&amp;source=editors&amp;ust=1730413584038918&amp;usg=AOvVaw3_4u5eNri-f8FLAWMcosEt">https://www.udio.com/songs/sVpFN9FcPN56jiepBgivZ7</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/iakV27LkjDM7NLBQDLJEMv&amp;sa=D&amp;source=editors&amp;ust=1730413584039177&amp;usg=AOvVaw3E-iw7RxQ81FFNAosdnGdr">https://www.udio.com/songs/iakV27LkjDM7NLBQDLJEMv</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/kyrBEo2ez3gPhDiaZTQW49&amp;sa=D&amp;source=editors&amp;ust=1730413584039437&amp;usg=AOvVaw1vi6KaPgBAl62Lf7NfGMJ9">https://www.udio.com/songs/kyrBEo2ez3gPhDiaZTQW49</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/cNEXTjwENgsW19pzcx8HVN&amp;sa=D&amp;source=editors&amp;ust=1730413584039684&amp;usg=AOvVaw33sAImiAxgYwXZiNN738qe">https://www.udio.com/songs/cNEXTjwENgsW19pzcx8HVN</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2XWKgvyr3g9VTfGWLh2RN3&amp;sa=D&amp;source=editors&amp;ust=1730413584039931&amp;usg=AOvVaw0A0To9Msi2_W9-114ditWl">https://www.udio.com/songs/2XWKgvyr3g9VTfGWLh2RN3</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/uwscenGwuBdPttVSu9T73F&amp;sa=D&amp;source=editors&amp;ust=1730413584040175&amp;usg=AOvVaw0Eq34cg-F4SUbNU3-HT4fT">https://www.udio.com/songs/uwscenGwuBdPttVSu9T73F</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5bYUkzUu3toB34N8q4P8jG&amp;sa=D&amp;source=editors&amp;ust=1730413584040418&amp;usg=AOvVaw0psQizaNDP0zWaX_yPvi2S">https://www.udio.com/songs/5bYUkzUu3toB34N8q4P8jG</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/csPCgoXsnSgJmv4TN17Jxw&amp;sa=D&amp;source=editors&amp;ust=1730413584040688&amp;usg=AOvVaw09w2qHXMbwtBBRB5C_PM0V">https://www.udio.com/songs/csPCgoXsnSgJmv4TN17Jxw</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/mBpC4WXm7T5AbnGbmr76Nw&amp;sa=D&amp;source=editors&amp;ust=1730413584040937&amp;usg=AOvVaw2RI0J9pYAiLTOkn-Ku1rJ5">https://www.udio.com/songs/mBpC4WXm7T5AbnGbmr76Nw</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/749GppyZMiVbqFAJKsrV7e&amp;sa=D&amp;source=editors&amp;ust=1730413584041182&amp;usg=AOvVaw1nCsOTmyeF4e3hQeFJ_xxE">https://www.udio.com/songs/749GppyZMiVbqFAJKsrV7e</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/xyxxiVQ9YRmHJTJ7ZqjLmg&amp;sa=D&amp;source=editors&amp;ust=1730413584041452&amp;usg=AOvVaw3nSU4Fxfs2p1kBDJox-oFt">https://www.udio.com/songs/xyxxiVQ9YRmHJTJ7ZqjLmg</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/s7FDqeUzGxxLMmbDKYQ6sz&amp;sa=D&amp;source=editors&amp;ust=1730413584041717&amp;usg=AOvVaw2kLmoihz-h159XsiuEYSBS">https://www.udio.com/songs/s7FDqeUzGxxLMmbDKYQ6sz</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5m7ERS3o56G8mZf2kUJYfV&amp;sa=D&amp;source=editors&amp;ust=1730413584041965&amp;usg=AOvVaw0SJGvh-Niu5vhqwON85Yrt">https://www.udio.com/songs/5m7ERS3o56G8mZf2kUJYfV</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/37FjnxppxrRH1XkvowuaeH&amp;sa=D&amp;source=editors&amp;ust=1730413584042216&amp;usg=AOvVaw3OnHbh_qQhu12VD1ss7oWr">https://www.udio.com/songs/37FjnxppxrRH1XkvowuaeH</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1VBd88zcMVAEKchiZTsX22&amp;sa=D&amp;source=editors&amp;ust=1730413584042464&amp;usg=AOvVaw3ZTsdOKwffjW-BYzFd93bj">https://www.udio.com/songs/1VBd88zcMVAEKchiZTsX22</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/akN7uMmvopJh6jKyrvgVue&amp;sa=D&amp;source=editors&amp;ust=1730413584042707&amp;usg=AOvVaw2KMD99I0GM8OPl1Cq9lQG9">https://www.udio.com/songs/akN7uMmvopJh6jKyrvgVue</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/9fb10b92-7e5e-45df-b7b9-73eae1ceb570&amp;sa=D&amp;source=editors&amp;ust=1730413584042960&amp;usg=AOvVaw2yRJ5se5RGAb3S-H52avx_">https://suno.com/song/9fb10b92-7e5e-45df-b7b9-73eae1ceb570</a></span></li><li class="c7 li-bullet-0"><span>Somewhat similar to Iron Maiden: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gzdXCZUzF61s6N6H9QJ3eq&amp;sa=D&amp;source=editors&amp;ust=1730413584043206&amp;usg=AOvVaw3oYXC7JtzylAbub9TIxfjV">https://www.udio.com/songs/gzdXCZUzF61s6N6H9QJ3eq</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/eaba4d6e-f7ab-4bc4-a48b-6e2c8d859dbc&amp;sa=D&amp;source=editors&amp;ust=1730413584043402&amp;usg=AOvVaw0K_VBdY4Pd5aACBbgiG0ni">https://suno.com/song/eaba4d6e-f7ab-4bc4-a48b-6e2c8d859dbc</a></span></li><li class="c7 li-bullet-0"><span>Similar to Rammstein: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/3ZLUxa7vvfjUQ96xyMFd2C&amp;sa=D&amp;source=editors&amp;ust=1730413584043607&amp;usg=AOvVaw2jGEJXKsM9g3Pw8simGR-u">https://www.udio.com/songs/3ZLUxa7vvfjUQ96xyMFd2C</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/o1pUVrG8tznzwXh3sxhyQP&amp;sa=D&amp;source=editors&amp;ust=1730413584043792&amp;usg=AOvVaw0rLOMgCoStIjas6pXALjLO">https://www.udio.com/songs/o1pUVrG8tznzwXh3sxhyQP</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Hip hop:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c1">Kanye West: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-3 start"><li class="c21 c26 li-bullet-0"><span class="c20 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/uRRycSzokNs8kZWdLLMHr7&amp;sa=D&amp;source=editors&amp;ust=1730413584044208&amp;usg=AOvVaw3Tsy_A8OEe67lUBPbxc9eW">https://www.udio.com/songs/uRRycSzokNs8kZWdLLMHr7</a></span></li><li class="c21 c26 li-bullet-0"><span class="c14">Kanye + Rihanna + Kendrick Lamar: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/usXnK54cNo317naXZANNpn&amp;sa=D&amp;source=editors&amp;ust=1730413584044497&amp;usg=AOvVaw2XeN-oTpPheotsiIsKcu5G">https://www.udio.com/songs/usXnK54cNo317naXZANNpn</a></span></li><li class="c21 c26 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/afoNvvA8UdnsppgQcuKvUF&amp;sa=D&amp;source=editors&amp;ust=1730413584044750&amp;usg=AOvVaw3nOrxaW_8Y-FGGGRatcEML">https://www.udio.com/songs/afoNvvA8UdnsppgQcuKvUF</a></span></li><li class="c21 c26 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2ZnftWC4k2tVKhjJmqEAs7&amp;sa=D&amp;source=editors&amp;ust=1730413584044994&amp;usg=AOvVaw0_0pXaALquLos1xEWAFUcL">https://www.udio.com/songs/2ZnftWC4k2tVKhjJmqEAs7</a></span></li><li class="c21 c26 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1YDNDLuhgzbTjwHpAaCoZQ&amp;sa=D&amp;source=editors&amp;ust=1730413584045239&amp;usg=AOvVaw2dmqgyGVptt_jfvs8LYiBA">https://www.udio.com/songs/1YDNDLuhgzbTjwHpAaCoZQ</a></span></li><li class="c21 c26 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/4mbVXF3MGvYepGc9V6A6zA&amp;sa=D&amp;source=editors&amp;ust=1730413584045491&amp;usg=AOvVaw00CY8dNF3ISM5B2eKNq9-2">https://www.udio.com/songs/4mbVXF3MGvYepGc9V6A6zA</a></span></li><li class="c21 c26 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/nFbMXKiW61CjNrYkTX3LTr&amp;sa=D&amp;source=editors&amp;ust=1730413584045739&amp;usg=AOvVaw2F0IytgHGGivXsRmsbO6PK">https://www.udio.com/songs/nFbMXKiW61CjNrYkTX3LTr</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c14">Jay-Z: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/6rNiTbW8JuB8RRCTPSwLPs&amp;sa=D&amp;source=editors&amp;ust=1730413584046007&amp;usg=AOvVaw1nKLnJuQH-rvPB4a4CwJgW">https://www.udio.com/songs/6rNiTbW8JuB8RRCTPSwLPs</a></span></li><li class="c7 li-bullet-0"><span class="c15">Kendrick Lamar w/ amazing beats: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/j1HkAJKjKnbN5avjsd6Xc5&amp;sa=D&amp;source=editors&amp;ust=1730413584046288&amp;usg=AOvVaw1I_NhMh1Wn2Jhu4ehvaJFR">https://www.udio.com/songs/j1HkAJKjKnbN5avjsd6Xc5</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/rzHqZXo4pD7dMqJAWWrXyh&amp;sa=D&amp;source=editors&amp;ust=1730413584046542&amp;usg=AOvVaw2N8GSsicUeZ8OLQ0kVl6KS">https://www.udio.com/songs/rzHqZXo4pD7dMqJAWWrXyh</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/6SsudZEWaSnq4Kdr7dANsF&amp;sa=D&amp;source=editors&amp;ust=1730413584046785&amp;usg=AOvVaw35gT2DPDZUTh_DQtw60blH">https://www.udio.com/songs/6SsudZEWaSnq4Kdr7dANsF</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/53a8521a-de15-4287-b683-4d3dc1687144&amp;sa=D&amp;source=editors&amp;ust=1730413584046991&amp;usg=AOvVaw0KmNnQ6RN9-KGDJfq5yJP7">https://suno.com/song/53a8521a-de15-4287-b683-4d3dc1687144</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/9BPh6bZ7QRnHYzoTrvpvKj&amp;sa=D&amp;source=editors&amp;ust=1730413584047180&amp;usg=AOvVaw3oKkULnTBwiYSZSPEjtJyH">https://www.udio.com/songs/9BPh6bZ7QRnHYzoTrvpvKj</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Country:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/coixNX1gnJ1oWT8z2LQddk&amp;sa=D&amp;source=editors&amp;ust=1730413584047449&amp;usg=AOvVaw2wy1K5vpME-gOPlf7X2vf-">https://www.udio.com/songs/coixNX1gnJ1oWT8z2LQddk</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-3 start"><li class="c21 c26 li-bullet-0"><span class="c1">Very good, in my opinion</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span>Country rock: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/kYUkkLEK9DUdQAfWHCynMf&amp;sa=D&amp;source=editors&amp;ust=1730413584047716&amp;usg=AOvVaw3HvPPFk-qLMEiXOI1LDu6r">https://www.udio.com/songs/kYUkkLEK9DUdQAfWHCynMf</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span>Song in various genres in one: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/9FkMQrFw7o51PRC3HDwqXk&amp;sa=D&amp;source=editors&amp;ust=1730413584048068&amp;usg=AOvVaw3ugOuJe8svAti_P8FFQtRy">https://www.udio.com/songs/9FkMQrFw7o51PRC3HDwqXk</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j3ti34irq4rs-0 start"><li class="c10 li-bullet-0"><span class="c1">K-Pop:</span></li></ul><ul class="c0 lst-kix_j3ti34irq4rs-1 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8mFAxvwdf1RNaoBeexT4D5&amp;sa=D&amp;source=editors&amp;ust=1730413584048477&amp;usg=AOvVaw0fFmWA25hLC0_rM_hujExV">https://www.udio.com/songs/8mFAxvwdf1RNaoBeexT4D5</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ohRxf4LvQxgwF3TvdfXqeS&amp;sa=D&amp;source=editors&amp;ust=1730413584048756&amp;usg=AOvVaw1lw1FYYHfiGh-aV-kV8CVR">https://www.udio.com/songs/ohRxf4LvQxgwF3TvdfXqeS</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_j3ti34irq4rs-0"><li class="c10 li-bullet-0"><span class="c1">J-Pop:</span></li></ul><ul class="c0 lst-kix_j3ti34irq4rs-1 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/n8vyyCPy8VKsCSpQopAyW9&amp;sa=D&amp;source=editors&amp;ust=1730413584049193&amp;usg=AOvVaw3KW4CD_E-pd6RyW_2wIVaQ">https://www.udio.com/songs/n8vyyCPy8VKsCSpQopAyW9</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/thpduuE5uhHJhuZgqmNZFm&amp;sa=D&amp;source=editors&amp;ust=1730413584049469&amp;usg=AOvVaw0KQJWPEALXKO3U6BgaSszu">https://www.udio.com/songs/thpduuE5uhHJhuZgqmNZFm</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qsgPsTNnVraQRLyUTTVmEA&amp;sa=D&amp;source=editors&amp;ust=1730413584049719&amp;usg=AOvVaw2LXgtECVTD6jkMg-HJp78j">https://www.udio.com/songs/qsgPsTNnVraQRLyUTTVmEA</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/7ZzFLMkkwxyBDQPCG1eQZ3&amp;sa=D&amp;source=editors&amp;ust=1730413584049968&amp;usg=AOvVaw1G1A3GVQXl06zQtfwA4-Kw">https://www.udio.com/songs/7ZzFLMkkwxyBDQPCG1eQZ3</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/eEqhAB3qRSt9nxp21Q3EBD&amp;sa=D&amp;source=editors&amp;ust=1730413584050218&amp;usg=AOvVaw0nE_T8yv_EPIRGwblLBRTs">https://www.udio.com/songs/eEqhAB3qRSt9nxp21Q3EBD</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gYtfMVg45tTAsxDULbWUZh&amp;sa=D&amp;source=editors&amp;ust=1730413584050470&amp;usg=AOvVaw0jkjeOj6u3J8_gru1W7qYF">https://www.udio.com/songs/gYtfMVg45tTAsxDULbWUZh</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/hp2EguaJ7vXFeErvyQCQYD&amp;sa=D&amp;source=editors&amp;ust=1730413584050712&amp;usg=AOvVaw3jQ7NgArpq_6P59Sq_NoLR">https://www.udio.com/songs/hp2EguaJ7vXFeErvyQCQYD</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/15746124-524c-495e-b444-de303df5722c&amp;sa=D&amp;source=editors&amp;ust=1730413584050977&amp;usg=AOvVaw3D8pW1nO90XqGPaXD69bWc">https://suno.com/song/15746124-524c-495e-b444-de303df5722c</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1HkNvzsiiweTR1XDMxQM2p&amp;sa=D&amp;source=editors&amp;ust=1730413584051246&amp;usg=AOvVaw2HIvlYjly7evKFLMQZ6h3S">https://www.udio.com/songs/1HkNvzsiiweTR1XDMxQM2p</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/eQpXCoyT7q3CdRRi5WhxnX&amp;sa=D&amp;source=editors&amp;ust=1730413584051519&amp;usg=AOvVaw1REQtiYtsGVosJsE67Iauh">https://www.udio.com/songs/eQpXCoyT7q3CdRRi5WhxnX</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/tjbhySfUsYMjYvNo5Ytvkx&amp;sa=D&amp;source=editors&amp;ust=1730413584051767&amp;usg=AOvVaw1qyhRjJ-ylcIZCpV13ToAB">https://www.udio.com/songs/tjbhySfUsYMjYvNo5Ytvkx</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/uWPDNLJCLfrhSoHV48Kg14&amp;sa=D&amp;source=editors&amp;ust=1730413584052011&amp;usg=AOvVaw0BD5bZIIVAR42pW7fc_UUm">https://www.udio.com/songs/uWPDNLJCLfrhSoHV48Kg14</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://kinkykawaii.bandcamp.com/album/dazzler&amp;sa=D&amp;source=editors&amp;ust=1730413584052251&amp;usg=AOvVaw0ioS9fmu3EhL1AcoGwiA0q">https://kinkykawaii.bandcamp.com/album/dazzler</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Jazz Fusion</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span>Persona-style: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/kqHjbuyW4H3yYKcwLZQo3K&amp;sa=D&amp;source=editors&amp;ust=1730413584052682&amp;usg=AOvVaw0xc2iCPoAiiPCwj-u0gNyL">https://www.udio.com/songs/kqHjbuyW4H3yYKcwLZQo3K</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/rXM6odgDvPYipNV9GKJnj1&amp;sa=D&amp;source=editors&amp;ust=1730413584052956&amp;usg=AOvVaw0UZ3-V-NX34evLiKxbd3zK">https://www.udio.com/songs/rXM6odgDvPYipNV9GKJnj1</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1HkNvzsiiweTR1XDMxQM2p&amp;sa=D&amp;source=editors&amp;ust=1730413584053222&amp;usg=AOvVaw3175Bl4m-FkJ4J63dFfpbn">https://www.udio.com/songs/1HkNvzsiiweTR1XDMxQM2p</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/ryXSV42z7DiXASy522pZmF&amp;sa=D&amp;source=editors&amp;ust=1730413584053494&amp;usg=AOvVaw0u3R54wLURJ7_18y9uH5Za">https://www.udio.com/songs/ryXSV42z7DiXASy522pZmF</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Chiptune:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/tnnrR5azG47mg9hyPNaxsm&amp;sa=D&amp;source=editors&amp;ust=1730413584053895&amp;usg=AOvVaw2sMhbGihij2ofDvGo9XcrO">https://www.udio.com/songs/tnnrR5azG47mg9hyPNaxsm</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/qKbxQz54m3CMbWZfyC3LK6&amp;sa=D&amp;source=editors&amp;ust=1730413584054165&amp;usg=AOvVaw1qNfpXfIlJV1IjVJDZBPEO">https://www.udio.com/songs/qKbxQz54m3CMbWZfyC3LK6</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Soul: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5bqNHibgAsRLvo6BporEB1&amp;sa=D&amp;source=editors&amp;ust=1730413584054568&amp;usg=AOvVaw2ZzFvkwyi1l2jG16jc-U4r">https://www.udio.com/songs/5bqNHibgAsRLvo6BporEB1</a></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/svRzxwgGWFFEgCcUQogYbw&amp;sa=D&amp;source=editors&amp;ust=1730413584054833&amp;usg=AOvVaw3Rh6SuHPwEZYuza5cMeZAF">https://www.udio.com/songs/svRzxwgGWFFEgCcUQogYbw</a></span><span class="c1 c14">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/r27bVnsLQmvQsE5VEj7Lya&amp;sa=D&amp;source=editors&amp;ust=1730413584055097&amp;usg=AOvVaw3iOTbN32OwvLdpOTlVtQLn">https://www.udio.com/songs/r27bVnsLQmvQsE5VEj7Lya</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/f275d9ac-5a62-4bbe-baf9-3fa10e0332f4&amp;sa=D&amp;source=editors&amp;ust=1730413584055370&amp;usg=AOvVaw3PF1ys-K2GXUStirj-EOr2">https://suno.com/song/f275d9ac-5a62-4bbe-baf9-3fa10e0332f4</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/1bec9b5b-e307-4198-a039-94cff9f2b090&amp;sa=D&amp;source=editors&amp;ust=1730413584055763&amp;usg=AOvVaw0CZ4v5FmwDjI5Hug9pCXqe">https://suno.com/song/1bec9b5b-e307-4198-a039-94cff9f2b090</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Funk:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/mwsr23c1fFDdk21fqfmESK&amp;sa=D&amp;source=editors&amp;ust=1730413584056076&amp;usg=AOvVaw3pusIiOy7vh0b7suwcE7rw">https://www.udio.com/songs/mwsr23c1fFDdk21fqfmESK</a></span></li></ul><p class="c9 c105"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">electro-pop: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/dFX8e3k87WQX8m2YUmR7cx&amp;sa=D&amp;source=editors&amp;ust=1730413584056371&amp;usg=AOvVaw37cRTzaw3GuFuVcH7Ro-yb">https://www.udio.com/songs/dFX8e3k87WQX8m2YUmR7cx</a></span></li><li class="c7 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gQxE7XZLtCHPKdk3eKZ2tk&amp;sa=D&amp;source=editors&amp;ust=1730413584056566&amp;usg=AOvVaw3BMZ_WSkTl6GYJFTSRiyQJ">https://www.udio.com/songs/gQxE7XZLtCHPKdk3eKZ2tk</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/mdoraUg81oJbKEjjiqXnAu&amp;sa=D&amp;source=editors&amp;ust=1730413584056794&amp;usg=AOvVaw3ffj9Q5IPxbXtP7oKiH6qs">https://www.udio.com/songs/mdoraUg81oJbKEjjiqXnAu</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/cxswG6VHxYSQw98QoPHpWi&amp;sa=D&amp;source=editors&amp;ust=1730413584056984&amp;usg=AOvVaw1G9xB9SVmMG-9OQZ9FKf6r">https://www.udio.com/songs/cxswG6VHxYSQw98QoPHpWi</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/9m6mdBw5eMU5ScKw4Tkkqz&amp;sa=D&amp;source=editors&amp;ust=1730413584057163&amp;usg=AOvVaw33R_BYetfuQxZZmAru8xfo">https://www.udio.com/songs/9m6mdBw5eMU5ScKw4Tkkqz</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/hyUUwqQepn8rWjevjeGFNh&amp;sa=D&amp;source=editors&amp;ust=1730413584057342&amp;usg=AOvVaw10GmZvAg9DWQZ8sp4f8mHV">https://www.udio.com/songs/hyUUwqQepn8rWjevjeGFNh</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span>Pop rap similar to K/DA: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8mBTYc1Bn28rceBb3MvV1g&amp;sa=D&amp;source=editors&amp;ust=1730413584057571&amp;usg=AOvVaw0cbUPhb3UKHTovUTAE11LQ">https://www.udio.com/songs/8mBTYc1Bn28rceBb3MvV1g</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Rnb: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span>Very similar to Frank Ocean: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gHFjyk36Xr2gyQhCvyWJxe&amp;sa=D&amp;source=editors&amp;ust=1730413584057825&amp;usg=AOvVaw3j4xIy2J-w9bnu45UnOyKb">https://www.udio.com/songs/gHFjyk36Xr2gyQhCvyWJxe</a></span></li><li class="c7 li-bullet-0"><span class="c15">Beyonc&eacute;: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/16nwqoukAQPyMTM1e3k3wf&amp;sa=D&amp;source=editors&amp;ust=1730413584058011&amp;usg=AOvVaw0tqXelEOYJIeznrnfpU-UD">https://www.udio.com/songs/16nwqoukAQPyMTM1e3k3wf</a></span><span class="c15">&nbsp;(</span><span class="c1">great vocal performance)</span></li><li class="c7 li-bullet-0"><span class="c15">Rihanna (Excellent vocals): </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/rmqyXEfnd4aBCgn3i5xwSq&amp;sa=D&amp;source=editors&amp;ust=1730413584058230&amp;usg=AOvVaw18qB9gJ3QnicofAKCeMO9N">https://www.udio.com/songs/rmqyXEfnd4aBCgn3i5xwSq</a></span><span class="c33 c15">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/37KXHspVLAcxanYeGfUjA7&amp;sa=D&amp;source=editors&amp;ust=1730413584058408&amp;usg=AOvVaw3N9tZoBSy4Z_wnfZ-oVp-6">https://www.udio.com/songs/37KXHspVLAcxanYeGfUjA7</a></span><span class="c1">&nbsp;</span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2tSdv7yRtpW24jsT6ZGZyf&amp;sa=D&amp;source=editors&amp;ust=1730413584058592&amp;usg=AOvVaw1_rbBsXDz2jHqmJhI9xomO">https://www.udio.com/songs/2tSdv7yRtpW24jsT6ZGZyf</a></span><span class="c1">&nbsp;(incredible vocals)</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">1950s:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/1guiJstbJk3SFzYJRP6AuG&amp;sa=D&amp;source=editors&amp;ust=1730413584058879&amp;usg=AOvVaw1dUdK3xQ-OkPF4nXMRLSnt">https://www.udio.com/songs/1guiJstbJk3SFzYJRP6AuG</a></span></li><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/bgPfgVWK_U0&amp;sa=D&amp;source=editors&amp;ust=1730413584059043&amp;usg=AOvVaw1ROc9IZjF9dTFVgzcgtS2d">https://youtu.be/bgPfgVWK_U0</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/5Ez3kNfY3F89Y7nnxrxssv&amp;sa=D&amp;source=editors&amp;ust=1730413584059224&amp;usg=AOvVaw0YFh2aIsKfihXEFw9BMyCb">https://www.udio.com/songs/5Ez3kNfY3F89Y7nnxrxssv</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Foilk:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/n7WS6BEW7Af5hrdmdgVnMb&amp;sa=D&amp;source=editors&amp;ust=1730413584059510&amp;usg=AOvVaw1Zxfm58WAV3X8a8rmzxYm7">https://www.udio.com/songs/n7WS6BEW7Af5hrdmdgVnMb</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2sd2JdafUTCZW4QkAtNAqT&amp;sa=D&amp;source=editors&amp;ust=1730413584059703&amp;usg=AOvVaw3PlI0IkPkP7c0-wgKBdkVh">https://www.udio.com/songs/2sd2JdafUTCZW4QkAtNAqT</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/wAHSpzDM4XXeixcvuDqU3w&amp;sa=D&amp;source=editors&amp;ust=1730413584059872&amp;usg=AOvVaw2DOTNjPbOaaSg2A0ckKVhB">https://www.udio.com/songs/wAHSpzDM4XXeixcvuDqU3w</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/gajKkTvivm1nJx6oNQjFk1&amp;sa=D&amp;source=editors&amp;ust=1730413584060038&amp;usg=AOvVaw2czVcg5gSqLmWktq_BB881">https://www.udio.com/songs/gajKkTvivm1nJx6oNQjFk1</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/wUZ63W1ixAnqssAUZr92T5&amp;sa=D&amp;source=editors&amp;ust=1730413584060206&amp;usg=AOvVaw1HaFP4mRDJ_wVUa8eudZ5v">https://www.udio.com/songs/wUZ63W1ixAnqssAUZr92T5</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/2y51k7sTwWisteYDnQ7Lne&amp;sa=D&amp;source=editors&amp;ust=1730413584060372&amp;usg=AOvVaw1YjGeFvmXoTjBb_xyzk8dm">https://www.udio.com/songs/2y51k7sTwWisteYDnQ7Lne</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span>Electro-swing song of The Raven by Edgar Allen Poe: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/3df191eb-6eb1-4577-a093-8711534b8c67&amp;sa=D&amp;source=editors&amp;ust=1730413584060599&amp;usg=AOvVaw2PPOtqU9Yp5B-_5ZbBM54w">https://suno.com/song/3df191eb-6eb1-4577-a093-8711534b8c67</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/cn2XKTpdANRTUbRbFWjnAG&amp;sa=D&amp;source=editors&amp;ust=1730413584060811&amp;usg=AOvVaw1tIi9LM0zhbZiXZNNXkwhj">https://www.udio.com/songs/cn2XKTpdANRTUbRbFWjnAG</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Lofi:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/aGiQSY3mpkgKLKqRYAwiwL&amp;sa=D&amp;source=editors&amp;ust=1730413584061045&amp;usg=AOvVaw0PRHG0-XQVIbNSFNSjDLdX">https://www.udio.com/songs/aGiQSY3mpkgKLKqRYAwiwL</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Movie score: </span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/vF9KKQbzdsbVnAwaFL7t3U&amp;sa=D&amp;source=editors&amp;ust=1730413584061255&amp;usg=AOvVaw3xl3GFyVqYbQosJ42MF1at">https://www.udio.com/songs/vF9KKQbzdsbVnAwaFL7t3U</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Arabic jazz:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/wsnFxiybEgdXfnMXw4LxMF&amp;sa=D&amp;source=editors&amp;ust=1730413584061524&amp;usg=AOvVaw2AkRb6jZ5g6gVzPWxJKRRq">https://www.udio.com/songs/wsnFxiybEgdXfnMXw4LxMF</a></span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1">Vocaloid:</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/dtGew3mi88Na17cEwnvFj3&amp;sa=D&amp;source=editors&amp;ust=1730413584061798&amp;usg=AOvVaw1bUs85l3xDHV2RvKePQ5fD">https://www.udio.com/songs/dtGew3mi88Na17cEwnvFj3</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/dtGew3mi88Na17cEwnvFj3&amp;sa=D&amp;source=editors&amp;ust=1730413584062006&amp;usg=AOvVaw3fyjGP_dVvIrpPNnwtxyDk">https://www.udio.com/songs/dtGew3mi88Na17cEwnvFj3</a></span></li><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/oCXgtuRdApE3hPvTQV5CXb&amp;sa=D&amp;source=editors&amp;ust=1730413584062208&amp;usg=AOvVaw2RgmHAqzvNWU_8HT_gxRax">https://www.udio.com/songs/oCXgtuRdApE3hPvTQV5CXb</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/playlists/smjmFjDiPMQ74wZHW9kbyj&amp;sa=D&amp;source=editors&amp;ust=1730413584062467&amp;usg=AOvVaw1jHL5E4C_o83m2yF628Zg6">https://www.udio.com/playlists/smjmFjDiPMQ74wZHW9kbyj</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/wqo7bgZn3xVtxTrNLhrDf6&amp;sa=D&amp;source=editors&amp;ust=1730413584062648&amp;usg=AOvVaw0Y2lcdTzfRgyW3jlmZxQK6">https://www.udio.com/songs/wqo7bgZn3xVtxTrNLhrDf6</a></span><span class="c1 c14">&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c6 c68"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/3gm5Cb8Jw8QqmjBfVn4tvr&amp;sa=D&amp;source=editors&amp;ust=1730413584062838&amp;usg=AOvVaw10ZbovguBaW2KsZqZSyC_y">https://www.udio.com/songs/3gm5Cb8Jw8QqmjBfVn4tvr</a></span></li><li class="c49 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/nmodbd8XHX8ttmwrMRZSyj&amp;sa=D&amp;source=editors&amp;ust=1730413584063021&amp;usg=AOvVaw0LXcyW7sxdP2vkmWSxa9_N">https://www.udio.com/songs/nmodbd8XHX8ttmwrMRZSyj</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/8e7gDcKW1PsuCqhbmuHVd7&amp;sa=D&amp;source=editors&amp;ust=1730413584063235&amp;usg=AOvVaw2Pbw_EvUlg9_N8J0UKe7ql">https://www.udio.com/songs/8e7gDcKW1PsuCqhbmuHVd7</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D1T_ILXF-K1o&amp;sa=D&amp;source=editors&amp;ust=1730413584063457&amp;usg=AOvVaw3sbuVal6ioNFgxrlf_aNay">https://www.youtube.com/watch?v=1T_ILXF-K1o</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DU_9E8HBZSfw&amp;sa=D&amp;source=editors&amp;ust=1730413584063641&amp;usg=AOvVaw25T2TKfqDPnQ1hILf-OCXd">https://www.youtube.com/watch?v=U_9E8HBZSfw</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/ac89e551-41bb-420f-8620-bbb884dcbe1f&amp;sa=D&amp;source=editors&amp;ust=1730413584063860&amp;usg=AOvVaw3wQQ0bnpk0hBRSod8KsqJF">https://suno.com/song/ac89e551-41bb-420f-8620-bbb884dcbe1f</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/d7df5feb-5237-4af1-b341-7e2458c8bd93&amp;sa=D&amp;source=editors&amp;ust=1730413584064042&amp;usg=AOvVaw2j2V--zCNCTqjgHdhxxY2b">https://suno.com/song/d7df5feb-5237-4af1-b341-7e2458c8bd93</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/3f0ff21b-23b1-4bbf-b6c9-5a8524a43ca3&amp;sa=D&amp;source=editors&amp;ust=1730413584064218&amp;usg=AOvVaw07e9I3ivQoBxnjg--YAtV1">https://suno.com/song/3f0ff21b-23b1-4bbf-b6c9-5a8524a43ca3</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://suno.com/song/def40b38-92f5-42c9-a645-189ca1921692&amp;sa=D&amp;source=editors&amp;ust=1730413584064440&amp;usg=AOvVaw1-lUvs51u6W6rgAS85R7Md">https://suno.com/song/def40b38-92f5-42c9-a645-189ca1921692</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/elevenlabsio/status/1788628175766859891&amp;sa=D&amp;source=editors&amp;ust=1730413584064640&amp;usg=AOvVaw2xIMFy7pz74V6vwiU4Ff9F">https://twitter.com/elevenlabsio/status/1788628175766859891</a></span><span class="c1 c14">&nbsp;</span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D7zTei5RMhQ8&amp;sa=D&amp;source=editors&amp;ust=1730413584064827&amp;usg=AOvVaw3SyflBLTR87KkyrIwjbOF5">https://m.youtube.com/watch?v=7zTei5RMhQ8</a></span><span class="c1 c14">&nbsp;(&gt;500k views in under a month)</span></li><li class="c10 li-bullet-0"><span class="c14">Very unique song: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.udio.com/songs/uN6g8GBBfTcP6GLrrQT638&amp;sa=D&amp;source=editors&amp;ust=1730413584065030&amp;usg=AOvVaw2BuiwjHvPBso1rDSS4GQHl">https://www.udio.com/songs/uN6g8GBBfTcP6GLrrQT638</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c14">Metro Boomin samples </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.vulture.com/article/bbl-drizzy-metro-boomin-sample-comedian.html&amp;sa=D&amp;source=editors&amp;ust=1730413584065333&amp;usg=AOvVaw34rCxzUsmNPhgTV0fvU0Wj">AI-generated song</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Df6Hr69ca9ZM%26t%3D7s&amp;sa=D&amp;source=editors&amp;ust=1730413584065556&amp;usg=AOvVaw2jU8aUQtxz5JKesmHn2K4x">https://youtube.com/watch?v=f6Hr69ca9ZM&amp;t=7s</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c1 c14">Won $10k from him and a free remix in a competition </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">The original song has a 3.33/5 with 46 reviews on RateYourMusic: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://rateyourmusic.com/release/single/king-willonius/bbl-drizzy/&amp;sa=D&amp;source=editors&amp;ust=1730413584065916&amp;usg=AOvVaw3iKhBInbJBDgwE_HaOdGsf">https://rateyourmusic.com/release/single/king-willonius/bbl-drizzy/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">The remix has a 3.88/5 with 612 reviews on RYM (for context, the highest rated albums of all time on the site hover around 4/5): </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://rateyourmusic.com/release/single/metro-boomin/bbl-drizzy-bpm-150_mp3/&amp;sa=D&amp;source=editors&amp;ust=1730413584066184&amp;usg=AOvVaw0cy8xXmorFGTvxOK3TiqCF">https://rateyourmusic.com/release/single/metro-boomin/bbl-drizzy-bpm-150_mp3/</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">Covered by Tim Henson from Polyphia: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3DOly6ayyckZI%26t%3D6s&amp;sa=D&amp;source=editors&amp;ust=1730413584066446&amp;usg=AOvVaw2Y-a15cLPTRuroB24bRxyh">https://youtube.com/watch?v=Oly6ayyckZI&amp;t=6s</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c14">3.</span><span class="c1">88/5 on Rate Your Music with 612 reviews. The best albums of all time get around a 4/5.</span></li></ul><p class="c21 c129"><span class="c1">&nbsp;</span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_codfi3rttsmj-1"><li class="c10 li-bullet-0"><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy&amp;sa=D&amp;source=editors&amp;ust=1730413584066826&amp;usg=AOvVaw0h9LkgeVYsI3qlcmv4Ygko">https://en.m.wikipedia.org/wiki/BBL_Drizzy</a></span></li></ul><p class="c9"><span class="c18 c92 c108 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c18 c108 c14">&quot;BBL Drizzy&quot; quickly </span><span class="c18 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Internet_meme&amp;sa=D&amp;source=editors&amp;ust=1730413584067060&amp;usg=AOvVaw1t1OI5lM5XfA5oXnaqs4SF">went viral</a></span><span class="c18 c108 c14">, generating more than 3.3 million streams on </span><span class="c18 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/SoundCloud&amp;sa=D&amp;source=editors&amp;ust=1730413584067202&amp;usg=AOvVaw0HGj86BIKEvaR5fqF5Yfp5">SoundCloud</a></span><span class="c18 c92 c108 c14">&nbsp;within a week</span></li></ul><p class="c9"><span class="c18 c92 c108 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-2"><li class="c7 li-bullet-0"><span class="c18 c108 c14">Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including </span><span class="c18 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Elon_Musk&amp;sa=D&amp;source=editors&amp;ust=1730413584067466&amp;usg=AOvVaw14HPi9Jl0HGtVw6UWT3OGQ">Elon Musk</a></span><span class="c18 c108 c14">&nbsp;and </span><span class="c18 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Dr._Miami&amp;sa=D&amp;source=editors&amp;ust=1730413584067644&amp;usg=AOvVaw3ehCoaGRV40e0Ax1fHNcOk">Dr. Miami</a></span><span class="c18 c108 c14">&nbsp;reacted to the beat.</span><span class="c37 c14 c38"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Complex_Cowen2024_DrMiamiLooping-19&amp;sa=D&amp;source=editors&amp;ust=1730413584067822&amp;usg=AOvVaw2w0WsljHhbpNuJtLzuUxeS">[19]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Dexerto_Horetski2024_WhatDoesBBLDrizzyMean-20&amp;sa=D&amp;source=editors&amp;ust=1730413584067958&amp;usg=AOvVaw3KxI7R5C5w759tkC41WN4m">[20]</a></span><span class="c18 c108 c14">&nbsp;Several corporations also responded, including </span><span class="c18 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Educational_technology&amp;sa=D&amp;source=editors&amp;ust=1730413584068130&amp;usg=AOvVaw3eC7tHrnKrgspUbqVfPFU9">educational technology</a></span><span class="c18 c108 c14">&nbsp;company </span><span class="c18 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Duolingo&amp;sa=D&amp;source=editors&amp;ust=1730413584068262&amp;usg=AOvVaw2WYKlVvvKByfgChMCERYky">Duolingo</a></span><span class="c18 c108 c14">&nbsp;and meat producer </span><span class="c18 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Oscar_Mayer&amp;sa=D&amp;source=editors&amp;ust=1730413584068397&amp;usg=AOvVaw2zpLvgC7kdYe7XBH28PfeC">Oscar Mayer</a></span><span class="c18 c108 c14">.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_codfi3rttsmj-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ArtificialInteligence/comments/1ciaf12/aigenerated_songs_rack_up_thousands_of_listens_on/&amp;sa=D&amp;source=editors&amp;ust=1730413584068714&amp;usg=AOvVaw2CHBYUmxeFd_XK-lA2Al-f">AI music gains thousands of listens on Spotify https://www.reddit.com/r/ArtificialInteligence/comments/1ciaf12/aigenerated_songs_rack_up_thousands_of_listens_on/</a></span></li><li class="c4 li-bullet-0"><span class="c14">AI Country Artists Like &ldquo;Terry &amp; The Dustriders&rdquo; Are Racking Up Millions Of Streams With AI Cover Albums On Spotify: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.whiskeyriff.com/2024/07/19/ai-country-artists-like-terry-the-dustriders-are-racking-up-millions-of-streams-with-fake-cover-albums-on-spotify/&amp;sa=D&amp;source=editors&amp;ust=1730413584069048&amp;usg=AOvVaw2-Ebi9btfYP0fXBbulFnLJ">https://www.whiskeyriff.com/2024/07/19/ai-country-artists-like-terry-the-dustriders-are-racking-up-millions-of-streams-with-fake-cover-albums-on-spotify/</a></span></li><li class="c4 li-bullet-0"><span class="c14">Sound to music: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/LinusEkenstam/status/1797761904640954430&amp;sa=D&amp;source=editors&amp;ust=1730413584069254&amp;usg=AOvVaw2Pr_Uxd8XUkZg9BZJRHyE3">https://x.com/LinusEkenstam/status/1797761904640954430</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_codfi3rttsmj-1 start"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/suno_ai_/status/1795878282631512512&amp;sa=D&amp;source=editors&amp;ust=1730413584069537&amp;usg=AOvVaw26oyBb65KJYVnVl_hzLnZZ">https://x.com/suno_ai_/status/1795878282631512512</a></span><span class="c1 c14">&nbsp;</span></li><li class="c49 li-bullet-0"><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1d92yvj/this_is_so_fucking_cool_udio_audio_input_feature/&amp;sa=D&amp;source=editors&amp;ust=1730413584069768&amp;usg=AOvVaw12VGBUaZu0EIS5yK_L-NYi">https://www.reddit.com/r/singularity/comments/1d92yvj/this_is_so_fucking_cool_udio_audio_input_feature/</a></span></li><li class="c49 li-bullet-0"><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/maxescu/status/1798426354888950131&amp;sa=D&amp;source=editors&amp;ust=1730413584070033&amp;usg=AOvVaw0T2cjud7ZUS1u0dFRgtOPI">https://x.com/maxescu/status/1798426354888950131</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><h2 class="c64" id="h.8wkiypqurh0"><span>11.5. Artists Who Support or Use AI</span></h2><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>&lsquo;He touched a nerve&rsquo;: how the first piece of AI music was born in 1956: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/music/2021/dec/07/he-touched-a-nerve-how-the-first-piece-of-ai-music-was-born-in-1956&amp;sa=D&amp;source=editors&amp;ust=1730413584070540&amp;usg=AOvVaw1aJywkEIt22SJNP53Ap5j7">https://www.theguardian.com/music/2021/dec/07/he-touched-a-nerve-how-the-first-piece-of-ai-music-was-born-in-1956</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c1">Long before Auto-Tune and deepfake compositions, the university professor Lejaren Hiller premiered a concert recital composed by a computer and became an overnight celebrity</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c24">&#39;AI will become the new normal&rsquo;: how the art world&#39;s technological boom is changing the industry: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.theartnewspaper.com/2023/02/28/ai-will-become-the-new-normal-how-the-art-worlds-technological-boom-is-changing-the-industry&amp;sa=D&amp;source=editors&amp;ust=1730413584071033&amp;usg=AOvVaw0UZF5I6WIxBLA1OqfklIrT">https://www.theartnewspaper.com/2023/02/28/ai-will-become-the-new-normal-how-the-art-worlds-technological-boom-is-changing-the-industry</a></span></li></ul><p class="c9"><span class="c112 c37 c35 c48 c120"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c112 c37 c35 c48 c120">Art created using artificial intelligence (AI) is burgeoning. From commercial gallery shows&mdash;including Jon Rafman&rsquo;s large-scale, algorithmically generated paintings at Spr&uuml;th Magers in London (Ebrah k&rsquo;dabri, until 25 March)&mdash;to the PATH-AI artist residency organised in collaboration with London&rsquo;s Somerset House, AI-related art projects are springing up everywhere.</span></li><li class="c10 li-bullet-0"><span class="c24">Artists in the field stress that AI is prompting a paradigm shift. Rafman says: &quot;</span><span class="c24 c34">I have been using AI in one form or another since I began making art on computers in the 1990s.</span><span class="c112 c37 c35 c48 c120">&nbsp;I only truly started using image-generating AI tools around 2020.&quot;</span></li><li class="c10 li-bullet-0"><span class="c24 c15">His 40-minute film at Spr&uuml;th Magers, Counterfeit Poast (2023), is entirely generated from AI imagery</span><span class="c24">; the characters in it are animated using an iPhone facial motion-capture app. &ldquo;AI has the potential to </span><span class="c24 c34">open the gates for new perceptions of image-making just as the development of photography liberated painting from pure factual representation and allowed painters to focus on other dimensions</span><span class="c112 c37 c35 c48 c120">, such as colour, light, and movement,&rdquo; Rafman adds.</span></li><li class="c10 li-bullet-0"><span class="c24">The German digital artist Mario Klingemann </span><span class="c24 c15">has been working with AI since 2015, developing works such as Memories of Passersby 1 (2018), which employ a system of neural networks to generate a never-ending stream of portraits</span><span class="c24">. &ldquo;I think </span><span class="c24 c34">artists should embrace or at least try out the possibilities that AI offers</span><span class="c24">,&rdquo; he says. &ldquo;This technology will become the new normal.&rdquo;Klingemann explains how he harnesses AI, creating works where the boundaries between human influence and machine creation become increasingly blurred. Botto, for instance, is a project to create an entity that can be perceived as an autonomous artist. &ldquo;It is set up as a </span><span class="c24 c34">hybrid between an AI that makes its own creative decisions and a community of human stewards that vote on Botto&rsquo;s proposals and thereby curate the output and indirectly steer the artistic development of the machine</span><span class="c112 c37 c35 c48 c120">,&rdquo; he says.</span></li><li class="c10 li-bullet-0"><span class="c24">Three artists have been selected for the six-month remote artist residency programme PATH-AI, which has been developed by the Alan Turing Institute in London, the University of Edinburgh and the RIKEN research institute in Japan. The AI-inspired works of Nouf Aljowaysir, Chris Zhongtian Yuan, and Juan Covelli are presented on Somerset House&rsquo;s online curated space known as Channel. Brooklyn-based Aljowaysir has made a film, Ana Min Wein (Where Am I From?), which tracks her immigration path to the US, charting her family&rsquo;s migration history across Saudi Arabia and Iraq. </span><span class="c112 c15 c35 c48 c120">An AI assistant supports her journey in a film.</span></li></ul><p class="c9"><span class="c112 c15 c35 c48 c120"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>James Cameron Joins AI Company Stability AI as Board Member: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.hollywoodreporter.com/business/business-news/james-cameron-joins-board-ai-firm-stability-stable-diffusion-1236010034/&amp;sa=D&amp;source=editors&amp;ust=1730413584072147&amp;usg=AOvVaw3X0gKcUkLF9wxy2Nlaxc37">https://www.hollywoodreporter.com/business/business-news/james-cameron-joins-board-ai-firm-stability-stable-diffusion-1236010034/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c1">&ldquo;I was at the forefront of CGI over 3 decades ago, and I&rsquo;ve stayed on the cutting edge since. Now, the intersection of generative AI and CGI image creation is the next wave&rdquo;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>The Smile band (led by Thom Yorke and Johnny Greenwood of Radiohead) uses AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DEWpI0n1FZIY&amp;sa=D&amp;source=editors&amp;ust=1730413584072539&amp;usg=AOvVaw2Epr-xQWMG0KBlDpDtlxOw">https://m.youtube.com/watch?v=EWpI0n1FZIY</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>&#39;Another Form of Magic&#39;: Andy Serkis Reveals He&#39;s Working on New Project Featuring &#39;AI Characters&#39; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cbr.com/andy-serkis-new-project-ai-characters/&amp;sa=D&amp;source=editors&amp;ust=1730413584072840&amp;usg=AOvVaw0zvPgeytzZZ40vALd7UVgF">https://www.cbr.com/andy-serkis-new-project-ai-characters/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Late Night With the Devil movie uses AI art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://letterboxd.com/film/late-night-with-the-devil/&amp;sa=D&amp;source=editors&amp;ust=1730413584073097&amp;usg=AOvVaw1P5NVpLTH2z7pWF03M1KCM">https://letterboxd.com/film/late-night-with-the-devil/</a></span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span>Recommended by Chainsaw Man/Look Back/Goodbye Eri author Tatsuki Fujimoto: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 464.00px;"><img alt="" src="images/image162.png" style="width: 624.00px; height: 464.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Other people like it too: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/&amp;sa=D&amp;source=editors&amp;ust=1730413584073474&amp;usg=AOvVaw2udX7Z7bLV6g3VNBCH1rMH">https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/</a></span></li><li class="c10 li-bullet-0"><span>3.4 out of 5 on Letterboxed despite anti AI review bombing </span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Krita implements generative AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://krita-artists.org/t/introducing-a-new-project-fast-line-art/94265&amp;sa=D&amp;source=editors&amp;ust=1730413584073799&amp;usg=AOvVaw0XiumWkzuuI6ys5Y1YnvmQ">https://krita-artists.org/t/introducing-a-new-project-fast-line-art/94265</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Genshin Impact developers talk about how they used AI in their hit game Honkai: Star Rail: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.as.com/meristation/news/genshin-impact-developers-talk-about-how-they-used-ai-in-their-hit-game-honkai-star-rail-n/&amp;sa=D&amp;source=editors&amp;ust=1730413584074094&amp;usg=AOvVaw2pTyf7aPOugC0VfPoPI_L2">https://en.as.com/meristation/news/genshin-impact-developers-talk-about-how-they-used-ai-in-their-hit-game-honkai-star-rail-n/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c1">The new miHoYo game already uses artificial intelligence techniques, but they have not used it to write narrative content, paying attention to &ldquo;its impact&rdquo;.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413584074461&amp;usg=AOvVaw10swnKtQOxMMn_NUzK65U3">AI image won Colorado state fair </a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413584074604&amp;usg=AOvVaw1UzI_kT1_GpmgSd_Xl0VQH">https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;Cal Duran, an artist and art teacher who was one of the judges for competition, said that while Allen&rsquo;s piece included a mention of Midjourney, he didn&rsquo;t realize that it was generated by AI when judging it. Still, he sticks by his decision to award it first place in its category, he said, calling it a &ldquo;beautiful piece&rdquo;.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;&ldquo;I think there&rsquo;s a lot involved in this piece and I think the AI technology may give more opportunities to people who may not find themselves artists in the conventional way,&rdquo; he said.</span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>iconic photographer </span><span>Annie Leibovitz sees AI as the beginning of new creative opportunities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.france24.com/en/live-news/20240320-photographer-annie-leibovitz-ai-doesn-t-worry-me-at-all&amp;sa=D&amp;source=editors&amp;ust=1730413584075196&amp;usg=AOvVaw1SeE_4jy44k0O741c9NOzn">https://www.france24.com/en/live-news/20240320-photographer-annie-leibovitz-ai-doesn-t-worry-me-at-all</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 565.33px;"><img alt="" src="images/image371.png" style="width: 624.00px; height: 565.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c97 c105 c194 li-bullet-0"><span class="c57 c37 c154 c65 c250">&ldquo;With each technological progress, there are hesitations and concerns. You just have to take the plunge and learn how to use it.&quot; </span></li><li class="c22 c194 c97 c105 li-bullet-0"><span class="c57 c37 c154 c65 c250">She says AI-generated images are no less authentic than photography.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">William Shatner defends AI: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/WilliamShatner/status/1782216252808745224&amp;sa=D&amp;source=editors&amp;ust=1730413584075745&amp;usg=AOvVaw1ZfWy9CknDvWoEmKkDjw7P">https://twitter.com/WilliamShatner/status/1782216252808745224</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Bjork partnered with Microsoft to use AI: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.engadget.com/2020-01-17-bjork-and-microsoft-ai-sky-music.html&amp;sa=D&amp;source=editors&amp;ust=1730413584076055&amp;usg=AOvVaw1wNRf62-YX8YW_O2kt_7sa">https://www.engadget.com/2020-01-17-bjork-and-microsoft-ai-sky-music.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">King Gizzard and the Lizard Wizard uses AI for a music video: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/videos/comments/xz5uc7/new_music_video_by_king_gizzard_and_the_lizard/&amp;sa=D&amp;source=editors&amp;ust=1730413584076344&amp;usg=AOvVaw3caEJ9xiy0izGUgjDvxG1_">https://www.reddit.com/r/videos/comments/xz5uc7/new_music_video_by_king_gizzard_and_the_lizard/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Brian Eno uses and endorses AI: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.latimes.com/entertainment-arts/movies/story/2024-01-18/brian-eno-gary-hustwit-ai-artificial-intelligence-sundance&amp;sa=D&amp;source=editors&amp;ust=1730413584076698&amp;usg=AOvVaw1oFy0Lg1einDAAFc_SxVAm">https://www.latimes.com/entertainment-arts/movies/story/2024-01-18/brian-eno-gary-hustwit-ai-artificial-intelligence-sunda</a></span><span class="c1 c14">nce</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.fastcompany.com/3061088/brian-eno-talks-about-using-artificial-intelligence-to-create-music-and-art&amp;sa=D&amp;source=editors&amp;ust=1730413584076995&amp;usg=AOvVaw0MzPhX2slOpCYn5JXmWxao">https://www.fastcompany.com/3061088/brian-eno-talks-about-using-artificial-intelligence-to-create-music-and-art</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span>Tony Levin (bass player of King Crimson and Peter Gabriel) posts AI animation: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.instagram.com/reel/C_BLXAwiG2b/?igsh%3DMTc4MmM1YmI2Ng%3D%3D&amp;sa=D&amp;source=editors&amp;ust=1730413584077323&amp;usg=AOvVaw0BSgraEHNIBeZ4T63YsTNC">https://www.instagram.com/reel/C_BLXAwiG2b/?igsh=MTc4MmM1YmI2Ng==</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">The Voidz release album with AI art cover: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.grimygoods.com/2024/07/09/julian-casablancas-responds-to-fans-disappointed-by-the-voidzs-ai-made-album-cover-art/&amp;sa=D&amp;source=editors&amp;ust=1730413584077732&amp;usg=AOvVaw1PQzQ0-PwJmSIH_B_oZGCp">https://www.grimygoods.com/2024/07/09/julian-casablancas-responds-to-fans-disappointed-by-the-voidzs-ai-made-album-cover-art/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c14">Many people complimenting it before realizing it&rsquo;s AI generated: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.albumoftheyear.org/album/1003824-the-voidz-like-all-before-you/comments/3/&amp;sa=D&amp;source=editors&amp;ust=1730413584078010&amp;usg=AOvVaw3NCRzJhm8qcyBBnaY4IagU">https://www.albumoftheyear.org/album/1003824-the-voidz-like-all-before-you/comments/3/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Grammy-winning producer Timbaland partnered with Suno to remix his new single &ldquo;Love Again&rdquo; </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://suno.com/playlist/2479ec84-fc53-4611-b014-0ffc90c030dd&amp;sa=D&amp;source=editors&amp;ust=1730413584078406&amp;usg=AOvVaw0wIAPXRXFhHpPh8H1F_xdw">https://suno.com/playlist/2479ec84-fc53-4611-b014-0ffc90c030dd</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1 c14">Long threads of Neil Cicieriega enjoying AI art and text generation:</span></li></ul><ul class="c0 lst-kix_prgyqriqvk4e-1 start"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/neilcic/status/1557150493532721156/&amp;sa=D&amp;source=editors&amp;ust=1730413584078700&amp;usg=AOvVaw1U_Un-cNOy2kzUx1yLxae_">https://x.com/neilcic/status/1557150493532721156/</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/neilcic/status/1533901457438785538&amp;sa=D&amp;source=editors&amp;ust=1730413584078881&amp;usg=AOvVaw0g-0R6bt_0iEcMZFqQG_sN">https://x.com/neilcic/status/1533901457438785538</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/neilcic/status/1564446232390541312&amp;sa=D&amp;source=editors&amp;ust=1730413584079053&amp;usg=AOvVaw18GujpaXvs_EEoLEBTeh6X">https://x.com/neilcic/status/1564446232390541312</a></span></li><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/neilcic/status/1618057273028534272&amp;sa=D&amp;source=editors&amp;ust=1730413584079240&amp;usg=AOvVaw32OatvVhufO8bejMtmbxJu">https://x.com/neilcic/status/1618057273028534272</a></span></li><li class="c10 li-bullet-0"><span class="c14">The last thread is AFTER he learned about the criticism artists made towards AI: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/neilcic/status/1599833251161309184&amp;sa=D&amp;source=editors&amp;ust=1730413584079442&amp;usg=AOvVaw0phmDwwXzfRwBpiQ9twiz3">https://x.com/neilcic/status/1599833251161309184</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://penji.co/ai-artists/&amp;sa=D&amp;source=editors&amp;ust=1730413584079659&amp;usg=AOvVaw3GUpzXRDHMUBuIUSxcV5iP">https://penji.co/ai-artists/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/dall-e-2-extending-creativity/&amp;sa=D&amp;source=editors&amp;ust=1730413584079886&amp;usg=AOvVaw0QWPor7acPjEh_XtXIjlzV">https://openai.com/index/dall-e-2-extending-creativity/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Lil Yatchy uses AI for an album cover (widely considered to be his best album): </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.vibe.com/music/music-news/lil-yachty-lets-start-here-album-cover-ai-1234728233/&amp;sa=D&amp;source=editors&amp;ust=1730413584080151&amp;usg=AOvVaw3URxuE5zB2gjxOEm_pCT4F">https://www.vibe.com/music/music-news/lil-yachty-lets-start-here-album-cover-ai-1234728233/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Nicki Minaj fans use AI: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.creativebloq.com/news/nicki-minaj-ai-trend&amp;sa=D&amp;source=editors&amp;ust=1730413584080373&amp;usg=AOvVaw1_kI7v5frV98hFPd-qVge9">https://www.creativebloq.com/news/nicki-minaj-ai-tren</a></span><span class="c1 c14">d</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Randy Travis uses AI to restore his voice: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/music/news/an-exclusive-look-inside-the-making-of-singer-randy-travis-new-ai-created-song/ar-AA1o6k98?ocid%3DBingNewsSerp%26darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584080653&amp;usg=AOvVaw08H9kWGSbzciAaiGPA5lP6">https://www.msn.com/en-us/music/news/an-exclusive-look-inside-the-making-of-singer-randy-travis-new-ai-created-song/ar-AA1o6k98?ocid=BingNewsSerp&amp;darkschemeovr=1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Drake uses AI: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.yahoo.com/entertainment/drake-baits-kendrick-lamar-weird-180317529.html?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584080895&amp;usg=AOvVaw24L7BkTP4Ver4VDPmaijsr">https://www.yahoo.com/entertainment/drake-baits-kendrick-lamar-weird-180317529.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt&amp;sa=D&amp;source=editors&amp;ust=1730413584081164&amp;usg=AOvVaw2LjdlcSje2R6RRYNt5blS1">https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c14">Metro Boomin samples </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.vulture.com/article/bbl-drizzy-metro-boomin-sample-comedian.html&amp;sa=D&amp;source=editors&amp;ust=1730413584081443&amp;usg=AOvVaw3cmbQroiNBoD2o_CJid8AS">AI-generated song</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Df6Hr69ca9ZM%26t%3D7s&amp;sa=D&amp;source=editors&amp;ust=1730413584081599&amp;usg=AOvVaw0ZmXkPpm3W2C8iwhn_2703">https://www.youtube.com/watch?v=f6Hr69ca9ZM&amp;t=7s</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c14">He did not even know it was AI generated: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy&amp;sa=D&amp;source=editors&amp;ust=1730413584081857&amp;usg=AOvVaw1o69BS2cd4gjx-8raRNUtJ">https://en.m.wikipedia.org/wiki/BBL_Drizzy</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-2"><li class="c7 li-bullet-0"><span class="c14">&nbsp;</span><span class="c29 c14">Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Elon_Musk&amp;sa=D&amp;source=editors&amp;ust=1730413584082111&amp;usg=AOvVaw0-uteyo3uJNN1duN72hSdO">Elon Musk</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Dr._Miami&amp;sa=D&amp;source=editors&amp;ust=1730413584082256&amp;usg=AOvVaw1MK1_y-VY11yC3AA1ecual">Dr. Miami</a></span><span class="c29 c14">&nbsp;reacted to the beat.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Complex_Cowen2024_DrMiamiLooping-19&amp;sa=D&amp;source=editors&amp;ust=1730413584082403&amp;usg=AOvVaw2Q2wQOTF7t_sPRwllg2uoa">[19]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Dexerto_Horetski2024_WhatDoesBBLDrizzyMean-20&amp;sa=D&amp;source=editors&amp;ust=1730413584082548&amp;usg=AOvVaw1KYMr-BM7cUOlBJK6_OGqs">[20]</a></span><span class="c29 c14">&nbsp;Several corporations also responded, including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Educational_technology&amp;sa=D&amp;source=editors&amp;ust=1730413584082696&amp;usg=AOvVaw0gQOrd251FG-6v4paiT0ef">educational technology</a></span><span class="c29 c14">&nbsp;company </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Duolingo&amp;sa=D&amp;source=editors&amp;ust=1730413584082827&amp;usg=AOvVaw2jZqCHy_pAHTgVt1uaGL0j">Duolingo</a></span><span class="c29 c14">&nbsp;and meat producer </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Oscar_Mayer&amp;sa=D&amp;source=editors&amp;ust=1730413584082993&amp;usg=AOvVaw0gCbPBwFLyKjXsR7XObsAL">Oscar Mayer</a></span><span class="c29 c14">.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-XXL_Ech2024_OscarMeyerBBLGlizzy-21&amp;sa=D&amp;source=editors&amp;ust=1730413584083161&amp;usg=AOvVaw2WZ6UonxMkTuZSGnb1msUi">[21]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Dexerto_Horetski2024_WhatDoesBBLDrizzyMean-20&amp;sa=D&amp;source=editors&amp;ust=1730413584083326&amp;usg=AOvVaw1_e0k0e0KlnN__wv5niLbO">[20]</a></span></li><li class="c109 c86 li-bullet-0"><span class="c29 c14">In addition to users releasing freestyle raps over the instrumental, the track also evolved into a </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Viral_phenomenon&amp;sa=D&amp;source=editors&amp;ust=1730413584083636&amp;usg=AOvVaw0xAQ8fyBhUfe_Bp_YUFK_o">viral phenomenon</a></span><span class="c29 c14">&nbsp;where users would create remixes of the song beyond the </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Hip_hop_music&amp;sa=D&amp;source=editors&amp;ust=1730413584083810&amp;usg=AOvVaw0hrUyZ9XSqYqxiTtyAEfip">hip hop</a></span><span class="c29 c14">&nbsp;genre.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-BET_Grove2024_BBLDrizzyRemixTreatment-22&amp;sa=D&amp;source=editors&amp;ust=1730413584083985&amp;usg=AOvVaw2NxJg3sG_zluKzhJ4raaNi">[22]</a></span><span class="c29 c14">&nbsp;Many recreated the song in other genres, including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/House_music&amp;sa=D&amp;source=editors&amp;ust=1730413584084135&amp;usg=AOvVaw09ptDgPuyh3V0hqoJxFS3t">house</a></span><span class="c29 c14">, </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Merengue_music&amp;sa=D&amp;source=editors&amp;ust=1730413584084271&amp;usg=AOvVaw0ndwfV_6q-nlemHZSHtpal">merengue</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Hindi_film_music&amp;sa=D&amp;source=editors&amp;ust=1730413584084405&amp;usg=AOvVaw2Z1UGfDaNCqlyWUcUeUM53">Bollywood</a></span><span class="c29 c14">.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Billboard_Saponara2024_FanRemixesGoingViral-23&amp;sa=D&amp;source=editors&amp;ust=1730413584084590&amp;usg=AOvVaw18mS0hUszRobk9KcsC9coU">[23]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Gizmodo_Zeff2024_SagaOfBBLDrizzy-18&amp;sa=D&amp;source=editors&amp;ust=1730413584084740&amp;usg=AOvVaw3Tu8QtpBGYd_sr-N1Aj560">[18]</a></span><span class="c29 c14">&nbsp;Users also created covers of the song on a variety of </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Musical_instruments&amp;sa=D&amp;source=editors&amp;ust=1730413584084897&amp;usg=AOvVaw3vAl88DKjlQjMYqt10iJBh">musical instruments</a></span><span class="c29 c14">, including on </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Saxophone&amp;sa=D&amp;source=editors&amp;ust=1730413584085032&amp;usg=AOvVaw17TreziV64-tUtt1HHJwo4">saxophone</a></span><span class="c29 c14">, </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Guitar&amp;sa=D&amp;source=editors&amp;ust=1730413584085159&amp;usg=AOvVaw0bFngr7EynH0csUQS0cDOj">guitar</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Harp&amp;sa=D&amp;source=editors&amp;ust=1730413584085282&amp;usg=AOvVaw1sSVEqEuGTxGb21uzNhLsT">harp</a></span><span class="c29 c14">.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c14">Covered by Tim Henson: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3DOly6ayyckZI%26t%3D6s&amp;sa=D&amp;source=editors&amp;ust=1730413584085546&amp;usg=AOvVaw0rr7uKcPmppfFTGTyP4e4w">https://youtube.com/watch?v=Oly6ayyckZI&amp;t=6s</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c1 c14">3.88/5 on Rate Your Music with 613 reviews, where the best albums of all time get around &#8536;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c14">Received an 86 on Album of the Year with 611 reviews, qualifying for an orange star denoting high quality</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-0"><li class="c4 li-bullet-0"><span class="c1 c14">&ldquo;Runway&#39;s tools and AI models have been utilized in films such as Everything Everywhere All At Once,[6] in music videos for artists including A$AP Rocky,[7] Kanye West,[8] Brockhampton, and The Dandy Warhols,[9] and in editing television shows like The Late Show[10] and Top Gear.[11]&rdquo; </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_prgyqriqvk4e-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Runway_(company)&amp;sa=D&amp;source=editors&amp;ust=1730413584086107&amp;usg=AOvVaw0XLetGhcSIdLYzc1ckXIm6">https://en.wikipedia.org/wiki/Runway_(company)</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_4knzszhhdok2-0 start"><li class="c4 li-bullet-0"><span class="c14">AI music video from Washed Out that received a Vimeo Staff Pick: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/openai-sora-first-commissioned-music-video/&amp;sa=D&amp;source=editors&amp;ust=1730413584086380&amp;usg=AOvVaw1qAbW8XvXJjikCbUrrFXlg">https://newatlas.com/technology/openai-sora-first-commissioned-music-video/</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_kfa6jji21f4h-0 start"><li class="c4 li-bullet-0"><span class="c14">Donald&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Glover endorses and uses AI video generation: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DdKAVFLB75xs&amp;sa=D&amp;source=editors&amp;ust=1730413584086697&amp;usg=AOvVaw1HOZAJVkYnBgSeZJ3HHG48">https://m.youtube.com/watch?v=dKAVFLB75xs</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_podkn7p9liyz-0 start"><li class="c4 li-bullet-0"><span class="c14">Will.i.am endorses AI: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.euronews.com/next/2023/07/15/exclusive-william-talks-ai-the-future-of-creativity-and-his-new-ai-app-to-co-pilot-creatio&amp;sa=D&amp;source=editors&amp;ust=1730413584087004&amp;usg=AOvVaw2SyNNzAufdBVVkzwihBnyw">https://www.euronews.com/next/2023/07/15/exclusive-william-talks-ai-the-future-of-creativity-and-his-new-ai-app-to-co-pilot-creatio</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_podkn7p9liyz-1 start"><li class="c10 li-bullet-0"><span class="c14">Interview: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dqy_ruqoVtJU&amp;sa=D&amp;source=editors&amp;ust=1730413584087248&amp;usg=AOvVaw2gMAItwIlM1cUqSc5IYoT5">https://www.youtube.com/watch?v=qy_ruqoVtJU</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_ehfx5m3tdqyv-0 start"><li class="c4 li-bullet-0"><span class="c14">Professional artist uses and supports AI, including AI training on their art, on a post where an anti-AI artist admits AI art can be very good: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/s/rbqjXcccCk&amp;sa=D&amp;source=editors&amp;ust=1730413584087510&amp;usg=AOvVaw1ATp3Dwb4DQiNBIPNAIlQo">https://www.reddit.com/r/aiwars/s/rbqjXcccCk</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_ehfx5m3tdqyv-1 start"><li class="c10 li-bullet-0"><span class="c14">Proof of their credentials: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1g396kr/comment/lrw2j4p/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584087794&amp;usg=AOvVaw2CHIyqx1Mru5VLHlObPdIO">https://www.reddit.com/r/aiwars/comments/1g396kr/comment/lrw2j4p/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0 start"><li class="c4 li-bullet-0"><span class="c14">AI used in Mad Max according to Anne Taylor Joy: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/s/1uSo0Lw34A&amp;sa=D&amp;source=editors&amp;ust=1730413584088111&amp;usg=AOvVaw1hbN--24vuTw2QURKNKi-z">https://www.reddit.com/r/singularity/s/1uSo0Lw34A</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-1 start"><li class="c10 li-bullet-0"><span class="c14">&#39;Furiosa&#39; Composer Tom Holkenborg Reveals How He Used AI in the Score to Create &#39;Deep Fake Voices&#39; </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/Variety/status/1796662916248166726&amp;sa=D&amp;source=editors&amp;ust=1730413584088408&amp;usg=AOvVaw0D3D9xfQsgZTgH_RqFVlz3">https://x.com/Variety/status/1796662916248166726</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span class="c14">George Lucas Thinks Artificial Intelligence in Filmmaking Is &#39;Inevitable&#39; - &quot;It&#39;s like saying, &#39;I don&#39;t believe these cars are gunna work. Let&#39;s just stick with the horses.&#39; &quot; </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.ign.com/articles/george-lucas-thinks-artificial-intelligence-in-filmmaking-is-inevitable&amp;sa=D&amp;source=editors&amp;ust=1730413584088712&amp;usg=AOvVaw3RyXFTypqFWfwltY3QXFpP">https://www.ign.com/articles/george-lucas-thinks-artificial-intelligence-in-filmmaking-is-inevitable</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span class="c14">Tim Cain (the creator of the Fallout game series) says AI voice-over solves a lot of VO problems and that new tools have always put some people out of work: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/DefendingAIArt/comments/1fv9fe3/tim_cain_the_creator_of_the_fallout_game_series/&amp;sa=D&amp;source=editors&amp;ust=1730413584088992&amp;usg=AOvVaw2rfiSqzO9solRoVnNtC1iU">https://www.reddit.com/r/DefendingAIArt/comments/1fv9fe3/tim_cain_the_creator_of_the_fallout_game_series/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span class="c14">Various devs outside the triple-A publishing space are positive about A.I: &nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.gameinformer.com/2024/05/27/brain-drain-ai-and-indies&amp;sa=D&amp;source=editors&amp;ust=1730413584089239&amp;usg=AOvVaw3PEMaGIHprIx8oDcBrnx5k">https://www.gameinformer.com/2024/05/27/brain-drain-ai-and-indies</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;&ldquo;If I had to pay humans, if I had to pay people to do 150-plus artworks, we would have never been able to do it,&rdquo; - Guillaume Mezino, Kipwak Studio (founder)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span class="c14">professional 2D animator and rigger (has worked on shows for Netflix and studios) and does rigging in Toon Boom Harmony and storyboarding supports and uses AI: &nbsp;</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/comments/1d4t9tt/the_amount_of_antiai_dissenters_are_at_an_alltime/&amp;sa=D&amp;source=editors&amp;ust=1730413584089640&amp;usg=AOvVaw2HaOQakurSGgSduoqVQCLk">https://www.reddit.com/r/StableDiffusion/comments/1d4t9tt/the_amount_of_antiai_dissenters_are_at_an_alltime/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span class="c14">The most influential illustrator on Japanese social media said, &quot;AI is just a tool&quot; and &quot;AI has no impact on the evaluation of artists.&quot; </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DT-VBEKZ2lb0&amp;sa=D&amp;source=editors&amp;ust=1730413584089918&amp;usg=AOvVaw2U1U-NtBbj33aGQZZyePtU">https://www.youtube.com/watch?v=T-VBEKZ2lb0</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span class="c14">Tribeca to screen AI generated films made with Sora: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.indiewire.com/news/festivals/tribeca-ai-generated-short-films-sora-shorts-1235010911/&amp;sa=D&amp;source=editors&amp;ust=1730413584090169&amp;usg=AOvVaw2UQtNZAPoccl6OzNdj3Z9U">https://www.indiewire.com/news/festivals/tribeca-ai-generated-short-films-sora-shorts-1235010911/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span>Ashton Kutcher has access to a beta version of OpenAI&#39;s Sora and says it will lead to personalized movies and a higher standard of content through increased competition: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1d8qufg/ashton_kutcher_has_access_to_a_beta_version_of/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584090518&amp;usg=AOvVaw0tSiYdxOpEhr2gglQGrb1S">https://www.reddit.com/r/singularity/comments/1d8qufg/ashton_kutcher_has_access_to_a_beta_version_of/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span>Grimes performs live on stage with Stable Diffusion AI Video: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aivideo/comments/1c4xg4j/coachella_2024_grimes_performs_live_on_stage_with/?share_id%3DS5egCMOslEhYoLJ7em_FX%26utm_content%3D1%26utm_medium%3Dios_app%26utm_name%3Dioscss%26utm_source%3Dshare%26utm_term%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584091147&amp;usg=AOvVaw2_hp06FXGxoknlOrJCThxp">https://www.reddit.com/r/aivideo/comments/1c4xg4j/coachella_2024_grimes_performs_live_on_stage_with/?share_id=S5egCMOslEhYoLJ7em_FX&amp;utm_content=1&amp;utm_medium=ios_app&amp;utm_name=ioscss&amp;utm_source=share&amp;utm_term=1</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span>48 Hour Film Project partners with Udio AI music generator: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://discord.com/channels/1211680535286648843/1281260908110282754/1294009018670518438&amp;sa=D&amp;source=editors&amp;ust=1730413584091657&amp;usg=AOvVaw35lX9trTPR2PMauUJCoHIk">https://discord.com/channels/1211680535286648843/1281260908110282754/1294009018670518438</a></span></li></ul><ul class="c0 lst-kix_53eqpuuodt5v-1 start"><li class="c10 li-bullet-0"><span class="c1">Active since 2001</span></li><li class="c8 li-bullet-0"><span class="c23 c54">Events in more than 200 cities and 45 countries over the years</span></li><li class="c10 li-bullet-0"><span class="c23 c92 c14 c54">The 48 Hour Film Project has seen some big names in our films, including such actors as Martin Freeman, J.K Simmons, J.Lee and Dennis Farina. Our judging panels have featured: Sean Gunn, Dave Costabile, Maggie Lawson, Simon West, Bruce Beresford, Jane Seymour and Shekhar Kapur to name but a few.</span></li><li class="c10 li-bullet-0"><span class="c23 c92 c14 c54">Partnered with Cannes Film Festival since 2004</span></li><li class="c8 li-bullet-0"><span class="c23 c92 c14 c54">Each year:</span></li></ul><ul class="c0 lst-kix_53eqpuuodt5v-2 start"><li class="c7 c116 li-bullet-0"><span class="c23 c92 c14 c54">More than 100 cities</span></li><li class="c116 c7 li-bullet-0"><span class="c23 c92 c14 c54">More than 4000 film teams</span></li><li class="c116 c7 li-bullet-0"><span class="c23 c92 c14 c54">More than 50,000 filmmakers</span></li><li class="c116 c7 li-bullet-0"><span class="c23 c92 c14 c54">70,000+ films have been made for the 48HFP</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span>Snoop Dogg&#39;s latest music video is AI-generated and took months to create: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://community.designtaxi.com/topic/5461-snoop-doggs-latest-music-video-is-ai-generated-and-took-months-to-create/&amp;sa=D&amp;source=editors&amp;ust=1730413584093057&amp;usg=AOvVaw3eoNdX4jSdH4UgnPzlcAq8">https://community.designtaxi.com/topic/5461-snoop-doggs-latest-music-video-is-ai-generated-and-took-months-to-create/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 506.50px; height: 870.95px;"><img alt="" src="images/image316.png" style="width: 506.50px; height: 870.95px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>New Dungeons &amp; Dragons Sourcebook Features AI Generated Art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://gizmodo.com/dnd-ai-art-bigbys-giants-book-artist-generators-wotc-1850710496&amp;sa=D&amp;source=editors&amp;ust=1730413584093649&amp;usg=AOvVaw1DJeTpIPsUO7kWhsPPqdei">https://gizmodo.com/dnd-ai-art-bigbys-giants-book-artist-generators-wotc-1850710496</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-1"><li class="c10 li-bullet-0"><span class="c1">An artist for Bigby Presents: Glory of the Giants! has admitted to using AI to generate &quot;certain details&quot; of new art for the sourcebook.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 457.33px;"><img alt="" src="images/image349.png" style="width: 624.00px; height: 457.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span>Artist in favor of using AI and compares it to backlash against 3D art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tumblr.com/yuumei-art/756332395536515072/ive-been-told-that-there-are-rumors-about-me&amp;sa=D&amp;source=editors&amp;ust=1730413584094267&amp;usg=AOvVaw3syaMPffrEVFYyo-d7nxVS">https://www.tumblr.com/yuumei-art/756332395536515072/ive-been-told-that-there-are-rumors-about-me</a></span></li><li class="c4 li-bullet-0"><span>Painter inspired by AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/DefendingAIArt/comments/1fv7kpy/comment/lq5r0pc/?utm_source%3Dshare%26utm_medium%3Dweb3x%26utm_name%3Dweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584094682&amp;usg=AOvVaw1ARxj1fllnTOAYqfzMhscM">https://www.reddit.com/r/DefendingAIArt/comments/1fv7kpy/comment/lq5r0pc/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><ul class="c0 lst-kix_53eqpuuodt5v-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 426.00px;"><img alt="" src="images/image655.png" style="width: 320.00px; height: 426.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_53eqpuuodt5v-0"><li class="c4 li-bullet-0"><span>&nbsp;Guy commissioned and properly credited artists in the past, multiple times got backstabbed by artists who copy-striked his videos, threatening to take his channel down: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DknUkXwJXcpY&amp;sa=D&amp;source=editors&amp;ust=1730413584095195&amp;usg=AOvVaw1Yjusl3KlNeEeh9w3DzpFG">https://www.youtube.com/watch?v=knUkXwJXcpY</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><h2 class="c73 c140" id="h.dnvsnw3xhtzn"><span class="c14">11.</span><span class="c14">6. Anti-AI </span><span class="c40 c37 c48 c14 c75">Hypocrisy/False Accusations of AI Usage</span></h2><ul class="c0 lst-kix_w9ot5xs5iuad-0 start"><li class="c4 li-bullet-0"><span class="c14">Williams won another Oscar for Star Wars and took inspiration from a 1942 movie called Kings Row, composed by Erich Wolfgang Korngold. Can you hear Star Wars? </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/ATRightMovies/status/1794345480207684058&amp;sa=D&amp;source=editors&amp;ust=1730413584095921&amp;usg=AOvVaw0ZmXEL54CtqLi7FmPjDGJE">https://x.com/ATRightMovies/status/1794345480207684058</a></span></li><li class="c4 li-bullet-0"><span class="c14">Patricia Taxxon explains how all creative work is derivative: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?si%3DAKh8kph9_ipSJ9Ha%26v%3Djcvd5JZkUXY%26feature%3Dyoutu.be&amp;sa=D&amp;source=editors&amp;ust=1730413584096257&amp;usg=AOvVaw3mZuLjs22Fhp7UA_8uibIY">https://m.youtube.com/watch?si=AKh8kph9_ipSJ9Ha&amp;v=jcvd5JZkUXY&amp;feature=youtu.be</a></span><span class="c1 c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c14">Anti AI hackers using ransomware to attack AI users and demanding cryptocurrency payments: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1de19q2/antis_are_now_desperate_theyre_embedding_viruses/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584096716&amp;usg=AOvVaw3Oeud_mkodA-yYcuNSbQDu">https://www.reddit.com/r/aiwars/comments/1de19q2/antis_are_now_desperate_theyre_embedding_viruses/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span><span class="c14">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c1 c14">If AI art is theft of IP, so is fan art of copyrighted characters</span></li><li class="c4 li-bullet-0"><span class="c14">Artist banned from r/art after being falsely accused of using AI: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.creativebloq.com/news/ai-art-accusation&amp;sa=D&amp;source=editors&amp;ust=1730413584097176&amp;usg=AOvVaw1ointQF6EVGjP_bXxLOema">https://www.creativebloq.com/news/ai-art-accusation</a></span></li></ul><p class="c12"><span class="c1"></span></p><p class="c12"><span class="c1"></span></p><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c143 c78 li-bullet-0"><span>Anti-AI artist admits AI can make good art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/s/yy7e0aFyC0&amp;sa=D&amp;source=editors&amp;ust=1730413584097610&amp;usg=AOvVaw2aPn_3Oqe_NFRE0dr6W2R0">https://www.reddit.com/r/aiwars/s/yy7e0aFyC0</a></span></li><li class="c143 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 604.00px; height: 680.00px;"><img alt="" src="images/image113.png" style="width: 604.00px; height: 680.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c143 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 446.00px; height: 822.00px;"><img alt="" src="images/image558.png" style="width: 446.00px; height: 822.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c143 c78 li-bullet-0"><span class="c1">One of the main arguments against AI art is that it decreases the number of jobs available. Another argument is that corporations will use it to commodify art to make money. These are clearly contradictory. If commodifying art is bad, why are artists so concerned about not being able to sell (aka commodify) their work? </span></li><li class="c143 c78 li-bullet-0"><span class="c1">Humans also hallucinate </span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-1 start"><li class="c85 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/The_dress&amp;sa=D&amp;source=editors&amp;ust=1730413584098245&amp;usg=AOvVaw2ygSCc0rHL8k0tc2Ga31uz">Blue and black dress vs white and gold dress </a></span></li><li class="c85 li-bullet-0"><span>Laurel vs yanny: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D7X_WvGAhMlQ&amp;sa=D&amp;source=editors&amp;ust=1730413584098544&amp;usg=AOvVaw2be6o-CbvoasxKT2UrmTyo">https://www.youtube.com/watch?v=7X_WvGAhMlQ</a></span><span class="c1">&nbsp;</span></li><li class="c85 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://time.com/5873627/green-needle-brainstorm-explained/&amp;sa=D&amp;source=editors&amp;ust=1730413584098829&amp;usg=AOvVaw1w2prTV1UazZFyE60W4NCT">Brainstorm vs green needle</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://time.com/5873627/green-needle-brainstorm-explained/&amp;sa=D&amp;source=editors&amp;ust=1730413584099042&amp;usg=AOvVaw0tNjZCSf7hcUi17AvD2D_A">https://time.com/5873627/green-needle-brainstorm-explained/</a></span><span class="c1">&nbsp;</span></li><li class="c85 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ChatGPT/s/FvnIBVmLrd&amp;sa=D&amp;source=editors&amp;ust=1730413584099306&amp;usg=AOvVaw28adY3rJgMHDcXNtWV1tWy">https://www.reddit.com/r/ChatGPT/s/FvnIBVmLrd</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c143 c78 li-bullet-0"><span class="c1">Artists use references from images found online all the time without compensation, asking for permission, or even crediting the original. </span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-1 start"><li class="c85 li-bullet-0"><span class="c1">They even do this to their sources of inspiration.</span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-2 start"><li class="c143 c86 li-bullet-0"><span class="c1">For example, the TV show Breaking Bad was inspired by the movie The Godfather according to the director of the former, but the company that owns Breaking Bad never received permission or gave compensation for it. This applies to virtually every piece of art ever made.</span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c143 c78 li-bullet-0"><span class="c1">Artists are fine with web scraping for web and image search but not for AI training </span></li><li class="c143 c78 li-bullet-0"><span class="c1">Artists still complain about &ldquo;ethically-trained&rdquo; models like Adobe&rsquo;s Firefly, which was only trained on images owned by Adobe</span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-1 start"><li class="c85 li-bullet-0"><span class="c1">Adobe&rsquo;s contract contains a clause that the images they pay for can be used for any technology, even ones that did not exist when the contract was signed </span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c143 c78 li-bullet-0"><span class="c1">Artists mocked NFT owners for complaining about &ldquo;right-clickers&rdquo; downloading their images but now complain about AI companies doing the same thing on a larger scale</span></li><li class="c143 c78 li-bullet-0"><span>AI art is significantly less pollutive compared to human-made art: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41598-024-54271-x&amp;sa=D&amp;source=editors&amp;ust=1730413584100248&amp;usg=AOvVaw1IIn080_6S-KfkZ9tNi-9b">https://www.nature.com/articles/s41598-024-54271-x</a></span></li><li class="c143 c78 li-bullet-0"><span class="c1">No complaints about &ldquo;theft&rdquo; when DALL-E Mini/CrAIyon was popular in mid-2022 despite being trained via web scraping</span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-1 start"><li class="c85 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 394.67px;"><img alt="" src="images/image443.png" style="width: 624.00px; height: 394.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c143 c78 li-bullet-0"><span>Anti-AI artist admits to enjoying AI art and believing it was human-made: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/meganroseruiz/status/1796606237838278875&amp;sa=D&amp;source=editors&amp;ust=1730413584100768&amp;usg=AOvVaw06iW3-zfFxNS7tiYzuLYB2">https://x.com/meganroseruiz/status/1796606237838278875</a></span><span class="c1">&nbsp;</span></li><li class="c143 c78 li-bullet-0"><span>Anti-AI artist tricked into thinking an actual art progress video is AI and points out &ldquo;signs of inconsistency&rdquo; that don&#39;t exist: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/i_shkipin/status/1797180394410020890&amp;sa=D&amp;source=editors&amp;ust=1730413584101087&amp;usg=AOvVaw0pmcgOPH7Bx62HrFdkzTHp">https://x.com/i_shkipin/status/1797180394410020890</a></span><span class="c1">&nbsp;</span></li><li class="c143 c78 li-bullet-0"><span>People accusing IRL video of being AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/toriel1one1/status/1799142881204249076&amp;sa=D&amp;source=editors&amp;ust=1730413584101395&amp;usg=AOvVaw3rW5q73wMna-M9Raqxpz0n">https://x.com/toriel1one1/status/1799142881204249076</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span>Harassment of AI user: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/DefendingAIArt/comments/1dxrgbn/i_spent_like_600_hours_over_2_months_creating/&amp;sa=D&amp;source=editors&amp;ust=1730413584101762&amp;usg=AOvVaw18FE4z9bk2FYua2QwX7wlL">https://www.reddit.com/r/DefendingAIArt/comments/1dxrgbn/i_spent_like_600_hours_over_2_months_creating/</a></span></li><li class="c4 li-bullet-0"><span class="c1">Glaze/Nightshade takes 15 minutes of computation for one image. How is that environmentally friendly? </span></li><li class="c143 c78 li-bullet-0"><span>Metal Band Axes AI-Generated Album Cover Following Fan Outcry: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/lesliekatz/2024/03/04/metal-band-pestilence-dumps-ai-generated-album-cover-following-fan-outcry/&amp;sa=D&amp;source=editors&amp;ust=1730413584102234&amp;usg=AOvVaw1e11WSJki3yFtQm_n1v3LO">https://www.forbes.com/sites/lesliekatz/2024/03/04/metal-band-pestilence-dumps-ai-generated-album-cover-following-fan-outcry/</a></span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-1 start"><li class="c85 li-bullet-0"><span class="c1">Yet antis accuse AI users of harassment</span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c143 c78 li-bullet-0"><span>Sam Yang, AI art critic, selling art of a shot-for-shot frame of Squid Game: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.inprnt.com/gallery/samdoesarts/the-alleyway/&amp;sa=D&amp;source=editors&amp;ust=1730413584102651&amp;usg=AOvVaw2_tIPqwCgHJYQARxdRcFOr">https://www.inprnt.com/gallery/samdoesarts/the-alleyway/</a></span></li><li class="c143 c78 li-bullet-0"><span>Artist who started Brazilian Hatsune Miku meme stole the design but is still universally praised with over 400k likes: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/thecat_mitsu/status/1826873385369956524&amp;sa=D&amp;source=editors&amp;ust=1730413584102970&amp;usg=AOvVaw2wuNb2CA7ZqLSezDXzs_fh">https://x.com/thecat_mitsu/status/1826873385369956524</a></span></li></ul><p class="c12"><span class="c1"></span></p><ul class="c0 lst-kix_w9ot5xs5iuad-1"><li class="c85 li-bullet-0"><span class="c1">Many other artists used the design without asking for permission from the original artist but aren&rsquo;t criticized for it at all</span></li></ul><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c143 c78 li-bullet-0"><span>r/196 post with many highly upvoted comments advocating against copyright: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/196/comments/1f95nag/the_worst_news_ive_heard_all_rule/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584103532&amp;usg=AOvVaw1r9ctbbM3rhkUsjLrpEaOs">https://www.reddit.com/r/196/comments/1f95nag/the_worst_news_ive_heard_all_rule/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li><li class="c143 c78 li-bullet-0"><span>Violent rhetoric against AI artists: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/AIHaters/comments/1fjz32z/the_ai_hate_movement_has_entirely_normalized/&amp;sa=D&amp;source=editors&amp;ust=1730413584103892&amp;usg=AOvVaw08WkC0FgC6cAUq7nW1xiLb">https://www.reddit.com/r/AIHaters/comments/1fjz32z/the_ai_hate_movement_has_entirely_normalized/</a></span></li><li class="c143 c78 li-bullet-0"><span>Popular Twitter artist accused of theft for having a similar art style: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/kaijufem/status/1758062988651643263&amp;sa=D&amp;source=editors&amp;ust=1730413584104195&amp;usg=AOvVaw1kfwQqcDilqESBPSOFzqC-">https://x.com/kaijufem/status/1758062988651643263</a></span></li></ul><p class="c9"><span class="c1"></span></p><h3 class="c119" id="h.qqmup6weomew"><span>11.</span><span class="c92 c37 c168 c48 c125">6.1. Criticism of Copyright Enforcement</span></h3><ul class="c0 lst-kix_w9ot5xs5iuad-0"><li class="c78 c143 li-bullet-0"><span>Overwhelming disapproval of Kit9 enforcing copyright claims against a fan artist: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/CoffinofAndyandLeyley/comments/1ded5wv/kit9_studios_copyright_claims_against_artists/&amp;sa=D&amp;source=editors&amp;ust=1730413584104798&amp;usg=AOvVaw08vkWaP8tki1OvCpON4tCZ">https://www.reddit.com/r/CoffinofAndyandLeyley/comments/1ded5wv/kit9_studios_copyright_claims_against_artists/</a></span><span class="c1">&nbsp;</span></li><li class="c143 c78 li-bullet-0"><span>Popular tweet criticizing Warner Bros for protecting their IP: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/GiveMeBanHammer/status/1795036807668666460&amp;sa=D&amp;source=editors&amp;ust=1730413584105106&amp;usg=AOvVaw39Hgh7lxukpuuszZoF9wxg">https://x.com/GiveMeBanHammer/status/1795036807668666460</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c14">Artists criticizing Nintendo for protecting their IP from unauthorized derivative works: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/nintendo-copyright-zelda-mod/&amp;sa=D&amp;source=editors&amp;ust=1730413584105416&amp;usg=AOvVaw2ucL9PgklrREyBDbZR84pY">https://www.wired.com/story/nintendo-copyright-zelda-mod/</a></span></li><li class="c4 li-bullet-0"><span>38k likes on a tweet criticizing Nintendo for defending their IP: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/Tubzbuster/status/1789757912857874499&amp;sa=D&amp;source=editors&amp;ust=1730413584105740&amp;usg=AOvVaw0DJXtRLuwOgjONyCG-v5Tc">https://twitter.com/Tubzbuster/status/1789757912857874499</a></span></li><li class="c4 li-bullet-0"><span>Artist who coined &ldquo;Inktober&rdquo; suing others for using it, angering artists: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/KikiDoodleTweet/status/1207805327476805643&amp;sa=D&amp;source=editors&amp;ust=1730413584106063&amp;usg=AOvVaw1T6oyA6DyT2skk_2Ow74Qw">https://x.com/KikiDoodleTweet/status/1207805327476805643</a></span></li></ul><p class="c9"><span class="c1"></span></p><h3 class="c119" id="h.f8gilt9cwobn"><span>11.</span><span class="c92 c37 c168 c48 c125">6.2. Theft Supported By Artists</span></h3><ul class="c0 lst-kix_izm55n8luwgn-0 start"><li class="c4 li-bullet-0"><span class="c14">Using the art styles of other artists was a meme that artists did for fun: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.deviantart.com/oldsouldreamin/art/Drawing-style-meme-561060713&amp;sa=D&amp;source=editors&amp;ust=1730413584106623&amp;usg=AOvVaw36sYaYN-DXA2rvupYl4XrQ">https://www.deviantart.com/oldsouldreamin/art/Drawing-style-meme-561060713</a></span></li></ul><ul class="c0 lst-kix_izm55n8luwgn-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 526.53px; height: 526.53px;"><img alt="" src="images/image353.jpg" style="width: 526.53px; height: 526.53px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_izm55n8luwgn-0"><li class="c143 c78 li-bullet-0"><span>Popular Anti-AI Twitter Artist Caught Using AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/StableDiffusion/s/vAvB5FmNE0&amp;sa=D&amp;source=editors&amp;ust=1730413584107089&amp;usg=AOvVaw3j6S36uoOEr6exsdTynkTm">https://www.reddit.com/r/StableDiffusion/s/vAvB5FmNE0</a></span></li><li class="c4 li-bullet-0"><span>Tweet with over 81k likes advocating for piracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/hacer_kun/status/1832144472215314939&amp;sa=D&amp;source=editors&amp;ust=1730413584107402&amp;usg=AOvVaw3Mbs73el-7ftMwbKDYdAJv">https://x.com/hacer_kun/status/1832144472215314939</a></span></li><li class="c143 c78 li-bullet-0"><span>Tweet with over 86k likes advocating for piracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/cvphead/status/1799603994802966773&amp;sa=D&amp;source=editors&amp;ust=1730413584107709&amp;usg=AOvVaw1rEdANgW5KE-iyt3FF4oBy">https://x.com/cvphead/status/1799603994802966773</a></span><span class="c1">&nbsp;</span></li><li class="c143 c78 li-bullet-0"><span>Tweet with 60k+ likes supporting piracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/WeirdBongs/status/1791280716245815380&amp;sa=D&amp;source=editors&amp;ust=1730413584108017&amp;usg=AOvVaw0_aWmDmNbdubPZX7Ko5CWF">https://x.com/WeirdBongs/status/1791280716245815380</a></span></li><li class="c4 li-bullet-0"><span class="c14">33k likes on tweet supporting piracy: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/ShitpostRock/status/1787727060426706994&amp;sa=D&amp;source=editors&amp;ust=1730413584108312&amp;usg=AOvVaw1RkwWUG_9bTMETzD8w2Fdl">https://twitter.com/ShitpostRock/status/1787727060426706994</a></span></li><li class="c143 c78 li-bullet-0"><span>Anti-AI artist commits piracy and IP theft from Nintendo: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Nyazsche/status/1801977619543429343&amp;sa=D&amp;source=editors&amp;ust=1730413584108608&amp;usg=AOvVaw1WPVdllqagOQpcmElzSk84">https://x.com/Nyazsche/status/1801977619543429343</a></span><span class="c1">&nbsp;</span></li><li class="c143 c78 li-bullet-0"><span>Tweet with almost 150k likes advocating for piracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/remembrancermx/status/1832461616690143245&amp;sa=D&amp;source=editors&amp;ust=1730413584108910&amp;usg=AOvVaw3QIuF9svYQBP2Hy406o-Qx">https://x.com/remembrancermx/status/1832461616690143245</a></span></li><li class="c143 c78 li-bullet-0"><span>Tweet with almost 140k likes advocating for piracy: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/chloetankahhui/status/1832320603761561678&amp;sa=D&amp;source=editors&amp;ust=1730413584109201&amp;usg=AOvVaw23TMchLv-Ffx6lWU5NKKtV">https://x.com/chloetankahhui/status/1832320603761561678</a></span></li><li class="c143 c78 li-bullet-0"><span>13k likes on tweet from an artist posting copyrighted work online: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/LokiRoki/status/1844550043124015404&amp;sa=D&amp;source=editors&amp;ust=1730413584109519&amp;usg=AOvVaw0hVy_lPIYZlwrv-IY9zlIm">https://x.com/LokiRoki/status/1844550043124015404</a></span></li></ul><p class="c12"><span class="c1"></span></p><h3 class="c140 c211" id="h.v0pcds3cw0b7"><span class="c92 c37 c168 c48 c125">11.6.3. False Accusations of Artists Using AI</span></h3><ul class="c0 lst-kix_h8mmrek0o9p9-0 start"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/MauLer/comments/1fnwo4z/marvel_why_does_the_sentryvoid_have_six_fingers/&amp;sa=D&amp;source=editors&amp;ust=1730413584110091&amp;usg=AOvVaw1XJBbjg2ztdfrMWHbxnRy_">https://www.reddit.com/r/MauLer/comments/1fnwo4z/marvel_why_does_the_sentryvoid_have_six_fingers/</a></span></li></ul><ul class="c0 lst-kix_h8mmrek0o9p9-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.00px; height: 249.00px;"><img alt="" src="images/image390.png" style="width: 320.00px; height: 249.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c4 li-bullet-0"><span>YouTuber falsely accused D&amp;D artist of using AI based on &quot;something feeling off&quot;: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.enworld.org/threads/wotc-updates-d-ds-ai-policy-after-youtubers-false-accusations.701714/&amp;sa=D&amp;source=editors&amp;ust=1730413584110643&amp;usg=AOvVaw1O88E5nDYRRWHobFjGpTVH">https://www.enworld.org/threads/wotc-updates-d-ds-ai-policy-after-youtubers-false-accusations.701714/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c143 c78 li-bullet-0"><span>Artist defends themself from false AI art accusations: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://nichegamer.com/artist-defends-himself-from-false-ai-art-accusations/&amp;sa=D&amp;source=editors&amp;ust=1730413584110935&amp;usg=AOvVaw2SL9dr4IHZA9CILtpDDK4m">https://nichegamer.com/artist-defends-himself-from-false-ai-art-accusations/</a></span></li></ul><p class="c12"><span class="c92 c153 c148 c34 c48"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c143 c78 li-bullet-0"><span>Famous artist Will Jack falsely accused of using AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/SuperMutantSam1/status/1790560785766216156&amp;sa=D&amp;source=editors&amp;ust=1730413584111314&amp;usg=AOvVaw0V21Z3Agd-0QrkdDERI8M8">https://twitter.com/SuperMutantSam1/status/1790560785766216156</a></span></li></ul><p class="c12"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c143 c78 li-bullet-0"><span>Another false accusation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/selfpublish/comments/1b6ohh3/need_help_with_a_legal_threat_over_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413584111725&amp;usg=AOvVaw3qHx_hUx21drs_KcId84YR">https://www.reddit.com/r/selfpublish/comments/1b6ohh3/need_help_with_a_legal_threat_over_ai/</a></span></li></ul><p class="c12"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c143 c78 li-bullet-0"><span>Yet another false accusation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/ArtistLounge/comments/15igkkn/why_do_i_get_accused_of_ai_even_with_evidence_its/&amp;sa=D&amp;source=editors&amp;ust=1730413584112140&amp;usg=AOvVaw1XjdaBJnGUZ4tYprfMmCMx">https://www.reddit.com/r/ArtistLounge/comments/15igkkn/why_do_i_get_accused_of_ai_even_with_evidence_its/</a></span></li></ul><p class="c12"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-1"><li class="c85 li-bullet-0"><span class="c1">Someone in the comments accuses OP of being a bot even though their comment history contradicts that </span></li></ul><p class="c12"><span class="c1"></span></p><p class="c12"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c4 li-bullet-0"><span>Artist falsely accused of using AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tumblr.com/yuumei-art/756332395536515072/ive-been-told-that-there-are-rumors-about-me&amp;sa=D&amp;source=editors&amp;ust=1730413584112781&amp;usg=AOvVaw2_1MIJO_jhUzmb3VHWxRsE">https://www.tumblr.com/yuumei-art/756332395536515072/ive-been-told-that-there-are-rumors-about-me</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c4 li-bullet-0"><span>Another one: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dq5N4W25c-ko&amp;sa=D&amp;source=editors&amp;ust=1730413584113121&amp;usg=AOvVaw1nZXpmFJaAsu3cqxCWfY_9">https://www.youtube.com/watch?v=q5N4W25c-ko</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c4 li-bullet-0"><span>Fashion brand falsely accused Artist of using AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1frktn2/fashion_brand_falsely_accused_artist_of_using_ai/&amp;sa=D&amp;source=editors&amp;ust=1730413584113546&amp;usg=AOvVaw057z526y3HOAgVDB67rJse">https://www.reddit.com/r/aiwars/comments/1frktn2/fashion_brand_falsely_accused_artist_of_using_ai/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_h8mmrek0o9p9-0"><li class="c4 li-bullet-0"><span>Twitter creature artist harasses another creature artist over AI accusations: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/DefendingAIArt/comments/1fvwphr/twitter_creature_artist_harasses_another_creature/&amp;sa=D&amp;source=editors&amp;ust=1730413584113984&amp;usg=AOvVaw3fig6r13j3kLfQaYFffI7i">https://www.reddit.com/r/DefendingAIArt/comments/1fvwphr/twitter_creature_artist_harasses_another_creature/</a></span></li></ul><h2 class="c140 c240" id="h.5l4snk8prfop"><span>11.</span><span class="c40 c37 c48 c75">7. Historical Complaints About Technology </span></h2><ul class="c0 lst-kix_9ynuh6dd4pus-0 start"><li class="c51 li-bullet-0"><span class="c37 c65 c60">All these: </span><span class="c5 c37 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://imgur.com/a/x8Ss0cQ&amp;sa=D&amp;source=editors&amp;ust=1730413584114455&amp;usg=AOvVaw0l3ez6EKaFRpUnPW3FgbaX">https://imgur.com/a/x8Ss0cQ</a></span></li><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">&ldquo;As long as &quot;invention and feeling constitute essential qualities in a work of Art,&quot; the writer argued, &quot;Photography can never assume a higher rank than engraving.&quot; Photography couldn&#39;t qualify as an art in its own right, the explanation went, because it lacked &quot;something beyond mere mechanism at the bottom of it.&quot; &mdash; 1855 issue of The Crayon</span></li><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">&quot;It is obvious that this industry, by invading the territories of art, has become art&rsquo;s most mor&shy;tal enemy... If it is allowed to supplement art in some of its functions, it will soon have supplanted or corrupted it altogether.&quot; - Charles Baudelaire, father of modern art criticism, on the topic of cameras and photography (1859)</span></li><li class="c4 li-bullet-0"><span class="c1">French art critic Charles Baudelaire hated photography and thought it would be the death of art, saying &quot;the photographic industry was the refuge of every would-be painter, every painter too ill-endowed or too lazy to complete his studies&quot;</span></li><li class="c4 li-bullet-0"><span>Charles Dodgson, AKA Lewis Carroll, threw a fit because </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Gelatin_silver_process&amp;sa=D&amp;source=editors&amp;ust=1730413584115189&amp;usg=AOvVaw21PqfV_nOA1XPA6-I6iRj2">dry plate</a></span><span>&nbsp;photography was invented, and he was upset now anybody could do it (he used the </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Collodion_process&amp;sa=D&amp;source=editors&amp;ust=1730413584115402&amp;usg=AOvVaw2otvatz0Iqewf23pSRv-jp">wet collodion process</a></span><span class="c1">&nbsp;which is complicated and messy) and abandoned photography.</span></li><li class="c4 li-bullet-0"><span>&nbsp;</span><span class="c40 c37 c65 c60">Th abolishment of pain in surgery is a chimera. It is absurd to go on seeking it... Knife and pain are two words in surgery that must forever be associated in the consciousness of the patient. - Dr. Alfred Velpeau (1839), French surgeon</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">There is a young madman proposing to light the streets of London&mdash;with what do you suppose&mdash;with smoke!</span></p><ul class="c0 lst-kix_vwxe3fdqgja8-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Sir Walter Scott (1771-1832) [On a proposal to light cities with gaslight.]</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">They will never try to steal the phonograph because it has no `commercial value.&#39;</span></p><ul class="c0 lst-kix_g4octshi0erf-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Thomas Edison (1847-1931). (He later revised that opinion.)</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">This `telephone&#39; has too many shortcomings to be seriously considered as a practical form of communication. The device is inherently of no value to us.</span></p><ul class="c0 lst-kix_9sxg1s3wlz7-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Western Union internal memo, 1878</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">Radio has no future.</span></p><ul class="c0 lst-kix_gzy546en7hix-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Lord Kelvin (1824-1907), British mathematician and physicist, ca. 1897.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">While theoretically and technically television may be feasible, commercially and financially I consider it an impossibility, a development of which we need waste little time dreaming.</span></p><ul class="c0 lst-kix_6jta2mj2opdj-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Lee DeForest, 1926 (American radio pioneer and inventor of the vacuum tube.)</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">[Television] won&#39;t be able to hold on to any market it captures after the first six months. People will soon get tired of staring at a plywood box every night.</span></p><ul class="c0 lst-kix_efwsvsniz58g-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Darryl F. Zanuck, head of 20th Century-Fox, 1946.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">That the automobile has practically reached the limit of its development is suggested by the fact that during the past year no improvements of a radical nature have been introduced.</span></p><ul class="c0 lst-kix_3g1k0ldodoso-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Scientific American, Jan. 2, 1909.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">There is no likelihood man can ever tap the power of the atom. The glib supposition of utilizing atomic energy when our coal has run out is a completely unscientific Utopian dream, a childish bug-a-boo. Nature has introduced a few fool-proof devices into the great majority of elements that constitute the bulk of the world, and they have no energy to give up in the process of disintegration.</span></p><ul class="c0 lst-kix_t75jqyambp7u-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Robert A. Millikan (1863-1953) [1928 speech to the Chemists&#39; Club (New York)]</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">...any one who expects a source of power from the transformation of these atoms is talking moonshine...</span></p><ul class="c0 lst-kix_87g5rwruaqks-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Ernest Rutherford (1871-1937) [1933]</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">There is not the slightest indication that [nuclear energy] will ever be obtainable. It would mean that the atom would have to be shattered at will.</span></p><ul class="c0 lst-kix_ey106e39uxys-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Albert Einstein, 1932.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">Heavier-than-air flying machines are impossible.</span></p><ul class="c0 lst-kix_oofi1dgq0nej-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c60 c65">Lord Kelvin (1824-1907), ca. 1895, British mathematician and physicist</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">...no possible combination of known substances, known forms of machinery, and known forms of force, can be united in a practical machine by which man shall fly long distances through the air...</span></p><ul class="c0 lst-kix_mniaj44rhjrq-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Simon Newcomb (1835-1909), astronomer, head of the U. S. Naval Observatory.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">I confess that in 1901 I said to my brother Orville that man would not fly for fifty years. Two years later we ourselves made flights. This demonstration of my impotence as a prophet gave me such a shock that ever since I have distrusted myself and avoided all predictions.</span></p><ul class="c0 lst-kix_gmr2bu8eavte-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Wilbur Wright (1867-1912) [In a speech to the Aero Club of France (Nov 5, 1908)]</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">Airplanes are interesting toys but of no military value.</span></p><ul class="c0 lst-kix_xgrv9tn3a2rg-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Marshal Ferdinand Foch, French military strategist, 1911. He was later a World War I commander.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">There is not in sight any source of energy that would be a fair start toward that which would be necessary to get us beyond the gravitative control of the earth.</span></p><ul class="c0 lst-kix_k4lchlqktts-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Forest Ray Moulton (1872-1952), astronomer, 1935.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">To place a man in a multi-stage rocket and project him into the controlling gravitational field of the moon where the passengers can make scientific observations, perhaps land alive, and then return to earth&mdash;all that constitutes a wild dream worthy of Jules Verne. I am bold enough to say that such a man-made voyage will never occur regardless of all future advances.</span></p><ul class="c0 lst-kix_yvkwax5bonzj-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Lee deForest (1873-1961) (American radio pioneer and inventor of the vacuum tube.) Feb 25, 1957.</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">Space travel is utter bilge.</span></p><ul class="c0 lst-kix_24obzjkgjhqt-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Dr. Richard van der Reit Wooley, Astronomer Royal, space advisor to the British government, 1956. (Sputnik orbited the earth the following year.)</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">If the world should blow itself up, the last audible voice would be that of an expert saying it can&#39;t be done.</span></p><ul class="c0 lst-kix_qzdp8v5qa4kd-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Peter Ustinov</span></li></ul><p class="c71"><span class="c40 c37 c65 c60">It is difficult to say what is impossible, for the dream of yesterday is the hope of today and the reality of tomorrow.</span></p><ul class="c0 lst-kix_gxvla3x57ko6-0 start"><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Robert Goddard (1882-1945)</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_vbr74uzbiasm-0 start"><li class="c4 li-bullet-0"><span class="c1">John Philip Sousa feared recorded music and thought it would lead to fewer musicians: &ldquo;Right here is the menace in machine-made music! The first rift in the lute has appeared. The cheaper of these instruments of the home are no longer being purchased as formerly, and all because the automaticmusicdevices are usurping their places. And what is a result? The child becomes indifferent to practice, for when music can be heard in the homes without the labor of study and close application, and without the slow process of acquiring a technic, it will be simply a question of time when the amateur disappears entirely, and with him a host of vocal and instrumental teachers, who will be without field or calling.&rdquo;</span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://explorepahistory.com/odocument.php?docId%3D1-4-1A1&amp;sa=D&amp;source=editors&amp;ust=1730413584119205&amp;usg=AOvVaw2KnyJ1AlspCiexP0bh40l7">https://explorepahistory.com/odocument.php?docId=1-4-1A1</a></span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-0"><li class="c4 li-bullet-0"><span class="c92 c37 c63 c137 c103">Wilbur Wright is quoted as saying, &quot;I confess that in 1901, I said to my brother Orville that man would not fly for 50 years.&quot; Two years later, &lsquo;man&rsquo; was not only flying, but it was these very men who achieved the feat</span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image207.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c37 c63 c137 c103">Newsweek in 1995: Why the Internet Will Fail: </span><span class="c5 c37 c63 c103"><a class="c13" href="https://www.google.com/url?q=https://thehustle.co/clifford-stoll-why-the-internet-will-fail&amp;sa=D&amp;source=editors&amp;ust=1730413584119996&amp;usg=AOvVaw1AcCN_aX7WuWge4lzCnqyt">https://thehustle.co/clifford-stoll-why-the-internet-will-fail</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 874.67px;"><img alt="" src="images/image241.png" style="width: 624.00px; height: 874.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-1 start"><li class="c10 li-bullet-0"><span class="c1">Dec 1909, the Engineering Magazine</span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 500.61px; height: 235.58px;"><img alt="" src="images/image188.jpg" style="width: 500.61px; height: 235.58px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c1">An article in 1890 talking about how the car will not replace the horse: The banker took him to a window. &ldquo;Look,&rdquo; he said pointing to the street. &ldquo;You see all those people on their bicycles riding along the boulevard? There is not as many as there was a year ago. The novelty is wearing off; they are losing interest. That&rsquo;s just the way it will be with automobiles. People will get the fever; and later they will throw them away. My advice is not to buy the stock. You might make money for a year or two, but in the end you would lose everything you put in. The horse is here to stay, but the automobile is only a novelty &mdash; a fad.&rdquo;</span></li><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Coal miners, milkmen, and manual telephone switch operators were all automated away, yet society had yet to collapse </span></li><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Most people used to be farmers, and now very few people are. </span></li><li class="c51 li-bullet-0"><span class="c40 c37 c65 c60">Luddites opposed technology but ultimately failed, which was a good thing as we would still be working in steel mills and textile factories today if they had won. </span></li><li class="c51 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 447.61px; height: 767.41px;"><img alt="" src="images/image198.png" style="width: 447.61px; height: 767.41px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-1 start"><li class="c10 li-bullet-0"><span>19th century mocking of the initial problems with photography: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.org/details/punch28a29lemouoft&amp;sa=D&amp;source=editors&amp;ust=1730413584121039&amp;usg=AOvVaw2uys0wuy2IiAXYrMUDJ7Z6">https://archive.org/details/punch28a29lemouoft</a></span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 570.67px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 570.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span class="c1">Lithograph company tried to argue that photographs were a wholly deterministic physical reaction and thus involved no artistic input, in regards to a famous photograph of Oscar Wilde</span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 373.33px;"><img alt="" src="images/image598.png" style="width: 624.00px; height: 373.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-1 start"><li class="c10 li-bullet-0"><span class="c1">&ldquo;I confess that, in 1901, I said to my brother Orville that men would not fly for 50 years. Two years later, we were making flights. This demonstration of my inability as a prophet gave me such a shock that I have ever since refrained from all prediction.&rdquo; -Wilbur Wright</span></li></ul><ul class="c0 lst-kix_vbr74uzbiasm-0"><li class="c4 li-bullet-0"><span class="c1">1977: &ldquo;There is no reason for any individual to have a computer in his home.&rdquo; &mdash; Ken Olsen, founder of Digital Equipment Corp.</span></li><li class="c4 c46 li-bullet-0"><span class="c1"></span></li><li class="c4 li-bullet-0"><span class="c1">1981: &ldquo;Cellular phones will not replace local wire systems.&rdquo; &mdash; Marty Cooper, inventor.</span></li><li class="c4 c46 li-bullet-0"><span class="c1"></span></li><li class="c4 li-bullet-0"><span class="c1">1992: &ldquo;The idea of a personal communicator in every pocket is a &ldquo;pipe dream driven by greed.&rdquo; &mdash; Andy Grove, then CEO of Intel.</span></li><li class="c4 c46 li-bullet-0"><span class="c1"></span></li><li class="c4 li-bullet-0"><span class="c1">1995: &ldquo;I predict the Internet will soon go spectacularly supernova and in 1996 catastrophically collapse.&rdquo; &mdash; Robert Metcalfe, founder of 3Com, inventor of Ethernet.</span></li></ul><p class="c9"><span class="c1"></span></p><h1 class="c123" id="h.m4v0adugapim"><span class="c40 c37 c48 c77">12. Debunks</span></h1><h2 class="c64" id="h.wsxrgwpm5bn4"><span>12.</span><span>1 Articles/Videos/Studies</span></h2><h3 class="c119" id="h.xqs8n4euelpc"><span>12.1.1. </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3613904.3642596&amp;sa=D&amp;source=editors&amp;ust=1730413584122219&amp;usg=AOvVaw0bAOxwfdgDH6Gt-qG93ZB4">Study that ChatGPT fails 52% of coding tasks </a></span></h3><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c14">&ldquo;this work has used the </span><span class="c34 c14">free version of ChatGPT (GPT-3.5)</span><span class="c1 c14">&nbsp;for acquiring the ChatGPT responses for the manual analysis.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c14">&ldquo;Thus, we chose to </span><span class="c34 c14">only consider the initial answer </span><span class="c1 c14">generated by ChatGPT.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected SO questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.&rdquo;</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-2 start"><li class="c7 li-bullet-0"><span class="c14">This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to</span><span class="c15">&nbsp;~77% for GPT 4</span><span class="c1">&nbsp;(equal to (517*0.48+517*6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-3 start"><li class="c21 c26 li-bullet-0"><span>Note: This was all done in</span><span class="c33 c15">&nbsp;ONE SHOT with no repeat attempts.</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c14">Study was released </span><span class="c15">before GPT-4o </span><span>and </span><span class="c34">may not have used GPT 4 Turbo</span><span>, both of which are significantly higher quality than GPT 4 according to the </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://chat.lmsys.org/?leaderboard&amp;sa=D&amp;source=editors&amp;ust=1730413584123083&amp;usg=AOvVaw3O_byLTg1JA7o7sNSfBzAU">LMSYS arena.</a></span></li></ul><h3 class="c119" id="h.9zsu58wpo9cq"><span class="c92 c37 c168 c48 c125">12.1.2 Google&rsquo;s Search AI Summaries </span></h3><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c1">The problem has nothing to do with training data. There&#39;s two primary problems.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&#8288;Googles results aren&#39;t generated by the AI, the AI just paraphrases search results. Literally, it just reads the search results and &quot;summarizes&quot; them for you</span></li><li class="c10 li-bullet-0"><span class="c1">2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&#8288;Because it&#39;s just a summary, the model they use is stupid as fuck. It&#39;s not supposed to think critically, it&#39;s just supposed to turn a few web pages into a paragraph.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">With actual AI generated results, stupid one-off satire articles like this don&#39;t matter, because they&#39;re &quot;intellectual outliers&quot;. They&#39;re both rare, and directly contradicted by a ton of other data. In addition to this, assistants like ChatGPT are actually trained to &quot;think&quot; about the response they&#39;re giving, and not just instructed to summarize web results.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">If you just asked the same model without the search results, I can almost guarantee it wouldn&#39;t say anything about actually eating rocks or putting glue on pizza. When you combine the fact that it&#39;s just being asked to summarize search results with the fact that it&#39;s not trained to actually think critically about what it&#39;s summarizing, is when you get problems like this.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">Also, much of it circulating social media is edited and fake, which was confirmed by Google itself.</span></li><li class="c10 li-bullet-0"><span>Google&rsquo;s response: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blog.google/products/search/ai-overviews-update-may-2024/&amp;sa=D&amp;source=editors&amp;ust=1730413584124280&amp;usg=AOvVaw1YQkZSQ9sfz43QiiFFDBeb">https://blog.google/products/search/ai-overviews-update-may-2024/</a></span><span class="c1">&nbsp;</span></li></ul><h3 class="c119" id="h.hau739o271jd"><span>12.1.3 </span><span>Debunk of </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DdDUC-LqVrPU&amp;sa=D&amp;source=editors&amp;ust=1730413584124571&amp;usg=AOvVaw1EFSiChlh0CuR59cr1lRf-">&ldquo;Has Generative AI Already Peaked?&rdquo; by Computerphile</a></span><span class="c92 c37 c168 c48 c125">&nbsp;(or the paper &ldquo;No &quot;Zero-Shot&quot; Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance&rdquo;)</span></h3><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c1 c14">The claim of the video/paper is that AI will plateau in a logarithmic curve as there is not enough training data for very specific information, like different tree species. This won&rsquo;t prevent AGI as most humans do not know very specific information like that either and can only learn if given enough training. This can also be done for AI by fine-tuning on that data, such as training it on a dataset of trees labeled with their species. Even rudimentary neural networks have been capable of this for well over a decade, like identifying different classes of images in the CIFAR-10 dataset using convolutional neural networks.</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-2 start"><li class="c7 li-bullet-0"><span class="c14">Example - We finetuned Llama-3-8B on math problems and pushed accuracy from 47% to 65%, getting over 90% of GPT-4&#39;s performance at a fraction of the cost: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/togethercompute/status/1811816439848042608&amp;sa=D&amp;source=editors&amp;ust=1730413584124992&amp;usg=AOvVaw2iqUX2913b3fNpQF__LqH5">https://x.com/togethercompute/status/1811816439848042608</a></span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c15">Synthetic data can also provide nigh infinite training data (see section 15)</span></li><li class="c10 li-bullet-0"><span class="c14">Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba&rsquo;s selective SSM that is </span><span class="c15">2-8&times; faster</span><span class="c14">, while continuing to be competitive with Transformers on language modeling: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2405.21060&amp;sa=D&amp;source=editors&amp;ust=1730413584125320&amp;usg=AOvVaw3DQs8ZvkjFNn0og4w6FaLU">https://arxiv.org/pdf/2405.21060</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-2 start"><li class="c7 li-bullet-0"><span class="c14">Loss:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 609.13px; height: 412.92px;"><img alt="" src="images/image462.png" style="width: 609.13px; height: 412.92px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/ctnzr/status/1801050835197026696&amp;sa=D&amp;source=editors&amp;ust=1730413584125611&amp;usg=AOvVaw2ydRjv1JnxsDnGTG-vhAR8">https://x.com/ctnzr/status/1801050835197026696</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-3 start"><li class="c21 c26 li-bullet-0"><span class="c1">A 8B-3.5T hybrid SSM model gets better accuracy than an 8B-3.5T transformer trained on the same dataset:</span></li><li class="c21 c26 li-bullet-0"><span class="c1">* 7% attention, the rest is Mamba2</span></li><li class="c21 c26 li-bullet-0"><span class="c1">* MMLU jumps from 50 to 53.6%</span></li><li class="c21 c26 li-bullet-0"><span class="c1">* Training efficiency is the same</span></li><li class="c21 c26 li-bullet-0"><span>* Inference cost is much less</span></li><li class="c21 c26 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 285.06px; height: 187.29px;"><img alt="" src="images/image359.png" style="width: 285.06px; height: 187.29px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1 c14"></span></p><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span class="c14">Google DeepMind&#39;s JEST method </span><span class="c15">can reduce AI training time by a factor of 13 and decreases computing power demand by 90%</span><span class="c14">. The method uses another pretrained reference model to select data subsets for training based on their &quot;collective learnability:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.17711v1&amp;sa=D&amp;source=editors&amp;ust=1730413584126586&amp;usg=AOvVaw3B3H2XhpoQ4XBxcZ4LkyMr">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.17711v1&amp;sa=D&amp;source=editors&amp;ust=1730413584126737&amp;usg=AOvVaw3swnzFU9MZJw9EoKtWOdc-">https://arxiv.org/html/2406.17711v1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><h3 class="c119" id="h.aurae6944p7m"><span class="c92 c37 c168 c48 c125">12.1.4 &ldquo;Vision language models are blind&rdquo; Study</span></h3><ul class="c0 lst-kix_4wi60e30t59b-0 start"><li class="c4 li-bullet-0"><span class="c1">The VLMs tokenize images just like they tokenize text. As a result, it is difficult for them to see small details like red circles surrounding letters in a word (which is one of the tasks in the study) just like how it is difficult for them to count letters in a word.</span></li><li class="c4 li-bullet-0"><span>LLMs can create images using code based on abstract requests even if they were never trained on any: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://news.mit.edu/2024/understanding-visual-knowledge-language-models-0617&amp;sa=D&amp;source=editors&amp;ust=1730413584127204&amp;usg=AOvVaw09-EaEckSPK1biiaLXN0PA">https://news.mit.edu/2024/understanding-visual-knowledge-language-models-0617</a></span></li></ul><ul class="c0 lst-kix_4wi60e30t59b-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image567.png" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><h3 class="c119" id="h.af7zmqjrvp6g"><span>12.</span><span class="c92 c37 c168 c48 c125">1.5. Real Photograph &ldquo;Won&rdquo; AI Art Competition</span></h3><ul class="c0 lst-kix_pfbe3x4ba630-0 start"><li class="c4 li-bullet-0"><span class="c14">The photograph only got third place: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2024/06/14/style/flamingo-photograph-ai-1839-awards/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413584127750&amp;usg=AOvVaw2Qvi1v0Q9xa0HJjdY6Nm0L">https://www.cnn.com/2024/06/14/style/flamingo-photograph-ai-1839-awards/index.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><h3 class="c119" id="h.qu2tayz30pez"><span>12.</span><span class="c92 c37 c168 c48 c125">1.6. ChatGPT Plagiarized NYT Articles</span></h3><ul class="c0 lst-kix_qvmzdr2urb9j-0 start"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/cybersecurity/openai-says-new-york-times-hacked-chatgpt-build-copyright-lawsuit-2024-02-27/&amp;sa=D&amp;source=editors&amp;ust=1730413584128288&amp;usg=AOvVaw01A3XbQBIc8f7L_IhFMQ4L">https://www.reuters.com/technology/cybersecurity/openai-says-new-york-times-hacked-chatgpt-build-copyright-lawsuit-2024-02-27/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qvmzdr2urb9j-1 start"><li class="c188 c97 c105 li-bullet-0"><span class="c92 c37 c185 c35 c48">OpenAI said in its filing that it took the Times &quot;tens of thousands of attempts to generate the highly anomalous results.&quot;</span></li><li class="c188 c97 c105 li-bullet-0"><span class="c92 c37 c185 c35 c48">&quot;In the ordinary course, one cannot use ChatGPT to serve up Times articles at will,&quot; OpenAI said.</span></li><li class="c188 c97 c105 li-bullet-0"><span class="c92 c37 c185 c35 c48">OpenAI&#39;s filing also said that it and other AI companies would eventually win their cases based on the fair-use question.</span></li><li class="c188 c97 c105 li-bullet-0"><span class="c92 c37 c35 c48 c185">&quot;The Times cannot prevent AI models from acquiring knowledge about facts, any more than another news organization can prevent the Times itself from re-reporting stories it had no role in investigating,&quot; OpenAI said</span></li></ul><h3 class="c140 c129 c245" id="h.h3cexxo6khqi"><span>12.</span><span class="c92 c37 c168 c48 c125">1.7. Government Study Finds AI worse than humans in every way at summarizing information</span></h3><ul class="c0 lst-kix_tx52nn14y93q-0 start"><li class="c188 c97 c105 li-bullet-0"><span class="c1">Used LLAMA 2 70b</span></li><li class="c10 li-bullet-0"><span class="c1">The report mentions some limitations and context to this study: the model used has already been superseded by one with further capabilities which may improve its ability to summarise information, and that Amazon increased the model&rsquo;s performance by refining its prompts and inputs, suggesting that there are further improvements that are possible. It includes optimism that this task may one day be competently undertaken by machines.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><h3 class="c119" id="h.f22rv2ndrl0i"><span class="c92 c37 c48 c125 c168">12.1.8. &ldquo;Generative AI&#39;s Illusory Case for Fair Use&rdquo; Study</span></h3><p class="c21"><span>Original Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4924997&amp;sa=D&amp;source=editors&amp;ust=1730413584129621&amp;usg=AOvVaw2csDAbSe4min8uuzZ0ZnAX">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4924997</a></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-0 start"><li class="c4 li-bullet-0"><span class="c1">False caims in the abstract alone:</span></li></ul><ul class="c0 lst-kix_ktcl1r9scb7w-1 start"><li class="c10 li-bullet-0"><span class="c1">&gt;&ldquo; [LLMs] do not &quot;know&quot; anything independently of the works on which they are trained, so their output is a function of the copied materials.&rdquo;</span></li></ul><ul class="c0 lst-kix_ktcl1r9scb7w-2 start"><li class="c7 li-bullet-0"><span>See [section 2](</span><span class="c5"><a class="c13" href="#h.fxgwobrx4yfq">https://docs.google.com/document/d/15myK_6eTxEPuKnDi5krjBM_0jrv3GELs8TGmqOYBvug/edit#heading=h.fxgwobrx4yfq</a></span><span class="c1">) for many studies debunking this</span></li></ul><ul class="c0 lst-kix_ktcl1r9scb7w-1"><li class="c10 li-bullet-0"><span>&gt;&ldquo;</span><span class="c87 c37 c35 c48 c14">The training works thus do not disappear, as claimed, but are encoded, token by token, into the model and relied upon to generate output.&rdquo;</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-2"><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Completely impossible. There are small language models that are only a few gigabytes in size, such as Microsoft&rsquo;s Phi models. For comparison, Wikipedia alone is nearly 20 GB without media.</span></li><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Additionally, it is very difficult to reproduce training data. NYT attempted to do it and it took tens of thousands of tries to produce a small snippet of an article:</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-3 start"><li class="c21 c26 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/cybersecurity/openai-says-new-york-times-hacked-chatgpt-build-copyright-lawsuit-2024-02-27/&amp;sa=D&amp;source=editors&amp;ust=1730413584130581&amp;usg=AOvVaw30daoKPDKMhpor_nFqXCi7">https://www.reuters.com/technology/cybersecurity/openai-says-new-york-times-hacked-chatgpt-build-copyright-lawsuit-2024-02-27/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-4 start"><li class="c135 c97 li-bullet-0"><span class="c92 c37 c185 c35 c48">OpenAI said in its filing that it took the Times &quot;tens of thousands of attempts to generate the highly anomalous results.&quot;</span></li><li class="c135 c97 li-bullet-0"><span class="c92 c37 c185 c35 c48">&quot;In the ordinary course, one cannot use ChatGPT to serve up Times articles at will,&quot; OpenAI said.</span></li><li class="c97 c135 li-bullet-0"><span class="c92 c37 c185 c35 c48">OpenAI&#39;s filing also said that it and other AI companies would eventually win their cases based on the fair-use question.</span></li><li class="c135 c97 li-bullet-0"><span class="c185 c35">&quot;The Times cannot prevent AI models from acquiring knowledge about facts, any more than another news organization can prevent the Times itself from re-reporting stories it had no role in investigating,&quot; OpenAI said</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-1"><li class="c10 li-bullet-0"><span class="c87 c37 c35 c48 c14">&gt;Like an LLM, an AI image generator relies on encoded representations of training works to generate its output.</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-2"><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">Stable Diffusion 1.5 models are only 2 GB in size despite being trained on nearly 6 billion images from the LAION dataset. That&rsquo;s about one byte for every three images. An image is typically 4.4 kilobytes.</span></li><li class="c7 li-bullet-0"><span class="c35 c208 c14">If AI images can only generate its encoded representations, it would not have the flexibility to generate novel images as proven in [section 12.1](</span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://docs.google.com/document/d/15myK_6eTxEPuKnDi5krjBM_0jrv3GELs8TGmqOYBvug/edit%23heading%3Dh.8kscl4xz7vhq&amp;sa=D&amp;source=editors&amp;ust=1730413584131616&amp;usg=AOvVaw3YbXs37diJoa8f3wi5iFuP">https://docs.google.com/document/d/15myK_6eTxEPuKnDi5krjBM_0jrv3GELs8TGmqOYBvug/edit#heading=h.8kscl4xz7vhq</a></span><span class="c87 c37 c35 c48 c14">)</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-1"><li class="c10 li-bullet-0"><span class="c87 c37 c35 c48 c14">&gt;the determination of fair use turned on the fact that the alleged infringer was not seeking to capitalize on expressive content-exactly the opposite of generative AI. </span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-2"><li class="c7 li-bullet-0"><span class="c87 c37 c35 c48 c14">There are many open-weight models released for free, such as Meta&rsquo;s LLAMA, Google&rsquo;s Gemma, and Microsoft&rsquo;s Phi series.</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-1"><li class="c10 li-bullet-0"><span class="c37 c35 c48 c14 c87">&gt;Generative AI&#39;s claim to fair use is further hampered by the propensity of models to generate copies and derivatives of training works, which are presumptively infringing</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-2"><li class="c7 li-bullet-0"><span class="c35 c208 c14">Courts have already ruled that AI outputs are not considered derivative works. See here: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/&amp;sa=D&amp;source=editors&amp;ust=1730413584132413&amp;usg=AOvVaw1rGSC5S8dbhqAWJue-vywc">https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/</a></span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-3"><li class="c21 c26 li-bullet-0"><span class="c52 c37 c14">&gt;Another claim that has been </span><span class="c52 c15">consistently dismissed by courts is that AI models are infringing derivative works of the training materials.</span><span class="c52 c37 c14">&nbsp;The law defines a derivative work as &ldquo;a work based upon one or more preexisting works, such as a translation, musical arrangement, &hellip; art reproduction, abridgment, condensation, or any other form in which a work may be recast, transformed, or adapted.&rdquo; To most of us, the idea that the model itself (as opposed to, say, outputs generated by the model) can be considered a derivative work seems to be a stretch. The courts have so far agreed. On November 20, 2023, </span><span class="c52 c15">the court in </span><span class="c52 c15 c61">Kadrey v. Meta Platforms </span><span class="c79 c15 c60 c118">said it is &ldquo;nonsensical&rdquo; to consider an AI model a derivative work of a book just because the book is used for training. </span></li><li class="c22 c128 c26 li-bullet-0"><span class="c52 c37 c14">Similarly, </span><span class="c52 c15">claims that all AI outputs should be automatically considered infringing derivative works have been dismissed by courts,</span><span class="c52 c37 c14">&nbsp;because the </span><span class="c52 c15">claims cannot point to specific evidence that an instance of output is substantially similar to an ingested work.</span><span class="c52 c37 c14">&nbsp;</span><span class="c133 c34 c60 c118 c14"><a class="c13" href="https://www.google.com/url?q=https://storage.courtlistener.com/recap/gov.uscourts.cand.407208/gov.uscourts.cand.407208.117.0_3.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584133121&amp;usg=AOvVaw3db_2iA6fGVin4CvYVcXSn">In </a></span><span class="c133 c34 c61 c60 c118 c14"><a class="c13" href="https://www.google.com/url?q=https://storage.courtlistener.com/recap/gov.uscourts.cand.407208/gov.uscourts.cand.407208.117.0_3.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584133282&amp;usg=AOvVaw3LVsRifQFdHynIY72VEaZy">Andersen v. Stability AI,</a></span><span class="c52 c37 c14">&nbsp;plaintiffs tried to argue &ldquo;that all elements of &hellip; Anderson&rsquo;s copyrighted works &hellip; were copied wholesale as Training Images and therefore the Output Images are necessarily derivative;&rdquo; </span><span class="c52 c34 c14">the court dismissed the argument </span><span class="c52 c37 c14">because&mdash;besides the fact that </span><span class="c52 c15">plaintiffs are unlikely able to show substantial similarity</span><span class="c52 c37 c14">&mdash;&ldquo;it is simply not plausible that every Training Image used to train Stable Diffusion was copyrighted &hellip; or that all &hellip; Output Images rely upon (theoretically) copyrighted Training Images and therefore all Output images are derivative images. &hellip; [The argument for dismissing these claims is strong] especially in light of </span><span class="c52 c15">plaintiffs&rsquo; admission that Output Images are unlikely to look like the Training Images</span><span class="c79 c37 c60 c118 c14">.&rdquo;</span></li></ul><p class="c22 c128 c97 c46"><span class="c79 c37 c60 c118 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-1"><li class="c10 li-bullet-0"><span class="c87 c37 c35 c48 c14">&gt;In addition, some AI models rely on retrieval-augmented generation, or RAG, which searches out and copies materials from online sources without permission to respond to user prompts (for example, a query concerning an event that postdates the training of the underlying model). Here again, the materials are being copied and exploited to make use of expressive content. </span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_ktcl1r9scb7w-2"><li class="c7 li-bullet-0"><span class="c35 c208 c14">Search engines already did this long before AI with no issues, such as Google&rsquo;s featured snippets and &ldquo;People Also Ask&rdquo; sections that quote text from a website directly with no alterations: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://support.google.com/websearch/answer/9351707?hl%3Den%26visit_id%3D638612725182118407-343145636%26p%3Dfeatured_snippets%26rd%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584134093&amp;usg=AOvVaw3eZFVH2DpUOsUX-o34jsaV">https://support.google.com/websearch/answer/9351707?hl=en&amp;visit_id=638612725182118407-343145636&amp;p=featured_snippets&amp;rd=1</a></span></li></ul><ul class="c0 lst-kix_ktcl1r9scb7w-3 start"><li class="c21 c26 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 519.50px; height: 187.32px;"><img alt="" src="images/image33.png" style="width: 519.50px; height: 187.32px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c21 c26 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 522.79px; height: 436.50px;"><img alt="" src="images/image466.png" style="width: 522.79px; height: 436.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_ktcl1r9scb7w-4 start"><li class="c21 c97 c165 li-bullet-0"><span class="c87 c37 c35 c48 c14">(Ignore the Japanese text; it&rsquo;s from a browser extension)</span></li></ul><ul class="c0 lst-kix_ktcl1r9scb7w-0"><li class="c4 li-bullet-0"><span class="c87 c37 c35 c48 c14">That was ALL just from the abstract</span></li></ul><p class="c9"><span class="c87 c37 c35 c48 c14"></span></p><h3 class="c119" id="h.lwvdjq7mtjgq"><span class="c92 c37 c168 c48 c125">12.1.9. Sequoia Capital said AI is overhyped</span></h3><p class="c21"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.sequoiacap.com/article/ais-600b-question/&amp;sa=D&amp;source=editors&amp;ust=1730413584134899&amp;usg=AOvVaw3Z0L5g8UAOyQ-Agq6dzIlI">https://www.sequoiacap.com/article/ais-600b-question/</a></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_bpsai7a4nzlw-1"><li class="c10 li-bullet-0"><span>&hellip;and then they invested in Ilya Sutskever&rsquo;s AI startup after their investment to OpenAI was rejected because they had too much money already: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.ph/gzpmv&amp;sa=D&amp;source=editors&amp;ust=1730413584135236&amp;usg=AOvVaw2VJ5fzxBgP21zUpAbbVO9w">https://archive.ph/gzpmv</a></span></li><li class="c10 li-bullet-0"><span>Sequoia Capital analysis of reasoning in AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.sequoiacap.com/article/generative-ais-act-o1/&amp;sa=D&amp;source=editors&amp;ust=1730413584135521&amp;usg=AOvVaw0n_5sGatr9A4WxDxYyNOIf">https://www.sequoiacap.com/article/generative-ais-act-o1/</a></span></li></ul><h3 class="c119" id="h.1d74ui2j1of8"><span class="c92 c37 c168 c48 c125">12.1.10. Apple Research Paper: LLM&rsquo;s cannot reason and rely on complex pattern matching </span></h3><ul class="c0 lst-kix_qymwuf8ggtk1-0 start"><li class="c4 li-bullet-0"><span class="c1">States that LLMs cannot reason because they are often led astray by irrelevant information in the prompt or more difficult problems</span></li><li class="c4 li-bullet-0"><span>Solved by a simple prompt, getting a perfect 10/10: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://andrewmayne.com/2024/10/18/can-you-dramatically-improve-results-on-the-latest-large-language-model-reasoning-benchmark-with-a-simple-prompt/&amp;sa=D&amp;source=editors&amp;ust=1730413584136018&amp;usg=AOvVaw1Xmg83gom7iRCIVmuVadjU">https://andrewmayne.com/2024/10/18/can-you-dramatically-improve-results-on-the-latest-large-language-model-reasoning-benchmark-with-a-simple-prompt/</a></span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qymwuf8ggtk1-0"><li class="c4 li-bullet-0"><span>Humans often fall for the same trap: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/List_of_cognitive_biases&amp;sa=D&amp;source=editors&amp;ust=1730413584136293&amp;usg=AOvVaw2hOUR6pQmeci2wUipoQK0y">https://en.m.wikipedia.org/wiki/List_of_cognitive_biases</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qymwuf8ggtk1-1 start"><li class="c10 li-bullet-0"><span class="c1">Example: trick questions like &quot;spell silk&quot; and then you spell &quot;S-I-L-K&quot; and then they ask &quot;what do cows drink&quot; and of course the answer is milk. except it&#39;s not milk, cows drink water.</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qymwuf8ggtk1-1"><li class="c10 li-bullet-0"><span>Americans deciding whether or not they support price controls: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/USA_Polling/status/1832880761285804434&amp;sa=D&amp;source=editors&amp;ust=1730413584136696&amp;usg=AOvVaw2h4XxX-BBray2qWwUH2fk6">https://x.com/USA_Polling/status/1832880761285804434</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qymwuf8ggtk1-2 start"><li class="c7 li-bullet-0"><span class="c1">&gt;A federal law limiting how much companies can raise the price of food/groceries: +15% net favorability</span></li><li class="c7 li-bullet-0"><span class="c1">A federal law establishing price controls on food/groceries: -10% net favorability </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_qymwuf8ggtk1-0"><li class="c4 li-bullet-0"><span class="c1">O1-preview/o1-mini still gets it right with very small drops regardless of the difficulty of the problem unless irrelevant information is added (and still gets it right 77% of the time). </span></li></ul><ul class="c0 lst-kix_qymwuf8ggtk1-1 start"><li class="c10 li-bullet-0"><span class="c1">The full O1 model would perform better. </span></li><li class="c10 li-bullet-0"><span class="c1">Claude 3.5 Sonnet was not tested either.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 405.33px;"><img alt="" src="images/image436.png" style="width: 624.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h3 class="c119 c197" id="h.cl703wyn20lq"><span class="c92 c37 c168 c48 c125"></span></h3><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.4x7edwi3alg7"><span>12.</span><span>2 </span><span class="c40 c37 c48 c75">&ldquo;AI is bad at math&rdquo;</span></h2><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 578.00px; height: 360.00px;"><img alt="" src="images/image118.png" style="width: 578.00px; height: 360.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-0"><li class="c4 li-bullet-0"><span>Fields Medalist Terence Tao explains how proof checkers and AI programs are dramatically changing mathematics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/&amp;sa=D&amp;source=editors&amp;ust=1730413584137689&amp;usg=AOvVaw3i5HdbC6kSaeUYB7KJbiP-">https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c33 c15">See sections 8.1 and 16.5</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.s7roy8b1uwrd"><span>12.3 </span><span class="c40 c37 c48 c75">&ldquo;Out-of-touch bosses and managers are forcing workers to use AI even if it is unnecessary, ineffective, or even harmful.&rdquo;</span></h2><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span>Gen AI at work has surged 66% in the UK, </span><span class="c34">but bosses aren&rsquo;t behind it:</span><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://finance.yahoo.com/news/gen-ai-surged-66-uk-053000325.html&amp;sa=D&amp;source=editors&amp;ust=1730413584138157&amp;usg=AOvVaw07MZrKLo6l3KVOWBlKpTXF">https://finance.yahoo.com/news/gen-ai-surged-66-uk-053000325.html</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_vexpnyyatkbq-2 start"><li class="c7 li-bullet-0"><span class="c1">Notably, of the seven million British workers that Deloitte extrapolates have used GenAI at work, only 27% reported that their employer officially encouraged this behavior.</span></li><li class="c7 li-bullet-0"><span class="c1">Although Deloitte doesn&rsquo;t break down the at-work usage by age and gender, it does reveal patterns among the wider population. Over 60% of people aged 16-34 (broadly, Gen Z and younger millennials) have used GenAI, compared with only 14% of those between 55 and 75 (older Gen Xers and Baby Boomers).</span></li></ul><h2 class="c64" id="h.baveyldyhab6"><span>12.4 </span><span class="c40 c37 c48 c75">&ldquo;LLMs always agree with the user, even when they are wrong&rdquo;</span></h2><ul class="c0 lst-kix_vexpnyyatkbq-1"><li class="c10 li-bullet-0"><span>This is a result of RLHF, where they are purposely trained to be sycophantic: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1796659397407768680&amp;sa=D&amp;source=editors&amp;ust=1730413584138579&amp;usg=AOvVaw1P3Hb_EsFSRc-569LG9SUh">https://x.com/tsarnick/status/1796659397407768680</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.z333zs7g0dw9"><span class="c40 c37 c48 c75">12.5. &ldquo;LLMs will level out at human level&rdquo;</span></h2><ul class="c0 lst-kix_o1ljou14zs74-0 start"><li class="c4 li-bullet-0"><span>If you train LLMs on 1000 Elo chess games, they don&#39;t cap out at 1000 - </span><span class="c15">they can play at 1500: </span><span class="c5 c37 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.11741v1&amp;sa=D&amp;source=editors&amp;ust=1730413584138914&amp;usg=AOvVaw2oO5emv5PjWNA9bCQ5uvN0">https://arxiv.org/html/2406.11741v1</a></span><span class="c40 c37 c65 c60">&nbsp;</span></li></ul><ul class="c0 lst-kix_o1ljou14zs74-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 189.33px;"><img alt="" src="images/image386.png" style="width: 624.00px; height: 189.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_o1ljou14zs74-0"><li class="c4 li-bullet-0"><span class="c1">AlphaGo, AlphaZero, Stockfish, and OpenAI Five beat humans at Go, chess, and Dota 2</span></li><li class="c4 li-bullet-0"><span class="c1">Computers are much faster than humans, don&rsquo;t get tired or injured, and anything they learn can be broadcasted globally in seconds </span></li><li class="c4 li-bullet-0"><span class="c1">Can be trained on only high quality data to be the best of every world </span></li><li class="c4 li-bullet-0"><span class="c33 c15">[2278 AI researchers were surveyed in 2023 and estimated that there is a 50% chance of AI being superior to humans in all possible tasks by 2047](https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf)</span></li></ul><ul class="c0 lst-kix_o1ljou14zs74-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 561.37px; height: 733.50px;"><img alt="" src="images/image428.png" style="width: 561.37px; height: 733.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c33 c15">In 2022, the year they had for that was 2060, and many of their predictions have already come true ahead of time, like AI being capable of answering queries using the web, transcribing speech, translation, and reading text aloud that they thought would only happen after 2025.</span></li></ul><ul class="c0 lst-kix_o1ljou14zs74-0"><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 320.50px; height: 765.94px;"><img alt="" src="images/image72.png" style="width: 320.50px; height: 765.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h2 class="c64" id="h.so3mobuj39g5"><span class="c40 c37 c48 c75">12.6. &ldquo;AI Should Be Doing My Dishes and Laundry Instead&rdquo;</span></h2><ul class="c0 lst-kix_d74axqjz5yj6-0 start"><li class="c4 li-bullet-0"><span class="c1">They are. Thats what laundry machines and dish washers are for.</span></li></ul><ul class="c0 lst-kix_d74axqjz5yj6-1 start"><li class="c10 li-bullet-0"><span>Robot folding laundry for $250: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Ilir_AI/status/1810609029967741139&amp;sa=D&amp;source=editors&amp;ust=1730413584139865&amp;usg=AOvVaw1X8NKPACtcePhaB9yg3ILx">https://x.com/Ilir_AI/status/1810609029967741139</a></span></li></ul><ul class="c0 lst-kix_d74axqjz5yj6-0"><li class="c4 li-bullet-0"><span class="c1">Robots are harder to build than AI software but they are being built</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.yti3e1u3uz9a"><span>12.7</span><span class="c40 c37 c48 c75">. Goldman Sachs Report On AI Being Overhyped</span></h2><ul class="c0 lst-kix_l5sge8zce4vp-0 start"><li class="c22 c32 li-bullet-0"><span class="c1 c14">The dotcom bubble also happened but the Internet is far larger than it was back then</span></li><li class="c22 c32 li-bullet-0"><span class="c1 c14">Goldman Sachs has other reports on AI that are very bullish</span></li></ul><ul class="c0 lst-kix_l5sge8zce4vp-1 start"><li class="c22 c72 li-bullet-0"><span class="c14">Goldman Sachs says generative A.I. could impact 300 million jobs: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2023/03/28/ai-automation-could-impact-300-million-jobs-heres-which-ones.html&amp;sa=D&amp;source=editors&amp;ust=1730413584140480&amp;usg=AOvVaw2ldza7N-W97wPk6Nvr939S">https://www.cnbc.com/2023/03/28/ai-automation-could-impact-300-million-jobs-heres-which-ones.html</a></span></li><li class="c22 c72 li-bullet-0"><span class="c14">Generative AI could raise global GDP by 7%: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html&amp;sa=D&amp;source=editors&amp;ust=1730413584140800&amp;usg=AOvVaw2KTevm_hdXaBJWP-AXVWzD">https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html</a></span></li><li class="c10 li-bullet-0"><span>Goldman Sachs CIO on How the Bank Is Actually Using AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://omny.fm/shows/odd-lots/080624-odd-lots-marco-argenti-v1?in_playlist%3Dpodcast&amp;sa=D&amp;source=editors&amp;ust=1730413584141109&amp;usg=AOvVaw1vI9_PdmuDVMtHLACYZvG9">https://omny.fm/shows/odd-lots/080624-odd-lots-marco-argenti-v1?in_playlist=podcast</a></span></li></ul><ul class="c0 lst-kix_l5sge8zce4vp-0"><li class="c22 c32 li-bullet-0"><span>JP Morgan: NVIDIA bears no resemblance to dot-com market leaders like Cisco whose P/E multiple also soared but without earnings to go with it (Page 10): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584141465&amp;usg=AOvVaw0OqXV5yc9EPsp5PZJjicLj">https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf</a></span></li><li class="c22 c32 li-bullet-0"><span class="c14">Many other reports and studies contradict this (see sections 4.2 and 5)</span></li></ul><p class="c22 c44"><span class="c1 c14"></span></p><h2 class="c22 c80" id="h.12bb2aukb30p"><span>12.8</span><span class="c40 c37 c48 c75">. HIVE AI Detector</span></h2><ul class="c0 lst-kix_hdkieo28r82q-0 start"><li class="c4 li-bullet-0"><span class="c1">False negatives</span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 349.33px;"><img alt="" src="images/image169.png" style="width: 624.00px; height: 349.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/nickfloats/status/1814165053903446310&amp;sa=D&amp;source=editors&amp;ust=1730413584142075&amp;usg=AOvVaw1WHsVwhmjp8i3vJHOSnPDK">https://x.com/nickfloats/status/1814165053903446310</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.25px; height: 379.50px;"><img alt="" src="images/image399.png" style="width: 569.25px; height: 379.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/images/15514083&amp;sa=D&amp;source=editors&amp;ust=1730413584142377&amp;usg=AOvVaw34tbgEBWTKJE_FuXWVVNNy">https://civitai.com/images/15514083</a></span></li><li class="c7 li-bullet-0"><span class="c1">AI generated but HIVE does not correctly detect it</span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 450.00px; height: 323.00px;"><img alt="" src="images/image429.png" style="width: 450.00px; height: 323.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/106609/sketch-anime-pose&amp;sa=D&amp;source=editors&amp;ust=1730413584142747&amp;usg=AOvVaw3-DGiZAOj1crsxMzrjdTV5">https://civitai.com/models/106609/sketch-anime-pose</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 566.40px; height: 737.50px;"><img alt="" src="images/image105.png" style="width: 566.40px; height: 737.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://checkyourfact.com/2024/06/19/fact-check-crash-involving-two-cybertrucks-ai-generated/&amp;sa=D&amp;source=editors&amp;ust=1730413584143100&amp;usg=AOvVaw36XMDgho6dT8DQsp9LVKsC">https://checkyourfact.com/2024/06/19/fact-check-crash-involving-two-cybertrucks-ai-generated/</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 316.00px;"><img alt="" src="images/image616.png" style="width: 624.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 416.00px;"><img alt="" src="images/image526.png" style="width: 624.00px; height: 416.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Qxnznghggktygf/status/1814945032476242110&amp;sa=D&amp;source=editors&amp;ust=1730413584143528&amp;usg=AOvVaw0EYECOlwj93mVDUYjgRCBk">https://x.com/Qxnznghggktygf/status/1814945032476242110</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 417.33px;"><img alt="" src="images/image420.png" style="width: 624.00px; height: 417.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/midjourney/status/1818342703618482265&amp;sa=D&amp;source=editors&amp;ust=1730413584143847&amp;usg=AOvVaw03yFbNxmGfYzZANUEcF-EH">https://x.com/midjourney/status/1818342703618482265</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 495.50px; height: 495.50px;"><img alt="" src="images/image153.png" style="width: 495.50px; height: 495.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 425.50px; height: 425.50px;"><img alt="" src="images/image530.png" style="width: 425.50px; height: 425.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 548.50px; height: 548.50px;"><img alt="" src="images/image537.png" style="width: 548.50px; height: 548.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 527.50px; height: 527.50px;"><img alt="" src="images/image212.png" style="width: 527.50px; height: 527.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 433.50px; height: 433.50px;"><img alt="" src="images/image488.png" style="width: 433.50px; height: 433.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 455.50px; height: 455.50px;"><img alt="" src="images/image519.png" style="width: 455.50px; height: 455.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ARTiV3RSE/status/1818714368587997515&amp;sa=D&amp;source=editors&amp;ust=1730413584144523&amp;usg=AOvVaw05pY3j5dV1osTkzwWXuyt0">https://x.com/ARTiV3RSE/status/1818714368587997515</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c17 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 477.31px; height: 597.50px;"><img alt="" src="images/image209.png" style="width: 477.31px; height: 597.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c50 c86 li-bullet-0"><span class="c1">Many people, including AI haters, couldnt tell it&rsquo;s AI generated: </span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-3 start"><li class="c50 c26 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/midosommar/status/1843013374919241868&amp;sa=D&amp;source=editors&amp;ust=1730413584144852&amp;usg=AOvVaw21xn3QLjOyUDhdqA3Agnxk">https://x.com/midosommar/status/1843013374919241868</a></span></li><li class="c50 c26 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/beyoncesspamacc/status/1843094040851726800&amp;sa=D&amp;source=editors&amp;ust=1730413584145046&amp;usg=AOvVaw1uyZn-lxB9i0ato3NMu4GD">https://x.com/beyoncesspamacc/status/1843094040851726800</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2"><li class="c50 c86 li-bullet-0"><span>And no photoshop was involved: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/2byStanuby/status/1843456682392801662&amp;sa=D&amp;source=editors&amp;ust=1730413584145243&amp;usg=AOvVaw0XSuMGLhPjCgev2gx3m8Bh">https://x.com/2byStanuby/status/1843456682392801662</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 350.00px; height: 440.00px;"><img alt="" src="images/image542.png" style="width: 350.00px; height: 440.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 382.77px; height: 524.50px;"><img alt="" src="images/image647.png" style="width: 382.77px; height: 524.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 239.00px; height: 394.00px;"><img alt="" src="images/image266.png" style="width: 239.00px; height: 394.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image483.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image384.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-2 start"><li class="c7 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/JamesLucasIT/status/1821599063638470700&amp;sa=D&amp;source=editors&amp;ust=1730413584146002&amp;usg=AOvVaw0TOK33WFgR4vsifXv51kig">https://x.com/JamesLucasIT/status/1821599063638470700</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 555.00px; height: 900.00px;"><img alt="" src="images/image485.png" style="width: 555.00px; height: 900.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 531.62px; height: 808.50px;"><img alt="" src="images/image303.png" style="width: 531.62px; height: 808.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 473.57px; height: 892.50px;"><img alt="" src="images/image255.png" style="width: 473.57px; height: 892.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 352.00px;"><img alt="" src="images/image217.png" style="width: 624.00px; height: 352.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 405.33px;"><img alt="" src="images/image381.png" style="width: 624.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 405.33px;"><img alt="" src="images/image230.png" style="width: 624.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 405.33px;"><img alt="" src="images/image573.png" style="width: 624.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 405.33px;"><img alt="" src="images/image658.png" style="width: 624.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Qxnznghggktygf/status/1814460140508401757&amp;sa=D&amp;source=editors&amp;ust=1730413584146883&amp;usg=AOvVaw0wEO6Qvn_jxi7fyuTRg_HD">https://x.com/Qxnznghggktygf/status/1814460140508401757</a></span><span class="c1">&nbsp;[NSFW warning]</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Heartwords3/status/1814794196529914127&amp;sa=D&amp;source=editors&amp;ust=1730413584147111&amp;usg=AOvVaw2KX7E8ZS7k4gDdCoiAPA00">https://x.com/Heartwords3/status/1814794196529914127</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Tazibao22/status/1814879726177296628&amp;sa=D&amp;source=editors&amp;ust=1730413584147334&amp;usg=AOvVaw2mjxLQv7SFnCBq6wBh9tY8">https://x.com/Tazibao22/status/1814879726177296628</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Tazibao22/status/1809791196484534730&amp;sa=D&amp;source=editors&amp;ust=1730413584147549&amp;usg=AOvVaw1C1JmA036oOhFBNEy9Dk-6">https://x.com/Tazibao22/status/1809791196484534730</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Tazibao22/status/1814583524604977530&amp;sa=D&amp;source=editors&amp;ust=1730413584147762&amp;usg=AOvVaw0pa7ztSI3mVOnvZsTZkcgr">https://x.com/Tazibao22/status/1814583524604977530</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Tazibao22/status/1806046182411833799&amp;sa=D&amp;source=editors&amp;ust=1730413584147977&amp;usg=AOvVaw2y1cby4tXL4N4or6XTtanI">https://x.com/Tazibao22/status/1806046182411833799</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 440.00px;"><img alt="" src="images/image321.png" style="width: 624.00px; height: 440.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/aiwars/comments/1fmirul/remember_folks_you_can_trust_ai_detectors_to_tell/&amp;sa=D&amp;source=editors&amp;ust=1730413584148288&amp;usg=AOvVaw0hVaglcvEUGxb2OjUTAmxB">https://www.reddit.com/r/aiwars/comments/1fmirul/remember_folks_you_can_trust_ai_detectors_to_tell/</a></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 415.50px; height: 415.50px;"><img alt="" src="images/image376.png" style="width: 415.50px; height: 415.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1 start"><li class="c10 li-bullet-0"><span class="c1">AI-generated album cover from The Voidz</span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 539.50px; height: 545.85px;"><img alt="" src="images/image403.png" style="width: 539.50px; height: 545.85px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 521.00px; height: 736.00px;"><img alt="" src="images/image648.png" style="width: 521.00px; height: 736.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_hdkieo28r82q-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/6722cbef-cf54-8000-b2be-61636a66da04&amp;sa=D&amp;source=editors&amp;ust=1730413584148817&amp;usg=AOvVaw22DDUYjZdGIl4-exa_KtGJ">https://chatgpt.com/share/6722cbef-cf54-8000-b2be-61636a66da04</a></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.9m1s75n3l9l5"><span>12.9. LLMs Can&rsquo;t Count Letters/LLMs Can&rsquo;t Compare Numbers/LLMs Can&rsquo;t Solve Riddles</span></h2><ul class="c0 lst-kix_jts281wjqw39-0 start"><li class="c4 li-bullet-0"><span class="c1">o1-preview and mini do it well:</span></li></ul><ul class="c0 lst-kix_jts281wjqw39-1 start"><li class="c10 li-bullet-0"><span>o1-preview gets letter occurrences 5/5 times: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/66ed942c-8ebc-8011-88a9-c19ce0d160fa&amp;sa=D&amp;source=editors&amp;ust=1730413584149460&amp;usg=AOvVaw0rmHel4xzyFfDMr5EYz7pe">https://chatgpt.com/share/66ed942c-8ebc-8011-88a9-c19ce0d160fa</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jts281wjqw39-2 start"><li class="c7 li-bullet-0"><span class="c1">It even notices the spellings are wrong and tells me the counts for both the wrong and correct spellings.</span></li></ul><ul class="c0 lst-kix_jts281wjqw39-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 384.00px;"><img alt="" src="images/image638.png" style="width: 624.00px; height: 384.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 768.00px;"><img alt="" src="images/image507.png" style="width: 624.00px; height: 768.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image254.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jts281wjqw39-0"><li class="c4 li-bullet-0"><span class="c1">This is an issue with tokenizers. The LLM groups characters together (called tokens) so it cannot analyze them individually </span></li></ul><ul class="c0 lst-kix_jts281wjqw39-1 start"><li class="c10 li-bullet-0"><span class="c1">Ex. It tokenizes the letters &ldquo;rr&rdquo; in the word &ldquo;strawberry&rdquo; so it only sees two &ldquo;r&rdquo; letters</span></li><li class="c10 li-bullet-0"><span>Explanation of tokenizers: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ephawr/a_brief_introduction_to_tokenizers/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584150221&amp;usg=AOvVaw1l_dnOBzcBOxL-GsJwoAmV">https://www.reddit.com/r/singularity/comments/1ephawr/a_brief_introduction_to_tokenizers/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li><li class="c47 li-bullet-0"><span>Tokens are a big reason today&rsquo;s generative AI falls short: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/07/06/tokens-are-a-big-reason-todays-generative-ai-falls-short/&amp;sa=D&amp;source=editors&amp;ust=1730413584150466&amp;usg=AOvVaw2J4uR0wcEzBi03BD9ZLtF9">https://techcrunch.com/2024/07/06/tokens-are-a-big-reason-todays-generative-ai-falls-short/</a></span></li></ul><p class="c130 c46"><span class="c1"></span></p><ul class="c0 lst-kix_jts281wjqw39-2"><li class="c130 c86 li-bullet-0"><span class="c67 c37">&gt;Feucht points to &ldquo;byte-level&rdquo; state space models like </span><span class="c37 c103 c68 c126"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2401.13660&amp;sa=D&amp;source=editors&amp;ust=1730413584150734&amp;usg=AOvVaw1aXrBiPwgyUZ6Kb1ywa6Zh">MambaByte</a></span><span class="c79 c37 c103 c126">, which can ingest far more data than transformers without a performance penalty by doing away with tokenization entirely. MambaByte, which works directly with raw bytes representing text and other data, is competitive with some transformer models on language-analyzing tasks while better handling &ldquo;noise&rdquo; like words with swapped characters, spacing and capitalized characters.</span></li></ul><ul class="c0 lst-kix_jts281wjqw39-0"><li class="c4 li-bullet-0"><span class="c1">Usually, asking it to break it down step by step resolves this problem</span></li></ul><ul class="c0 lst-kix_jts281wjqw39-1 start"><li class="c47 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 563.50px; height: 1148.12px;"><img alt="" src="images/image654.jpg" style="width: 563.50px; height: 1148.12px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span class="c67 c37">This can be done without prompting for it: </span><span class="c5 c37 c103 c126"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2402.10200&amp;sa=D&amp;source=editors&amp;ust=1730413584151245&amp;usg=AOvVaw0xO-Z6hdqZRngAafSZMLkc">https://arxiv.org/pdf/2402.10200</a></span></li></ul><ul class="c0 lst-kix_jts281wjqw39-2 start"><li class="c130 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 228.00px;"><img alt="" src="images/image301.png" style="width: 624.00px; height: 228.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c130 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 509.33px;"><img alt="" src="images/image469.png" style="width: 624.00px; height: 509.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c130 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 181.33px;"><img alt="" src="images/image58.png" style="width: 624.00px; height: 181.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c130 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 621.94px; height: 140.17px;"><img alt="" src="images/image242.png" style="width: 621.94px; height: 140.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jts281wjqw39-0"><li class="c4 li-bullet-0"><span class="c1">There may also be overfitting</span></li></ul><ul class="c0 lst-kix_jts281wjqw39-1 start"><li class="c10 li-bullet-0"><span class="c1">Ex. It may incorrectly believe 9.11 &gt; 9.9 as this is true for software versioning (it may also be a tokenization problem as well)</span></li><li class="c10 li-bullet-0"><span>It may also incorrectly answer riddles like &ldquo;</span><span class="c6">which order should I carry the chickens or the fox over a river</span><span class="c1">&rdquo; for this reason</span></li></ul><ul class="c0 lst-kix_jts281wjqw39-2 start"><li class="c7 li-bullet-0"><span class="c6">GPT-4 gets it correct EVEN WITH A MAJOR CHANGE if you replace the fox with a &quot;zergling&quot; and the chickens with &quot;robots&quot;: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636&amp;sa=D&amp;source=editors&amp;ust=1730413584152184&amp;usg=AOvVaw3if6OP1E3JMCSz5oWGe8Fw">https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_jts281wjqw39-3 start"><li class="c21 c26 li-bullet-0"><span class="c6 c40">This doesn&rsquo;t work if you use the original phrasing though. The problem isn&#39;t poor reasoning, but overfitting on the original version of the riddle.</span></li></ul><p class="c9"><span class="c6 c40"></span></p><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_1l36jc1oov6-1 start"><li class="c7 li-bullet-0"><span class="c6">Also gets this riddle subversion correct for the same reason: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92&amp;sa=D&amp;source=editors&amp;ust=1730413584152660&amp;usg=AOvVaw3rKfhjAiBDrlkcInFtMzRs">https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><p class="c9"><span class="c6 c40"></span></p><ul class="c0 lst-kix_1l36jc1oov6-1"><li class="c7 li-bullet-0"><span class="c6">Researcher formally solves this issue: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition&amp;sa=D&amp;source=editors&amp;ust=1730413584153011&amp;usg=AOvVaw1t_KjWUYA7feEAVMjfvuD2">https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition</a></span></li></ul><p class="c9"><span class="c6 c40"></span></p><h2 class="c64" id="h.wb2wf525ttxm"><span class="c40 c37 c48 c75">12.10. LLMs Can&rsquo;t Learn Continuously</span></h2><ul class="c0 lst-kix_54yn6dknd642-0 start"><li class="c4 li-bullet-0"><span>This AI Learns Continuously From New Experiences&mdash;Without Forgetting Its Past: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://singularityhub.com/2024/08/22/this-ai-learns-continuously-from-new-experiences-without-forgetting-its-past/&amp;sa=D&amp;source=editors&amp;ust=1730413584153425&amp;usg=AOvVaw1Ni1qK1s4_dlYv77j_Dt0f">https://singularityhub.com/2024/08/22/this-ai-learns-continuously-from-new-experiences-without-forgetting-its-past/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_54yn6dknd642-0"><li class="c4 li-bullet-0"><span>Topology AI&rsquo;s CLM </span><span>remembers interactions, learns skills autonomously, and thinks in its free time, just like humans: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/aidan_mclau/status/1818071890755469365?t%3DbiE9iwV1_1CzcE8CHDYhGw%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413584153746&amp;usg=AOvVaw3fSVZDhXOwxkHfK8YY1eYk">https://x.com/aidan_mclau/status/1818071890755469365</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_54yn6dknd642-0"><li class="c4 li-bullet-0"><span>Taybot from 2016 can do this: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Tay_(chatbot)&amp;sa=D&amp;source=editors&amp;ust=1730413584154023&amp;usg=AOvVaw0Y4EDxpuQxzMH_xC9ysRTf">https://en.m.wikipedia.org/wiki/Tay_(chatbot)</a></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.90y67xfv32o0"><span class="c40 c37 c48 c75">12.11. Apple is Pessimistic On AI</span></h2><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tsc2yqmm539t-1 start"><li class="c10 li-bullet-0"><span>Apple is producing an AI chip for data centers: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wsj.com/tech/ai/apple-is-developing-ai-chips-for-data-centers-seeking-edge-in-arms-race-0bedd2b2&amp;sa=D&amp;source=editors&amp;ust=1730413584154487&amp;usg=AOvVaw2Q_gigM8V9CmiOeC8Akb-h">https://www.wsj.com/tech/ai/apple-is-developing-ai-chips-for-data-centers-seeking-edge-in-arms-race-0bedd2b2</a></span></li><li class="c10 li-bullet-0"><span>Apple announces new iPad Mini focused on AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/news/news/content/ar-AA1sj3uf&amp;sa=D&amp;source=editors&amp;ust=1730413584154764&amp;usg=AOvVaw2SXKOwsFMGI5DexEXHtNTu">https://www.msn.com/en-us/news/news/content/ar-AA1sj3uf</a></span></li></ul><h2 class="c64" id="h.3zl1zhlymqyj"><span class="c40 c37 c48 c75">12.12, AI Companies Are Training On Benchmarks to Inflate Their Scores</span></h2><ul class="c0 lst-kix_o9zj68me8yj0-0 start"><li class="c4 li-bullet-0"><span>If LLMs were specifically trained to score well on benchmarks, it could score 100% on all of them very easily with only one million parameters by purposefully overfitting: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2309.08632&amp;sa=D&amp;source=editors&amp;ust=1730413584155081&amp;usg=AOvVaw1zAi07O4E654g9k9_wR0aP">https://arxiv.org/pdf/2309.08632</a></span></li></ul><ul class="c0 lst-kix_tsc2yqmm539t-1 start"><li class="c10 li-bullet-0"><span class="c1">The fact that they don&rsquo;t shows companies are not just cheating</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tsc2yqmm539t-1"><li class="c10 li-bullet-0"><span class="c1">Also, why would they be spending billions of dollars on research and compute if they can just train on the data? Why do some LLMs perform better than others if they all have access to the same data online?</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_l5j0c6x8jedh-0 start"><li class="c4 li-bullet-0"><span class="c1">OpenAI still hasn&rsquo;t hard coded their LLMs to be correct for common questions like counting the number of &ldquo;r&rdquo;s in &ldquo;strawberry&rdquo; and finding the greater value between 9.11 and 9.8. If they wanted to cheat to increase benchmark scores, why wouldn&rsquo;t they solve these issues manually?</span></li></ul><ul class="c0 lst-kix_tsc2yqmm539t-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 256.00px;"><img alt="" src="images/image387.png" style="width: 624.00px; height: 256.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/stas_kulesh/status/1834334863232827682&amp;sa=D&amp;source=editors&amp;ust=1730413584155849&amp;usg=AOvVaw30LdrzxQmV9VhaMEwVvBjc">https://x.com/stas_kulesh/status/1834334863232827682</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_v38knoi1xqwy-0 start"><li class="c4 li-bullet-0"><span class="c1">Some benchmarks like the one used by Scale.ai and the test dataset of MathVista do not release their testing data to the public, so it is impossible to train on them. Yet LLMs can still perform wel.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_v38knoi1xqwy-0"><li class="c4 li-bullet-0"><span class="c1">Other benchmarks like LiveBench update every month so training on the dataset will not have any lasting effects</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.vva6k49whx0e"><span class="c40 c37 c48 c75">12.13. AI Cannot Learn As Fast As Humans</span></h2><ul class="c0 lst-kix_tgtuyk7iugqt-0 start"><li class="c106 c56 c78 li-bullet-0"><span class="c1">AI needs lots of training because it knows more than people do about every subject, from art to science to trivia to every hobby. This is what makes it generalized.</span></li></ul><p class="c106 c56 c97 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tgtuyk7iugqt-0"><li class="c106 c56 c78 li-bullet-0"><span class="c1">AI can learn very quickly, such as Apple&rsquo;s face identification that only takes a few seconds or explaining patterns to an LLM</span></li></ul><ul class="c0 lst-kix_tgtuyk7iugqt-1 start"><li class="c10 li-bullet-0"><span class="c23 c14 c81">Ex. </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 202.67px;"><img alt="" src="images/image579.png" style="width: 624.00px; height: 202.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c106 c56 c97 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tgtuyk7iugqt-0"><li class="c106 c56 c78 li-bullet-0"><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/%23performance&amp;sa=D&amp;source=editors&amp;ust=1730413584157273&amp;usg=AOvVaw2XGvnjxCz2-bWTWlYuOcaD">LLMs can already learn new languages within their context window better than humans can with the same amount of data</a></span><span class="c37 c35 c103 c14">: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/%23performance&amp;sa=D&amp;source=editors&amp;ust=1730413584157564&amp;usg=AOvVaw1olBKxCQvvUGE4aSyDaroT">https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#performance</a></span></li></ul><p class="c106 c56 c97 c46"><span class="c1"></span></p><h2 class="c106 c56 c97 c140" id="h.x1c6pt1a2xcx"><span class="c40 c37 c48 c75">12.14. AI Text Detectors</span></h2><ul class="c0 lst-kix_4o6376uieeve-0 start"><li class="c4 li-bullet-0"><span>Turnitin explicitly advises not to use its tool against students, stating that it is not reliable enough: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://help.turnitin.com/ai-writing-detection.htm&amp;sa=D&amp;source=editors&amp;ust=1730413584158028&amp;usg=AOvVaw1u95m5jgNOKjanIC7V89oP">https://help.turnitin.com/ai-writing-detection.htm</a></span></li></ul><ul class="c0 lst-kix_4o6376uieeve-1 start"><li class="c10 li-bullet-0"><span class="c1">&ldquo;Our AI writing detection model may not always be accurate (it may misidentify both human and AI-generated text) so it should not be used as the sole basis for adverse actions against a student. It takes further scrutiny and human judgment in conjunction with an organization&#39;s application of its specific academic policies to determine whether any academic misconduct has occurred.&rdquo;</span></li></ul><ul class="c0 lst-kix_4o6376uieeve-0"><li class="c4 li-bullet-0"><span>Here&rsquo;s a warning specifically from OpenAI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own&amp;sa=D&amp;source=editors&amp;ust=1730413584158377&amp;usg=AOvVaw3mxQZoLczVfVPaA9PjpRTz">https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own</a></span></li><li class="c4 li-bullet-0"><span>This paper references literally hundreds of studies 100% of which concluded that AI text detection is not accurate: A Survey on LLM-Generated Text Detection: Necessity, Methods, and Future Directions </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.14724&amp;sa=D&amp;source=editors&amp;ust=1730413584158625&amp;usg=AOvVaw2zKfehox4GcLoy1rVT6ZBf">https://arxiv.org/abs/2310.14724</a></span></li><li class="c4 li-bullet-0"><span class="c1">And here are statements from various major American universities on why they won&#39;t support or allow the use of any of these &quot;detector&quot; tools for academic integrity:</span></li><li class="c4 li-bullet-0"><span>MIT &ndash; AI Detectors Don&rsquo;t Work. Here&rsquo;s What to do Instead </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://mitsloanedtech.mit.edu/ai/teach/ai-detectors-dont-work/&amp;sa=D&amp;source=editors&amp;ust=1730413584159055&amp;usg=AOvVaw3ePvxAeJ8x60bwuN7K38m8">https://mitsloanedtech.mit.edu/ai/teach/ai-detectors-dont-work/</a></span></li><li class="c4 li-bullet-0"><span>Syracuse &ndash; Detecting AI Created Content </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://answers.syr.edu/display/blackboard01/Detecting%2BAI%2BCreated%2BContent&amp;sa=D&amp;source=editors&amp;ust=1730413584159329&amp;usg=AOvVaw1iPKqZSKjp42_e6ObTxeWT">https://answers.syr.edu/display/blackboard01/Detecting+AI+Created+Content</a></span></li><li class="c4 li-bullet-0"><span>UC Berkley &ndash; Availability of Turnitin Artificial Intelligence Detection </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://rtl.berkeley.edu/news/availability-turnitin-artificial-intelligence-detection&amp;sa=D&amp;source=editors&amp;ust=1730413584159605&amp;usg=AOvVaw3LY9RQiz68Khv53C45n-Eq">https://rtl.berkeley.edu/news/availability-turnitin-artificial-intelligence-detection</a></span></li><li class="c4 li-bullet-0"><span>UCF - Faculty Center - Artificial Intelligence </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://fctl.ucf.edu/technology/artificial-intelligence/&amp;sa=D&amp;source=editors&amp;ust=1730413584159886&amp;usg=AOvVaw0yJ-_nqcYE5DuV05mi3tkj">https://fctl.ucf.edu/technology/artificial-intelligence/</a></span></li><li class="c4 li-bullet-0"><span>Colorado State - Why you can&rsquo;t find Turnitin&rsquo;s AI Writing Detection tool </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://tilt.colostate.edu/why-you-cant-find-turnitins-ai-writing-detection-tool/&amp;sa=D&amp;source=editors&amp;ust=1730413584160135&amp;usg=AOvVaw0Uc8zm5lTTNfJ6lJGMc6Os">https://tilt.colostate.edu/why-you-cant-find-turnitins-ai-writing-detection-tool/</a></span></li><li class="c4 li-bullet-0"><span>Missouri &ndash; Detecting Artificial Intelligence (AI) Plagiarism </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://teachingtools.umsystem.edu/support/solutions/articles/11000119557-detecting-artificial-intelligence-ai-plagiarism&amp;sa=D&amp;source=editors&amp;ust=1730413584160416&amp;usg=AOvVaw0gPviCN8jmC3ixbWsJfK5h">https://teachingtools.umsystem.edu/support/solutions/articles/11000119557-detecting-artificial-intelligence-ai-plagiarism</a></span></li><li class="c4 li-bullet-0"><span>Northwestern &ndash; Use of Generative Artificial Intelligence in Courses </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ai.northwestern.edu/education/use-of-generative-artificial-intelligence-in-courses.html&amp;sa=D&amp;source=editors&amp;ust=1730413584160725&amp;usg=AOvVaw0kaRPrwHNI1th8oYYXl2yB">https://ai.northwestern.edu/education/use-of-generative-artificial-intelligence-in-courses.html</a></span></li><li class="c4 li-bullet-0"><span>SMU &ndash; Changes to Turnitin AI Detection Tool at SMU </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blog.smu.edu/itconnect/2023/12/13/discontinue-turnitin-ai-detection-tool/&amp;sa=D&amp;source=editors&amp;ust=1730413584160996&amp;usg=AOvVaw0Zgqv_LDt8y3CxrIjF_hKL">https://blog.smu.edu/itconnect/2023/12/13/discontinue-turnitin-ai-detection-tool/</a></span></li><li class="c4 li-bullet-0"><span>Vanderbilt &ndash; Guidance on AI Detection and Why We&rsquo;re Disabling Turnitin&rsquo;s AI Detector </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.vanderbilt.edu/brightspace/2023/08/16/guidance-on-ai-detection-and-why-were-disabling-turnitins-ai-detector/&amp;sa=D&amp;source=editors&amp;ust=1730413584161317&amp;usg=AOvVaw2VArYq8p2jnY851x6nHKzN">https://www.vanderbilt.edu/brightspace/2023/08/16/guidance-on-ai-detection-and-why-were-disabling-turnitins-ai-detector/</a></span></li><li class="c4 li-bullet-0"><span>Yale &ndash; AI Guidance for Teachers </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://poorvucenter.yale.edu/AIguidance&amp;sa=D&amp;source=editors&amp;ust=1730413584161524&amp;usg=AOvVaw0XNzcSeKEJEZthWxm0CczQ">https://poorvucenter.yale.edu/AIguidance</a></span></li><li class="c4 li-bullet-0"><span>Alabama - Turnitin AI writing detection unavailable </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cit.ua.edu/known-issue-turnitin-ai-writing-detection-unavailable/&amp;sa=D&amp;source=editors&amp;ust=1730413584161760&amp;usg=AOvVaw1S0MXsb17Tkmv2YxU8FxAp">https://cit.ua.edu/known-issue-turnitin-ai-writing-detection-unavailable/</a></span></li><li class="c4 li-bullet-0"><span class="c1">The MIT and Syracuse statements in particular contain extensive references to supporting research.</span></li><li class="c4 li-bullet-0"><span class="c1">And of course the most famous examples for false positives: Both the U.S. Constitution and the Old Testament were &ldquo;detected&rdquo; as 100% AI generated.</span></li><li class="c4 li-bullet-0"><span class="c1">Using these unreliable tools to fail students is highly unethical.</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.b710wsbvhaxn"><span class="c40 c37 c48 c75">12.15. Model Collapse/AI Inbreeding </span></h2><ul class="c0 lst-kix_8ylfq8z9iqph-0 start"><li class="c4 li-bullet-0"><span class="c1">See section 14</span></li></ul><p class="c106 c56 c97 c46"><span class="c1"></span></p><h1 class="c106 c56 c97 c140" id="h.ummc5u6dysl6"><span class="c40 c37 c48 c77">13. Energy Use/Water Use/Environmental Impact/Cost/Sustainability</span></h1><p class="c9"><span class="c1"></span></p><p class="c117"><span class="c15">See section 3.3 for hardware efficiency improvements</span></p><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.afnpgy4klq9p"><span class="c40 c37 c48 c75">13.1. Energy Use/Water Use/Environmental Impact/Sustainability</span></h2><ul class="c0 lst-kix_jk6itlvdyknk-0 start"><li class="c4 li-bullet-0"><span>AI is significantly less pollutive compared to humans: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/s41598-024-54271-x&amp;sa=D&amp;source=editors&amp;ust=1730413584162780&amp;usg=AOvVaw1B9U7eoD6aD4BZMFxgbyqX">https://www.nature.com/articles/s41598-024-54271-x</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span>&gt;AI systems emit </span><span class="c33 c15">between 130 and 1500 times less CO2e per page of text compared to human writers, while AI illustration systems emit between 310 and 2900 times less CO2e per image than humans.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c33 c15">It shows a computer creates about 500 grams of CO2e when used for the duration of creating an image. Midjourney and DALLE 2 create about 2-3 grams per image. &nbsp;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 593.50px; height: 311.02px;"><img alt="" src="images/image468.png" style="width: 593.50px; height: 311.02px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 324.00px;"><img alt="" src="images/image627.png" style="width: 624.00px; height: 324.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Data centers that host AI are cooled with a closed loop. The water doesn&rsquo;t even touch computer parts, it just carries the heat away, which is radiated elsewhere. </span><span class="c33 c15">It does no get polluted in the loop. Water is not wasted or lost in this process.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c55 c37 c65 c148 c14">&ldquo;The most common type of water-based cooling in data centers is the chilled water system. In this system, water is initially cooled in a central chiller, and then it circulates through cooling coils. These coils absorb heat from the air inside the data center. The system then expels the absorbed heat into the outside environment via a cooling tower. In the cooling tower, the now-heated water interacts with the outside air, allowing heat to escape </span><span class="c92 c15 c55 c65 c148">before the water cycles back into the system for re-cooling.&rdquo;</span></li></ul><p class="c9"><span class="c92 c15 c55 c65 c148"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-2 start"><li class="c7 li-bullet-0"><span class="c55 c37 c65 c148 c14">Source: </span><span class="c5 c55 c37 c65 c14"><a class="c13" href="https://www.google.com/url?q=https://dgtlinfra.com/data-center-water-usage/&amp;sa=D&amp;source=editors&amp;ust=1730413584163797&amp;usg=AOvVaw2nFCDUoN3HBQfj5rjL4Z1q">https://dgtlinfra.com/data-center-water-usage/</a></span></li></ul><p class="c9"><span class="c92 c55 c37 c65 c148 c14"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c55 c37 c65 c148 c14">Training GPT 3 (which is 175 billion parameters, much bigger and costlier to train than better AND smaller models like LLAMA 3.1 8b) evaporated 700,000 liters of water for cooling data centers: </span><span class="c5 c55 c37 c65 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2304.03271&amp;sa=D&amp;source=editors&amp;ust=1730413584164048&amp;usg=AOvVaw13PeVXSWAedGMRZeimxgd0">https://arxiv.org/pdf/2304.03271</a></span></li></ul><p class="c9"><span class="c92 c55 c37 c65 c148 c14"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c55 c37 c65 c148 c14">In 2015, the US used over 322 billion gallons of water PER DAY </span><span class="c5 c55 c37 c65 c14"><a class="c13" href="https://www.google.com/url?q=https://usgs.gov/faqs/how-much-water-used-people-united-states&amp;sa=D&amp;source=editors&amp;ust=1730413584164295&amp;usg=AOvVaw2RS0NYqK3wyuFXULbh1jFQ">https://usgs.gov/faqs/how-much-water-used-people-united-states</a></span></li></ul><p class="c9"><span class="c92 c55 c37 c65 c148 c14"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c92 c55 c37 c65 c148 c14">Also, evaporation is a normal part of the water cycle. The water isnt lost and will come back when it rains. </span></li></ul><p class="c9"><span class="c92 c55 c37 c65 c148 c14"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Data centers do not use a lot of water. Microsoft&rsquo;s data center in Goodyear uses 56 million gallons of water a year. The city produces 4.9 BILLION gallons per year just from surface water and, with future expansion, has the ability to produce 5.84 billion gallons (source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.goodyearaz.gov/government/departments/water-services/water-conservation&amp;sa=D&amp;source=editors&amp;ust=1730413584164664&amp;usg=AOvVaw0EtQRwFNAHS4OmDqYgvSZZ">https://www.goodyearaz.gov/government/departments/water-services/water-conservation</a></span><span class="c1">). It produces more from groundwater, but the source doesn&#39;t say how much. Additionally, the city actively recharges the aquifer by sending treated effluent to a Soil Aquifer Treatment facility. This provides needed recharged water to the aquifer and stores water underground for future needs. Also, the Goodyear facility doesn&#39;t just host AI. We have no idea how much of the compute is used for AI. It&#39;s probably less than half.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>gpt-4 (which has 1.75 trillion parameters and is the largest LLM ever made afaik) used 21 billion petaflops of compute during training (</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/grapher/artificial-intelligence-training-computation&amp;sa=D&amp;source=editors&amp;ust=1730413584164972&amp;usg=AOvVaw28DTlQ39UL6PHOtHhrM6T1">https://ourworldindata.org/grapher/artificial-intelligence-training-computation</a></span><span>) </span><span>and the world uses 1.1 zetaflop per second (</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://market.us/report/computing-power-market/&amp;sa=D&amp;source=editors&amp;ust=1730413584165137&amp;usg=AOvVaw0SY_5rbYepeESsnwxNmgM8">https://market.us/report/computing-power-market/</a></span><span>&nbsp;</span><span class="c1">per second as flops is flop per second). So from these numbers (21 * 10^9 * 10^15) / (1.1 * 10^21 * 60 * 60 * 24 * 365) gpt-4 used 0.06% of the world&#39;s compute per year. So this would also only be 0.06% of the water and energy used for compute worldwide. That&rsquo;s the equivalent of adding 52.3 seconds worth of computations on the planet each day for one year (totaling 5.3 hours) being dedicated to training an LLM that several hundreds of millions of people use every month. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c22 c72 li-bullet-0"><span class="c30 c37">Using it after it finished training costs HALF as much as it took to train it: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584165569&amp;usg=AOvVaw3ncLQcj-QHImxfG9A0mlS5">https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf</a></span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-2"><li class="c22 c104 c86 li-bullet-0"><span class="c1">(Page 10)</span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">Models have also become more efficient and large scale projects like ChatGPT will be cheaper (For example, gpt 4o mini and Gemini 1.5 Flash-002 are already better than gpt 4 and are only a fraction of its 1.75 trillion parameter size).</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c63 c14">Training GPT-4 (the largest LLM ever made at 1.75 trillion parameters) requires approximately 1,750 MWh of energy, an equivalent to the annual consumption of approximately 160 average American homes: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://www.baeldung.com/cs/chatgpt-large-language-models-power-consumption%23:~:text%3DTraining%2520GPT-4%2520is%2520even%2520more%2520demanding.%2520With%2520an,annual%2520consumption%2520of%2520approximately%2520160%2520average%2520American%2520homes&amp;sa=D&amp;source=editors&amp;ust=1730413584166199&amp;usg=AOvVaw0cJl1bhSTuFBH5nJiRMhC9">https://www.baeldung.com/cs/chatgpt-large-language-models-power-consumption</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">The average power bill in the US is about $1644 a year, so the total cost of the energy needed is about $263k without even considering economies of scale. Not much for a full-sized company worth billions of dollars like OpenAI.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>For reference, </span><span class="c35 c148">a single large power plant can generate about 2,000 megawatts, meaning it would only take 52.5 minutes worth of electricity from ONE power plant to train GPT 4: </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.explainthatstuff.com/powerplants.html&amp;sa=D&amp;source=editors&amp;ust=1730413584166698&amp;usg=AOvVaw15V2lW7XHt2paV1rIAn-K-">https://www.explainthatstuff.com/powerplants.html</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>The US uses about 2,300,000x that every year (4000 TeraWatts). That&rsquo;s like spending an extra </span><span class="c34">0.038 SECONDS worth of energy</span><span>, or about 1.15 frames in a 30 FPS video,</span><span class="c34">&nbsp;</span><span>for the country each day for </span><span class="c34">ONLY ONE YEAR</span><span>&nbsp;in exchange for creating a service used by hundreds of millions of people each month: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/%23:~:text%3DElectricity%2520consumption%2520in%2520the%2520U.S.%25201975-2023.%2520Published%2520by%2520Statista%2520Research&amp;sa=D&amp;source=editors&amp;ust=1730413584167133&amp;usg=AOvVaw2Mnl5g1_RZBpLnjs3HI88E">https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>ALL data centers in the US (not just for AI) consumed about 149 TWh (17 GW * 365 days * 24 hours) in 2022 (3.7% of the US total in 2023) and is expected to grow to 306.6 TWh (35 GW * 365 days * 24 hours) by 2030: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://archive.ph/QL9LB&amp;sa=D&amp;source=editors&amp;ust=1730413584167374&amp;usg=AOvVaw0C9Tll7Q5fqggDtIsjeBle">https://archive.ph/QL9LB</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">This is to power all of the internet + AI + all cloud compute and storage running in every website, hospital, business, online gaming server, etc.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>The US consumes 4000 TWh each year: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/%23:~:text%3DElectricity%2520consumption%2520in%2520the%2520U.S.%25201975-2023.%2520Published%2520by%2520Statista%2520Research&amp;sa=D&amp;source=editors&amp;ust=1730413584167769&amp;usg=AOvVaw0IoMH0Gg0SCT4J0K7XwIkW">https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c1">Stable Diffusion 1.5 was trained with 23,835 A100 GPU hours. An A100 tops out at 250W. So that&#39;s over 6000 KWh at most, which costs about $900. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>For reference, the US uses about 666,666,667x that every year (4000 TeraWatts). That makes it about 6 months of energy for one person: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/%23:~:text%3DElectricity%2520consumption%2520in%2520the%2520U.S.%25201975-2023.%2520Published%2520by%2520Statista%2520Research&amp;sa=D&amp;source=editors&amp;ust=1730413584168249&amp;usg=AOvVaw3-Cy7oyt4miPXgq-CsIltt">https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Training a diffusion model better than stable diffusion 1.5 and DALLE 2 from scratch for $1890 on only 37 million images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.15811&amp;sa=D&amp;source=editors&amp;ust=1730413584168494&amp;usg=AOvVaw3T_S5-XBhpjKvWzPYxVskD">https://arxiv.org/abs/2407.15811</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c3">using only 37M publicly available real and synthetic images, we train a 1.16 billion parameter sparse transformer with only $1,890 economical cost and achieve a 12.7 FID in zero-shot generation on the COCO dataset. Notably, our model achieves competitive FID and high-quality generations while incurring 118x lower cost than stable diffusion models and 14x lower cost than the current state-of-the-art approach that costs $28,400.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 476.43px; height: 876.50px;"><img alt="" src="images/image290.png" style="width: 476.43px; height: 876.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 458.67px;"><img alt="" src="images/image146.png" style="width: 624.00px; height: 458.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Image generators only use about 2.9 W of electricity per image, or 0.2 grams of CO2 per image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.16863&amp;sa=D&amp;source=editors&amp;ust=1730413584169027&amp;usg=AOvVaw1cCT8WKMieKNnEdUBZNKtZ">https://arxiv.org/pdf/2311.16863</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>For reference, a good gaming computer can use over 862 Watts per hour with a headroom of 688 Watts. Therefore, each image is about 12 seconds of gaming: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/how-much-power-does-my-pc-use/&amp;sa=D&amp;source=editors&amp;ust=1730413584169270&amp;usg=AOvVaw088RtxyISismhMSvdY-ll0">https://www.pcgamer.com/how-much-power-does-my-pc-use/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>One AI image generated creates the same amount of carbon emissions as about 7.7 tweets (at 0.026 grams of CO2 each, totaling 0.2 grams for both). There are 316 billion tweets each year and 486 million active users, an average of 650 tweets per account each year: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/%23:~:text%3DBased%2520on%2520their%2520calculation%2520that%2520a%2520single%2520tweet,4%252C685%2520flights%2520flying%2520between%2520Paris%2520and%2520New%2520York&amp;sa=D&amp;source=editors&amp;ust=1730413584169609&amp;usg=AOvVaw1E_dZ-E_FBgfXEoAChm2TQ">https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">With my hardware, the video card spikes to ~200W for about 7.5 seconds per image at my current settings. I can generate around 500 images/hour, so it costs 0.4 Watts each, which amounts to a couple cents of electricity or about 1.67 seconds of gaming with a high end computer.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Text generators use 0.047 Wh and emit 0.005 grams of CO2e per query: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.16863&amp;sa=D&amp;source=editors&amp;ust=1730413584169949&amp;usg=AOvVaw1HMdXTuu3AEQOyuIeztvbl">https://arxiv.org/pdf/2311.16863</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>For reference, a good gaming computer can use over 862 Watts per hour with a headroom of 688 Watts. Therefore, each query is about 0.2 seconds of gaming: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/how-much-power-does-my-pc-use/&amp;sa=D&amp;source=editors&amp;ust=1730413584170206&amp;usg=AOvVaw0543oWy2zgAAK1XXB2YeOt">https://www.pcgamer.com/how-much-power-does-my-pc-use/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>One AI query generated creates the same amount of carbon emissions as about 0.2 tweets on Twitter (so 5 AI generated queries = 1 tweet). There are 316 billion tweets each year and 486 million active users, an average of 650 tweets per account each year: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/%23:~:text%3DBased%2520on%2520their%2520calculation%2520that%2520a%2520single%2520tweet,4%252C685%2520flights%2520flying%2520between%2520Paris%2520and%2520New%2520York&amp;sa=D&amp;source=editors&amp;ust=1730413584170513&amp;usg=AOvVaw2lazQw9usJbsaMrI0W86yC">https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-00478-x&amp;sa=D&amp;source=editors&amp;ust=1730413584170792&amp;usg=AOvVaw1ZDHVlk2fQtUAZ0l1czFBQ">https://www.nature.com/articles/d41586-024-00478-x</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>&ldquo;ChatGPT is already consuming the energy of 33,000 homes&rdquo; for 13.6 BILLION annual visits plus API usage (source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.visualcapitalist.com/ranked-the-most-popular-ai-tools/&amp;sa=D&amp;source=editors&amp;ust=1730413584171048&amp;usg=AOvVaw3abEOJi4SefxEtxw4BxMyV">https://www.visualcapitalist.com/ranked-the-most-popular-ai-tools/</a></span><span class="c1">). that&#39;s 442,000 visits per household, not even including API usage.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">Models have also become more efficient and large scale projects like ChatGPT will be cheaper (For example, gpt 4o mini and LLAMA 3.1 70b are already better than gpt 4 and are only a fraction of its 1.75 trillion parameter size).</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>From this estimate (</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://discuss.huggingface.co/t/understanding-flops-per-token-estimates-from-openais-scaling-laws/23133&amp;sa=D&amp;source=editors&amp;ust=1730413584171493&amp;usg=AOvVaw3BCWygb8yKM2tGWcbJOgtf">https://discuss.huggingface.co/t/understanding-flops-per-token-estimates-from-openais-scaling-laws/23133</a></span><span>), the amount of FLOPS a model uses per token should be around twice the number of parameters. Given that LLAMA 3.1 405b spits out 28 tokens per second (</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://artificialanalysis.ai/models/gpt-4&amp;sa=D&amp;source=editors&amp;ust=1730413584171666&amp;usg=AOvVaw3GSOXMIqI4ZYDma3QLQ1J2">https://artificialanalysis.ai/models/gpt-4</a></span><span>), you get 22.7 teraFLOPS (2 * 405 billion parameters * 28 tokens per second), while a gaming rig&#39;s RTX 4090 would give you 83 teraFLOPS.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c22 c32 li-bullet-0"><span class="c40 c30 c37">Everything consumes power and resources, including superfluous things like video games and social media. Why is AI not allowed to when other, less useful things can? </span></li></ul><p class="c22 c44"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c22 c72 li-bullet-0"><span class="c30 c37">In 2022, T</span><span class="c14 c126 c134">witter created 8,200 tons in CO2e emissions, the equivalent of 4,685 flights between Paris and New York. </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/%23:~:text%3DBased%2520on%2520their%2520calculation%2520that%2520a%2520single%2520tweet,4%252C685%2520flights%2520flying%2520between%2520Paris%2520and%2520New%2520York&amp;sa=D&amp;source=editors&amp;ust=1730413584172236&amp;usg=AOvVaw2LuBXoFNXLA1QQDq3Cla1m">https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/</a></span></li></ul><p class="c22 c72 c46"><span class="c5 c30 c37 c120 c162"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c22 c72 li-bullet-0"><span class="c30 c37">Meanwhile, GPT-3 (which has 175 billion parameters, almost 22x the size of significantly better models like LLAMA 3.1 8b) only took about 8 cars worth of emissions (502 tons of CO2e) to train from start to finish: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://truthout.org/articles/report-on-chatgpt-models-emissions-offers-rare-glimpse-of-ais-climate-impacts/&amp;sa=D&amp;source=editors&amp;ust=1730413584172617&amp;usg=AOvVaw2YUAMU0lrocWsZd7EgOcRO">https://truthout.org/articles/report-on-chatgpt-models-emissions-offers-rare-glimpse-of-ais-climate-impacts/</a></span><span class="c40 c30 c37">&nbsp;</span></li></ul><p class="c22 c44"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-2"><li class="c22 c104 c86 li-bullet-0"><span class="c30 c37">By the way, using it after it finished training costs HALF as much as it took to train it: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584173019&amp;usg=AOvVaw2FsT7aD8WifJApwU2h9MfS">https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf</a></span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-3 start"><li class="c22 c104 c26 li-bullet-0"><span class="c1">(Page 10)</span></li></ul><p class="c22 c44"><span class="c1"></span></p><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-2"><li class="c22 c104 c86 li-bullet-0"><span class="c1">And 95% of the costs ($237 billion of $249 billion total spent) were one-time costs for GPUs and other chips or AI research. The cost of inference itself was only $12 billion (5%), not accounting for future chips that may be more cost and power efficient. This means if they stop buying new chips and all AI research, they can cost their costs by 95% by just running inference (not considering personnel costs, which can also be cut with layoffs).</span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c1">The first commercial computer in the world, UNIVAC 1101 from 1950s was as heavy as a truck and consumed 150KWh of power PER HOUR, while having only a few MB of storage and like a few KB of memory. Why was this justified while AI is not? Additionally, AI will improve as computers did (see section 13.2).</span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>The increase in power usage of data centers has been seen for decades long before AI was a thing. Here is a graph showing Google&#39;s yearly power use. Can you spot when they started pursuing AI at scale? </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.statista.com/statistics/788540/energy-consumption-of-google/&amp;sa=D&amp;source=editors&amp;ust=1730413584173812&amp;usg=AOvVaw25ngv4x4c9c2az1ZmR_5vw">https://www.statista.com/statistics/788540/energy-consumption-of-google/</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 885.33px;"><img alt="" src="images/image487.png" style="width: 624.00px; height: 885.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h2 class="c22 c80" id="h.slym8wy59wmv"><span class="c40 c37 c48 c75">13.2. Cost</span></h2><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>OpenAI&rsquo;s GPT-4o API is surprisingly profitable: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://futuresearch.ai/openai-api-profit&amp;sa=D&amp;source=editors&amp;ust=1730413584174356&amp;usg=AOvVaw0aE8H_2B7lQypPlygg3Acs">https://futuresearch.ai/openai-api-profit</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">75% of the cost of their API in June 2024 is profit. In August 2024, it&rsquo;s 55%. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">&gt;at full utilization, we estimate OpenAI could serve all of its gpt-4o API traffic with less than 10% of their provisioned 60k GPUs.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c1">Most of their costs are in research compute, data partnerships, marketing, and employee payroll, all of which can be cut if they need to go lean.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 436.00px;"><img alt="" src="images/image422.png" style="width: 624.00px; height: 436.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 545.33px;"><img alt="" src="images/image111.png" style="width: 624.00px; height: 545.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c22 c72 li-bullet-0"><span class="c30 c37">By the way, using a model after it finished training costs HALF as much as it took to train it: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584175324&amp;usg=AOvVaw2Dikcz_dCKTyZB_Np3Zn2m">https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf</a></span><span class="c1">&nbsp;(Page 10)</span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-2"><li class="c22 c104 c86 li-bullet-0"><span class="c1">This means only 1/3 of their costs are in running existing models (2:1 cost ratio for training vs. running). </span></li><li class="c22 c104 c86 li-bullet-0"><span class="c1">And 95% of the costs ($237 billion of $249 billion total spent) were one-time costs for GPUs and other chips or AI research. The cost of inference itself was only $12 billion (5%), not accounting for future chips that may be more cost and power efficient. This means if they stop buying new chips and all AI research, they can cost their costs by 95% by just running inference (not considering personnel costs, which can also be cut with layoffs). </span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c15">OpenAI&rsquo;s funding round closed with demand so high they&rsquo;ve had to turn down &quot;billions of dollars&quot; in surplus offers: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://archive.ph/gzpmv&amp;sa=D&amp;source=editors&amp;ust=1730413584175820&amp;usg=AOvVaw0LLMeGHkr37WQw26vS5yzj">https://archive.ph/gzpmv</a></span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c22 c32 li-bullet-0"><span>JP Morgan: NVIDIA bears no resemblance to dot-com bubble market leaders like Cisco whose P/E multiple also soared but without earnings to go with it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584176220&amp;usg=AOvVaw0dZydJ3bTzbFzri91K0AVR">https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf</a></span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c1">Stable Diffusion 1.5 was trained with 23,835 A100 GPU hours. An A100 tops out at 250W. So that&#39;s over 6000 KWh at most, which costs about $900. </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>For reference, the US uses about 666,666,667x every year (4000 TeraWatts). That makes it about 6 months of energy for one person: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/%23:~:text%3DElectricity%2520consumption%2520in%2520the%2520U.S.%25201975-2023.%2520Published%2520by%2520Statista%2520Research&amp;sa=D&amp;source=editors&amp;ust=1730413584176643&amp;usg=AOvVaw2N9IYuF6qEJPfIZQlLLBA5">https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>With my hardware, the video card spikes to ~200W for about 7.5 seconds per image at my current settings. I can generate around 500 images/hour, so it costs 0.4 Watts each, which amounts to a couple cents of electricity or about 1.67 seconds of gaming with a high end computer, which can use over 862 Watts per hour with a headroom of 688 Watts: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/how-much-power-does-my-pc-use/&amp;sa=D&amp;source=editors&amp;ust=1730413584176941&amp;usg=AOvVaw3vBEBX_7cm3eUut_zfukuy">https://www.pcgamer.com/how-much-power-does-my-pc-use/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Most</span><span class="c1">&nbsp;of their spending is on research. Even if they plateau, they can still easily profit by giving up on improving the AI and selling their extra GPUs so their only major cost is running inference for their existing models, which is much cheaper than training them from scratch.</span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 346.67px;"><img alt="" src="images/image631.png" style="width: 624.00px; height: 346.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 285.33px;"><img alt="" src="images/image161.png" style="width: 624.00px; height: 285.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 454.67px;"><img alt="" src="images/image538.png" style="width: 624.00px; height: 454.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span>According to Thompson&rsquo;s estimate, OpenAI&rsquo;s most expensive RELEASED model (GPT 4) cost $224 million, which is 0.14% of their $157 BILLION valuation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2024/10/02/openai-raises-at-157-billion-valuation-microsoft-nvidia-join-round.html&amp;sa=D&amp;source=editors&amp;ust=1730413584177562&amp;usg=AOvVaw3Ab4FHg7CFhzRZX9-fktvT">https://www.cnbc.com/2024/10/02/openai-raises-at-157-billion-valuation-microsoft-nvidia-join-round.html</a></span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.4hl0usql6g1"><span class="c40 c37 c48 c75">13.3. AI Is Becoming More Efficient </span></h2><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Addition is All You Need for Energy-efficient Language Models. &quot;This will deliver high-speed and energy-efficient AI hosting solutions, reducing the energy cost for data centers, robotics, and a wide spectrum of edge-computing devices.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.00907&amp;sa=D&amp;source=editors&amp;ust=1730413584177966&amp;usg=AOvVaw1UsBil8I99oh3v4zJWkXse">https://arxiv.org/abs/2410.00907</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span>We propose the </span><span class="c15">linear-complexity </span><span>multiplication L-Mul algorithm that approximates floating point number multiplication with integer addition operations. The new algorithm </span><span class="c15">costs significantly less computation resource than 8-bit floating point multiplication but achieves higher precision</span><span>. Compared to 8-bit floating point multiplications, the proposed method </span><span class="c15">achieves higher precision but consumes significantly less bit-level computation. </span><span>Since multiplying floating point numbers requires substantially higher energy compared to integer addition operations, applying the L-Mul operation in tensor processing hardware </span><span class="c15">can potentially reduce 95% energy cost by element-wise floating point tensor multiplications and 80% energy cost of dot products</span><span class="c1">. </span></li><li class="c10 li-bullet-0"><span>Our numerical analysis experiments agree with the theoretical error estimation, which indicates that L-Mul with 4-bit mantissa achieves </span><span class="c34">comparable precision</span><span>&nbsp;as float8_e4m3 multiplications, and L-Mul with </span><span class="c15">3-bit mantissa outperforms float8_e5m2</span><span>. Evaluation results on popular benchmarks show that directly applying L-Mul to the attention mechanism is </span><span class="c15">almost lossless</span><span>. We further show that replacing all floating point multiplications with 3-bit mantissa L-Mul in a transformer model </span><span class="c34">achieves equivalent precision as using float8_e4m3</span><span class="c1">&nbsp;as accumulation precision in both fine-tuning and inference</span></li><li class="c10 li-bullet-0"><span>To unlock the full potential of our proposed method, we will implement the L-Mul and L-Matmul kernel algorithms on hardware level and develop programming APIs for high-level model design. Furthermore, we will train textual, symbolic, and multi-modal generative AI models optimized for deployment on L-Mul native hardware. This will deliver </span><span class="c33 c15">high-speed and energy-efficient AI hosting solutions, reducing the energy cost for data centers, robotics, and a wide spectrum of edge-computing devices.</span></li><li class="c10 li-bullet-0"><span class="c1">&nbsp;<br>CONCLUSION:</span></li><li class="c10 li-bullet-0"><span>In this paper, we introduced L-Mul, an efficient algorithm that approximates floating-point multiplication using integer addition. We first demonstrated that the algorithm exhibits </span><span class="c34">linear complexity </span><span>relative to the bit size of its floating-point operands. We then showed that the </span><span class="c15">expected accuracy of L-Mul surpasses that of fp8 multiplications while requiring significantly less computational power</span><span>. To assess the practical impact of L-Mul, we evaluated it on natural language, vision, and mathematics benchmarks using popular language models. Our experiments indicate that </span><span class="c15">L-Mul outperforms 8-bit transformers with lower computational consumption and achieves lossless performance</span><span>&nbsp;when applied to computation-intensive attention layers without additional training. Based on this evidence, we argue that </span><span class="c33 c15">tensor multiplications in language models can be effectively implemented using L-Mul to preserve performance while enabling energy-efficient model deployment.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>&nbsp;new quantized versions of Llama 3.2 1B &amp; 3B that deliver up to 2-4x increases in inference speed and, on average, 56% reduction in model size, and 41% reduction in memory footprint: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/AIatMeta/status/1849469912521093360&amp;sa=D&amp;source=editors&amp;ust=1730413584179251&amp;usg=AOvVaw2hcwNp0pPM7Ih45ppe60a4">https://x.com/AIatMeta/status/1849469912521093360</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>&gt;While quantized models have existed in the community before, these approaches often came at a tradeoff between performance and accuracy. To solve this, we Quantization-Aware Training with LoRA adaptors as opposed to only post-processing. As a result, our new models </span><span class="c15">offer a reduced memory footprint, faster on-device inference, accuracy and portability &mdash; while maintaining quality and safety for developers to deploy on resource-constrained devices.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 386.67px;"><img alt="" src="images/image310.png" style="width: 624.00px; height: 386.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 596.50px; height: 302.07px;"><img alt="" src="images/image569.png" style="width: 596.50px; height: 302.07px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.55px; height: 550.50px;"><img alt="" src="images/image155.png" style="width: 600.55px; height: 550.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. </span><span class="c15">13B models achieve similar accuracy with this method (while using only 2K training samples) as GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413584179959&amp;usg=AOvVaw2CEug02AL8OFsr6zu-gD9l">https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Google DeepMind&#39;s JEST method can </span><span class="c15">reduce AI training time by a factor of 13 and decreases computing power demand by 90%.</span><span>&nbsp;The method uses another pretrained reference model to select data subsets for training based on their &quot;collective learnability: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.17711v1&amp;sa=D&amp;source=editors&amp;ust=1730413584180246&amp;usg=AOvVaw3DBYrgs80pnfmSCDxWhHCY">https://arxiv.org/html/2406.17711v1</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Blackwell GPUs are 25x more energy efficient than H100s: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/3/18/24105157/nvidia-blackwell-gpu-b200-ai&amp;sa=D&amp;source=editors&amp;ust=1730413584180534&amp;usg=AOvVaw16O8qmQRbpxX2TfvQ4y-uC">https://www.theverge.com/2024/3/18/24105157/nvidia-blackwell-gpu-b200-ai</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Significantly more energy efficient LLM variant: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.17764&amp;sa=D&amp;source=editors&amp;ust=1730413584180784&amp;usg=AOvVaw1B2F5lE01Rsx_fAphbCARO">https://arxiv.org/abs/2402.17764</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single parameter (or weight) of the LLM is ternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16) Transformer LLM with the same model size and training tokens in terms of both perplexity and end-task performance, while being </span><span class="c15">significantly more cost-effective in terms of latency, memory, throughput, and energy consumption. </span><span class="c1">More profoundly, the 1.58-bit LLM defines a new scaling law and recipe for training new generations of LLMs that are both high-performance and cost-effective. Furthermore, it enables a new computation paradigm and opens the door for designing specific hardware optimized for 1-bit LLMs.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Study on increasing energy efficiency of ML data centers: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2104.10350&amp;sa=D&amp;source=editors&amp;ust=1730413584181215&amp;usg=AOvVaw3iMvKmDwv4TldRGOLKgFLc">https://arxiv.org/abs/2104.10350</a></span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c14 c31">Large but sparsely activated DNNs can consume &lt;1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO2e vary ~5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. Specific datacenter infrastructure matters, as Cloud datacenters can be ~1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be ~2-5X more effective than off-the-shelf systems. </span><span class="c28 c43">Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to ~100-1000X.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Scalable MatMul-free Language Modeling: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.02528&amp;sa=D&amp;source=editors&amp;ust=1730413584181643&amp;usg=AOvVaw3E-My_L-bIfmQknrSUrTid">https://arxiv.org/abs/2406.02528</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c14 c31">In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model&#39;s memory consumption can be reduced by more than 10x compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. </span><span class="c15 c31">We processed billion-parameter scale models at 13W beyond human readable throughput</span><span class="c3">, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>Implemented by Deepsilicon running neural nets with </span><span class="c15">5x less RAM and ~20x faster.</span><span>&nbsp;They are building software and custom silicon for it: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/sdianahu/status/1833186687369023550&amp;sa=D&amp;source=editors&amp;ust=1730413584182166&amp;usg=AOvVaw2AaxUD_n-XnyBvgyuSLdMr">https://x.com/sdianahu/status/1833186687369023550</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-2"><li class="c7 li-bullet-0"><span class="c1">&rdquo;representing transformer models as ternary values (-1, 0, 1) eliminates the need for computationally expensive floating-point math&quot; </span></li><li class="c7 li-bullet-0"><span class="c1">Runs SOTA models </span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c22 c32 li-bullet-0"><span class="c30 c37">Lisa Su says AMD is on track to a </span><span class="c30 c15">100x power efficiency improvement by 2027: </span><span class="c5 c30 c37"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/pc-components/cpus/lisa-su-announces-amd-is-on-the-path-to-a-100x-power-efficiency-improvement-by-2027-ceo-outlines-amds-advances-during-keynote-at-imecs-itf-world-2024&amp;sa=D&amp;source=editors&amp;ust=1730413584182698&amp;usg=AOvVaw2FfwYBzQwXhq3ZybZeMt-P">https://www.tomshardware.com/pc-components/cpus/lisa-su-announces-amd-is-on-the-path-to-a-100x-power-efficiency-improvement-by-2027-ceo-outlines-amds-advances-during-keynote-at-imecs-itf-world-2024</a></span><span class="c40 c30 c37">&nbsp;</span></li></ul><p class="c22 c44"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c22 c32 li-bullet-0"><span>Intel unveils brain-inspired neuromorphic chip system for more energy-efficient AI workloads: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://siliconangle.com/2024/04/17/intel-unveils-powerful-brain-inspired-neuromorphic-chip-system-energy-efficient-ai-workloads/&amp;sa=D&amp;source=editors&amp;ust=1730413584183083&amp;usg=AOvVaw0vIrJj1l7Ui-UX8uMTIfD9">https://siliconangle.com/2024/04/17/intel-unveils-powerful-brain-inspired-neuromorphic-chip-system-energy-efficient-ai-workloads/</a></span><span class="c1">&nbsp;</span></li></ul><p class="c22 c44"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Sohu is</span><span class="c15">&nbsp;&gt;10x faster and cheaper than even NVIDIA&rsquo;s next-generation Blackwell (B200) </span><span>GPUs. One Sohu server runs over 500,000 Llama 70B tokens per second, </span><span class="c15">20x more than an H100 server (23,000 tokens/sec), and 10x more than a B200 server (~45,000 tokens/sec):</span><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/tech-industry/artificial-intelligence/sohu-ai-chip-claimed-to-run-models-20x-faster-and-cheaper-than-nvidia-h100-gpus&amp;sa=D&amp;source=editors&amp;ust=1730413584183528&amp;usg=AOvVaw1WfQOKFAsY-h4Jfy5W9tYO">https://www.tomshardware.com/tech-industry/artificial-intelligence/sohu-ai-chip-claimed-to-run-models-20x-faster-and-cheaper-than-nvidia-h100-gpus</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 376.93px; height: 506.50px;"><img alt="" src="images/image175.png" style="width: 376.93px; height: 506.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Engineering researchers at the University of Minnesota Twin Cities have demonstrated a state-of-the-art hardware device that could reduce energy consumption for artificial intelligent (AI) computing applications by a factor of at least 1,000: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cse.umn.edu/college/news/researchers-develop-state-art-device-make-artificial-intelligence-more-energy&amp;sa=D&amp;source=editors&amp;ust=1730413584184042&amp;usg=AOvVaw0bol_hQokyCO1LIfQM4aI0">https://cse.umn.edu/college/news/researchers-develop-state-art-device-make-artificial-intelligence-more-energy</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">Do you know your LLM uses less than 1% of your GPU at inference? Too much time is wasted on KV cache memory access &#10145;&#65039; We tackle this with the &#127873; Block Transformer: a </span><span class="c15 c31">global-to-local architecture that speeds up decoding up to 20x: </span><span class="c5 c15 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/itsnamgyu/status/1807400609429307590&amp;sa=D&amp;source=editors&amp;ust=1730413584184485&amp;usg=AOvVaw0CzQEbcAhxN-n8wOXdB2td">https://x.com/itsnamgyu/status/1807400609429307590</a></span><span class="c15 c31">&nbsp;</span></li></ul><p class="c131 c53 c56 c46"><span class="c40 c37 c48 c31"></span></p><p class="c22 c44"><span class="c40 c30 c37"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>It is possible to get the same performance on &#8533; the amount of training: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Yuchenj_UW/status/1806713556047716603&amp;sa=D&amp;source=editors&amp;ust=1730413584184982&amp;usg=AOvVaw03KpKXz0smTm-i7PtpMRoY">https://x.com/Yuchenj_UW/status/1806713556047716603</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Mixture of A Million Experts. Daniel Jeffries:&quot;</span><span class="c15">Reduces inference cost and memory usage, scales to millions of experts, oh and just happens to overcome catastrophic forgetting and enable life long learning for the model</span><span>.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.04153&amp;sa=D&amp;source=editors&amp;ust=1730413584185380&amp;usg=AOvVaw0fPrdmehi-_u7qxOqS9YKH">https://arxiv.org/abs/2407.04153</a></span></li></ul><p class="c9"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>This paper introduces PEER (parameter efficient expert retrieval), a novel layer design that utilizes the product key technique for sparse retrieval from a vast pool of tiny experts (over a million). Experiments on language modeling tasks demonstrate that </span><span class="c34">PEER layers outperform dense FFWs and coarse-grained MoEs in terms of performance-compute trade-off</span><span>. By enabling efficient utilization of a massive number of experts, PEER </span><span class="c34">unlocks the potential for further scaling of transformer models while maintaining computational efficiency</span><span class="c1">.</span></li><li class="c10 li-bullet-0"><span class="c1">It has been proved that by simply adding new experts and regularizing them properly, MoE models can adapt to continuous data streams</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c131 c53 c56 c78 li-bullet-0"><span>E5-V: Universal Embeddings with Multimodal Large Language Models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.12580&amp;sa=D&amp;source=editors&amp;ust=1730413584186149&amp;usg=AOvVaw2uNiHYeFmd8wJgEV93QtMv">https://huggingface.co/papers/2407.12580</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span>By leveraging MLLMs with prompts, E5-V effectively bridges the modality gap between different types of inputs, demonstrating strong performance in multimodal embeddings even without fine-tuning. We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs. This method demonstrates </span><span class="c15">significant improvements over traditional multimodal training on image-text pairs, while reducing training costs by approximately 95%. </span><span>Additionally, this approach</span><span class="c43">&nbsp;</span><span class="c15">eliminates the need for costly multimodal training data collection</span><span>. Extensive experiments across four types of tasks demonstrate the effectiveness of E5-V. As a universal multimodal model, E5-V not only achieves but often </span><span class="c33 c15">surpasses state-of-the-art performance in each task, despite being trained on a single modality.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c15">New training technique to reduce computation cost: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.12665&amp;sa=D&amp;source=editors&amp;ust=1730413584186730&amp;usg=AOvVaw2jrswBf5Fk32e5_PiUb4hm">https://huggingface.co/papers/2407.12665</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">During patch-level training, we feed the language model shorter sequences of patches and train it to predict the next patch, thereby processing the majority of the training data at a </span><span class="c15 c31">significantly reduced computational cost</span><span class="c14 c31">. Following this, the model continues token-level training on the remaining training data to align with the inference mode. Experiments on a diverse range of models (370M-2.7B parameters) demonstrate that patch-level training can </span><span class="c15 c31">reduce overall computational costs to 0.5x</span><span class="c3">, without compromising the model performance compared to token-level training.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>RGM, active inference non-llm approach using </span><span class="c15">90% less data (less need for synthetic data, lower energy footprint). 99.8% accuracy in MNIST </span><span>benchmark using 90% less data to train on less powerful devices: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.20292&amp;sa=D&amp;source=editors&amp;ust=1730413584187139&amp;usg=AOvVaw1frzBy2UxOzW709-fauiXq">https://arxiv.org/pdf/2407.20292</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c1">Use for Atari game performance: &ldquo;This fast structure learning took about 18 seconds on a personal computer. &ldquo;</span></li><li class="c10 li-bullet-0"><span class="c1">Use for MNIST dataset classification: For example, the variational procedures above attained state-of-the-art classification accuracy on a self-selected subset of test data after seeing 10,000 training images. Each training image was seen once, with continual learning (and no notion of batching). Furthermore, the number of training images actually used for learning was substantially smaller10 than 10,000; because active learning admits only those informative images that reduce expected free energy. This (Maxwell&rsquo;s Demon) aspect of selecting the right kind of data for learning will be a recurrent theme in subsequent sections. Finally, the requisite generative model was self-specifying, given some exemplar data. In other words, the hierarchical depth and size of the requisite tensors were learned automatically within a few seconds on a personal computer.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c14 c31">Scaling Diffusion Transformers to 16 Billion Parameters: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.11633&amp;sa=D&amp;source=editors&amp;ust=1730413584187581&amp;usg=AOvVaw2dvhG3rBjiAzZdoSD34Iig">https://huggingface.co/papers/2407.11633</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">Based on the above guidance, a series of DiT-MoE experimentally achieves performance on par with dense networks yet requires</span><span class="c15 c31">&nbsp;much less computational load during inference</span><span class="c14 c31">. More encouragingly, we demonstrate the potential of DiT-MoE with </span><span class="c15 c31">synthesized image data,</span><span class="c14 c31">&nbsp;scaling diffusion model at a 15.5B parameter that attains</span><span class="c28 c43">&nbsp;a new SoTA FID-50K score of 1.80 in 512x512 resolution settings.</span></li><li class="c10 li-bullet-0"><span class="c40 c37 c48 c31">For reference, Stable Diffusion XL is only about 3 billion parameters</span></li></ul><p class="c9"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c31">Very efficient image diffusion training method: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.11966&amp;sa=D&amp;source=editors&amp;ust=1730413584188118&amp;usg=AOvVaw3th7LK3cSDXpXbify_RYVV">https://huggingface.co/papers/2407.11966</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c31">Compared to training from scratch (i.e., Pix2pix), we achieve a </span><span class="c28 c43">15x training time acceleration for a new concept while obtaining even better image generation quality.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c1 c14">August 6 GPT 4o update:</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c14">The new GPT-4o is </span><span class="c15">slightly better and 33% cheaper than the old one!</span><span class="c1 c14">&nbsp; Right now, it&#39;s only a tad below Sonnet 3.5 on Livebench!</span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 594.67px;"><img alt="" src="images/image262.png" style="width: 624.00px; height: 594.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 342.67px;"><img alt="" src="images/image115.png" style="width: 624.00px; height: 342.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c130 c78 li-bullet-0"><span>OpenAI unveils GPT-4o mini, a smaller and cheaper AI model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?guccounter%3D2&amp;sa=D&amp;source=editors&amp;ust=1730413584188780&amp;usg=AOvVaw0Gygqna8Q5JlTqGLE7RLCJ">https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?guccounter=2</a></span></li></ul><p class="c130 c46"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c47 li-bullet-0"><span class="c67 c37">The company says GPT-4o mini outperforms industry leading small AI models on reasoning tasks involving text and vision. As small AI models improve, they are becoming more popular for developers due to their speed and cost efficiencies compared to larger models, such as </span><span class="c37 c103 c68 c126"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/05/13/openais-newest-model-is-gpt-4o/&amp;sa=D&amp;source=editors&amp;ust=1730413584189102&amp;usg=AOvVaw2tRb1HTxxMj0-_p5KV1LgQ">GPT-4 Omni</a></span><span class="c37 c67">&nbsp;or </span><span class="c37 c103 c68 c126"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/&amp;sa=D&amp;source=editors&amp;ust=1730413584189279&amp;usg=AOvVaw1lu5DjcHGk1gL4SP__D-1C">Claude 3.5 Sonnet</a></span><span class="c79 c37 c103 c126">. They&rsquo;re a useful option for high volume, simple tasks that developers might repeatedly call on an AI model to perform.</span></li><li class="c47 li-bullet-0"><span class="c67 c37">The company claims its newest AI model scores 82% on MMLU, a benchmark to measure reasoning, compared to 79% for Gemini 1.5 Flash and 75% for Claude 3 Haiku, according to data from </span><span class="c37 c103 c68 c126"><a class="c13" href="https://www.google.com/url?q=https://artificialanalysis.ai/models&amp;sa=D&amp;source=editors&amp;ust=1730413584189514&amp;usg=AOvVaw2f651kbpPzfM4WpqgfPqUE">Artificial Analysis</a></span><span class="c79 c37 c103 c126">. On MGSM, which measures math reasoning, GPT-4o mini scored 87%, compared to 78% for Flash and 72% for Haiku.</span></li><li class="c47 li-bullet-0"><span class="c67 c37">Further, OpenAI says GPT-4o mini is significantly more affordable to run than its previous frontier models, and more than </span><span class="c67 c15">60% cheaper than GPT-3.5 Turbo</span><span class="c79 c37 c103 c126">. Today, GPT-4o mini supports text and vision in the API, and OpenAI says the model will support video and audio capabilities in the future.</span></li><li class="c47 li-bullet-0"><span class="c40 c37 c63 c76">So, what took OpenAI so long? Godement said it was &ldquo;pure prioritization&rdquo; as the company was focused on creating bigger and better models like GPT-4, which took a lot of &ldquo;people and compute efforts.&rdquo;</span></li><li class="c47 li-bullet-0"><span class="c37 c63 c76">LMSYS arena shows it is better than GPT 4 and Claude 3 Opus</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image560.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 326.67px;"><img alt="" src="images/image144.png" style="width: 624.00px; height: 326.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://x.com/terryyuezhuo/status/1813998867039617444&amp;sa=D&amp;source=editors&amp;ust=1730413584190044&amp;usg=AOvVaw31o2lPT6VlB4v3c-autd9Y">https://x.com/terryyuezhuo/status/1813998867039617444</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-2 start"><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">GPT-4o mini on BigCodeBench-Hard is out:</span></li><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">Complete Pass@1: 27.0</span></li><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">Instruct Pass@1: 24.3</span></li><li class="c86 c130 li-bullet-0"><span class="c40 c37 c63 c76">Average: 25.7</span></li><li class="c130 c86 li-bullet-0"><span class="c40 c37 c63 c76">The average score is very close to Claude-3-Opus (26.0)!</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c47 li-bullet-0"><span class="c37 c63 c76">RewardBench: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 82.67px;"><img alt="" src="images/image34.png" style="width: 624.00px; height: 82.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span class="c37 c63 c76">WildBench: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 194.67px;"><img alt="" src="images/image281.png" style="width: 624.00px; height: 194.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c47 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 868.00px;"><img alt="" src="images/image157.png" style="width: 624.00px; height: 868.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c130 c78 li-bullet-0"><span class="c37 c63 c76">Google </span><span class="c15 c63 c76">drops cost of Gemini 1.5 Flash by 80-85%</span><span class="c37 c63 c76">: </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/blog/products/ai-machine-learning/lower-costs-more-languages-for-gemini-on-vertex?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1730413584191127&amp;usg=AOvVaw3-DV1mrGgODRBhuMHUuXnn">https://cloud.google.com/blog/products/ai-machine-learning/lower-costs-more-languages-for-gemini-on-vertex?hl=e</a></span><span class="c40 c37 c63 c76">n</span></li><li class="c131 c78 li-bullet-0"><span>Q-Sparse: All Large Language Models can be Fully Sparsely-Activated: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.10969&amp;sa=D&amp;source=editors&amp;ust=1730413584191441&amp;usg=AOvVaw2dA0xRuoGaY2tdN1Raonze">https://arxiv.org/abs/2407.10969</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c47 li-bullet-0"><span class="c14 c31">The key results from this work are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs while being </span><span class="c15 c31">much more efficient at inference time</span><span class="c14 c31">; (2) We present an inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is </span><span class="c14 c31 c34">effective in different settings, including training-from-scratch, continue-training of off-the-shelf LLMs, and finetuning;</span><span class="c14 c31">&nbsp;(4) Q-Sparse works for both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the cornerstone and a </span><span class="c28 c43">clear path to revolutionize the efficiency, including cost and energy consumption, of future LLMs.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>RouteLLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://lmsys.org/blog/2024-07-01-routellm/&amp;sa=D&amp;source=editors&amp;ust=1730413584192049&amp;usg=AOvVaw2g3Xixb-uL6Q_1Gfh9D7G1">https://lmsys.org/blog/2024-07-01-routellm/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>they can </span><span class="c15">significantly reduce costs without compromising quality</span><span class="c1">, with cost reductions of over 85% on MT Bench, 45% on MMLU, and 35% on GSM8K as compared to using only GPT-4, while still achieving 95% of GPT-4&rsquo;s performance</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 433.50px; height: 384.18px;"><img alt="" src="images/image454.png" style="width: 433.50px; height: 384.18px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c130 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image346.png" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c131 c78 li-bullet-0"><span>Q-Sparse: All Large Language Models can be Fully Sparsely-Activated: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.10969&amp;sa=D&amp;source=editors&amp;ust=1730413584192844&amp;usg=AOvVaw2PQ99ZDX715sASLLvuAI2E">https://arxiv.org/abs/2407.10969</a></span></li></ul><p class="c131 c46"><span class="c3"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c47 li-bullet-0"><span class="c14 c31">The key results from this work are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs while being </span><span class="c15 c31">much more efficient at inference time</span><span class="c14 c31">; (2) We present an inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is </span><span class="c34 c14 c31">effective in different settings, including training-from-scratch, continue-training of off-the-shelf LLMs, and finetuning;</span><span class="c14 c31">&nbsp;(4) Q-Sparse works for both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the cornerstone and a </span><span class="c28 c43">clear path to revolutionize the efficiency, including cost and energy consumption, of future LLMs.</span></li></ul><p class="c130 c46"><span class="c28 c43"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c130 c78 li-bullet-0"><span>Research on AI agents: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/rohanpaul_ai/status/1814029081819615364&amp;sa=D&amp;source=editors&amp;ust=1730413584193717&amp;usg=AOvVaw1mGc-MY_7cdH-rorkFxqym">https://x.com/rohanpaul_ai/status/1814029081819615364</a></span></li></ul><p class="c130 c46"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c47 li-bullet-0"><span>&gt;&#128204; AI agent evaluations must be cost-controlled. </span><span class="c15">Simple baselines like retrying or gradually increasing model temperature can match or outperform complex &quot;state-of-the-art&quot; agents on benchmarks like HumanEval while costing much less.</span></li><li class="c47 li-bullet-0"><span>&#128204; Jointly </span><span class="c15">optimizing accuracy and cost can yield better agent designs. </span><span>By visualizing results as a Pareto curve of accuracy vs. inference cost, researchers can explore new design spaces. An example modification to the DSPy framework </span><span class="c15">reduced costs by over 50% while maintaining accuracy on HotPotQA.</span></li></ul><p class="c130 c46"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c130 c78 li-bullet-0"><span class="c15 c31">&nbsp;Finetuning NeMo 12B (from its in 12GB of VRAM and is 2x faster, and uses 60% less VRAM, with no accuracy degradation and works for free in a Google Colab: </span><span class="c5 c34 c31"><a class="c13" href="https://www.google.com/url?q=https://x.com/rohanpaul_ai/status/1814482763472613551&amp;sa=D&amp;source=editors&amp;ust=1730413584194606&amp;usg=AOvVaw2MI4hXtCRGts4CXzEBBzBl">https://x.com/rohanpaul_ai/status/1814482763472613551</a></span></li><li class="c130 c78 li-bullet-0"><span class="c40 c37 c48 c31">LookupViT: https://x.com/fly51fly/status/1814058398847058044 </span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c47 li-bullet-0"><span class="c31">- LookupViT introduces a novel Multi-Head Bidirectional Cross-attention (MHBC) module that enables effective information flow with </span><span class="c28">significant computational savings.</span></li><li class="c47 li-bullet-0"><span class="c31">- LookupViT</span><span class="c34 c31">&nbsp;reduces quadratic dependence on number of lookup tokens and achieves significant FLOPs reduction</span><span class="c40 c37 c48 c31">&nbsp;compared to vanilla ViT blocks.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Sparsecraft: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1815204831679664191&amp;sa=D&amp;source=editors&amp;ust=1730413584195327&amp;usg=AOvVaw3hgwgTLPEhXNf0E8OAW925">https://x.com/_akhaliq/status/1815204831679664191</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c1">our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Training a diffusion model better than stable diffusion 1.5 and DALLE 2 from scratch for $1890 on only 37 million images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.15811&amp;sa=D&amp;source=editors&amp;ust=1730413584195742&amp;usg=AOvVaw3BrGlO1xpJ4OUkwrEqqH_N">https://arxiv.org/abs/2407.15811</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span class="c3">using only 37M publicly available real and synthetic images, we train a 1.16 billion parameter sparse transformer with only $1,890 economical cost and achieve a 12.7 FID in zero-shot generation on the COCO dataset. Notably, our model achieves competitive FID and high-quality generations while incurring 118x lower cost than stable diffusion models and 14x lower cost than the current state-of-the-art approach that costs $28,400.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1148.00px;"><img alt="" src="images/image290.png" style="width: 624.00px; height: 1148.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 458.67px;"><img alt="" src="images/image146.png" style="width: 624.00px; height: 458.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c14 c31">Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2408.03314&amp;sa=D&amp;source=editors&amp;ust=1730413584196529&amp;usg=AOvVaw1DAfpVTX5JL_-Wvp7gEG9B">https://huggingface.co/papers/2408.03314</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span>This observation motivates applying a &quot;compute-optimal&quot; scaling strategy, which acts to most </span><span class="c34">effectively allocate test-time compute adaptively per prompt.</span><span>&nbsp;Using this compute-optimal strategy, we can</span><span class="c15">&nbsp;improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline</span><span>. Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller base model attains somewhat non-trivial success rates, test-time compute can be used to </span><span class="c33 c15">outperform a 14x larger model.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Japanese scientists developed simplified EUV scanner that can make production of chips considerably cheaper: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.tomshardware.com/tech-industry/japanese-scientists-develop-simplified-euv-scanner-that-can-make-production-of-chips-considerably-cheaper&amp;sa=D&amp;source=editors&amp;ust=1730413584197309&amp;usg=AOvVaw3-WVv68jPvvUDo2DdjO-E1">https://www.tomshardware.com/tech-industry/japanese-scientists-develop-simplified-euv-scanner-that-can-make-production-of-chips-considerably-cheaper</a></span></li><li class="c4 li-bullet-0"><span class="c1">Nvidia Research team has developed a method to efficiently create smaller, accurate language models by using structured weight pruning and knowledge distillation, offering several advantages for developers:</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c1">16% better performance on MMLU scores.</span></li><li class="c10 li-bullet-0"><span class="c1">40x fewer tokens for training new models.</span></li><li class="c10 li-bullet-0"><span class="c1">Up to 1.8x cost saving for training a family of models.</span></li><li class="c10 li-bullet-0"><span>The effectiveness of these strategies is demonstrated with the Meta Llama 3.1 8B model, which was refined into the Llama-3.1-Minitron 4B. The collection on huggingface: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e&amp;sa=D&amp;source=editors&amp;ust=1730413584198037&amp;usg=AOvVaw2GKuR2WeIfA_1tjV-aKAx4">https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e</a></span></li><li class="c10 li-bullet-0"><span>Technical dive: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model&amp;sa=D&amp;source=editors&amp;ust=1730413584198402&amp;usg=AOvVaw0EUNlAVIIBZwh_8bopXjt2">https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model</a></span></li><li class="c10 li-bullet-0"><span>Research paper: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.14679&amp;sa=D&amp;source=editors&amp;ust=1730413584198694&amp;usg=AOvVaw1Z4aJsOnNieMHxqea9AmKQ">https://arxiv.org/abs/2407.14679</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Nous Research announces DisTrO: Distributed Optimizers with 1000x-10,000x reduced inter-GPU communication: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/NousResearch/DisTrO/blob/main/A_Preliminary_Report_on_DisTrO.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584199037&amp;usg=AOvVaw1dIoZJkkqp45Eis8rrUJjW">https://github.com/NousResearch/DisTrO/blob/main/A_Preliminary_Report_on_DisTrO.pdf</a></span></li></ul><ul class="c0 lst-kix_3hrtg26wb9bu-0 start"><li class="c10 li-bullet-0"><span class="c1">It matches AdamW+All-Reduce in convergence speed</span></li><li class="c4 li-bullet-0"><span>Can Smaller AI Models Outperform Giants? This AI Paper from Google DeepMind Unveils the Power of &lsquo;Smaller, Weaker, Yet Better&rsquo; Training for LLM Reasoners: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.marktechpost.com/2024/09/01/can-smaller-ai-models-outperform-giants-this-ai-paper-from-google-deepmind-unveils-the-power-of-smaller-weaker-yet-better-training-for-llm-reasoners/&amp;sa=D&amp;source=editors&amp;ust=1730413584199558&amp;usg=AOvVaw0_VViEPSiWaZxDFbetzBB-">https://www.marktechpost.com/2024/09/01/can-smaller-ai-models-outperform-giants-this-ai-paper-from-google-deepmind-unveils-the-power-of-smaller-weaker-yet-better-training-for-llm-reasoners/</a></span></li></ul><ul class="c0 lst-kix_3hrtg26wb9bu-1 start"><li class="c10 li-bullet-0"><span>Small models are much cheaper to use </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 377.33px;"><img alt="" src="images/image412.png" style="width: 624.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 586.60px; height: 254.43px;"><img alt="" src="images/image586.png" style="width: 586.60px; height: 254.43px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 596.02px; height: 253.25px;"><img alt="" src="images/image516.png" style="width: 596.02px; height: 253.25px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_3hrtg26wb9bu-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2409.02889&amp;sa=D&amp;source=editors&amp;ust=1730413584200079&amp;usg=AOvVaw04-_dTlJt8WY7D3gPV_AjX">https://huggingface.co/papers/2409.02889</a></span></li></ul><ul class="c0 lst-kix_3hrtg26wb9bu-1 start"><li class="c10 li-bullet-0"><span>The released model LongLLaVA~(Long-Context Large Language and Vision Assistant) is the first hybrid MLLM, which achieved a better balance between efficiency and effectiveness. LongLLaVA not only achieves competitive results across various benchmarks, but also maintains high throughput and low memory consumption. Especially, it could </span><span class="c15">process nearly a thousand images on a single A100 80GB GPU,</span><span class="c1">&nbsp;showing promising application prospects for a wide range of tasks.</span></li></ul><ul class="c0 lst-kix_3hrtg26wb9bu-0"><li class="c4 li-bullet-0"><span>OpenMoE model has best performance/cost ratio for small models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2409.02060&amp;sa=D&amp;source=editors&amp;ust=1730413584200534&amp;usg=AOvVaw2rZIiLgBT2Y6Vxd98hjAfH">https://arxiv.org/pdf/2409.02060</a></span></li></ul><ul class="c0 lst-kix_3hrtg26wb9bu-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 364.00px;"><img alt="" src="images/image409.png" style="width: 624.00px; height: 364.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2409.00509&amp;sa=D&amp;source=editors&amp;ust=1730413584200901&amp;usg=AOvVaw0EF7BioJcabpRiLVKp0goQ">https://huggingface.co/papers/2409.00509</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span>we introduce **LongRecipe**, an efficient training strategy for extending the context window of LLMs, including impactful token analysis, position index transformation, and training optimization strategies. It simulates long-sequence inputs while </span><span class="c15">maintaining training efficiency and significantly improves the model&#39;s understanding of long-range dependencies</span><span>. Experiments on three types of LLMs show that LongRecipe can utilize long sequences while requiring only 30% of the target context window size, and </span><span class="c15">reduces computational training resource over 85% compared to full sequence training</span><span>. Furthermore, LongRecipe </span><span class="c34">also preserves the original LLM&#39;s capabilities in general tasks.</span><span>&nbsp;Ultimately, *we can extend the effective content window of open-source LLMs</span><span class="c15">&nbsp;from 8k to 128k, achieving performance close to GPT-4 with just one day of dedicated training using a single GPU with 80G memory</span><span>.* Our code is released at </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/zhiyuanhubj/LongRecipe&amp;sa=D&amp;source=editors&amp;ust=1730413584201318&amp;usg=AOvVaw3bB18F77-TzzJ0HkKLXgTg">https://github.com/zhiyuanhubj/LongRecipe</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>&ldquo;</span><span>SkillMimic&quot; uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmimic_uses_just_35_minutes_of_video_and/&amp;sa=D&amp;source=editors&amp;ust=1730413584201581&amp;usg=AOvVaw2qsFC_S58Lrmx9vmreB3dh">https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmimic_uses_just_35_minutes_of_video_and/</a></span></li><li class="c4 li-bullet-0"><span class="c31">The Memory^3 model</span><span class="c15 c31">&nbsp;achieved better performance than larger models and RAG models on various benchmarks, while maintaining higher decoding speed</span><span class="c31">. It showed particular improvements in </span><span class="c15 c31">factuality and reduced hallucination</span><span class="c31">: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2407.01178v1&amp;sa=D&amp;source=editors&amp;ust=1730413584201892&amp;usg=AOvVaw0nH3SEDhpxEDuRkx6lDVP3">https://arxiv.org/html/2407.01178v1</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c1">we reduce cost by equipping LLMs with an explicit memory format cheaper than model parameters and text retrieval-augmented generation (RAG).</span></li><li class="c10 li-bullet-0"><span>Conceptually, with most of its knowledge externalized to explicit memory, the LLM can enjoy a</span><span class="c43">&nbsp;</span><span class="c33 c15">smaller parameter size, training cost, and inference cost, all proportional to the amount of remaining &ldquo;abstract knowledge&rdquo;.</span></li><li class="c10 li-bullet-0"><span>As a preliminary proof of concept, we train from scratch a 2.4B LLM, which achieves </span><span class="c33 c15">better performance than much larger LLMs as well as RAG models, and maintains higher decoding speed than RAG.</span></li><li class="c10 li-bullet-0"><span class="c1">We introduce a memory circuitry theory to support the externalization of knowledge, and present novel techniques including a memory sparsification mechanism that makes storage tractable and a two-stage pretraining scheme that facilitates memory formation.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c1">Molmo: State of the art multimodal open source using 1000x less data</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c1">&quot;Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">Outperforming GPT-4o, Gemini 1.5 Pro &amp; Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.</span></li><li class="c10 li-bullet-0"><span>Info: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/blog&amp;sa=D&amp;source=editors&amp;ust=1730413584202990&amp;usg=AOvVaw0dG6VlqzN3kuTaObRJE37q">https://molmo.allenai.org/blog</a></span></li><li class="c10 li-bullet-0"><span>Try it: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/&amp;sa=D&amp;source=editors&amp;ust=1730413584203252&amp;usg=AOvVaw2l-kJZi79e7s2lgXgkii2O">https://molmo.allenai.org</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2410.01201&amp;sa=D&amp;source=editors&amp;ust=1730413584203479&amp;usg=AOvVaw0z9__kmRAHn3HeJhXJmrU4">https://arxiv.org/pdf/2410.01201</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span>we show that by removing their hidden state dependencies from their input, forget, and update gates, LSTMs and GRUs no longer need to BPTT and can be </span><span class="c34">efficiently trained in parallel</span><span>. Building on this, we introduce minimal versions (minLSTMs and minGRUs) that (1) use </span><span class="c15">sig- nificantly fewer parameters</span><span class="c34">&nbsp;</span><span>than their traditional counterparts and (2) are </span><span class="c34">fully parallelizable </span><span>during training (175&times; faster for a sequence of length 512). Lastly, we show that these stripped-down versions of decade-old RNNs </span><span class="c33 c34">match the empir- ical performance of recent sequence models.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 253.33px;"><img alt="" src="images/image269.png" style="width: 624.00px; height: 253.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-2 start"><li class="c7 li-bullet-0"><span class="c40 c37 c48 c31">Notice how it reaches the lowest loss on the test set long before the transformer does </span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 725.33px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 725.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 213.33px;"><img alt="" src="images/image348.png" style="width: 624.00px; height: 213.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>the first series of Liquid Foundation Models (LFMs) &ndash; a new generation of generative AI models that achieve </span><span class="c15">state-of-the-art performance at every scale, while maintaining a smaller memory footprint and more efficient inference.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.liquid.ai/liquid-foundation-models&amp;sa=D&amp;source=editors&amp;ust=1730413584204461&amp;usg=AOvVaw1jgANOu7FhMq6II67PGE9d">https://www.liquid.ai/liquid-foundation-models</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.liquid.ai/blog/liquid-neural-networks-research&amp;sa=D&amp;source=editors&amp;ust=1730413584204669&amp;usg=AOvVaw0PA3L4HaZBEe90HS40NCwQ">https://www.liquid.ai/blog/liquid-neural-networks-research</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/LiquidAI_/status/1840768716784697688&amp;sa=D&amp;source=editors&amp;ust=1730413584204875&amp;usg=AOvVaw0S2MoG7qY79K_sFUItIakg">https://x.com/LiquidAI_/status/1840768716784697688</a></span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/teortaxesTex/status/1840897331773755476&amp;sa=D&amp;source=editors&amp;ust=1730413584205072&amp;usg=AOvVaw0o6lEXhJgGbVDRrVPGnnO0">https://x.com/teortaxesTex/status/1840897331773755476</a></span></li><li class="c10 li-bullet-0"><span class="c1">&quot;We announce the first series of Liquid Foundation Models (LFMs), a new generation of generative AI models built from first principles.</span></li><li class="c10 li-bullet-0"><span class="c1">Our 1B, 3B, and 40B LFMs achieve state-of-the-art performance in terms of quality at each scale, while maintaining a smaller memory footprint and more efficient inference.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">inference.&quot;</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image313.jpg" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image284.jpg" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 426.67px;"><img alt="" src="images/image525.jpg" style="width: 624.00px; height: 426.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Differential transformer: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.05258&amp;sa=D&amp;source=editors&amp;ust=1730413584205716&amp;usg=AOvVaw2YM2B05v-xaChAWb1f9-zt">https://arxiv.org/abs/2410.05258</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 422.67px;"><img alt="" src="images/image50.png" style="width: 624.00px; height: 422.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-2 start"><li class="c7 li-bullet-0"><span class="c1">Can run on less memory with no/lower drop in performance compared to regular transformers </span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 622.67px;"><img alt="" src="images/image229.png" style="width: 624.00px; height: 622.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>NVIDIA VP Bob Pette says the energy cost of generating tokens for AI models has fallen by 100,000X in the past 10 years and Blackwell, which is now in production, continues this trend: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fzbp4l/comment/lr0o5dl&amp;sa=D&amp;source=editors&amp;ust=1730413584206130&amp;usg=AOvVaw2uBqvbX8P_UnwPKccebxeW">https://www.reddit.com/r/singularity/comments/1fzbp4l/comment/lr0o5dl</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c1">Humans might write a max of 6k tokens an hour (1.6 tokens per word * 60 words per minute * 60 minutes per hour), assuming consistent speed without slowing down, and use about 83 calories an hour (2000 kcals/24 hours) while awake. 1 calorie is about 4 joules. So a human uses 392 joules of energy to make 6k tokens an hour. Blackwell does 2400 Joules for 6k tokens, but generates them in less than 0.8 seconds. A 10x energy efficiency gain makes hardware more energy efficient per unit of thought than humans. It is already at least 4500x faster (3600 seconds/0.8 seconds to generate 6k tokens).</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Stem </span><span>Cells from Foreskin of Circumcised Baby Penis&#39; used to Grow &#39;Mini-Brains&#39; able to Process Data and Run AI, Faster - While Consuming Almost NO ENERGY: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technews.city/2024/10/the-edge-stem-cells-from-foreskin-of.html?%3Dreport%26m%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584206485&amp;usg=AOvVaw2mMzgZ4pvKaszzCoRiP-d1">https://www.technews.city/2024/10/the-edge-stem-cells-from-foreskin-of.html</a></span></li><li class="c4 li-bullet-0"><span>Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08146&amp;sa=D&amp;source=editors&amp;ust=1730413584206699&amp;usg=AOvVaw1iKnY6E4a3_SxUWwd0kV0p">https://arxiv.org/abs/2410.08146</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span>We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is</span><span class="c15">&nbsp;&gt;8% more accurate, and 1.5&minus;5&times; more compute-efficient. </span><span>Online RL with dense rewards from PAVs enables one of the first results with</span><span class="c33 c15">&nbsp;5&minus;6&times; gain in sample efficiency, and &gt;6% gain in accuracy, over ORMs.</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span class="c1">Nvidia Nemotron 70B - beats Llama 3.1 405B, GPT4o &amp; Claude 3.5 Sonnet on Arena Hard, AlpacaEval and MT Bench. They release the Instruct model, reward model and the dataset all on Hugging Face</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image317.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Mistral introduces two new state-of-the-art models for on-device computing and at-the-edge use cases. &quot;We call them les Ministraux: Ministral 3B and Ministral 8B. These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/&amp;sa=D&amp;source=editors&amp;ust=1730413584207208&amp;usg=AOvVaw1kzeV5FVPdKTiTliBQXG-F">https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 266.67px;"><img alt="" src="images/image477.png" style="width: 624.00px; height: 266.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>New Transformer architecture modifications from NVIDIA researchers - nGPT: A hypersphere-based Transformer achieving 4-20x faster training and improved stability for LLMs: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2410.01131v1&amp;sa=D&amp;source=editors&amp;ust=1730413584207499&amp;usg=AOvVaw1QhOIIElsOr5bdBKAvWJ8u">https://arxiv.org/html/2410.01131v1</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c1">&bull; 4x faster training for 1k context length</span></li><li class="c10 li-bullet-0"><span class="c1">&bull; 10x faster training for 4k context length</span></li><li class="c10 li-bullet-0"><span class="c1">&bull; 20x faster training for 8k context length</span></li><li class="c10 li-bullet-0"><span class="c1">&bull; Similar or better performance on downstream tasks with less training</span></li><li class="c10 li-bullet-0"><span class="c1">&bull; More stable performance when extrapolating to longer sequences</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Near Infinite Batch Size Scaling for Contrastive Loss: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.17243&amp;sa=D&amp;source=editors&amp;ust=1730413584208136&amp;usg=AOvVaw10EqZSLC5ngqW7tJMQC76-">https://arxiv.org/abs/2410.17243</a></span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 320.00px;"><img alt="" src="images/image433.png" style="width: 624.00px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c14 c31">&quot;Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed&quot;</span></li></ul><ul class="c0 lst-kix_jk6itlvdyknk-0"><li class="c4 li-bullet-0"><span>Google CEO Sundar Pichai says AI is a platform shift and as compute is scaled like never before and the cost of generating tokens has fallen by 97% in the past 18 months, we will get &quot;intelligence, just like air, too cheap to meter&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fme0zb/google_ceo_sundar_pichai_says_ai_is_a_platform/&amp;sa=D&amp;source=editors&amp;ust=1730413584208764&amp;usg=AOvVaw2RyETtBjVX2akvc0OJ0H9q">https://www.reddit.com/r/singularity/comments/1fme0zb/google_ceo_sundar_pichai_says_ai_is_a_platform/</a></span></li><li class="c4 li-bullet-0"><span class="c1">Glaze/Nightshade takes 15 minutes of computation for one image. How is that environmentally friendly? &nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><h1 class="c123" id="h.jhzi7ak5dcet"><span class="c40 c37 c48 c77">14. AI Inbreeding/AI Training Off Its Own Output/AI Running Out Of Data/Model Collapse</span></h1><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0 start"><li class="c4 li-bullet-0"><span>Full debunk here: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/rylanschaeffer/status/1816881533795422404?s%3D46&amp;sa=D&amp;source=editors&amp;ust=1730413584209472&amp;usg=AOvVaw3dSgsUmxNxlUuZtub0ObX1">https://x.com/rylanschaeffer/status/1816881533795422404?s=46</a></span></li><li class="c4 li-bullet-0"><span class="c1">Molmo: State of the art multimodal open source using 1000x less data</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">&quot;Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">Outperforming GPT-4o, Gemini 1.5 Pro &amp; Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.</span></li><li class="c10 li-bullet-0"><span>Info: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/blog&amp;sa=D&amp;source=editors&amp;ust=1730413584209919&amp;usg=AOvVaw2XNMW8psQ5JvG8UX5sCeEM">https://molmo.allenai.org/blog</a></span></li><li class="c10 li-bullet-0"><span>Try it: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/&amp;sa=D&amp;source=editors&amp;ust=1730413584210148&amp;usg=AOvVaw3yitLt4sHvh6JDa60zDfHU">https://molmo.allenai.org</a></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 377.33px;"><img alt="" src="images/image52.png" style="width: 624.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while using only 2K training samples) as GPT-4: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413584210586&amp;usg=AOvVaw1uJYNuMkaLL86EgjGd87O3">https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c37 c35 c103 c14 c151">Auto Evol used to create an infinite amount and variety of high quality data: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/CanXu20/status/1812842568557986268&amp;sa=D&amp;source=editors&amp;ust=1730413584211036&amp;usg=AOvVaw0ei93wnoUsUEulh-necUk2">https://x.com/CanXu20/status/1812842568557986268</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 li-bullet-0"><span>Auto Evol allows the training of WizardLM2 to be conducted with nearly an </span><span class="c33 c15">unlimited number and variety of synthetic data.</span></li><li class="c10 li-bullet-0"><span>Auto Evol-Instruct automatically designs evolving methods that </span><span class="c15">make given instruction data more complex, enabling almost cost-free adaptation to different tasks by only changing the input data of the framework</span><span>&nbsp;&hellip;This optimization process involves two critical stages: (1) Evol Trajectory Analysis: The optimizer LLM carefully analyzes the potential issues and failures exposed in instruction evolution performed by evol LLM, generating feedback for subsequent optimization. (2) Evolving Method Optimization: The optimizer LLM optimizes the evolving method by addressing these identified issues in feedback. These stages alternate and repeat to progressively develop an effective evolving method using only a subset of the instruction data. Once the optimal evolving method is identified, it directs the evol LLM to convert the entire instruction dataset into </span><span class="c33 c15">more diverse and complex forms, thus facilitating improved instruction tuning.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>Our experiments show that the evolving methods designed by Auto Evol-Instruct </span><span class="c15">outperform the Evol-Instruct methods designed by human experts in instruction tuning across various capabilities, including instruction following, mathematical reasoning, and code generation</span><span>. On the instruction following task, Auto Evol-Instruct can achieve a</span><span class="c34">&nbsp;improvement of 10.44% over the Evol method used by WizardLM-1 on MT-bench</span><span>; on the code task HumanEval, it can</span><span class="c34">&nbsp;achieve a 12% improvement over the method used by WizardCoder; on the math task GSM8k</span><span>, it can achieve a</span><span class="c33 c34">&nbsp;6.9% improvement over the method used by WizardMath.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>With the new technology of Auto Evol-Instruct, the evolutionary synthesis data of WizardLM-2 has</span><span class="c15">&nbsp;scaled up from the three domains of chat, code, and math in WizardLM-1 to dozens of domains</span><span>, covering tasks in all aspects of large language models. This allows Arena Learning to train and learn from an almost </span><span class="c15">infinite pool of high-difficulty instruction data</span><span>, fully unlocking all the potential of Arena Learning.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 697.33px;"><img alt="" src="images/image248.png" style="width: 624.00px; height: 697.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c95 c14 c46 c129"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c22 c95 c14 c129 li-bullet-0"><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://allenpike.com/2024/llms-trained-on-internet&amp;sa=D&amp;source=editors&amp;ust=1730413584212726&amp;usg=AOvVaw21ZYZHYahTLXjRS-2Gn1oo">LLMs Aren&rsquo;t Just &ldquo;Trained On the Internet&rdquo; Anymore</a></span><span class="c15">: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://allenpike.com/2024/llms-trained-on-internet&amp;sa=D&amp;source=editors&amp;ust=1730413584212945&amp;usg=AOvVaw1vzsOSV1p6Dz3H3UTvAG57">https://allenpike.com/2024/llms-trained-on-internet</a></span></li></ul><p class="c22 c14 c46 c95"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c22 c32 c14 li-bullet-0"><span>New very high quality dataset: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1&amp;sa=D&amp;source=editors&amp;ust=1730413584213325&amp;usg=AOvVaw2cL6X73iD1GKhLNUXAqLIZ">https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c22 c72 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.50px; height: 451.88px;"><img alt="" src="images/image292.png" style="width: 602.50px; height: 451.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c22 c32 c14 li-bullet-0"><span>MMIS: Multimodal Dataset for Interior Scene Visual Generation and Recognition: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.05980v1&amp;sa=D&amp;source=editors&amp;ust=1730413584213868&amp;usg=AOvVaw1-fVPbBL-zMUQB3ogYIqU0">https://arxiv.org/abs/2407.05980v1</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c22 c32 c14 li-bullet-0"><span>announcing our first suite of specialized language models for document processing tasks (OCR correction, text segmentation, bibliographic extraction) and a</span><span class="c15">&nbsp;new major multimodal dataset we used to train them, Finance Commons</span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/Dorialexander/status/1814234566158118977&amp;sa=D&amp;source=editors&amp;ust=1730413584214325&amp;usg=AOvVaw0-sXzg_hltjTGrrahffjyN">https://x.com/Dorialexander/status/1814234566158118977</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c45 li-bullet-0"><span class="c14">NuminaMath 72b TIR model: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/JiaLi52524397/status/1814957190320631929/&amp;sa=D&amp;source=editors&amp;ust=1730413584214730&amp;usg=AOvVaw3dAnKlqMlpz3nlkgmkpGsW">https://x.com/JiaLi52524397/status/1814957190320631929/</a></span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c59 li-bullet-0"><span class="c1 c14">Trained on new competition math dataset ever released, with 860K problem solution pairs that was created with GPT 4</span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-2 start"><li class="c73 c86 li-bullet-0"><span class="c1 c14">&ldquo;We selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and producing results until the solution was complete. We filtered out solutions where the final answer did not match the reference and repeated this process three times to ensure accuracy and consistency. This iterative approach allowed us to generate high-quality TORA data efficiently.&rdquo;</span></li></ul><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 514.67px;"><img alt="" src="images/image35.png" style="width: 624.00px; height: 514.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c59 li-bullet-0"><span class="c1 c14">For AMC 10 2023, the average score is 43%, </span></li><li class="c59 li-bullet-0"><span class="c39 c37 c14">AIME Floor: 70% (top ~6%)</span></li><li class="c177 c97 c14 c105 li-bullet-0"><span class="c39 c37 c14">Distinction: 75%</span></li><li class="c177 c97 c14 c105 li-bullet-0"><span class="c55 c37 c65 c14">Distinguished Honor Roll: 90%</span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>&nbsp;Scaling Retrieval-Based Language Models with a Trillion-Token Datastore: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.12854&amp;sa=D&amp;source=editors&amp;ust=1730413584216041&amp;usg=AOvVaw2fZgoPpni-hYWmzNtl2W2h">https://arxiv.org/abs/2407.12854</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">- This paper investigates how scaling up the datastore in retrieval-augmented language models improves performance without signs of saturation on both language modeling and downstream tasks. </span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- The authors built MASSIVEDS, an open-sourced 1.4 trillion token datastore covering a diverse set of domains. MASSIVEDS is the largest open-sourced datastore for studying retrieval scaling.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span class="c1">- They designed an efficient pipeline to make the study computationally tractable by sharing indexing and retrieval computation across different datastore configurations.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Experiments show datastore scaling </span><span class="c33 c15">brings consistent improvements in language modeling perplexity on web data and scientific papers. &nbsp;</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- On downstream tasks, datastore scaling </span><span class="c15">significantly boosts performance</span><span>&nbsp;on knowledge-intensive QA tasks like TriviaQA and Natural Questions. Smaller retrieval models can </span><span class="c33 c15">match or exceed their larger LM-only counterparts.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Datastore scaling also</span><span class="c15">&nbsp;improves performance on reasoning tasks</span><span class="c1">&nbsp;like MMLU, but the improvements are more modest, indicating potential need for more in-domain data.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Compared to LM-only models, retrieval models achieve </span><span class="c34">superior compute-optimal scaling curves by offloading FLOPs </span><span class="c1">from model pretraining to datastore indexing.</span></li><li class="c10 c46 li-bullet-0"><span class="c1"></span></li><li class="c10 li-bullet-0"><span>- Analysis reveals the retriever can</span><span class="c34">&nbsp;stay robust to out-of-domain data and tend to retrieve relevant documents even from a broad datastore.</span></li></ul><p class="c22 c95 c14 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c22 c95 c14 c129 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/&amp;sa=D&amp;source=editors&amp;ust=1730413584217989&amp;usg=AOvVaw3008BjN2YbiOv7oqXu5Z1D">https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/</a></span></li></ul><p class="c22 c95 c14 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 li-bullet-0"><span>Michael Gerstenhaber, product lead at Anthropic, says that the improvements are the result of architectural tweaks and new training data, including </span><span class="c15">AI-generated data</span><span>. Which data specifically? Gerstenhaber wouldn&rsquo;t disclose, but he implied that </span><span class="c33 c15">Claude 3.5 Sonnet draws much of its strength from these training sets.</span></li></ul><p class="c22 c95 c14 c46"><span class="c92 c37 c65 c60 c144 c187"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>Google DeepMind&#39;s JEST method </span><span class="c15">can reduce AI training time by a factor of 13 and decreases computing power demand by 90%</span><span>. The method uses another pretrained reference model to select data subsets for training based on their &quot;collective learnability: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/html/2406.17711v1&amp;sa=D&amp;source=editors&amp;ust=1730413584218787&amp;usg=AOvVaw100xGbC4bOSRy_CgcSPOYp">https://arxiv.org/html/2406.17711v1</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 198.67px;"><img alt="" src="images/image604.png" style="width: 624.00px; height: 198.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 234.67px;"><img alt="" src="images/image394.png" style="width: 624.00px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 217.33px;"><img alt="" src="images/image311.png" style="width: 624.00px; height: 217.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c18 c14">Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math:</span><span class="c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1793864788579090917?s%3D46%26t%3DlZJAHzXMXI1MgQuyBgEhgA&amp;sa=D&amp;source=editors&amp;ust=1730413584219568&amp;usg=AOvVaw0gmGQi-V_HrhrHnT4rqY3d">&nbsp;</a></span><span class="c5 c18 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/_akhaliq/status/1793864788579090917?s%3D46%26t%3DlZJAHzXMXI1MgQuyBgEhgA&amp;sa=D&amp;source=editors&amp;ust=1730413584219795&amp;usg=AOvVaw0Ig1zRANPUbEpdRwayoXTj">https://x.com/_akhaliq/status/1793864788579090917?s=46&amp;t=lZJAHzXMXI1MgQuyBgEhgA</a></span></li></ul><p class="c9"><span class="c5 c18 c14 c120 c162"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c14">Researchers shows Model Collapse is easily avoided by keeping old human data with new synthetic data in the training set:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.01413&amp;sa=D&amp;source=editors&amp;ust=1730413584220161&amp;usg=AOvVaw3EDgoWX1RCRUCbMffjaJ5X">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.01413&amp;sa=D&amp;source=editors&amp;ust=1730413584220317&amp;usg=AOvVaw22v5yVY0F61a8VFBm4nu_g">https://arxiv.org/abs/2404.01413</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c14">Teaching Language Models to Hallucinate Less with Synthetic Tasks: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.06827?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584220674&amp;usg=AOvVaw1Y_midZqUv4Y6W5x2jlzOX">https://arxiv.org/abs/2310.06827?darkschemeovr=1</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 li-bullet-0"><span class="c14 c31">&gt;In this work, we show that reducing hallucination on a synthetic task can also reduce hallucination on real-world downstream tasks. Our method, SynTra, first designs a synthetic task where hallucinations are easy to elicit and measure. It next optimizes the LLM&#39;s system message via prefix-tuning on the synthetic task, and finally transfers the system message to realistic, hard-to-optimize tasks. Across three realistic abstractive summarization tasks, SynTra reduces hallucination for two 13B-parameter LLMs using only a synthetic retrieval task for supervision. We also find that optimizing the system message rather than the model weights can be critical; fine-tuning the entire model on the synthetic task can counterintuitively increase hallucination. Overall, SynTra demonstrates that the extra flexibility of working with synthetic data can help mitigate undesired behaviors in practice.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 c53 c56 li-bullet-0"><span class="c37 c35 c103 c14 c151">IBM on synthetic data: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://www.ibm.com/topics/synthetic-data&amp;sa=D&amp;source=editors&amp;ust=1730413584221339&amp;usg=AOvVaw2y34jJdiu4TAqszV1MWN-m">https://www.ibm.com/topics/synthetic-data</a></span></li></ul><p class="c21 c53 c56"><span class="c92 c37 c35 c103 c14 c151">&nbsp;</span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span class="c92 c37 c35 c103 c14 c151">&gt;Data quality: Unlike real-world data, synthetic data removes the inaccuracies or errors that can occur when working with data that is being compiled in the real world. Synthetic data can provide high quality and balanced data if provided with proper variables. The artificially-generated data is also able to fill in missing values and create labels that can enable more accurate predictions for your company or business. &nbsp;</span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c53 c111 c56 c78 li-bullet-0"><span>Synthetic data could be better than real data: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-023-01445-8&amp;sa=D&amp;source=editors&amp;ust=1730413584221915&amp;usg=AOvVaw2BkVyn43uiJYNrpVQ3u23L">https://www.nature.com/articles/d41586-023-01445-8</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c53 c111 c56 c97 c105 li-bullet-0"><span>Example of this improving LLAMA 1 LLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2304.12244&amp;sa=D&amp;source=editors&amp;ust=1730413584222199&amp;usg=AOvVaw3zWLbuY_WipQ8wm3lcvOaM">https://arxiv.org/pdf/2304.12244</a></span></li></ul><p class="c53 c111 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c53 c111 c56 c78 li-bullet-0"><span>Boosting Visual-Language Models with Synthetic Captions and Image Embeddings: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.07750&amp;sa=D&amp;source=editors&amp;ust=1730413584222548&amp;usg=AOvVaw1C4Lpo-wNabzp-ZC_BSKlN">https://arxiv.org/pdf/2403.07750</a></span></li></ul><p class="c53 c111 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c53 c111 c56 c97 c105 li-bullet-0"><span>&gt;Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator&rsquo;s ability to create </span><span class="c15">novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. </span><span>Extensive experiments demonstrate that our VLM, </span><span class="c15">finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. </span><span>Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up </span><span class="c33 c15">promising avenues for the development of self-improving multi-modal models.</span></li><li class="c53 c111 c56 c97 c105 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 540.66px; height: 655.51px;"><img alt="" src="images/image297.png" style="width: 540.66px; height: 655.51px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 277.33px;"><img alt="" src="images/image268.png" style="width: 624.00px; height: 277.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c53 c111 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c53 c111 c56 c78 li-bullet-0"><span>Simulations transfer very well to real life: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.01967v1&amp;sa=D&amp;source=editors&amp;ust=1730413584223636&amp;usg=AOvVaw0kGDBFHdcdvJ65OYiaagJq">https://arxiv.org/abs/2406.01967v1</a></span></li></ul><p class="c53 c111 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 c53 c56 li-bullet-0"><span class="c37 c35 c103 c14 c151">Study on quality of synthetic data shows improvements across the board: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2210.07574&amp;sa=D&amp;source=editors&amp;ust=1730413584224027&amp;usg=AOvVaw2tHnsXz_5xaft8iUHIH6jf">https://arxiv.org/pdf/2210.07574</a></span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span class="c92 c37 c35 c103 c14 c151">&gt;&ldquo;We systematically investigate whether synthetic data from current state-of-the-art text-to-image generation models are readily applicable for image recognition. Our extensive experiments demonstrate that synthetic data are beneficial for classifier learning in zero-shot and few-shot recognition, bringing significant performance boosts and yielding new state-of-the-art performance. Further, current synthetic data show strong potential for model pre-training, even surpassing the standard ImageNet pre-training. We also point out limitations and bottlenecks for applying synthetic data for image recognition, hoping to arouse more future research in this direction.&rdquo;</span></li><li class="c10 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 332.00px;"><img alt="" src="images/image124.png" style="width: 624.00px; height: 332.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 150.67px;"><img alt="" src="images/image512.png" style="width: 624.00px; height: 150.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 229.33px;"><img alt="" src="images/image563.png" style="width: 624.00px; height: 229.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 420.00px;"><img alt="" src="images/image300.png" style="width: 624.00px; height: 420.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c131 c53 c56 c78 li-bullet-0"><span>E5-V: Universal Embeddings with Multimodal Large Language Models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.12580&amp;sa=D&amp;source=editors&amp;ust=1730413584225128&amp;usg=AOvVaw1QoThcu42IOv5HGwsDV6gu">https://huggingface.co/papers/2407.12580</a></span></li></ul><p class="c131 c53 c56 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span>&gt;By leveraging MLLMs with prompts, E5-V effectively bridges the modality gap between different types of inputs, demonstrating strong performance in multimodal embeddings even without fine-tuning. We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs. This method demonstrates </span><span class="c15">significant improvements over traditional multimodal training on image-text pairs, while reducing training costs by approximately 95%. </span><span>Additionally, this approach</span><span class="c43">&nbsp;</span><span class="c15">eliminates the need for costly multimodal training data collection</span><span>. Extensive experiments across four types of tasks demonstrate the effectiveness of E5-V. As a universal multimodal model, E5-V not only achieves but often </span><span class="c33 c15">surpasses state-of-the-art performance in each task, despite being trained on a single modality.</span></li></ul><p class="c9 c53 c56 c129"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 c53 c56 li-bullet-0"><span class="c92 c37 c35 c103 c14 c151">Scaling Synthetic Data Creation with 1,000,000,000 Personas</span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span class="c92 c37 c35 c103 c14 c151">- Presents a collection of 1B diverse personas automatically curated from web data</span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span class="c92 c37 c35 c103 c14 c151">- Massive gains on MATH: 49.6 -&gt;64.9</span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span class="c37 c35 c103 c14 c151">repo: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://github.com/tencent-ailab/persona-hub&amp;sa=D&amp;source=editors&amp;ust=1730413584226422&amp;usg=AOvVaw0jlSV2SQmApp4-1jFoH9ks">https://github.com/tencent-ailab/persona-hub</a></span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span class="c37 c35 c103 c14 c151">abs: </span><span class="c5 c37 c35 c103 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.20094&amp;sa=D&amp;source=editors&amp;ust=1730413584226807&amp;usg=AOvVaw2Gs3P4LtAuTk1W3PopfiOZ">https://arxiv.org/abs/2406.20094</a></span></li><li class="c10 c53 c56 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 475.50px; height: 445.92px;"><img alt="" src="images/image23.png" style="width: 475.50px; height: 445.92px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>LLAMA Groq 3 tool use: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/RickLamers/status/1813341037198204962&amp;sa=D&amp;source=editors&amp;ust=1730413584227328&amp;usg=AOvVaw07bGyyX_HOtac8hbHvMzDt">https://x.com/RickLamers/status/1813341037198204962</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">An open source Tool Use full finetune of Llama 3 that reaches the #1 position on BFCL beating all other models, including proprietary ones like Claude Sonnet 3.5, GPT-4 Turbo, GPT-4o and Gemini 1.5 Pro.</span></li><li class="c10 li-bullet-0"><span class="c1">The model has been trained on synthetic data only. This is a powerful full finetune, not a LoRA. Yes, we&#39;ve checked rigorously for overfitting using the LMSYS described robust decontamination techniques, they only score 5.6% on SFT synthetic data and 1.3% on synthetic DPO data.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 567.05px; height: 353.50px;"><img alt="" src="images/image221.png" style="width: 567.05px; height: 353.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9 c129"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://venturebeat.com/ai/meta-drops-ai-bombshell-multi-token-prediction-models-now-open-for-research/&amp;sa=D&amp;source=editors&amp;ust=1730413584228061&amp;usg=AOvVaw36iDh-XVgKW_klFD47xa5z">https://venturebeat.com/ai/meta-drops-ai-bombshell-multi-token-prediction-models-now-open-for-research/</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span>&gt;</span><span class="c92 c99 c37 c65 c60 c144">3x faster token prediction means 3x cheaper and on top of that it seems to greatly increase coding, summarization, and mathematical reasoning abilities. Best of all the improvements have shown to only become more significant with larger models (13b+ according to the paper). Unlike some other research where improvements are mostly seen in smaller models and won&#39;t advance the frontier, this is infact worse performing on smaller models and shows great potential at scale. </span></li></ul><p class="c9"><span class="c92 c99 c37 c65 c60 c144"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 c53 c56 li-bullet-0"><span class="c92 c37 c35 c103 c14 c151">Has a cutoff date of 6/12/24 with no &ldquo;inbreeding&rdquo; issues </span></li></ul><p class="c9 c53 c56"><span class="c92 c37 c35 c103 c14 c151"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c14 c31">Scaling Diffusion Transformers to 16 Billion Parameters: </span><span class="c5 c14 c31"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/papers/2407.11633&amp;sa=D&amp;source=editors&amp;ust=1730413584228666&amp;usg=AOvVaw2YXss9L73QSKTkbG9lqYDs">https://huggingface.co/papers/2407.11633</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">Based on the above guidance, a series of DiT-MoE experimentally achieves performance on par with dense networks yet requires</span><span class="c15 c31">&nbsp;much less computational load during inference</span><span class="c14 c31">. More encouragingly, we demonstrate the potential of DiT-MoE with </span><span class="c15 c31">synthesized image data,</span><span class="c14 c31">&nbsp;scaling diffusion model at a 15.5B parameter that attains</span><span class="c28 c43">&nbsp;a new SoTA FID-50K score of 1.80 in 512x512 resolution settings.</span></li><li class="c10 li-bullet-0"><span class="c40 c37 c48 c31">For reference, Stable Diffusion XL is only about 3 billion parameters</span></li></ul><p class="c9"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c31">GPT 4 achieves 93% on subset of MedQA on respiratory diseases using simulated hospital starting from 86% baseline: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2405.02957&amp;sa=D&amp;source=editors&amp;ust=1730413584229139&amp;usg=AOvVaw0DkrPdT5PNGSDpV_CW8B5r">https://arxiv.org/abs/2405.02957</a></span></li></ul><p class="c9"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c78 c164 li-bullet-0"><span>NVIDIA Releases Open Synthetic Data Generation Pipeline for Training Large Language Models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/&amp;sa=D&amp;source=editors&amp;ust=1730413584229418&amp;usg=AOvVaw0uPjMpH8t0E8_7fcRqRuo_">https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/</a></span></li></ul><p class="c164 c46"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c95 c105 li-bullet-0"><span class="c92 c42 c37 c251">Nemotron-4 340B, a family of models optimized for NVIDIA NeMo and NVIDIA TensorRT-LLM, includes cutting-edge instruct and reward models, and a dataset for generative AI training.</span></li><li class="c145 c97 c105 li-bullet-0"><span class="c35">The </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/nemotron-4-340b-instruct&amp;sa=D&amp;source=editors&amp;ust=1730413584229782&amp;usg=AOvVaw2eD8FeTZuP7aMDCq4kE6j6">Nemotron-4 340B Instruct</a></span><span class="c40 c37 c35 c48">&nbsp;model creates diverse synthetic data that mimics the characteristics of real-world data, helping improve data quality to increase the performance and robustness of custom LLMs across various domains.</span></li><li class="c145 c97 c105 li-bullet-0"><span class="c35">Then, to boost the quality of the AI-generated data, developers can use the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/nemotron-4-340b-reward&amp;sa=D&amp;source=editors&amp;ust=1730413584230029&amp;usg=AOvVaw2sPVf54Ilrz-tbpJhRCNV0">Nemotron-4 340B Reward</a></span><span class="c35">model to filter for high-quality responses. Nemotron-4 340B Reward grades responses on five attributes: helpfulness, correctness, coherence, complexity and verbosity. It&rsquo;s currently first place on the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/spaces/allenai/reward-bench&amp;sa=D&amp;source=editors&amp;ust=1730413584230191&amp;usg=AOvVaw1RsPBLaIgtIATVQtTThHkS">Hugging Face RewardBench leaderboard</a></span><span class="c35">, created by </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://allenai.org/&amp;sa=D&amp;source=editors&amp;ust=1730413584230316&amp;usg=AOvVaw2Q9nA-QH3-t8TfMs1TmnIq">AI2</a></span><span class="c40 c37 c35 c48">, for evaluating the capabilities, safety and pitfalls of reward models.</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>RGM, active inference non-llm approach using 90% less data (less need for synthetic data, lower energy footprint). 99.8% accuracy in MNIST benchmark using 90% less data to train on less powerful devices: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2407.20292&amp;sa=D&amp;source=editors&amp;ust=1730413584230538&amp;usg=AOvVaw2gdd62VB4Cs5ybIphV0PwI">https://arxiv.org/pdf/2407.20292</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Use for Atari game performance: &ldquo;This fast structure learning took about 18 seconds on a personal computer.&rdquo;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 li-bullet-0"><span class="c1">&gt;Use for MNIST dataset classification: For example, the variational procedures above attained state-of-the-art classification accuracy on a self-selected subset of test data after seeing 10,000 training images. Each training image was seen once, with continual learning (and no notion of batching). Furthermore, the number of training images actually used for learning was substantially smaller10 than 10,000; because active learning admits only those informative images that reduce expected free energy. This (Maxwell&rsquo;s Demon) aspect of selecting the right kind of data for learning will be a recurrent theme in subsequent sections. Finally, the requisite generative model was self-specifying, given some exemplar data. In other words, the hierarchical depth and size of the requisite tensors were learned automatically within a few seconds on a personal computer.</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c1">Nvidia Research team has developed a method to efficiently create smaller, accurate language models by using structured weight pruning and knowledge distillation, offering several advantages for developers:</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">16% better performance on MMLU scores.</span></li><li class="c10 li-bullet-0"><span class="c1">40x fewer tokens for training new models.</span></li><li class="c10 li-bullet-0"><span class="c1">Up to 1.8x cost saving for training a family of models.</span></li><li class="c10 li-bullet-0"><span>The effectiveness of these strategies is demonstrated with the Meta Llama 3.1 8B model, which was refined into the Llama-3.1-Minitron 4B. The collection on huggingface: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e&amp;sa=D&amp;source=editors&amp;ust=1730413584231360&amp;usg=AOvVaw2h9d4V9qG5re4LQx-e1TtJ">https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e</a></span></li><li class="c10 li-bullet-0"><span>Technical dive: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model&amp;sa=D&amp;source=editors&amp;ust=1730413584231615&amp;usg=AOvVaw3DPFZPC3O-hzwHLXguv8UG">https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model</a></span></li><li class="c10 li-bullet-0"><span>Research paper: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.14679&amp;sa=D&amp;source=editors&amp;ust=1730413584231818&amp;usg=AOvVaw0C7AyWwTwxlZ5Uah5Ha4Pq">https://arxiv.org/abs/2407.14679</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>OpenAI Shows &lsquo;Strawberry&rsquo; AI to the Feds and Uses It to Develop &lsquo;Orion&rsquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion&amp;sa=D&amp;source=editors&amp;ust=1730413584232108&amp;usg=AOvVaw2yhArN5pmSSMc9rHhLJ6sN">https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">Strawberry can solve math problems it hasn&#39;t seen before&mdash;something today&rsquo;s chatbots cannot reliably do</span></li><li class="c10 li-bullet-0"><span class="c1">When given additional time to &ldquo;think,&rdquo; the Strawberry model can also answer customers&rsquo; questions about more subjective topics, such as product marketing strategies. To demonstrate Strawberry&rsquo;s prowess with language-related tasks, OpenAI employees have shown their co-workers how Strawberry can, for example, solve New York Times Connections, a complex word puzzle</span></li><li class="c10 li-bullet-0"><span class="c1">Its sales of LLMs to corporations and of ChatGPT subscriptions have roughly tripled to $283 million in monthly revenue compared to a year ago</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI&rsquo;s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI&rsquo;s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion</span></li><li class="c10 li-bullet-0"><span class="c1">Using Strawberry to generate higher-quality training data could help OpenAI reduce the number of errors its models generate, otherwise known as hallucinations, said Alex Graveley, CEO of agent startup Minion AI and former chief architect of GitHub Copilot.</span></li><li class="c10 li-bullet-0"><span class="c1">Imagine &ldquo;a model without hallucinations, a model where you ask it a logic puzzle and it&rsquo;s right on the first try,&rdquo; Graveley said. The reason why the model is able to do that is because &ldquo;there is less ambiguity in the training data, so it&rsquo;s guessing less.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1">&ldquo;We feel like we have enough [data] for this next model,&rdquo; Altman said at an event in May, likely referring to Orion. &ldquo;We have done all sorts of experiments including generating synthetic data.&rdquo;</span></li><li class="c10 li-bullet-0"><span class="c1">Strawberry has its roots in research. It was started years ago by Ilya Sutskever, then OpenAI&#39;s chief scientist. He recently left to start a competing AI lab. Before he left, OpenAI researchers Jakub Pachocki and Szymon Sidor built on Sutskever&#39;s work by developing a new math-solving model, Q*, alarming some researchers focused on AI safety.</span></li><li class="c10 li-bullet-0"><span class="c1">Last year, in the leadup to Q*, OpenAI researchers developed a variation of a concept known as test-time computation, meant to boost LLMs&rsquo; problem-solving abilities. The method gives them the opportunity to spend more time considering all parts of a command or question someone has asked the model to execute. At the time, Sutskever published a blog post related to this work.</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 920.00px;"><img alt="" src="images/image294.png" style="width: 624.00px; height: 920.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://time.com/6300942/ai-progress-charts/&amp;sa=D&amp;source=editors&amp;ust=1730413584233115&amp;usg=AOvVaw1qeNOWaTAi9g5SrT0gPi3_">https://time.com/6300942/ai-progress-charts/</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>Agent Q, Research Breakthrough for the Next Generation of AI Agents with Planning &amp; Self Healing Capabilities: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities&amp;sa=D&amp;source=editors&amp;ust=1730413584233395&amp;usg=AOvVaw00Q1unkwXiMDLCHcmJEZzy">https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span>In real-world booking experiments on Open Table, MultiOn&rsquo;s Agents </span><span class="c15">drastically improved the zero-shot performance of the LLaMa-3 model from an 18.6% success rate to 81.7%, a 340% jump after just one day of autonomous data collection and further to 95.4% with online search.</span><span class="c1">&nbsp;These results highlight our method&rsquo;s efficiency and ability for autonomous web agent improvement.</span></li><li class="c10 li-bullet-0"><span class="c63 c34 c134">Guided Search with MCTS</span><span class="c19">: This technique autonomously generates data by exploring different actions and web-pages, balancing exploration and exploitation. MCTS expands the action space using high sampling temperatures and diverse prompting, ensuring diverse and optimal trajectory collections.</span></li><li class="c10 li-bullet-0"><span class="c63 c34 c134">AI Self-Critique</span><span class="c19">: At each step, AI-based self-critique provides valuable feedback, refining the agent&#39;s decision-making process. This step-level feedback is crucial for long-horizon tasks, where sparse signals often lead to learning difficulties.</span></li><li class="c10 li-bullet-0"><span class="c63 c34 c134">Direct Preference Optimization</span><span class="c19">: The DPO algorithm fine-tunes the model by constructing preference pairs from MCTS-generated data. This off-policy training method allows the model to learn effectively from aggregate datasets including the sub-optimal branches explored during search, improving success rates in complex environments.</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>&ldquo;SkillMimic&quot; uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmimic_uses_just_35_minutes_of_video_and/&amp;sa=D&amp;source=editors&amp;ust=1730413584234190&amp;usg=AOvVaw3xmhDA6Nil8C8eLzosY8ig">https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmim</a></span></li><li class="c4 li-bullet-0"><span>Source2Synth: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/jaseweston/status/1834402693995024453&amp;sa=D&amp;source=editors&amp;ust=1730413584234520&amp;usg=AOvVaw2zO2PUJsXpb4aoN16Kf1C3">https://x.com/jaseweston/status/1834402693995024453</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">- Generates synthetic examples grounded in real data </span></li><li class="c10 li-bullet-0"><span class="c1">- Curation step makes data high quality based on answerability</span></li><li class="c10 li-bullet-0"><span class="c1">- Improves performance on two challenging domains: Multi-hop QA and using tools: SQL for tabular QA </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 214.67px;"><img alt="" src="images/image421.png" style="width: 624.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 205.33px;"><img alt="" src="images/image314.png" style="width: 624.00px; height: 205.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 472.50px; height: 683.75px;"><img alt="" src="images/image194.png" style="width: 472.50px; height: 683.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span class="c1">Molmo: State of the art multimodal open source using 1000x less data</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">&quot;Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data.&quot;</span></li><li class="c10 li-bullet-0"><span class="c1">Outperforming GPT-4o, Gemini 1.5 Pro &amp; Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.</span></li><li class="c10 li-bullet-0"><span>Info: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/blog&amp;sa=D&amp;source=editors&amp;ust=1730413584235257&amp;usg=AOvVaw0QL4Evtmmdz6zOwOVd1l7v">https://molmo.allenai.org/blog</a></span></li><li class="c10 li-bullet-0"><span>Try it: &nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://molmo.allenai.org/&amp;sa=D&amp;source=editors&amp;ust=1730413584235456&amp;usg=AOvVaw1YZsTZwjys45nTweAcmFq2">https://molmo.allenai.org</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>The Race to Block OpenAI&rsquo;s Scraping Bots Is Slowing Down: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/open-ai-publisher-deals-scraping-bots/&amp;sa=D&amp;source=editors&amp;ust=1730413584235673&amp;usg=AOvVaw1Ir7NYRRuUkCCUmkisRQSo">https://www.wired.com/story/open-ai-publisher-deals-scraping-bots/</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c1">At its peak, the high was just over a third of the websites; it has now dropped down closer to a quarter. Within a smaller pool of the most prominent news outlets, the block rate is still above 50 percent, but it&rsquo;s down from heights earlier this year of almost 90 percent.</span></li><li class="c10 li-bullet-0"><span>But last May, after Dotdash Meredith announced a licensing deal with OpenAI, that number dipped significantly. It then dipped again at the end of May when Vox </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/5/29/24167072/openai-content-copyright-vox-media-the-atlantic&amp;sa=D&amp;source=editors&amp;ust=1730413584236018&amp;usg=AOvVaw3IA1yYR-69ZHJjhoLrOFnf">announced</a></span><span>&nbsp;its own arrangement&mdash;and again once more this August when WIRED&rsquo;s parent company, Cond&eacute; Nast, </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/conde-nast-openai-deal/&amp;sa=D&amp;source=editors&amp;ust=1730413584236204&amp;usg=AOvVaw0j1AzoXa-w-6pxkNzsX9Ks">struck a deal</a></span><span class="c1">. The trend toward increased blocking appears to be over, at least for now.</span></li><li class="c10 li-bullet-0"><span class="c1">These dips make obvious sense. When companies enter into partnerships and give permission for their data to be used, they&rsquo;re no longer incentivized to barricade it, so it would follow that they would update their robots.txt files to permit crawling; make enough deals and the overall percentage of sites blocking crawlers will almost certainly go down. </span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-0"><li class="c4 li-bullet-0"><span>paper from Meta discloses TPO (Thought Preference Optimization) technique with impressive results: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.10630&amp;sa=D&amp;source=editors&amp;ust=1730413584236657&amp;usg=AOvVaw0prmr7JjMMrGAiBJbOU-mi">https://arxiv.org/abs/2410.10630</a></span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1 start"><li class="c10 li-bullet-0"><span class="c14 c31">We propose a training method for equipping existing LLMs with such thinking abilities for general instruction following </span><span class="c15 c31">without use of additional human data</span><span class="c14 c31">. We achieve this by an iterative search and optimization procedure that explores the space of possible thought generations, </span><span class="c15 c31">allowing the model to learn how to think without direct supervision. </span><span class="c14 c31">For each instruction, the thought candidates are scored using a judge model to evaluate their responses only, and then optimized via preference optimization. We show that this procedure leads to </span><span class="c28 c43">superior performance on AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning categories such as marketing, health and general knowledge, in addition to more traditional reasoning &amp; problem-solving tasks.</span></li><li class="c10 li-bullet-0"><span class="c1">highest win rate our model TPO achieves is 52.5%, which is +4.1% better than the direct baseline, as shown in Table 1. It is also a +27.6% increase over the seed model and puts our method in 3rd position on the leaderboard(1), just after GPT-4 Omni and GPT-4 Turbo. This is an impressive result given the small size (8B) of our model.&rdquo;</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-2 start"><li class="c7 li-bullet-0"><span class="c1">GPT-4o does 57.5%. GPT-4 Turbo 54.0%</span></li></ul><ul class="c0 lst-kix_tzrck1qfmyqd-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 257.33px;"><img alt="" src="images/image388.png" style="width: 624.00px; height: 257.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><p class="c9"><span class="c40 c37 c48 c31"></span></p><h2 class="c64 c129" id="h.ar97txmx1lmk"><span class="c40 c37 c48 c75">14.1 AI Image Training</span></h2><ul class="c0 lst-kix_uu0tjb1960c1-0 start"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 441.33px;"><img alt="" src="images/image24.png" style="width: 624.00px; height: 441.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>New open source AI image generator beats Midjourney: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://blackforestlabs.ai/announcing-black-forest-labs/&amp;sa=D&amp;source=editors&amp;ust=1730413584237985&amp;usg=AOvVaw3DAcz7XgjGom-vPIxwSDiP">https://blackforestlabs.ai/announcing-black-forest-labs/</a></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1 start"><li class="c10 li-bullet-0"><span class="c1">API costs $0.025 per image. It&#39;s cheaper than Dalle 3 and can do realism.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 390.67px;"><img alt="" src="images/image364.png" style="width: 624.00px; height: 390.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image107.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Very realistic images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/&amp;sa=D&amp;source=editors&amp;ust=1730413584238505&amp;usg=AOvVaw3JIWhYXnAbDUi0Z0pz85aS">https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1106.67px;"><img alt="" src="images/image120.png" style="width: 624.00px; height: 1106.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1080.00px;"><img alt="" src="images/image278.png" style="width: 624.00px; height: 1080.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1094.67px;"><img alt="" src="images/image46.png" style="width: 624.00px; height: 1094.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 638.67px;"><img alt="" src="images/image135.png" style="width: 624.00px; height: 638.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt with no additional editing: meme image with two men in it. On the left side the man is taller and is wearing a shirt that says Black Forest Labs. On the right side the other smaller scrawny man is wearing a shirt that says Stability AI and is sad. The taller man is hitting the back of the head of the small man. A caption coming from the tall man reads &quot;That&#39;s how you do a next-gen model!</span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 501.33px;"><img alt="" src="images/image233.png" style="width: 624.00px; height: 501.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.</span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 489.33px;"><img alt="" src="images/image37.png" style="width: 624.00px; height: 489.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.</span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 249.72px; height: 240.88px;"><img alt="" src="images/image82.png" style="width: 249.72px; height: 240.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 357.33px;"><img alt="" src="images/image319.png" style="width: 624.00px; height: 357.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 633.33px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 633.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span class="c1">Created on first try. Robe and hands are perfect </span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 885.33px;"><img alt="" src="images/image42.png" style="width: 624.00px; height: 885.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span class="c1">First attempt: &quot;Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat.&quot;</span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 636.00px;"><img alt="" src="images/image85.png" style="width: 624.00px; height: 636.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span class="c1">Prompt: person take photo of Graffiti art spelling out the words &quot;WAFERSELAMAT&quot;, graffiti, white wall, dynamic color, spray paint,</span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 640.00px;"><img alt="" src="images/image186.png" style="width: 624.00px; height: 640.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-2 start"><li class="c7 li-bullet-0"><span>Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura&#39;s styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span>Google&rsquo;s new image diffusion model: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/&amp;sa=D&amp;source=editors&amp;ust=1730413584240945&amp;usg=AOvVaw2ZCOnVfGGDEPSXcg5zCZoC">https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/</a></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image189.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 628.00px;"><img alt="" src="images/image177.png" style="width: 624.00px; height: 628.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 621.33px;"><img alt="" src="images/image40.png" style="width: 624.00px; height: 621.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 629.33px;"><img alt="" src="images/image130.png" style="width: 624.00px; height: 629.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 630.67px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 630.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span>Lumina-GPT: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/Alpha-VLLM/Lumina-mGPT&amp;sa=D&amp;source=editors&amp;ust=1730413584241529&amp;usg=AOvVaw3cbyrYPOU_O6yQ0mdYrr4W">https://github.com/Alpha-VLLM/Lumina-mGPT</a></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1 start"><li class="c10 li-bullet-0"><span class="c1">A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. </span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1013.33px;"><img alt="" src="images/image275.png" style="width: 624.00px; height: 1013.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span class="c14">Stable Diffusion lora trained on Midjourney images: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://civitai.com/models/251417/midjourney-mimic&amp;sa=D&amp;source=editors&amp;ust=1730413584242009&amp;usg=AOvVaw3hMX4fdvruxEr-wu7UnRDx">https://civitai.com/models/251417/midjourney-mimic</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span class="c14">Adobe Firefly used thousands of Midjourney images in training its &#39;ethical AI&#39; model: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://tomsguide.com/ai/ai-image-video/adobe-firefly-used-thousands-of-midjourney-images-in-training-its-ethical-ai-model&amp;sa=D&amp;source=editors&amp;ust=1730413584242307&amp;usg=AOvVaw12_erTm-HDIxWPQdJVGIHz">https://tomsguide.com/ai/ai-image-video/adobe-firefly-used-thousands-of-midjourney-images-in-training-its-ethical-ai-model</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span>Openjourney is an open source Stable Diffusion fine tuned model on Midjourney image: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/prompthero/openjourney&amp;sa=D&amp;source=editors&amp;ust=1730413584242554&amp;usg=AOvVaw1QRsCKSZUVIi85kihuFuVB">https://huggingface.co/prompthero/openjourney</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span>Training a diffusion model better than stable diffusion 1.5 and DALLE 2 from scratch for $1890 on only 37 real and synthetic million images: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.15811&amp;sa=D&amp;source=editors&amp;ust=1730413584242792&amp;usg=AOvVaw15slb-9OpnZIB0g8S6QdH2">https://arxiv.org/abs/2407.15811</a></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1 start"><li class="c10 li-bullet-0"><span class="c3">using only 37M publicly available real and synthetic images, we train a 1.16 billion parameter sparse transformer with only $1,890 economical cost and achieve a 12.7 FID in zero-shot generation on the COCO dataset. Notably, our model achieves competitive FID and high-quality generations while incurring 118x lower cost than stable diffusion models and 14x lower cost than the current state-of-the-art approach that costs $28,400.</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 1148.00px;"><img alt="" src="images/image290.png" style="width: 624.00px; height: 1148.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 458.67px;"><img alt="" src="images/image146.png" style="width: 624.00px; height: 458.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 454.67px;"><img alt="" src="images/image181.png" style="width: 624.00px; height: 454.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 440.00px;"><img alt="" src="images/image351.png" style="width: 624.00px; height: 440.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span>Diffusion Augmented Agents can autonomously learn and generate infinite synthetic data: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2407.20798&amp;sa=D&amp;source=editors&amp;ust=1730413584243349&amp;usg=AOvVaw23-xIS8zuM_lCWXCfQm-ht">https://arxiv.org/abs/2407.20798</a></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-1 start"><li class="c10 li-bullet-0"><span>We introduce Diffusion Augmented Agents (DAAG), a novel framework that leverages large language models, vision language models, and diffusion models to improve sample efficiency and transfer learning in reinforcement learning for embodied agents. DAAG hindsight relabels the agent&#39;s past experience by using diffusion models to transform videos in a temporally and geometrically consistent way to align with target instructions with a technique we call Hindsight Experience Augmentation. A large language model orchestrates this </span><span class="c15">autonomous process without requiring human supervision, making it well-suited for lifelong learning scenarios</span><span>. The framework reduces the amount of reward-labeled data needed to 1) finetune a vision language model that acts as a reward detector, and 2) train RL agents on new tasks. We demonstrate the sample efficiency gains of DAAG in simulated robotics environments involving manipulation and navigation. Our results show that DAAG </span><span class="c15">improves learning of reward detectors, transferring past experience, and acquiring new tasks - key abilities for developing efficient lifelong learning agents</span><span>. Supplementary material and visualizations are available on our website </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://sites.google.com/view/diffusion-augmented-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413584243769&amp;usg=AOvVaw0ouAH1umn9THFwyZ7wZ2PY">this https URL</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://sites.google.com/view/diffusion-augmented-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413584243942&amp;usg=AOvVaw2Welhmu6pJe8ROyVEr8xrA">https://sites.google.com/view/diffusion-augmented-agents/</a></span></li></ul><ul class="c0 lst-kix_uu0tjb1960c1-0"><li class="c4 li-bullet-0"><span>Ideagram 2.0 has no &ldquo;inbreeding&rdquo; issues: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/&amp;sa=D&amp;source=editors&amp;ust=1730413584244173&amp;usg=AOvVaw0Yi-ZdIezz2-_jWWHn7Hvt">https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/</a></span></li><li class="c4 li-bullet-0"><span>OpenAI is already training a new version of Sora with even higher quality and longer videos: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign%3DEditorial%26utm_content%3DNewsletter%252CAI%2BAgenda%26utm_medium%3Dorganic_social%26utm_source%3Dtwitter&amp;sa=D&amp;source=editors&amp;ust=1730413584244424&amp;usg=AOvVaw1UfSx5eqqoATVm-c5oUgj_">https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video</a></span></li><li class="c4 li-bullet-0"><span>Meta&#39;s Joe Spisak explains how AI models can train themselves by generating images, asking itself questions about them, and choosing the best answers, in order to move beyond human data and human fine-tuning, and teach itself from synthetic data: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1847789784078618640&amp;sa=D&amp;source=editors&amp;ust=1730413584244660&amp;usg=AOvVaw2gx6EOHHifP_shmReA8EJJ">https://x.com/tsarnick/status/1847789784078618640</a></span></li></ul><h1 class="c123" id="h.gzehpkdfmgeo"><span>15. </span><span class="c40 c37 c48 c77">AI Achievements </span></h1><ul class="c0 lst-kix_7kr9zis60z3j-0 start"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 543.66px; height: 727.50px;"><img alt="" src="images/image123.png" style="width: 543.66px; height: 727.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span>Source: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://ourworldindata.org/artificial-intelligence&amp;sa=D&amp;source=editors&amp;ust=1730413584245196&amp;usg=AOvVaw0zb-0YT890eZL-YpBoC5NC">https://ourworldindata.org/artificial-intelligence</a></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>&quot;GPT-3 displayed some of the cognitive biases observed in people, but they have largely disappeared in the latest generation of LLMs. The tests...designed to be challenging for humans, possibly no longer challenge the growing reasoning abilities in LLMs&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2303.13988&amp;sa=D&amp;source=editors&amp;ust=1730413584245421&amp;usg=AOvVaw2zrEgUrC6ONaKkN2rcQlNB">https://arxiv.org/pdf/2303.13988</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>ChatGPT in top 1% of creativity: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.cnbc.com/2023/07/17/study-chatgpt-can-match-the-top-1percent-of-creative-human-thinkers.html&amp;sa=D&amp;source=editors&amp;ust=1730413584245710&amp;usg=AOvVaw23VJk1CEsSd7ycuKwaZBW-">https://www.cnbc.com/2023/07/17/study-chatgpt-can-match-the-top-1percent-of-creative-human-thinkers.html</a></span><span class="c1">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/hardmaru/status/1801074062535676193&amp;sa=D&amp;source=editors&amp;ust=1730413584245889&amp;usg=AOvVaw3UtXyP-8hlB3RaT9S0j8Ww">https://x.com/hardmaru/status/1801074062535676193</a></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span>We&rsquo;re excited to release DiscoPOP: a </span><span class="c33 c15">new SOTA preference optimization algorithm that was discovered and written by an LLM!</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/OdRY60ihG8&amp;sa=D&amp;source=editors&amp;ust=1730413584246154&amp;usg=AOvVaw35g5gG3SsKwuedv4pAR4SW">https://sakana.ai/llm-squared/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span>Our method leverages LLMs to propose and implement new preference optimization algorithms. We then train models with those algorithms and evaluate their performance, providing feedback to the LLM. By repeating this process for multiple generations in an evolutionary loop, the </span><span class="c33 c15">LLM discovers many highly-performant and novel preference optimization objectives!</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span>Paper:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/IBSOyUQ3jW&amp;sa=D&amp;source=editors&amp;ust=1730413584246537&amp;usg=AOvVaw1Q_MgCnz8UXjoHYIBTAE8n">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2406.08414&amp;sa=D&amp;source=editors&amp;ust=1730413584246648&amp;usg=AOvVaw2s9oA6YYuQzMPjxptQc0Ol">https://arxiv.org/abs/2406.08414</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span>GitHub:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/P4rhmIWPCN&amp;sa=D&amp;source=editors&amp;ust=1730413584246891&amp;usg=AOvVaw2pdjeMcCKJxU98cGtpSyAX">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://github.com/SakanaAI/DiscoPOP&amp;sa=D&amp;source=editors&amp;ust=1730413584247011&amp;usg=AOvVaw1XO-y4ulw_9CvxXYnfgUSF">https://github.com/SakanaAI/DiscoPOP</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span>Model:</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://t.co/jrKH1bFmaN&amp;sa=D&amp;source=editors&amp;ust=1730413584247223&amp;usg=AOvVaw2Zniz6C3N1uplg04zDUeiB">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma&amp;sa=D&amp;source=editors&amp;ust=1730413584247353&amp;usg=AOvVaw0ZE5jPxn3nJPz9xhH_TJZp">https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma</a></span></li></ul><p class="c71 c46"><span class="c40 c37 c65 c60"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>Claude 3 recreated an unpublished paper on quantum theory without ever seeing it according to former Google quantum computing engineer and CEO of Extropic AI: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GillVerd/status/1764901418664882327&amp;sa=D&amp;source=editors&amp;ust=1730413584247622&amp;usg=AOvVaw3SYoUA295kBx6FHxsg6ex_">https://twitter.com/GillVerd/status/1764901418664882327</a></span></li><li class="c4 c46 li-bullet-0"><span class="c1"></span></li></ul><p class="c21"><span class="c1">&nbsp;</span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>&ldquo;Godfather of AI&rdquo; and Turing Award winner Geoffrey Hinton: A neural net given training data where half the </span><span class="c15">ex</span><span class="c15 c35 c65">amples are incorrect still had an error rate of &lt;=25% rather than 50% because it is able to generalize and find patterns even with very flawed training data</span><span class="c23 c14">: </span><span class="c5 c23 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/n4IQOBka8bc?si%3DwM423YLd-48YC-eY?t%3D840&amp;sa=D&amp;source=editors&amp;ust=1730413584247989&amp;usg=AOvVaw36gUMlg21lojzWtEfjl4DA">https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY</a></span><span class="c1">&nbsp;(14:00 timestamp)</span></li><li class="c4 li-bullet-0"><span class="c14">AI beat humans at being persuasive: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1bto2zm/ai_chatbots_beat_humans_at_persuading_their/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584248296&amp;usg=AOvVaw0idGuCeA0rucRirItCAt3k">https://www.reddit.com/r/singularity/comments/1bto2zm/ai_chatbots_beat_humans_at_persuading_their/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-01087-4&amp;sa=D&amp;source=editors&amp;ust=1730413584248542&amp;usg=AOvVaw1MAjMpkCUppAYKnb6Irw4i">AI beats humans at basic tasks</a></span><span class="c14">: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.nature.com/articles/d41586-024-01087-4&amp;sa=D&amp;source=editors&amp;ust=1730413584248722&amp;usg=AOvVaw0nuBcNfzP3rlw3DfgbRrN4">https://www.nature.com/articles/d41586-024-01087-4</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c30 c37 c14">GPT4 passes Turing test 54% of the time: </span><span class="c5 c30 c14 c37"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/camrobjones/status/1790766472458903926&amp;sa=D&amp;source=editors&amp;ust=1730413584249064&amp;usg=AOvVaw2x0ciFsUowBP-Js56E1Ux9">https://twitter.com/camrobjones/status/1790766472458903926</a></span></li><li class="c4 li-bullet-0"><span class="c15 c35 c65">&nbsp;[Claude 3 recreated an unpublished paper on quantum theory without ever seeing it](</span><span class="c20 c15 c35 c65"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/GillVerd/status/1764901418664882327&amp;sa=D&amp;source=editors&amp;ust=1730413584249399&amp;usg=AOvVaw2_cumlHyrKASxOIZ9-e4aS">https://twitter.com/GillVerd/status/1764901418664882327</a></span><span class="c40 c15 c35 c65">) </span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>Predicting </span><span class="c15">out of distribution phenomenon </span><span>of NaCl in solvent: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2310.12535&amp;sa=D&amp;source=editors&amp;ust=1730413584249727&amp;usg=AOvVaw1ME1G4x4TCxNXsvTeo73YF">https://arxiv.org/abs/2310.12535</a></span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_izsd5g4fgpc-0 start"><li class="c22 c4 li-bullet-0"><span class="c14">China&rsquo;s &lsquo;AI Ship Designer&rsquo; Works At Unprecedented Speed; Performed A Year&rsquo;s Work Only In 24 Hours!: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/&amp;sa=D&amp;source=editors&amp;ust=1730413584250036&amp;usg=AOvVaw1f-bzonDQbEcL617Yt0xOu">https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/</a></span><span class="c14">&nbsp;</span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0 start"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/&amp;sa=D&amp;source=editors&amp;ust=1730413584250320&amp;usg=AOvVaw3ioTDpxZIWBKHWfInFYhhz">AI-powered F-16 impresses ride-along SECAF in dogfight</a></span><span class="c14">:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/&amp;sa=D&amp;source=editors&amp;ust=1730413584250488&amp;usg=AOvVaw29LpI-5dLLiYpeSYcjax_9">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/&amp;sa=D&amp;source=editors&amp;ust=1730413584250633&amp;usg=AOvVaw1PSs9ma2aZJDhlOKz03-jU">https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/</a></span></li></ul><p class="c9"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c22 c4 li-bullet-0"><span class="c14">[ChatGPT can do chemistry research better than AI designed for it and the creators didn&rsquo;t even know](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://youtu.be/0b03ibtVYhw?feature%3Dshared%26t%3D447&amp;sa=D&amp;source=editors&amp;ust=1730413584250920&amp;usg=AOvVaw0Xqga8f4glpJPU1VSnt0BT">https://youtu.be/0b03ibtVYhw?feature=shared&amp;t=447</a></span><span class="c1 c14">)</span></li></ul><p class="c22 c9 c97"><span class="c1 c14"></span></p><p class="c73 c46"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c45 li-bullet-0"><span class="c14">Claude 3 solves a problem thought to be impossible for LLMs to solve: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1byusmx/someone_prompted_claude_3_opus_to_solve_a_problem/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584251284&amp;usg=AOvVaw2uuE2kPTLYbEpqP98slw67">https://www.reddit.com/r/singularity/comments/1byusmx/someone_prompted_claude_3_opus_to_solve_a_problem/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c73 c46"><span class="c40 c15 c35 c65"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c22 c74 c129 li-bullet-0"><span class="c15">A new study shows a 21% drop in demand for digital freelancers since ChatGPT was launched. The hype in AI is real but so is the risk of job displacement: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4602944&amp;sa=D&amp;source=editors&amp;ust=1730413584251548&amp;usg=AOvVaw1DVARGrHyp-cSwF6vFlYAi">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4602944</a></span><span class="c33 c15">&nbsp;</span></li></ul><p class="c22 c74 c46"><span class="c33 c15"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c22 c74 c105 li-bullet-0"><span class="c87 c37 c35 c48 c14">Our findings indicate a 21 percent decrease in the number of job posts for automation-prone jobs related to writing and coding compared to jobs requiring manual-intensive skills after the introduction of ChatGPT. We also find that the introduction of Image-generating AI technologies led to a significant 17 percent decrease in the number of job posts related to image creation. Furthermore, we use Google Trends to show that the more pronounced decline in the demand for freelancers within automation-prone jobs correlates with their higher public awareness of ChatGPT&#39;s substitutability.</span></li></ul><p class="c22 c74 c46"><span class="c87 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">Human level text to speech: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/&amp;sa=D&amp;source=editors&amp;ust=1730413584251957&amp;usg=AOvVaw0PCqd9q3ZTA3lQIdGm_z-9">https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/</a></span></li></ul><p class="c131 c53 c56"><span class="c40 c37 c48 c31">&nbsp;</span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c131 c53 c56 c78 li-bullet-0"><span class="c31">AI makes code refactoring much faster: </span><span class="c5 c31"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/&amp;sa=D&amp;source=editors&amp;ust=1730413584252241&amp;usg=AOvVaw0QpfaLG6XBrjiTjVWqyz0k">https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/</a></span></li></ul><p class="c131 c53 c56 c46"><span class="c40 c37 c48 c31"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c22 c4 li-bullet-0"><span>AI is better than humans at lie detection: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2024/07/05/1094703/ai-lie-detectors-are-better-than-humans-at-spotting-lies/&amp;sa=D&amp;source=editors&amp;ust=1730413584252581&amp;usg=AOvVaw3sqKeKSK-eGq0kdyg0dZ45">https://www.technologyreview.com/2024/07/05/1094703/ai-lie-detectors-are-better-than-humans-at-spotting-lies/</a></span></li><li class="c4 li-bullet-0"><span>AI used by official Disney show for intro: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits&amp;sa=D&amp;source=editors&amp;ust=1730413584252846&amp;usg=AOvVaw37FnJBjeBffp0Xj6PsZLMg">https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits</a></span></li><li class="c4 li-bullet-0"><span>gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It&#39;s very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves. </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/a_karvonen/status/1705340535836221659&amp;sa=D&amp;source=editors&amp;ust=1730413584253063&amp;usg=AOvVaw1dIUDzG71NxgTmotoC5z1w">https://x.com/a_karvonen/status/1705340535836221659</a></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.96px; height: 294.48px;"><img alt="" src="images/image253.png" style="width: 588.96px; height: 294.48px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>We&#39;ve created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DanHendrycks/status/1833152719756116154&amp;sa=D&amp;source=editors&amp;ust=1730413584253462&amp;usg=AOvVaw1j52UYlsdksJknm1f2dfHE">https://x.com/DanHendrycks/status/1833152719756116154</a></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c10 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters</span></li><li class="c10 li-bullet-0"><span class="c57 c37 c154 c48 c141 c14">Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.</span></li><li class="c10 li-bullet-0"><span class="c141 c14">On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% &plusmn; 1.4. A link to the technical report is </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://drive.google.com/file/d/1Tc_xY1NM-US4mZ4OpzxrpTudyo1W4KsE/view?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1730413584253971&amp;usg=AOvVaw1xeL9cx4Z-AuyvPz3xh3qx">here</a></span><span class="c57 c37 c154 c48 c141 c14">. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they&rsquo;re similarly accurate.</span></li><li class="c10 li-bullet-0"><span class="c141 c14">The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=http://forecast.safe.ai/&amp;sa=D&amp;source=editors&amp;ust=1730413584254324&amp;usg=AOvVaw0RXSARZ7PKR4M3sjRuZNBO">forecast.safe.ai</a></span><span class="c141 c14">.) Moreover, probabilities from AIs are also known to lead to </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Automation_bias&amp;sa=D&amp;source=editors&amp;ust=1730413584254517&amp;usg=AOvVaw0t4zPzV-mT-I8j_ea2RUvK">automation bias</a></span><span class="c57 c37 c154 c48 c141 c14">, and improvements in the interface could ameliorate this.</span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>A* planning: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning&amp;sa=D&amp;source=editors&amp;ust=1730413584254770&amp;usg=AOvVaw1NrCxIOzBCUjeRUoqhjthL">https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-1"><li class="c10 li-bullet-0"><span class="c92 c183 c37 c14 c114">Based on the claims of the research team, their transformer model optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A&lowast; search. Their solution also robustly follows the execution trace of a symbolic planner and improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.</span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 446.67px;"><img alt="" src="images/image435.jpg" style="width: 624.00px; height: 446.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c10 li-bullet-0"><span class="c1">Note that this test is an offline-only IQ quiz that a Mensa member created for my testing, which is *not in any AI training data* (so scores are lower than for public IQ tests.)</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/maximlott/status/1834652893229859212&amp;sa=D&amp;source=editors&amp;ust=1730413584255671&amp;usg=AOvVaw2hT5fNiQfSjYJe683ahTd0">https://x.com/maximlott/status/1834652893229859212</a></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>Large Language Models for Idea Generation in Innovation: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4526071&amp;sa=D&amp;source=editors&amp;ust=1730413584255974&amp;usg=AOvVaw0OUunRMIrEa2gQVyiec8hT">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-1"><li class="c10 li-bullet-0"><span class="c87 c37 c35 c48 c14">ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. </span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Da8QvnIAGjPA&amp;sa=D&amp;source=editors&amp;ust=1730413584256415&amp;usg=AOvVaw2xJ7kWVGr1JmJFXka98boA">https://m.youtube.com/watch?v=a8QvnIAGjPA</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 754.67px;"><img alt="" src="images/image467.png" style="width: 624.00px; height: 754.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs &amp; this lasts for months: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.adq1814&amp;sa=D&amp;source=editors&amp;ust=1730413584256895&amp;usg=AOvVaw00JND8tpdZks2f_eM6Osi4">https://www.science.org/doi/10.1126/science.adq1814</a></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 622.67px;"><img alt="" src="images/image279.png" style="width: 624.00px; height: 622.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>Our LLM-driven bi-level programming shows it&rsquo;s possible to learn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the &ldquo;chain rule&rdquo; to guide reward search directly from video demos&rdquo; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/&amp;sa=D&amp;source=editors&amp;ust=1730413584257414&amp;usg=AOvVaw2lUH8-Hfmc_kOd6yoGGcfP">https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/</a></span></li><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 748.00px;"><img alt="" src="images/image87.png" style="width: 624.00px; height: 748.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c10 li-bullet-0"><span class="c14">Google trained grandmaster level chess (2895 Elo) without search in a 270 million parameter transformer model with a training dataset of 10 million chess games: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2402.04494&amp;sa=D&amp;source=editors&amp;ust=1730413584257865&amp;usg=AOvVaw0KnD9YeN8nSI8Zbf3XGomn">https://arxiv.org/abs/2402.04494</a></span></li><li class="c10 li-bullet-0"><span class="c1 c14">&nbsp;In the paper, they present results for models sizes 9m (internal bot tournament elo 2007), 136m (elo 2224), and 270m trained on the same dataset. Which is to say, data efficiency scales with model size</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-1"><li class="c10 li-bullet-0"><span class="c14">Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Shannon_number&amp;sa=D&amp;source=editors&amp;ust=1730413584258206&amp;usg=AOvVaw1TRtNqK9pUH_VQCSEka4-1">https://en.wikipedia.org/wiki/Shannon_number</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-2 start"><li class="c7 li-bullet-0"><span class="c14">There are only 10^80 atoms in the universe: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.thoughtco.com/number-of-atoms-in-the-universe-603795%23:~:text%3DScientists%2520estimate%2520there%2520are%252010,80%2520atoms%2520in%2520the%2520universe&amp;sa=D&amp;source=editors&amp;ust=1730413584258637&amp;usg=AOvVaw2Cvzua2lM4UPtrgUh-qLsK">https://www.thoughtco.com/number-of-atoms-in-the-universe-603795</a></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>Sundar Pichai said on an earnings call that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/&amp;sa=D&amp;source=editors&amp;ust=1730413584259009&amp;usg=AOvVaw1Vxr4REoCmgnha1Ftceqp9">https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-1"><li class="c10 li-bullet-0"><span class="c1">Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said &ldquo;a large percentage&rdquo; instead of a specific and verifiable number.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ul><h2 class="c64" id="h.2a84qeq4aymv"><span>15.1. Jobs</span></h2><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c111 c78 li-bullet-0"><span>OpenAI tech increased productivity of Philippine contact center agents by 12.8% &ndash; study: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.rappler.com/technology/openai-gpt-productivity-effects-philippines-contact-center-agents/&amp;sa=D&amp;source=editors&amp;ust=1730413584259501&amp;usg=AOvVaw1i5-MmdcQTNzIkGFPi8VZ6">https://www.rappler.com/technology/openai-gpt-productivity-effects-philippines-contact-center-agents/</a></span><span class="c1">&nbsp;</span></li></ul><p class="c111 c46"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c15">&ldquo;GenAI will save [Klarna] $10m in marketing this year. We&rsquo;re spending less on photographers, image banks, and marketing agencies</span><span class="c14">&rdquo;</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/&amp;sa=D&amp;source=editors&amp;ust=1730413584259821&amp;usg=AOvVaw2WVTcCRZBULYor89Rh03Lw">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/&amp;sa=D&amp;source=editors&amp;ust=1730413584260008&amp;usg=AOvVaw3-kqvEQD9I-8V25mD4kxlh">https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/</a></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span class="c33 c15">$6m less on producing images.</span></li><li class="c10 li-bullet-0"><span class="c1 c14">- 1,000 in-house AI-produced images in 3 months. Includes the creative concept, quality check, and legal compliance.</span></li><li class="c10 li-bullet-0"><span class="c14">- AI-image production </span><span class="c33 c15">reduced from 6 WEEKS TO 1 WEEK ONLY.</span></li><li class="c10 li-bullet-0"><span class="c14">- Customer response to AI images </span><span class="c33 c15">on par with human produced images.</span></li><li class="c10 li-bullet-0"><span class="c14">- Cutting external marketing agency costs by</span><span class="c15">&nbsp;25%</span><span class="c1 c14">&nbsp;(mainly translation, production, CRM, and social agencies).</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c14">Our in-house marketing team is </span><span class="c15">HALF the size</span><span class="c14">&nbsp;it was last year but is </span><span class="c15">producing MORE</span><span class="c1 c14">!</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c1 c14">We&rsquo;ve removed the need for stock imagery from image banks like </span></li><li class="c10 li-bullet-0"><span class="c1 c14">@gettyimages</span></li><li class="c10 c46 li-bullet-0"><span class="c1 c14"></span></li><li class="c10 li-bullet-0"><span class="c1 c14">Now we use genAI tools like Midjourney, DALL-E, and Firefly to generate images, and Topaz Gigapixel and Photoroom to make final adjustments.</span></li><li class="c10 li-bullet-0"><span class="c14">Faster images means </span><span class="c15">more app updates</span><span class="c1 c14">, which is great for customers. And our employees get to work on more fun projects AND we&#39;re saving money.</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">&lsquo;I will never go back&rsquo;: Ontario family doctor says new AI notetaking saved her job:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413584261040&amp;usg=AOvVaw3k2K2V8Pk50ah_7LDDQP7T">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413584261192&amp;usg=AOvVaw0wUxyU5Yv7loAkMzZshgrh">https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes</a></span><span class="c1 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span class="c14">&ldquo;If the physician is unhappy with the note, Lall said, they can ask the AI model to regenerate the information or add more detail to any one of the categories. While the tool has some imperfections, she said, the improvements have been noticeable over the 10 months since she began using it.&ldquo;I really feel this should be the</span><span class="c15">&nbsp;next gold standard for all of our doctors.</span><span class="c14">&nbsp;It decreases the cognitive load you feel at the end of the day,&rdquo; she said.The Ford government has been so impressed with the technology that it announced </span><span class="c15">a pilot program to allow 150 family physicians to use AI Scribe as part of their practices.</span><span class="c1 c14">&nbsp;The health minister said the early signs were promising but stressed government would proceed carefully.&rdquo;</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/&amp;sa=D&amp;source=editors&amp;ust=1730413584261629&amp;usg=AOvVaw2Vt4XRecocJFkJjK9zYaXb">Nvidia&rsquo;s AI Bot Outperforms Nurses, Study Finds</a></span><span class="c35 c14">: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/&amp;sa=D&amp;source=editors&amp;ust=1730413584261816&amp;usg=AOvVaw0lRtSZKElwCKCdtlhfBK-P">https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/</a></span><span class="c40 c37 c35 c48 c14">&nbsp;</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI&amp;sa=D&amp;source=editors&amp;ust=1730413584262079&amp;usg=AOvVaw2y7K3EdOcUyp21wgT8mFev">And they only cost $9 an hour</a></span><span class="c35 c14">: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI&amp;sa=D&amp;source=editors&amp;ust=1730413584262293&amp;usg=AOvVaw3NatXdLZLB_wWM_sHW0wcf">https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI</a></span></li><li class="c10 li-bullet-0"><span class="c37 c76 c84 c114 c138">According to </span><span class="c37 c14 c76 c114 c155"><a class="c13" href="https://www.google.com/url?q=https://www.foxbusiness.com/technology/nvidia-announces-ai-powered-health-care-agents-outperform-nurses-cost-9-hour&amp;sa=D&amp;source=editors&amp;ust=1730413584262535&amp;usg=AOvVaw2upRGyikma3IWqv_ppMD1Z">company-released data</a></span><span class="c70 c37 c76 c114">, the AI bots are 16% better than nurses at identifying a medication&rsquo;s impact on lab values, 24% more accurate detecting toxic dosages of over-the-counter drugs, and 43% better at identifying condition-specific negative interactions from OTC meds. All that at $9 an hour compared to the $39.05 median hourly pay for U.S. nurses. These AI nurse-bots are designed to make new diagnoses, manage chronic disease, and give patients a detailed but clear explanation of clinicians&rsquo; advice.</span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.z97u1xnppdf6"><span class="c40 c37 c48 c75">15.2. Medicine</span></h2><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.41px; height: 570.34px;"><img alt="" src="images/image202.png" style="width: 569.41px; height: 570.34px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/&amp;sa=D&amp;source=editors&amp;ust=1730413584263264&amp;usg=AOvVaw3ZwE3QZZBIFg-ySfJQj06P">https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/</a></span></li><li class="c4 li-bullet-0"><span>AI Detects More Breast Cancers with Fewer False Positives </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers&amp;sa=D&amp;source=editors&amp;ust=1730413584263492&amp;usg=AOvVaw2tcfEfUPPl6xjTH6v2J7lP">https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers</a></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span class="c1">Recall (false positive) rate and radiologist reading workload decreased significantly in AI-screened group</span></li><li class="c10 li-bullet-0"><span class="c1">Using AI, breast radiologists in Denmark have improved breast cancer screening performance and reduced the rate of false-positive findings.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">In total, 60,751 women were screened without AI, and 58,246 women were screened with the AI system. In the AI implementation group, 66.9% (38,977) of the screenings were single-read, and 33.1% (19,269) were double-read with AI assistance. </span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">Compared to screening without AI, screening with the AI system detected significantly more breast cancers (0.82% versus 0.70%) and had a lower false-positive rate (1.63% versus 2.39%). </span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">&ldquo;In the AI-screened group, the recall rate decreased by 20.5 percent, and the radiologists&rsquo; reading workload was lowered by 33.4 percent,&rdquo; Dr. Lauritzen said.</span></li><li class="c10 li-bullet-0"><span class="c92 c37 c65 c126 c81">The positive predictive value of AI screening was also greater than that of screening without AI (33.5% versus 22.5%). In the AI group, a higher proportion of invasive cancers detected were 1 centimeter or less in size (44.93% vs. 36.60%).</span></li><li class="c10 li-bullet-0"><span class="c37 c65 c126 c81">&ldquo;All screening performance indicators improved except for the node-negative rate which showed no evidence of change,&rdquo; Dr. Lauritzen said.</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>AI spots cancer and viral infections at nanoscale precision: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html&amp;sa=D&amp;source=editors&amp;ust=1730413584264311&amp;usg=AOvVaw3K02DM6Hxkjk9kSbgeZrWt">https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/?f%3Dflair_name%253A%2522AI%2522&amp;sa=D&amp;source=editors&amp;ust=1730413584264525&amp;usg=AOvVaw3hlxlzJLaaXJYK3uQhQNpd"></a></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c1">Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c22 c4 li-bullet-0"><span class="c14">New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S135964462400134X&amp;sa=D&amp;source=editors&amp;ust=1730413584264929&amp;usg=AOvVaw1vYRQ1hxXztuuEEqfRx8Lt">https://www.sciencedirect.com/science/article/pii/S135964462400134X</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/&amp;sa=D&amp;source=editors&amp;ust=1730413584265353&amp;usg=AOvVaw2KjDUuAeRs1iYJwICWjCA8">Nvidia&rsquo;s AI Bot Outperforms Nurses, Study Finds</a></span><span class="c35 c14">: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/&amp;sa=D&amp;source=editors&amp;ust=1730413584265568&amp;usg=AOvVaw3VCM0lu-qgmDCv2CzTXDBE">https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI&amp;sa=D&amp;source=editors&amp;ust=1730413584265879&amp;usg=AOvVaw08O52aqrfjWTRguHvGigDc">And they only cost $9 an hour</a></span><span class="c35 c14">: </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI&amp;sa=D&amp;source=editors&amp;ust=1730413584266097&amp;usg=AOvVaw0VEL-34EHleg7uQm8QnheC">https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI</a></span></li><li class="c10 li-bullet-0"><span class="c37 c76 c84 c138 c114">According to </span><span class="c37 c14 c76 c155 c114"><a class="c13" href="https://www.google.com/url?q=https://www.foxbusiness.com/technology/nvidia-announces-ai-powered-health-care-agents-outperform-nurses-cost-9-hour&amp;sa=D&amp;source=editors&amp;ust=1730413584266360&amp;usg=AOvVaw03FO0U_oz_Ni-J8K4xFFQb">company-released data</a></span><span class="c70 c37 c76 c114">, the AI bots are 16% better than nurses at identifying a medication&rsquo;s impact on lab values, 24% more accurate detecting toxic dosages of over-the-counter drugs, and 43% better at identifying condition-specific negative interactions from OTC meds. All that at $9 an hour compared to the $39.05 median hourly pay for U.S. nurses. These AI nurse-bots are designed to make new diagnoses, manage chronic disease, and give patients a detailed but clear explanation of clinicians&rsquo; advice.</span></li></ul><p class="c9"><span class="c70 c37 c76 c114"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients&rsquo; tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color&amp;sa=D&amp;source=editors&amp;ust=1730413584266700&amp;usg=AOvVaw0EH4d4kAm-oEmGdKmdPEdS">https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color</a></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span>the paper itself shows that the best model has a f1 score, precision, recall all above 98% </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.mdpi.com/2227-7080/12/7/97&amp;sa=D&amp;source=editors&amp;ust=1730413584266915&amp;usg=AOvVaw2R53RzE56OOfCHGfjyDxXm">https://www.mdpi.com/2227-7080/12/7/97</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c45 c46 li-bullet-0"><span class="c6 c40"></span></li><li class="c45 li-bullet-0"><span class="c6">Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx&amp;sa=D&amp;source=editors&amp;ust=1730413584267284&amp;usg=AOvVaw2BEhicL-brgxA-LyH6mzvq">https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c4 li-bullet-0"><span>AI spots cancer and viral infections at nanoscale precision: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html&amp;sa=D&amp;source=editors&amp;ust=1730413584267566&amp;usg=AOvVaw3btBuAKEKQCo-lQSG7LK_H">https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/?f%3Dflair_name%253A%2522AI%2522&amp;sa=D&amp;source=editors&amp;ust=1730413584267770&amp;usg=AOvVaw1v55i9FC9Iho8i64mkybHM"></a></span></p><ul class="c0 lst-kix_4nm4szcl7et4-1"><li class="c10 li-bullet-0"><span class="c1">Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c4 li-bullet-0"><span>AI Detects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131&amp;sa=D&amp;source=editors&amp;ust=1730413584268076&amp;usg=AOvVaw0iHuME3svzvPmFMQmiXQih">https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_4nm4szcl7et4-0"><li class="c45 li-bullet-0"><span class="c6">GPs use AI to boost cancer detection rates in England by 8%: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8&amp;sa=D&amp;source=editors&amp;ust=1730413584268396&amp;usg=AOvVaw2YPYnE7xS24-cCiz0VwcWN">https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8</a></span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c22 c32 li-bullet-0"><span>Med-Gemini : </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.18416&amp;sa=D&amp;source=editors&amp;ust=1730413584268677&amp;usg=AOvVaw29BU8rHF4tEmy2KaquWeTQ">https://</a></span><span class="c5 c37 c65 c60"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2404.18416&amp;sa=D&amp;source=editors&amp;ust=1730413584268796&amp;usg=AOvVaw1S_cBNwkSlL_KsUWIOHIlF">arxiv.org/abs/2404.18416</a></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c22 c72 li-bullet-0"><span class="c14 c31">We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves </span><span class="c15 c31">SoTA performance of 91.1% accuracy,</span><span class="c14 c31">&nbsp;using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health &amp; medicine), Med-Gemini </span><span class="c15 c31">improves over GPT-4V by an average relative margin of 44.5%</span><span class="c14 c31">. We demonstrate the effectiveness of Med-Gemini&#39;s long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini&#39;s performance suggests real-world utility by </span><span class="c15 c31">surpassing human experts</span><span class="c34 c14 c31">&nbsp;</span><span class="c14 c31">on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. </span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c22 c32 li-bullet-0"><span class="c18">Double-blind study with Patient Actors and Doctors, who didn&#39;t know if they were communicating with a human, or an AI. Best performers were AI: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DjQwwLEZ2Hz8&amp;sa=D&amp;source=editors&amp;ust=1730413584269376&amp;usg=AOvVaw3yMqhlCC2UwZMOsNy6SkVx">https://m.youtube.com/watch?v=jQwwLEZ2Hz8</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c22 c72 li-bullet-0"><span class="c15 c65 c114">Human doctors + AI did worse, than AI by itself.</span><span class="c40 c18">&nbsp;The mere involvement of a human reduced the accuracy of the diagnosis.</span></li><li class="c22 c72 li-bullet-0"><span class="c15 c65 c114">AI was consistently rated to have better bedside manner than human doctors</span><span class="c40 c18">. </span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c22 c32 li-bullet-0"><span class="c14">&lsquo;I will never go back&rsquo;: Ontario family doctor says new AI notetaking saved her job:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413584269982&amp;usg=AOvVaw3zA9XowrGKOiQVjXyRd-GX">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes&amp;sa=D&amp;source=editors&amp;ust=1730413584270178&amp;usg=AOvVaw0LpkheeXnrd_PoaYmyt8Yx">https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c22 c44"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c22 c32 li-bullet-0"><span class="c14">[Google&#39;s medical AI destroys GPT&#39;s benchmark and outperforms doctors](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/google-med-gemini-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413584270456&amp;usg=AOvVaw0HRiuv1b4XoL73_K8X7eEs">https://newatlas.com/technology/google-med-gemini-ai/</a></span><span class="c1 c14">)</span></li></ul><p class="c22 c44"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c22 c32 li-bullet-0"><span class="c14">[The first randomized trial of medical #AI to show it saves lives. ECG-AI alert in 16,000 hospitalized patients. 31% reduction of mortality (absolute 7 per 100 patients) in pre-specified high-risk group](</span><span class="c20 c124 c34 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/erictopol/status/1784936718283805124&amp;sa=D&amp;source=editors&amp;ust=1730413584270786&amp;usg=AOvVaw36MjUtxysKi4HkzVUSs9xN">https://twitter.com/erictopol/status/1784936718283805124</a></span><span class="c40 c124 c34 c14">)</span></li><li class="c22 c32 li-bullet-0"><span class="c18">Medical Text Written By Artificial Intelligence Outperforms Doctors: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/&amp;sa=D&amp;source=editors&amp;ust=1730413584271059&amp;usg=AOvVaw16orPyLUV3fch1bcCsqDES">https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/</a></span><span class="c40 c18">&nbsp;</span></li></ul><p class="c22 c44"><span class="c40 c18"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">AI can make healthcare better and safer: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/singularity/comments/1brojzm/ais_will_make_health_care_safer_and_better/?utm_source%3Dshare%26utm_medium%3Dmweb3x%26utm_name%3Dmweb3xcss%26utm_term%3D1%26utm_content%3Dshare_button&amp;sa=D&amp;source=editors&amp;ust=1730413584271473&amp;usg=AOvVaw1gnmlnLvrjcAZG2sI1W1Oy">https://www.reddit.com/r/singularity/comments/1brojzm/ais_will_make_health_care_safer_and_better/?utm_source=share&amp;utm_medium=mweb3x&amp;utm_name=mweb3xcss&amp;utm_term=1&amp;utm_content=share_button</a></span></li></ul><p class="c9"><span class="c40 c18"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c18">CheXzero significantly outperformed humans, especially on uncommon conditions. Huge implications for improving diagnosis of neglected &quot;long tail&quot; diseases: </span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/pranavrajpurkar/status/1797292562333454597&amp;sa=D&amp;source=editors&amp;ust=1730413584271742&amp;usg=AOvVaw26aBPrQi3GI0LAigvzQb_z">https://x.com/pranavrajpurkar/status/1797292562333454597</a></span><span class="c40 c18">&nbsp;</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 611.50px; height: 371.41px;"><img alt="" src="images/image101.png" style="width: 611.50px; height: 371.41px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-2 start"><li class="c7 li-bullet-0"><span class="c40 c18">Humans near chance level (50-55% accuracy) on rarest conditions, while CheXzero maintains 64-68% accuracy.</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image57.png" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c45 li-bullet-0"><span class="c6">ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584272217&amp;usg=AOvVaw3nyh-09VKp6iGaeW6TIiL-">https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_txo0zcn8hx7-0"><li class="c4 li-bullet-0"><span class="c6">AI is better than doctors at detecting breast cancer:</span><span class="c6"><a class="c13" href="https://www.google.com/url?q=https://www.bing.com/videos/search?q%3Dai%2Bbetter%2Bthan%2Bdoctors%2Busing%2Bai%26mid%3D6017EF2744FCD442BA926017EF2744FCD442BA92%26view%3Ddetail%26FORM%3DVIRE%26PC%3DEMMX04&amp;sa=D&amp;source=editors&amp;ust=1730413584272514&amp;usg=AOvVaw0QTDlO1hYKWIBur4Zjm0xy">&nbsp;</a></span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.bbc.com/news/health-50857759&amp;sa=D&amp;source=editors&amp;ust=1730413584272646&amp;usg=AOvVaw2mF14Z8gioWl8quU5BREp1">https://www.bbc.com/news/health-50857759</a></span></li></ul><p class="c73 c46 c129"><span class="c6 c40"></span></p><ul class="c0 lst-kix_snh8lpyqaleg-0"><li class="c45 li-bullet-0"><span class="c6">AI just as good at diagnosing illness as humans: </span><span class="c6 c5"><a class="c13" href="https://www.google.com/url?q=https://www.medicalnewstoday.com/articles/326460?darkschemeovr%3D1&amp;sa=D&amp;source=editors&amp;ust=1730413584274930&amp;usg=AOvVaw1bJN2-_L80Au4bWXLSn1Gg">https://www.medicalnewstoday.com/articles/326460</a></span></li></ul><p class="c73 c46"><span class="c6 c40"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>First NHS physiotherapy clinic run by AI to start this year. New platform to provide same-day appointments with digital physiotherapist in effort to cut waiting times: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year&amp;sa=D&amp;source=editors&amp;ust=1730413584275387&amp;usg=AOvVaw0GdY67tB6moVuOu5saV765">https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year</a></span><span>&nbsp;</span></li><li class="c4 li-bullet-0"><span>China&#39;s first (simulated) AI hospital town debuts: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.globaltimes.cn/page/202405/1313235.shtml&amp;sa=D&amp;source=editors&amp;ust=1730413584275690&amp;usg=AOvVaw3RNbTNBh0zTudTwZ-0WICl">https://www.globaltimes.cn/page/202405/1313235.shtml</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">Remarkably, AI doctors can treat 10,000 [simulated] &nbsp;patients in just a few days. It would take human doctors at least two years to treat that many patients. Furthermore, evolved doctor agents achieved an impressive 93.06 percent accuracy rate on the MedQA dataset (US Medical Licensing Exam questions) covering major respiratory diseases. They simulate the entire process of diagnosing and treating patients, including consultation, examination, diagnosis, treatment and follow-up. </span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">Research team leader of the Agent Hospital Liu Yang, also executive dean of Institute for AI Industry Research (AIR) and associate dean of the Department of Computer Science and Technology at Tsinghua University, told the Global Times that the AI hospital town is set to transform the way doctors diagnose and treat patients, bringing immense benefits to both medical professionals and the general public. </span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c37 c14 c42">For example, this innovative concept allows for virtual patients to be treated by real doctors, providing medical students with enhanced training opportunities. By simulating a variety of AI patients, medical students can confidently propose treatment plans without the fear of causing harm to real patients due to decision-making error, Liu said. </span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">This simulation training enables medical students to practice diagnosis and treatment in a risk-free environment, ultimately leading to the cultivation of highly skilled doctors, according to Liu.</span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">If the patients in the town are real and the doctors are virtual, online telemedicine services can be provided to patients. The AI hospital town utilizes a vast repository of authoritative medical knowledge, allowing AI doctors to handle thousands, even millions, of cases.</span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">The potential for high-quality, affordable and convenient healthcare services for the public is on the horizon, as the diagnostic capabilities of AI doctors evolve from the virtual world to the real world, Liu stated.</span></li><li class="c10 c46 li-bullet-0"><span class="c40 c42 c37 c14"></span></li><li class="c10 li-bullet-0"><span class="c40 c42 c37 c14">Liu went on to say that the AI hospital town can simulate and predict various medical scenarios, such as the spread, development and control of infectious diseases in a region.</span></li></ul><p class="c9"><span class="c40 c42 c37 c14"></span></p><ul class="c0 lst-kix_snh8lpyqaleg-0"><li class="c45 li-bullet-0"><span class="c63 c14">AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: </span><span class="c5 c63 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/tsarnick/status/1814048365002596425&amp;sa=D&amp;source=editors&amp;ust=1730413584277106&amp;usg=AOvVaw3upxPDOpk3U9JtsS6M0sdK">https://x.com/tsarnick/status/1814048365002596425</a></span></li><li class="c22 c32 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.00px; height: 925.00px;"><img alt="" src="images/image505.png" style="width: 569.00px; height: 925.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Google DeepMind&#39;s AlphaProteo generates novel proteins for biology and health research: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source%3Dx%26utm_medium%3D%26utm_campaign%3Dgdm%26utm_content%3D&amp;sa=D&amp;source=editors&amp;ust=1730413584277657&amp;usg=AOvVaw133S4xe5yfEqTNfKH0TTKf">https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source=x&amp;utm_medium=&amp;utm_campaign=gdm&amp;utm_content=</a></span></li></ul><ul class="c0 lst-kix_snh8lpyqaleg-1 start"><li class="c22 c95 c105 li-bullet-0"><span class="c35">AlphaProteo can generate new protein binders for diverse target proteins, including </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www1.rcsb.org/structure/1BJ1&amp;sa=D&amp;source=editors&amp;ust=1730413584277935&amp;usg=AOvVaw2ArlmKwvuNy9cRSpFYxXjZ">VEGF-A</a></span><span class="c40 c37 c35 c48">, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.</span></li><li class="c22 c95 c105 li-bullet-0"><span class="c40 c37 c35 c48">AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.</span></li></ul><ul class="c0 lst-kix_snh8lpyqaleg-0"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 596.00px;"><img alt="" src="images/image575.jpg" style="width: 624.00px; height: 596.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_snh8lpyqaleg-1 start"><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DeryaTR_/status/1834630356286558336&amp;sa=D&amp;source=editors&amp;ust=1730413584278437&amp;usg=AOvVaw0LB1UaGHji6CSmIru4rjb3">https://x.com/DeryaTR_/status/1834630356286558336</a></span></li></ul><ul class="c0 lst-kix_snh8lpyqaleg-0"><li class="c4 li-bullet-0"><span>Tx-LLM: Supporting therapeutic development with large language models: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/&amp;sa=D&amp;source=editors&amp;ust=1730413584278771&amp;usg=AOvVaw1knHTlIYjneLxSEtJMgm7w">https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/</a></span></li><li class="c4 li-bullet-0"><span>BrainLM: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584279069&amp;usg=AOvVaw1C3QS_-gQi0osg6E1DOEXS">https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf</a></span></li></ul><ul class="c0 lst-kix_snh8lpyqaleg-1 start"><li class="c10 li-bullet-0"><span>Utilizing self-supervised masked-prediction training, BrainLM demonstrates </span><span class="c15">proficiency in both fine-tuning and zero-shot inference tasks</span><span>. Fine-tuning allows for the </span><span class="c15">accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states</span><span>. Critically, the model </span><span class="c15">generalizes well to entirely new external cohorts not seen during training.</span><span>&nbsp;In zero-shot inference mode, BrainLM can i</span><span class="c15">dentify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training</span><span>. The model also generates i</span><span class="c15">nterpretable latent representations that reveal relationships between brain activity patterns and cognitive states</span><span>. Overall, BrainLM offers a </span><span class="c34">versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. </span><span>It serves as a powerful &quot;lens&quot; through which m</span><span class="c15">assive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale</span><span class="c1">. The work demonstrates the potential of foundation models to advance computational neuroscience research. </span></li><li class="c10 li-bullet-0"><span class="c33 c15">Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 444.00px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 444.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 601.33px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 601.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 568.00px;"><img alt="" src="images/image38.png" style="width: 624.00px; height: 568.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 160.00px;"><img alt="" src="images/image133.png" style="width: 624.00px; height: 160.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 653.33px;"><img alt="" src="images/image211.png" style="width: 624.00px; height: 653.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 613.96px; height: 520.50px;"><img alt="" src="images/image13.png" style="width: 613.96px; height: 520.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_snh8lpyqaleg-0"><li class="c4 li-bullet-0"><span>Cardiologists working with AI said it was equal or better than human cardiologists in most areas: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/DKThomp/status/1843993273825964312&amp;sa=D&amp;source=editors&amp;ust=1730413584280134&amp;usg=AOvVaw2l-09I2V1VlmDhDgTxrOWZ">https://x.com/DKThomp/status/1843993273825964312</a></span></li></ul><ul class="c0 lst-kix_snh8lpyqaleg-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 209.33px;"><img alt="" src="images/image77.png" style="width: 624.00px; height: 209.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h2 class="c64" id="h.sjbhebyoadqp"><span>15.</span><span>3. Art/Music/Literature</span></h2><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c15">First legally recognized nonbinary person with disabilities writes book with ChatGPT: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/&amp;sa=D&amp;source=editors&amp;ust=1730413584280755&amp;usg=AOvVaw1WGYx5IQcCExjEknMm_54p">https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/</a></span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span>The novel draws from Shupe&rsquo;s eventful life, </span><span class="c15">including her advocacy for more inclusive gender recognition</span><span class="c1">.</span></li><li class="c10 li-bullet-0"><span>Shupe believes fervently that she was </span><span class="c15">only able to complete her book with the assistance of generative AI tools</span><span class="c1">. She says she has been assessed as 100 percent disabled by the Department of Veterans Affairs and struggles to write due to cognitive impairment related to conditions including bipolar disorder, borderline personality disorder, and a brain stem malformation.</span></li><li class="c10 li-bullet-0"><span>She is proud of the finished work and sees working with a text generator as a </span><span class="c15">different but no less worthwhile method of expressing thoughts</span><span>. &ldquo;You don&#39;t just hit &lsquo;generate&rsquo; and get something worthy of publishing. That may come in the future, but we&#39;re still far from it,&rdquo; she says, noting that she spen</span><span class="c33 c15">t upwards of 14 hours a day working on her draft.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney&amp;sa=D&amp;source=editors&amp;ust=1730413584281341&amp;usg=AOvVaw3t5sXB0CSaB4Kqk7J7YNWN">https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney</a></span></li></ul><p class="c9"><span class="c40 c37 c63 c76"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c37 c63 c76">&gt;AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/11/6/23948454/microsoft-xbox-generative-ai-developer-tools-inworld-partnership&amp;sa=D&amp;source=editors&amp;ust=1730413584281630&amp;usg=AOvVaw22sVXS11_EZJQpoHJDuOOY">to develop tools for developers to generate AI NPCs, quests, and stories</a></span><span class="c37 c63 c76">. </span><span class="c5 c37 c63 c61 c76"><a class="c13" href="https://www.google.com/url?q=https://www.theverge.com/2023/12/7/23991851/the-finals-embark-studios-launch-xbox-ps5-pc-steam-available-now&amp;sa=D&amp;source=editors&amp;ust=1730413584281816&amp;usg=AOvVaw2UxxpgG1bu7MZFErZ9wmi0">The Finals</a></span><span class="c37 c63 c76">, a free-to-play multiplayer shooter, </span><span class="c5 c37 c63 c76"><a class="c13" href="https://www.google.com/url?q=https://www.pcgamer.com/the-finals-uses-ai-text-to-speech-because-it-can-produce-lines-in-just-a-matter-of-hours-rather-than-months-baffles-actual-voice-actors/&amp;sa=D&amp;source=editors&amp;ust=1730413584282013&amp;usg=AOvVaw25TykxM_JBX3EggA_1Ma4i">was criticized by voice actors</a></span><span class="c37 c63 c76">&nbsp;for its use of text-to-speech programs to generate voices. Despite the backlash, the game </span><span class="c40 c15 c63 c76">has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.</span></li></ul><p class="c9"><span class="c40 c37 c63 c76"></span></p><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>AI video wins Pink Floyd music video competition: </span><span class="c14 c20"><a class="c13" href="https://www.google.com/url?q=https://ew.com/ai-wins-pink-floyd-s-dark-side-of-the-moon-video-competition-8628712&amp;sa=D&amp;source=editors&amp;ust=1730413584282368&amp;usg=AOvVaw0atVKyGMWkRMcmViXemmTD">https://ew.com/ai-wins-pink-floyd-s-dark-side-of-the-moon-video-competition-8628712</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413584282603&amp;usg=AOvVaw1XVyvIs_TQvoyHomujLkUc">AI image won Colorado state fair </a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413584282739&amp;usg=AOvVaw3Xt0t0kOst3fwuZ6JIYbiN">https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_12ba2se2e37v-1"><li class="c10 li-bullet-0"><span class="c14">&gt;</span><span class="c35 c14">You can feed a phrase like </span><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/rachelmetz/status/1565780528384524288&amp;sa=D&amp;source=editors&amp;ust=1730413584282984&amp;usg=AOvVaw1eLuYXsxHotomQNovkBK1k">&ldquo;an oil painting of an angry strawberry&rdquo;</a></span><span class="c40 c37 c35 c48 c14">&nbsp;to Midjourney and receive several images from the AI system within seconds, but Allen&rsquo;s process wasn&rsquo;t that simple. To get the final three images he entered in the competition, he said, took more than 80 hours.</span></li><li class="c214 c97 c105 li-bullet-0"><span class="c35 c14">First, he said, he played around with phrasing that led Midjourney to generate images of women in frilly dresses and space helmets &mdash; he was trying to mash up Victorian-style costuming with space themes, he said. Over time, with many slight tweaks to his written prompt (such as to adjust lighting and color harmony), he created 900 iterations of what led to his final three images. He cleaned up those three images in Photoshop, such as by giving one of the female figures in his winning image a head with wavy, dark hair after Midjourney had rendered her headless. Then he ran the images through another software program called Gigapixel AI that can improve resolution and had the images printed on canvas at a local print shop.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;Cal Duran, an artist and art teacher who was one of the judges for competition, said that while Allen&rsquo;s piece included a mention of Midjourney, he didn&rsquo;t realize that it was generated by AI when judging it. Still, he sticks by his decision to award it first place in its category, he said, calling it a &ldquo;beautiful piece&rdquo;.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c1 c14">&gt;&ldquo;I think there&rsquo;s a lot involved in this piece and I think the AI technology may give more opportunities to people who may not find themselves artists in the conventional way,&rdquo; he said.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">AI image won in the Sony World Photography Awards: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.scientificamerican.com/article/how-my-ai-image-won-a-major-photography-competition/&amp;sa=D&amp;source=editors&amp;ust=1730413584283586&amp;usg=AOvVaw2-HpvqjH2IBWv9QT_h8wfk">https://www.scientificamerican.com/article/how-my-ai-image-won-a-major-photography-competition/</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">AI image wins another photography competition: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://petapixel.com/2023/02/10/ai-image-fools-judges-and-wins-photography-contest/&amp;sa=D&amp;source=editors&amp;ust=1730413584283853&amp;usg=AOvVaw0-AU-hK7bnkhJJkHi26Pam">https://petapixel.com/2023/02/10/ai-image-fools-judges-and-wins-photography-contest/</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt&amp;sa=D&amp;source=editors&amp;ust=1730413584284089&amp;usg=AOvVaw2FbB925WHp2cAG6cUMRjFu">https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>Fake beauty queens charm judges at the Miss AI pageant: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.npr.org/2024/06/09/nx-s1-4993998/the-miss-ai-beauty-pageant-ushers-in-a-new-type-of-influencer&amp;sa=D&amp;source=editors&amp;ust=1730413584284363&amp;usg=AOvVaw2eC1x2je2kxk5EdQJ6Vc9a">https://www.npr.org/2024/06/09/nx-s1-4993998/the-miss-ai-beauty-pageant-ushers-in-a-new-type-of-influencer</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c35 c14">People PREFER AI art and that was in 2017, long before it got as good as it is today: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/1706.07068&amp;sa=D&amp;source=editors&amp;ust=1730413584284594&amp;usg=AOvVaw3JnjP-zqI2QTJH32YFxdx8">https://arxiv.org/abs/1706.07068</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c14">&gt;</span><span class="c3">The results show that human subjects could not distinguish art generated by the proposed system from art generated by contemporary artists and shown in top art fairs. Human subjects even rated the generated images higher on various scales.</span></li></ul><p class="c9"><span class="c3"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c14 c31">&gt;</span><span class="c55 c14">People took bot-made art for the real deal 75 percent of the time, and 85 percent of the time for the Abstract Expressionist pieces. The collection of works included Andy Warhol, Leonardo Drew, David Smith and more.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">People couldn&rsquo;t distinguish human art from AI art in 2021 (a year before DALLE Mini/CrAIyon even got popular): </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://news.artnet.com/art-world/machine-art-versus-human-art-study-1946514&amp;sa=D&amp;source=editors&amp;ust=1730413584285171&amp;usg=AOvVaw17rLRq9Nq4IjmSxWHfRLV1">https://news.artnet.com/art-world/machine-art-versus-human-art-study-1946514</a></span><span class="c1 c14">&nbsp;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c189 c97 c105 li-bullet-0"><span class="c92 c37 c48 c14 c114 c246">&gt;Some 211 subjects recruited on Amazon answered the survey. A majority of respondents were only able to identify one of the five AI landscape works as such. Around 75 to 85 percent of respondents guessed wrong on the other four. When they did correctly attribute an artwork to AI, it was the abstract one. </span></li></ul><p class="c46 c189"><span class="c92 c37 c246 c48 c14 c114"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">Katy Perry&rsquo;s own mother got tricked by an AI image of Perry: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://abcnews.go.com/GMA/Culture/katy-perry-shares-mom-fooled-ai-photos-2024/story?id%3D109997891&amp;sa=D&amp;source=editors&amp;ust=1730413584285751&amp;usg=AOvVaw3f9Q6YBdhPNCne5GtBBWEh">https://abcnews.go.com/GMA/Culture/katy-perry-shares-mom-fooled-ai-photos-2024/story?id=109997891</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c50 c78 li-bullet-0"><span>Todd McFarlane&#39;s Spawn Cover Contest Was Won By AI User Robot9000: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://bleedingcool.com/comics/todd-mcfarlanes-spawn-cover-contest-was-won-by-ai-user-robo9000/&amp;sa=D&amp;source=editors&amp;ust=1730413584286175&amp;usg=AOvVaw0b7UG94MWJaOve6ZYR4n0Q">https://bleedingcool.com/comics/todd-mcfarlanes-spawn-cover-contest-was-won-by-ai-user-robo9000/</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c1 c14">&ldquo;Runway&#39;s tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.&rdquo; </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Runway_(company)&amp;sa=D&amp;source=editors&amp;ust=1730413584286739&amp;usg=AOvVaw0xdL9zb2E1qNFWd_TbQWQt">https://en.wikipedia.org/wiki/Runway_(company)</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">AI music video from Washed Out that received a Vimeo Staff Pick: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://newatlas.com/technology/openai-sora-first-commissioned-music-video/&amp;sa=D&amp;source=editors&amp;ust=1730413584287155&amp;usg=AOvVaw1iqDO0NmLz5WTAn4gYtdaz">https://newatlas.com/technology/openai-sora-first-commissioned-music-video/</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>Runway and Lionsgate are partnering to explore the use of AI in film production: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://runwayml.com/news/runway-partners-with-lionsgate&amp;sa=D&amp;source=editors&amp;ust=1730413584287517&amp;usg=AOvVaw0-mXG2LGZqwiP7ow96ToBK">https://runwayml.com/news/runway-partners-with-lionsgate</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">Tribeca to screen AI generated films made with Sora: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.indiewire.com/news/festivals/tribeca-ai-generated-short-films-sora-shorts-1235010911/&amp;sa=D&amp;source=editors&amp;ust=1730413584287909&amp;usg=AOvVaw1bsQNJqm6B0kSOWHTSYi7n">https://www.indiewire.com/news/festivals/tribeca-ai-generated-short-films-sora-shorts-1235010911/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve &ldquo;hundreds&rdquo; of people at the company and will primarily focus on post-production and visual effects: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.thewrap.com/disney-ai-initiative/&amp;sa=D&amp;source=editors&amp;ust=1730413584288280&amp;usg=AOvVaw19YFQLtuesLdDhrmdZEIYf">https://www.thewrap.com/disney-ai-initiative/</a></span></li></ul><p class="c9 c129"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">SIX AI images entered top 300 finalists of official Pokemon art competition (2% of all finalists): </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://kotaku.com/pokemon-trading-card-tcg-ai-art-illustration-contest-1851559041&amp;sa=D&amp;source=editors&amp;ust=1730413584288690&amp;usg=AOvVaw19vJV4PdabDBEQQtFrIbUB">https://kotaku.com/pokemon-trading-card-tcg-ai-art-illustration-contest-1851559041</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">AI image becomes top 5 finalist for &ldquo;Girl With Pearl Earring&rdquo; art competition: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.smithsonianmag.com/smart-news/girl-with-a-pearl-earring-vermeer-artificial-intelligence-mauritshuis-180981767/&amp;sa=D&amp;source=editors&amp;ust=1730413584289127&amp;usg=AOvVaw1d_HHUXsb4g4oDSeWV5FPE">https://www.smithsonianmag.com/smart-news/girl-with-a-pearl-earring-vermeer-artificial-intelligence-mauritshuis-180981767/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">Real photograph only got third place in AI art competition: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://www.cnn.com/2024/06/14/style/flamingo-photograph-ai-1839-awards/index.html&amp;sa=D&amp;source=editors&amp;ust=1730413584289539&amp;usg=AOvVaw3dKODRaxXuYbDYvXvB6twt">https://www.cnn.com/2024/06/14/style/flamingo-photograph-ai-1839-awards/index.html</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c50 c78 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 477.31px; height: 597.50px;"><img alt="" src="images/image209.png" style="width: 477.31px; height: 597.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-1 start"><li class="c17 li-bullet-0"><span class="c1">Many people, including AI haters, couldnt tell this image is AI generated: </span></li></ul><ul class="c0 lst-kix_7kr9zis60z3j-2 start"><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/midosommar/status/1843013374919241868&amp;sa=D&amp;source=editors&amp;ust=1730413584290013&amp;usg=AOvVaw3R61JxT2LwkHMJyBS3aVtg">https://x.com/midosommar/status/1843013374919241868</a></span></li><li class="c50 c86 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/beyoncesspamacc/status/1843094040851726800&amp;sa=D&amp;source=editors&amp;ust=1730413584290211&amp;usg=AOvVaw0FyniFYFkdm1gHAKqOALCT">https://x.com/beyoncesspamacc/status/1843094040851726800</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">AI generated song remixed by Metro Boomin, who did not even realize it was AI generated: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy&amp;sa=D&amp;source=editors&amp;ust=1730413584290472&amp;usg=AOvVaw2UPQOHWG63OVfI3UJm0aS9">https://en.m.wikipedia.org/wiki/BBL_Drizzy</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c109 c97 c105 li-bullet-0"><span class="c18 c92 c108 c14">&gt;Unbeknownst to Metro at the time, the original track&#39;s vocals and instrumental were generated entirely by an artificial intelligence model.</span></li><li class="c109 c97 c105 li-bullet-0"><span class="c29 c14">Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Elon_Musk&amp;sa=D&amp;source=editors&amp;ust=1730413584290924&amp;usg=AOvVaw2TUQuGwR3JX1qn9MN8ChGf">Elon Musk</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Dr._Miami&amp;sa=D&amp;source=editors&amp;ust=1730413584291111&amp;usg=AOvVaw1weCstjHhF2ICQglAsBfjy">Dr. Miami</a></span><span class="c29 c14">&nbsp;reacted to the beat.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Complex_Cowen2024_DrMiamiLooping-19&amp;sa=D&amp;source=editors&amp;ust=1730413584291315&amp;usg=AOvVaw259PWV6WGmrv9iBOmlcXni">[19]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Dexerto_Horetski2024_WhatDoesBBLDrizzyMean-20&amp;sa=D&amp;source=editors&amp;ust=1730413584291498&amp;usg=AOvVaw3HJwveBFRdu7GFGBgJzQee">[20]</a></span><span class="c14 c29">&nbsp;Several corporations also responded, including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Educational_technology&amp;sa=D&amp;source=editors&amp;ust=1730413584291692&amp;usg=AOvVaw0PuTSTNkXs1vQnKuBmlWHm">educational technology</a></span><span class="c29 c14">&nbsp;company </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Duolingo&amp;sa=D&amp;source=editors&amp;ust=1730413584291867&amp;usg=AOvVaw3bKWvzEKWG-ERVjE5abDSw">Duolingo</a></span><span class="c29 c14">&nbsp;and meat producer </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Oscar_Mayer&amp;sa=D&amp;source=editors&amp;ust=1730413584292044&amp;usg=AOvVaw1PiLiWcVzc6XyP3ZCKfbfL">Oscar Mayer</a></span><span class="c29 c14">.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-XXL_Ech2024_OscarMeyerBBLGlizzy-21&amp;sa=D&amp;source=editors&amp;ust=1730413584292251&amp;usg=AOvVaw1DOSN_iVPl_Eh41M8sKOs4">[21]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Dexerto_Horetski2024_WhatDoesBBLDrizzyMean-20&amp;sa=D&amp;source=editors&amp;ust=1730413584292444&amp;usg=AOvVaw3kZMbp52hJ-Gi5odx1pkKC">[20]</a></span></li><li class="c109 c97 c105 li-bullet-0"><span class="c29 c14">In addition to users releasing freestyle raps over the instrumental, the track also evolved into a </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Viral_phenomenon&amp;sa=D&amp;source=editors&amp;ust=1730413584292725&amp;usg=AOvVaw1XEq9ONm3vzLpXZD2nk-Cm">viral phenomenon</a></span><span class="c29 c14">&nbsp;where users would create remixes of the song beyond the </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Hip_hop_music&amp;sa=D&amp;source=editors&amp;ust=1730413584292906&amp;usg=AOvVaw0mmfB-LNTTJEVvdqXsan9S">hip hop</a></span><span class="c29 c14">&nbsp;genre.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-BET_Grove2024_BBLDrizzyRemixTreatment-22&amp;sa=D&amp;source=editors&amp;ust=1730413584293111&amp;usg=AOvVaw3JqFfsyjVlTUe0kWg63Ygk">[22]</a></span><span class="c29 c14">&nbsp;Many recreated the song in other genres, including </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/House_music&amp;sa=D&amp;source=editors&amp;ust=1730413584293304&amp;usg=AOvVaw3hZ-5ehejxTA-mh7FmkXgs">house</a></span><span class="c29 c14">, </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Merengue_music&amp;sa=D&amp;source=editors&amp;ust=1730413584293488&amp;usg=AOvVaw34axK1oqw-U2DCm3Dx6Y0M">merengue</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Hindi_film_music&amp;sa=D&amp;source=editors&amp;ust=1730413584293660&amp;usg=AOvVaw1Wc9OQnfhB52JsFuWGQ9T9">Bollywood</a></span><span class="c29 c14">.</span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Billboard_Saponara2024_FanRemixesGoingViral-23&amp;sa=D&amp;source=editors&amp;ust=1730413584293869&amp;usg=AOvVaw29Txfh9cq1AnaARPQdu9vQ">[23]</a></span><span class="c38 c37 c14"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/BBL_Drizzy%23cite_note-Gizmodo_Zeff2024_SagaOfBBLDrizzy-18&amp;sa=D&amp;source=editors&amp;ust=1730413584294039&amp;usg=AOvVaw0tm2mtUUUpkW_553U7sdtL">[18]</a></span><span class="c29 c14">&nbsp;Users also created covers of the song on a variety of </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Musical_instruments&amp;sa=D&amp;source=editors&amp;ust=1730413584294222&amp;usg=AOvVaw1r1rvF89u4rbHt8CqBGy8f">musical instruments</a></span><span class="c29 c14">, including on </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Saxophone&amp;sa=D&amp;source=editors&amp;ust=1730413584294517&amp;usg=AOvVaw3Yoof-lZlYb2jW7sJB0JMu">saxophone</a></span><span class="c29 c14">, </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Guitar&amp;sa=D&amp;source=editors&amp;ust=1730413584294712&amp;usg=AOvVaw036TnQw-HYcpUFE89Pe7cK">guitar</a></span><span class="c29 c14">&nbsp;and </span><span class="c37 c65 c14 c68"><a class="c13" href="https://www.google.com/url?q=https://en.m.wikipedia.org/wiki/Harp&amp;sa=D&amp;source=editors&amp;ust=1730413584294928&amp;usg=AOvVaw28tVALPOdEsmX880HgJ--o">harp</a></span><span class="c29 c14">.</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c14">3.88/5 with 613 reviews on Rate Your Music (the best albums of ALL time get about a &#8536; on the site): </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://rateyourmusic.com/release/single/metro-boomin/bbl-drizzy-bpm-150_mp3/&amp;sa=D&amp;source=editors&amp;ust=1730413584295391&amp;usg=AOvVaw3f4TMHRwC5U692IUGzDe6X">https://rateyourmusic.com/release/single/metro-boomin/bbl-drizzy-bpm-150_mp3/</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c1 c14">86 on Album of the Year (qualifies for an orange star denoting high reviews from fans despite multiple anti AI negative review bombers)</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c1 c14">Charted as 22nd top single in New Zealand</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span>AI-generated song made it to 72nd highest ranking song in Germany: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DtUA7mBxCpb4&amp;sa=D&amp;source=editors&amp;ust=1730413584296028&amp;usg=AOvVaw0vGGrLqfg7IUrxh13QIyHR">https://www.youtube.com/watch?v=tUA7mBxCpb4</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c14">AI music creator has 229k total subscribers and 7.5 million views on all channels </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/@ObscurestVinyl/videos&amp;sa=D&amp;source=editors&amp;ust=1730413584296410&amp;usg=AOvVaw3zdpmtu3kVt0UwcpmENtkA">https://m.youtube.com/@ObscurestVinyl</a></span></li></ul><p class="c9"><span class="c5 c57 c37 c48 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c14">Topic channel: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/channel/UCSeqzYZQ8GEoF6eMdvJREyw&amp;sa=D&amp;source=editors&amp;ust=1730413584296811&amp;usg=AOvVaw2wksy6qDIN8bWBSFwG9qxN">https://m.youtube.com/channel/UCSeqzYZQ8GEoF6eMdvJREyw</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c1 c14">A few very popular songs: </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-2"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DwPlOYPGMRws%26pp%3DygUPb2JzY3VyZXN0IHZpbnls&amp;sa=D&amp;source=editors&amp;ust=1730413584297322&amp;usg=AOvVaw3JApNZ0r-VUczqh3rFXOWY">https://m.youtube.com/watch?v=wPlOYPGMRws&amp;pp=ygUPb2JzY3VyZXN0IHZpbnls</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-2"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D7zTei5RMhQ8%26pp%3DygUPb2JzY3VyZXN0IHZpbnls&amp;sa=D&amp;source=editors&amp;ust=1730413584297694&amp;usg=AOvVaw37ZCTzmryAotwJgKVSIsYm">https://m.youtube.com/watch?v=7zTei5RMhQ8&amp;pp=ygUPb2JzY3VyZXN0IHZpbnls</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-2"><li class="c7 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DsuXO7Yy_A-8%26pp%3DygUPb2JzY3VyZXN0IHZpbnls&amp;sa=D&amp;source=editors&amp;ust=1730413584298065&amp;usg=AOvVaw2gNEGr8D_5w2Xc0geRRV3t">https://m.youtube.com/watch?v=suXO7Yy_A-8&amp;pp=ygUPb2JzY3VyZXN0IHZpbnls</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c4 li-bullet-0"><span class="c1 c14">AI song covers with have hundreds of thousands or even millions of views each: </span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DGvnTSLS1dTU&amp;sa=D&amp;source=editors&amp;ust=1730413584298546&amp;usg=AOvVaw2tLke8jn8O2k9nW3_3fYMr">https://m.youtube.com/watch?v=GvnTSLS1dTU</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DVNWudHD3Kt8&amp;sa=D&amp;source=editors&amp;ust=1730413584298875&amp;usg=AOvVaw05SeDwl4RvMO-028x2p-i2">https://m.youtube.com/watch?v=VNWudHD3Kt8</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3DrH14QH9jSDQ&amp;sa=D&amp;source=editors&amp;ust=1730413584299261&amp;usg=AOvVaw2Q59bRlYgLdV-phqPwBByo">https://m.youtube.com/watch?v=rH14QH9jSDQ</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D-pAW1-bSsAc&amp;sa=D&amp;source=editors&amp;ust=1730413584299574&amp;usg=AOvVaw0EJlLHQpq-xR8m4fx701Jf">https://m.youtube.com/watch?v=-pAW1-bSsAc</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D_Y543NEiR5w&amp;sa=D&amp;source=editors&amp;ust=1730413584299910&amp;usg=AOvVaw33rSxjvr0g4bZ1NPPnNnGi">https://m.youtube.com/watch?v=_Y543NEiR5w</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D-ugjFAljBKI&amp;sa=D&amp;source=editors&amp;ust=1730413584300235&amp;usg=AOvVaw36ZK1pjb9EIL13cTl9ZirH">https://m.youtube.com/watch?v=-ugjFAljBKI</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3Df32P3ZAoJg0&amp;sa=D&amp;source=editors&amp;ust=1730413584300573&amp;usg=AOvVaw3cllSuuWGiCUNmI5ZKedX0">https://m.youtube.com/watch?v=f32P3ZAoJg0</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c10 li-bullet-0"><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://m.youtube.com/watch?v%3D89H4OyZRFcA&amp;sa=D&amp;source=editors&amp;ust=1730413584300934&amp;usg=AOvVaw2O6DR5EyB6mcNmBa7zsFsi">https://m.youtube.com/watch?v=89H4OyZRFcA</a></span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-0"><li class="c50 c78 li-bullet-0"><span>Even f</span><span class="c1">ollowers of an AI hate account like AI posts: </span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/FacebookAIslop/status/1812513303824073124&amp;sa=D&amp;source=editors&amp;ust=1730413584301480&amp;usg=AOvVaw3gw4hr9EJGtBl7u1st0dUG">https://x.com/FacebookAIslop/status/1812513303824073124</a></span></li></ul><p class="c50 c46"><span class="c1"></span></p><ul class="c0 lst-kix_7kr9zis60z3j-1"><li class="c17 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/FacebookAIslop/status/1832194473884844515&amp;sa=D&amp;source=editors&amp;ust=1730413584301846&amp;usg=AOvVaw2InRF5QQh52vsJDyKP3uV6">https://x.com/FacebookAIslop/status/1832194473884844515</a></span></li></ul><h2 class="c64" id="h.rkgnifgl4fua"><span class="c40 c37 c48 c75">15.4. Coding/Computer Science</span></h2><ul class="c0 lst-kix_wv60nibffqic-0 start"><li class="c4 li-bullet-0"><span>LLM skeptic Internet of Bugs says ChatGPT-O1 Changes Programming as a Profession. I really hated saying that: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://youtube.com/watch?v%3Dj0yKLumIbaM&amp;sa=D&amp;source=editors&amp;ust=1730413584302292&amp;usg=AOvVaw1Y_8-2uzgOKZ_QpmEpBAXW">https://youtube.com/watch?v=j0yKLumIbaM</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_wv60nibffqic-0"><li class="c4 li-bullet-0"><span>OpenAI o1 model released: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/&amp;sa=D&amp;source=editors&amp;ust=1730413584302683&amp;usg=AOvVaw2YDKjCoghJHOYhl4MLD597">https://openai.com/index/learning-to-reason-with-llms/</a></span></li></ul><ul class="c0 lst-kix_wv60nibffqic-1 start"><li class="c10 li-bullet-0"><span class="c1">o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories</span></li><li class="c10 li-bullet-0"><span class="c1">OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).</span></li><li class="c10 li-bullet-0"><span class="c1">On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.</span></li><li class="c10 li-bullet-0"><span class="c1">We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.</span></li></ul><ul class="c0 lst-kix_wv60nibffqic-2 start"><li class="c7 li-bullet-0"><span class="c1">With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 &ndash; above the gold medal threshold &ndash; even without any test-time selection strategy. &nbsp;</span></li><li class="c7 c46 li-bullet-0"><span class="c1"></span></li></ul><ul class="c0 lst-kix_wv60nibffqic-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 412.27px; height: 343.95px;"><img alt="" src="images/image326.png" style="width: 412.27px; height: 343.95px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 342.77px; height: 420.52px;"><img alt="" src="images/image9.png" style="width: 342.77px; height: 420.52px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating</span><span class="c5 c107"><a class="c13" href="https://www.google.com/url?q=https://openai.com/index/learning-to-reason-with-llms/%23citation-bottom-3&amp;sa=D&amp;source=editors&amp;ust=1730413584303929&amp;usg=AOvVaw3Y8KWosdqXthsqxqoDukyv">3</a></span><span class="c1">&nbsp;of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1&mdash;it achieved an Elo rating of 1807, performing better than 93% of competitors.</span></li><li class="c10 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://cdn.openai.com/o1-system-card.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584304206&amp;usg=AOvVaw182xC-KR3ndbZKNRnelqXq">https://cdn.openai.com/o1-system-card.pdf</a></span></li></ul><ul class="c0 lst-kix_wv60nibffqic-2 start"><li class="c7 li-bullet-0"><span class="c1">&nbsp;We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn&rsquo;t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the &ldquo;Unknown&rdquo; option (ambiguous questions). This is not necessarily an indicator of o1-preview&rsquo;s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 555.50px; height: 82.79px;"><img alt="" src="images/image1.png" style="width: 555.50px; height: 82.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.50px; height: 98.99px;"><img alt="" src="images/image288.png" style="width: 551.50px; height: 98.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 556.75px; height: 348.86px;"><img alt="" src="images/image344.png" style="width: 556.75px; height: 348.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.49px; height: 341.22px;"><img alt="" src="images/image116.png" style="width: 554.49px; height: 341.22px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 580.86px; height: 491.50px;"><img alt="" src="images/image95.png" style="width: 580.86px; height: 491.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 558.50px; height: 207.65px;"><img alt="" src="images/image206.png" style="width: 558.50px; height: 207.65px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 543.51px; height: 408.50px;"><img alt="" src="images/image286.png" style="width: 543.51px; height: 408.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.82px; height: 313.86px;"><img alt="" src="images/image203.png" style="width: 554.82px; height: 313.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wv60nibffqic-1"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 498.67px;"><img alt="" src="images/image68.png" style="width: 624.00px; height: 498.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span class="c1">Note: This is the weakest model compared to o1-preview and the full o1 model</span></li><li class="c10 li-bullet-0"><span>OpenAI&rsquo;s o1 model can get perfect scores on their research engineer interview coding questions:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 610.00px; height: 377.33px;"><img alt="" src="images/image137.png" style="width: 610.00px; height: 377.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 c46 li-bullet-0"><span class="c92 c102 c42 c37"></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 550.67px;"><img alt="" src="images/image88.png" style="width: 624.00px; height: 550.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 404.00px;"><img alt="" src="images/image163.png" style="width: 624.00px; height: 404.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 605.33px;"><img alt="" src="images/image183.png" style="width: 624.00px; height: 605.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 657.33px;"><img alt="" src="images/image224.png" style="width: 624.00px; height: 657.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 730.67px;"><img alt="" src="images/image66.png" style="width: 624.00px; height: 730.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 494.67px;"><img alt="" src="images/image134.png" style="width: 624.00px; height: 494.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 499.50px; height: 935.31px;"><img alt="" src="images/image78.png" style="width: 499.50px; height: 935.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 490.32px; height: 933.50px;"><img alt="" src="images/image73.png" style="width: 490.32px; height: 933.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 394.67px;"><img alt="" src="images/image167.png" style="width: 624.00px; height: 394.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_wv60nibffqic-0"><li class="c45 li-bullet-0"><span class="c15">ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: </span><span class="c5 c15"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2311.00176&amp;sa=D&amp;source=editors&amp;ust=1730413584307192&amp;usg=AOvVaw0okAPwoIsbxtpUyQXvxXPG">https://arxiv.org/pdf/2311.00176</a></span><span class="c33 c15">&nbsp;</span></li><li class="c4 li-bullet-0"><span class="c14">[Alphacode 2 beat 85% of competitive programming participants in Codeforce competitions](</span><span class="c35 c14">https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/</span><span class="c1 c14">)</span></li></ul><ul class="c0 lst-kix_wv60nibffqic-1 start"><li class="c10 li-bullet-0"><span class="c6 c40">Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it&rsquo;s STILL much better than those guys. </span></li><li class="c10 li-bullet-0"><span class="c6">In the article, it says &ldquo;AlphaCode 2 can understand programming challenges involving &ldquo;complex&rdquo; math and theoretical computer science. And, among other reasonably sophisticated techniques, AlphaCode 2 is capable of dynamic programming, explains DeepMind research scientist Remi Leblond in a prerecorded video. Dynamic programming entails simplifying a complex problem by breaking it down into easier sub-problems over and over; Leblond says that AlphaCode 2 knows not only when to properly implement this strategy but where to use it. That&rsquo;s noteworthy, considering programming problems requiring dynamic programming were a major trip-up for the original AlphaCode. &ldquo;[AlphaCode 2] needs to show some level of understanding, some level of reasoning and designing of code solutions before it can get to the actual implementation to solve [a] coding problem,&rdquo; Leblond said. &ldquo;And it does all that on problems it&rsquo;s never seen before.&rdquo;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_wv60nibffqic-0"><li class="c4 li-bullet-0"><span class="c14">Microsoft AutoDev:</span><span class="c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.08299&amp;sa=D&amp;source=editors&amp;ust=1730413584308186&amp;usg=AOvVaw2DFkkLT69RLd_3FChlIg1Z">&nbsp;</a></span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/pdf/2403.08299&amp;sa=D&amp;source=editors&amp;ust=1730413584308366&amp;usg=AOvVaw3SEP1XygNFQUxa83QKTJN2">https://arxiv.org/pdf/2403.08299</a></span></li></ul><p class="c9 c93"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_npq7lfz9ly6z-0"><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;We tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_dav1jecmp52o-0 start"><li class="c4 li-bullet-0"><span class="c37 c14 c76 c98 c75">NYT article on ChatGPT:</span><span class="c37 c14 c76 c98 c75"><a class="c13" href="https://www.google.com/url?q=https://archive.is/hy3Ae&amp;sa=D&amp;source=editors&amp;ust=1730413584308940&amp;usg=AOvVaw25Z262zD1s9ZgbgJiU2ggj">&nbsp;</a></span><span class="c5 c37 c14 c76 c75"><a class="c13" href="https://www.google.com/url?q=https://archive.is/hy3Ae&amp;sa=D&amp;source=editors&amp;ust=1730413584309099&amp;usg=AOvVaw1BeJ5idBu2AwtMZ7dNSmzp">https://archive.is/hy3Ae</a></span></li></ul><p class="c9 c93"><span class="c40 c37 c35 c48 c14"></span></p><ul class="c0 lst-kix_qx6x5q8dhn22-0"><li class="c4 li-bullet-0"><span class="c92 c37 c14 c76 c98 c75">&ldquo;In a trial run by GitHub&rsquo;s researchers, developers given an entry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than those who did the assignment manually.&rdquo;</span></li></ul><p class="c9"><span class="c92 c37 c14 c76 c98 c75"></span></p><p class="c9"><span class="c92 c37 c14 c76 c98 c75"></span></p><ul class="c0 lst-kix_afhhqgs3rfh2-0 start"><li class="c4 li-bullet-0"><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3613904.3642596&amp;sa=D&amp;source=editors&amp;ust=1730413584309687&amp;usg=AOvVaw1EFEDC0uvXP4pFeAgWGFn7">Study that ChatGPT supposedly fails 52% of coding tasks</a></span><span>: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://dl.acm.org/doi/pdf/10.1145/3613904.3642596&amp;sa=D&amp;source=editors&amp;ust=1730413584309895&amp;usg=AOvVaw1LvoI7b_uiDBvpNdEanv7i">https://dl.acm.org/doi/pdf/10.1145/3613904.3642596</a></span><span class="c1">&nbsp;</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_afhhqgs3rfh2-1 start"><li class="c10 li-bullet-0"><span class="c14">&ldquo;this work has used the </span><span class="c34 c14">free version of ChatGPT (GPT-3.5)</span><span class="c1 c14">&nbsp;for acquiring the ChatGPT responses for the manual analysis.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_afhhqgs3rfh2-1"><li class="c10 li-bullet-0"><span class="c14">&ldquo;Thus, we chose to </span><span class="c34 c14">only consider the initial answer </span><span class="c1 c14">generated by ChatGPT.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_afhhqgs3rfh2-1"><li class="c10 li-bullet-0"><span class="c1 c14">&ldquo;To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected [StackOverflow] questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.&rdquo;</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_afhhqgs3rfh2-2 start"><li class="c7 li-bullet-0"><span class="c14">This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to</span><span class="c15">&nbsp;~77% for GPT 4</span><span class="c1">&nbsp;(equal to (517*0.48+517*6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_afhhqgs3rfh2-3 start"><li class="c21 c26 li-bullet-0"><span>Note: This was all done in</span><span class="c33 c15">&nbsp;ONE SHOT with no repeat attempts or follow up.</span></li></ul><p class="c9"><span class="c33 c15"></span></p><ul class="c0 lst-kix_3mbe6pf0vyok-0"><li class="c22 c72 c14 li-bullet-0"><span class="c14">Also, the study was released </span><span class="c15">before GPT-4o </span><span>and </span><span class="c34">may not have used GPT-4-Turbo</span><span>, both of which are significantly higher quality in coding capacity than GPT 4 according to the </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://chat.lmsys.org/?leaderboard&amp;sa=D&amp;source=editors&amp;ust=1730413584311285&amp;usg=AOvVaw1_a6Oy196pqWWRJb2432TN">LMSYS arena</a></span></li></ul><p class="c22 c44 c14"><span class="c1"></span></p><ul class="c0 lst-kix_3mbe6pf0vyok-1"><li class="c22 c104 c86 c14 li-bullet-0"><span>On top of that, both of those models are inferior to Claude 3.5 Sonnet: &quot;In an </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf&amp;sa=D&amp;source=editors&amp;ust=1730413584311722&amp;usg=AOvVaw1np6PwPO6nB2o_dJT0rkLS">internal agentic coding evaluation</a></span><span>, </span><span class="c15">Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%.</span><span class="c1">&quot; Claude 3.5 Opus (which will be even better than Sonnet) is set to be released later this year.</span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-0"><li class="c10 li-bullet-0"><span class="c14">Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what&rsquo;s available now </span><span class="c20 c14"><a class="c13" href="https://www.google.com/url?q=https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/&amp;sa=D&amp;source=editors&amp;ust=1730413584312149&amp;usg=AOvVaw09N6Z3gAP1yCMAgDV53e6Z">https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/</a></span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-1 start"><li class="c22 c7 li-bullet-0"><span class="c60 c14">The resulting model mastered the intricacies of a complex game. &quot;Cicero can </span><span class="c60">deduce, for example, that later in the game it will need the support of one particular player,&quot; says Meta, &quot;and then </span><span class="c15 c60">craft a strategy to win that person&rsquo;s favor&mdash;and even recognize the risks and opportunities that that player sees from their particular point of view</span><span class="c40 c37 c60 c48">.&quot;</span></li><li class="c22 c7 li-bullet-0"><span class="c60">Meta&#39;s Cicero research </span><span class="c60"><a class="c13" href="https://www.google.com/url?q=https://www.science.org/doi/10.1126/science.ade9097&amp;sa=D&amp;source=editors&amp;ust=1730413584312623&amp;usg=AOvVaw1IiDL-N_O37iecxSBD3V9d">appeared</a></span><span class="c60">&nbsp;in the journal Science under the title, &quot;Human-level play in the game of Diplomacy by combining language models with strategic reasoning.</span><span class="c82 c37 c60 c48 c14">&quot;</span></li><li class="c22 c7 li-bullet-0"><span class="c92 c37 c35 c103 c14 c179">CICERO uses relationships with other players to keep its ally, Adam, in check.</span></li><li class="c22 c7 li-bullet-0"><span class="c37 c35 c173 c103 c14">When playing 40 games against human players, CICERO achieved more than</span><span class="c15 c35 c173 c103">&nbsp;double the average score of the human players and ranked in the top 10% of participants who played more than one game.</span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-0"><li class="c59 li-bullet-0"><span class="c14">First Results from Med-Gemini (the successor to Med-Palm, a medically fine tuned LLM). &quot;More accurate multimodal conversations about medical images&#129659;, surgical videos&#128253;&#65039;, genomics&#129516;, ultra-long health records&#128218;, ECGs&#129728; &amp; more with state-of-art performance across multiple benchmarks&quot;](</span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://twitter.com/alan_karthi/status/1785117444383588823&amp;sa=D&amp;source=editors&amp;ust=1730413584313240&amp;usg=AOvVaw0DwjEXSh7BZIdIjqIol3lG">https://twitter.com/alan_karthi/status/1785117444383588823</a></span><span class="c1 c14">&nbsp;)</span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-1 start"><li class="c73 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 590.00px; height: 265.71px;"><img alt="" src="images/image413.png" style="width: 590.00px; height: 265.71px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c73 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 571.12px; height: 543.50px;"><img alt="" src="images/image320.png" style="width: 571.12px; height: 543.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-0"><li class="c10 li-bullet-0"><span>Stanford researchers: &ldquo;Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers.&quot; </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/ChengleiSi/status/1833166031134806330&amp;sa=D&amp;source=editors&amp;ust=1730413584313823&amp;usg=AOvVaw0H0Igj1hG47MV-joIXtZt_">https://x.com/ChengleiSi/status/1833166031134806330</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3mbe6pf0vyok-1"><li class="c7 li-bullet-0"><span class="c1">&gt;Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_3mbe6pf0vyok-1"><li class="c7 li-bullet-0"><span>&gt;We also used an LLM to </span><span class="c34">standardize the writing styles of human and LLM ideas to avoid potential confounders</span><span class="c1">, while preserving the original content.</span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image152.jpg" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c7 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 481.33px;"><img alt="" src="images/image91.png" style="width: 624.00px; height: 481.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-0"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 486.67px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 486.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c163 c97 c105 li-bullet-0"><span>How AlphaChip transformed computer chip design: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/&amp;sa=D&amp;source=editors&amp;ust=1730413584314870&amp;usg=AOvVaw2px3RF5q0ACrXgZAP-Sou8">https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</a></span></li></ul><ul class="c0 lst-kix_3mbe6pf0vyok-1 start"><li class="c22 c86 c248 li-bullet-0"><span class="c1">Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world</span></li><li class="c22 c95 c192 li-bullet-0"><span class="c35">The method has been used to design superhuman chip layouts in the last three generations of Google&rsquo;s custom AI accelerator, the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/tpu?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1730413584315312&amp;usg=AOvVaw15yEQupTllFoKet-WoXApI">Tensor Processing Unit</a></span><span class="c40 c37 c35 c48">&nbsp;(TPU).</span></li><li class="c22 c95 c192 li-bullet-0"><span class="c40 c37 c35 c48">AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.</span></li><li class="c22 c95 c192 li-bullet-0"><span class="c35">AlphaChip has generated superhuman chip layouts used in every generation of Google&rsquo;s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google&rsquo;s </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/&amp;sa=D&amp;source=editors&amp;ust=1730413584315873&amp;usg=AOvVaw35KAnkkmULPjrCZIrlLapw">Transformer</a></span><span class="c40 c37 c35 c48">&nbsp;architecture.</span></li><li class="c22 c95 c192 li-bullet-0"><span class="c35">Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu&amp;sa=D&amp;source=editors&amp;ust=1730413584316213&amp;usg=AOvVaw2YSyj4NuPfgae06HVI57bX">Google Axion Processors</a></span><span class="c40 c37 c35 c48">, our first Arm-based general-purpose data center CPUs.</span></li><li class="c22 c95 c192 li-bullet-0"><span class="c35">External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips &mdash; like the </span><span class="c5 c35"><a class="c13" href="https://www.google.com/url?q=https://www.mediatek.com/products/smartphones/dimensity-5g&amp;sa=D&amp;source=editors&amp;ust=1730413584316547&amp;usg=AOvVaw38ceyJKtWDLRd6N6fdKaqp">Dimensity Flagship 5G</a></span><span class="c35">&nbsp;used in Samsung mobile phones &mdash; while improving power, performance and chip area.</span></li><li class="c22 c163 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 536.00px;"><img alt="" src="images/image76.png" style="width: 624.00px; height: 536.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c22 c163 c86 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 586.67px;"><img alt="" src="images/image122.png" style="width: 624.00px; height: 586.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><h2 class="c64" id="h.taev84afmwiv"><span>15.</span><span class="c40 c37 c48 c75">5. Math</span></h2><ul class="c0 lst-kix_yxl9yzqp3bqd-0 start"><li class="c4 li-bullet-0"><span>Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.08304&amp;sa=D&amp;source=editors&amp;ust=1730413584317260&amp;usg=AOvVaw3gfizglQ0MFqLj1BXUkfqL">https://arxiv.org/abs/2410.08304</a></span></li></ul><ul class="c0 lst-kix_yxl9yzqp3bqd-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 464.00px;"><img alt="" src="images/image416.png" style="width: 624.00px; height: 464.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 600.00px;"><img alt="" src="images/image354.png" style="width: 624.00px; height: 600.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 346.67px;"><img alt="" src="images/image333.png" style="width: 624.00px; height: 346.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yxl9yzqp3bqd-0"><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413584317818&amp;usg=AOvVaw1AYjrkMfLhWPuWYpqmeZx8">https://arxiv.org/abs/2410.0620</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yxl9yzqp3bqd-1"><li class="c10 li-bullet-0"><span class="c1">LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_yxl9yzqp3bqd-0"><li class="c4 li-bullet-0"><span class="c14">Abacus Embeddings, a simple tweak to positional embeddings that</span><span class="c15">&nbsp;enables LLMs to do addition, multiplication, sorting, and more</span><span class="c14">. Our Abacus Embeddings </span><span class="c15">trained only on 20-digit addition generalise near perfectly to 100+ digits:</span><span>&nbsp;</span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/SeanMcleish/status/1795481814553018542&amp;sa=D&amp;source=editors&amp;ust=1730413584318368&amp;usg=AOvVaw3OjYX4p-Qha40rgcZEIeAr">https://x.com/SeanMcleish/status/1795481814553018542</a></span><span class="c1">&nbsp;</span></li></ul><ul class="c0 lst-kix_yxl9yzqp3bqd-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 478.50px; height: 245.38px;"><img alt="" src="images/image455.png" style="width: 478.50px; height: 245.38px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 316.00px;"><img alt="" src="images/image343.png" style="width: 624.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yxl9yzqp3bqd-2 start"><li class="c7 li-bullet-0"><span class="c14">OOD means &ldquo;out of distribution&rdquo; so it was </span><span class="c33 c15">NOT in the training data</span></li></ul><p class="c9"><span class="c1 c14"></span></p><ul class="c0 lst-kix_yxl9yzqp3bqd-0"><li class="c4 li-bullet-0"><span class="c18">First AI to solve International Mathematical Olympiad problems at a silver medalist level:</span><span class="c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/GoogleDeepMind/status/1816498082860667086&amp;sa=D&amp;source=editors&amp;ust=1730413584319017&amp;usg=AOvVaw3dyq5dnEwp8kIaxddADGjP">&nbsp;</a></span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/GoogleDeepMind/status/1816498082860667086&amp;sa=D&amp;source=editors&amp;ust=1730413584319200&amp;usg=AOvVaw1KoyLgw3f9UkSqZDL4k6wV">https://x.com/GoogleDeepMind/status/1816498082860667086</a></span></li></ul><p class="c9"><span class="c1"></span></p><ul class="c0 lst-kix_j0o0ck7ntjzh-0 start"><li class="c10 li-bullet-0"><span class="c40 c18">&gt;It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. </span></li><li class="c10 li-bullet-0"><span class="c40 c18">Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.</span></li><li class="c10 li-bullet-0"><span class="c40 c18">It solved this year&rsquo;s IMO Problem 4 within 19 seconds</span></li><li class="c10 li-bullet-0"><span class="c1">The fact that the program can come up with a non-obvious construction like this is very impressive, and well beyond what I thought was state of the art. -PROF SIR TIMOTHY GOWERS, IMO GOLD MEDALIST AND FIELDS MEDAL WINNER</span></li><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 624.00px;"><img alt="" src="images/image609.png" style="width: 624.00px; height: 624.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c10 li-bullet-0"><span>Math professor on DeepMind&#39;s breakthrough: &quot;When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert&quot;</span><span><a class="c13" href="https://www.google.com/url?q=https://x.com/PoShenLoh/status/1816500461484081519&amp;sa=D&amp;source=editors&amp;ust=1730413584320206&amp;usg=AOvVaw3lEC2zWpZfb3D9Tt6ALmR6">&nbsp;</a></span><span class="c5 c18"><a class="c13" href="https://www.google.com/url?q=https://x.com/PoShenLoh/status/1816500461484081519&amp;sa=D&amp;source=editors&amp;ust=1730413584320400&amp;usg=AOvVaw2yK968JUemlHebYJW8EaqX">https://x.com/PoShenLoh/status/1816500461484081519</a></span></li></ul><ul class="c0 lst-kix_zep9qz8je63n-0 start"><li class="c4 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 578.67px; height: 360.00px;"><img alt="" src="images/image151.png" style="width: 578.67px; height: 360.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c4 li-bullet-0"><span>Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans:</span><span><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/&amp;sa=D&amp;source=editors&amp;ust=1730413584320851&amp;usg=AOvVaw3TkV3W6UoiQjlt8w13Hm5j">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/&amp;sa=D&amp;source=editors&amp;ust=1730413584321015&amp;usg=AOvVaw0L__7OpF6-sf1nt-LRsF0o">https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/</a></span></li><li class="c4 li-bullet-0"><span>Google DeepMind used a large language model to solve an unsolved math problem:</span><span><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/&amp;sa=D&amp;source=editors&amp;ust=1730413584321265&amp;usg=AOvVaw0ivHHGO2TQJPQSgg5hxF3c">&nbsp;</a></span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/&amp;sa=D&amp;source=editors&amp;ust=1730413584321437&amp;usg=AOvVaw0FIc7-aaU_gJIsAALQkJqx">https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/</a></span></li><li class="c45 li-bullet-0"><span class="c14">NuminaMath 72b TIR model: </span><span class="c5 c14"><a class="c13" href="https://www.google.com/url?q=https://x.com/JiaLi52524397/status/1814957190320631929/&amp;sa=D&amp;source=editors&amp;ust=1730413584321659&amp;usg=AOvVaw1p-o1ZizmlVcudkilGlNiY">https://x.com/JiaLi52524397/status/1814957190320631929/</a></span></li></ul><ul class="c0 lst-kix_tsc2yqmm539t-1 start"><li class="c59 li-bullet-0"><span class="c1 c14">Trained on new competition math dataset ever released, with 860K problem solution pairs that was created with GPT 4</span></li></ul><ul class="c0 lst-kix_tsc2yqmm539t-2 start"><li class="c73 c86 li-bullet-0"><span class="c1 c14">We selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and producing results until the solution was complete. We filtered out solutions where the final answer did not match the reference and repeated this process three times to ensure accuracy and consistency. This iterative approach allowed us to generate high-quality TORA data efficiently.</span></li></ul><ul class="c0 lst-kix_tsc2yqmm539t-1"><li class="c59 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 514.67px;"><img alt="" src="images/image35.png" style="width: 624.00px; height: 514.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c59 li-bullet-0"><span class="c1 c14">For AMC 12 2023, the average score is 43%, </span></li><li class="c59 li-bullet-0"><span class="c39 c37 c14">AIME Floor: 70% (top ~6%)</span></li><li class="c97 c14 c105 c177 li-bullet-0"><span class="c39 c37 c14">Distinction: 75%</span></li><li class="c177 c97 c14 c105 li-bullet-0"><span class="c39 c37 c14">Distinguished Honor Roll: 90%</span></li></ul><p class="c177 c14 c46"><span class="c39 c37 c14"></span></p><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>Six months ago, we launched Numina to lead open research in AI4Math. The Numina Math 7B model won the 1st progress prize of the AI Math Olympiad: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/JiaLi52524397/status/1808886880164880631&amp;sa=D&amp;source=editors&amp;ust=1730413584322429&amp;usg=AOvVaw3YMLA0fSA6sO1bQus2yA9-">https://x.com/JiaLi52524397/status/1808886880164880631</a></span></li><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 512.00px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 512.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://mathvista.github.io/&amp;sa=D&amp;source=editors&amp;ust=1730413584322793&amp;usg=AOvVaw24-Q5DvEEkrswzI2nsucr7">https://mathvista.github.io/</a></span></li><li class="c22 c72 c14 li-bullet-0"><span class="c35 c34 c14 c127">test</span><span class="c92 c37 c35 c48 c14 c127">: 5,141 examples for standard evaluation. Notably, the answer labels for test will NOT be publicly released</span></li><li class="c22 c72 c14 li-bullet-0"><span class="c92 c37 c35 c48 c14 c127">Human performance is 60.8%. Average human performance is from AMT annotators who have high school diplomas or above.</span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c22 c32 c14 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 712.00px;"><img alt="" src="images/image136.png" style="width: 624.00px; height: 712.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c22 c72 c14 li-bullet-0"><span class="c5 c35 c14"><a class="c13" href="https://www.google.com/url?q=https://mathstodon.xyz/@tao/113132503432772494&amp;sa=D&amp;source=editors&amp;ust=1730413584323319&amp;usg=AOvVaw2YLFGWKG0ydmvQ-6ZL8mTJ">https://mathstodon.xyz/@tao/113132503432772494</a></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span class="c1">Scores of o1-preview and GPT-4o on &quot;official national exam in abstract mathematics used in Dutch high schools.&quot; Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: &quot;System 2 thinking in OpenAI&rsquo;s o1-preview model: Near-perfect performance on a mathematics exam&quot; &nbsp;</span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c10 li-bullet-0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 406.67px;"><img alt="" src="images/image132.png" style="width: 624.00px; height: 406.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-0"><li class="c4 li-bullet-0"><span>A thread of a researcher sharing his team&#39;s findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://x.com/robertghrist/status/1841462507543949581?t%3D5zV3VpQI0mbrSU9_QRtfkQ%26s%3D19&amp;sa=D&amp;source=editors&amp;ust=1730413584324329&amp;usg=AOvVaw3Tuz86NmOqeBYDTMdID5tk">https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&amp;s=19</a></span></li><li class="c4 li-bullet-0"><span>LeanAgent: Lifelong Learning for Formal Theorem Proving: </span><span class="c5"><a class="c13" href="https://www.google.com/url?q=https://arxiv.org/abs/2410.06209&amp;sa=D&amp;source=editors&amp;ust=1730413584324569&amp;usg=AOvVaw3lOZwuHr0dM2s5l8f16RO7">https://arxiv.org/abs/2410.06209</a></span></li></ul><ul class="c0 lst-kix_yk9rpx5uikpv-1 start"><li class="c10 li-bullet-0"><span>LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.</span></li></ul><p class="c177 c14 c46"><span class="c39 c37 c14"></span></p><h1 class="c123" id="h.g2b405me7lwq"><span>16. </span><span>Change Log for Past Week (In PST)</span></h1><h2 class="c64" id="h.244s1zoiwd7c"><span class="c40 c37 c48 c75">10/22/24</span></h2><ul class="c0 lst-kix_d62vaysn6wq1-0 start"><li class="c4 li-bullet-0"><span class="c1">Added Genmo AI video generator in section 3.4</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.jfh0dhj8lvxa"><span class="c40 c37 c48 c75">10/23/24</span></h2><ul class="c0 lst-kix_vnj3yd9aagbp-0 start"><li class="c4 li-bullet-0"><span class="c1">Added Claude autonomously finding more than a dozen 0-day exploits in popular GitHub projects in section 4</span></li><li class="c4 li-bullet-0"><span class="c1">Added Voice Design by ElevenLabs in section 4.1</span></li></ul><p class="c9"><span class="c1"></span></p><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.ad0b8kljqzjw"><span class="c40 c37 c48 c75">10/24/24</span></h2><ul class="c0 lst-kix_g3e6y0f95n7u-0 start"><li class="c4 li-bullet-0"><span class="c1">Added QLoRA from Meta model to section 13.3</span></li><li class="c4 li-bullet-0"><span class="c1">Added US government response to AI in section 4</span></li><li class="c4 li-bullet-0"><span class="c1">Added AI agents entering workplace to sections 4.2 and 5</span></li><li class="c4 li-bullet-0"><span class="c1">Added article on Orion release date to section 3</span></li><li class="c4 li-bullet-0"><span class="c1">Added Disney set to announce a major AI initiative that will transform its creative output</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.6hi28nelsu1u"><span class="c40 c37 c48 c75">10/27/24</span></h2><ul class="c0 lst-kix_eh7lncq6en9i-0 start"><li class="c4 li-bullet-0"><span class="c1">Added Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions</span></li></ul><p class="c9"><span class="c1"></span></p><h2 class="c64" id="h.bolste5z3mw8"><span class="c40 c37 c48 c75">10/29/24</span></h2><ul class="c0 lst-kix_j8606buix1qi-0 start"><li class="c4 li-bullet-0"><span class="c1">Added Google CEO claim that 25% of code written at Google is from AI</span></li><li class="c4 li-bullet-0"><span class="c1">Added AI discovering physics variables independently</span></li></ul><div><p class="c117 c46"><span class="c1"></span></p></div></body></html>